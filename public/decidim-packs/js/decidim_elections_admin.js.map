{"version":3,"file":"js/decidim_elections_admin.js","mappings":";;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACvBA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AARA;AAAA;AAAA;AASA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AATA;AAAA;AAAA;AAWA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAQA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAQA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAOA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AARA;AAAA;AAAA;AAAA;AASA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AANA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AATA;AAAA;AAAA;AAAA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AARA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AARA;AAAA;AAAA;AAAA;AAAA;AASA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AANA;AAAA;AAQA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAPA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AALA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AARA;AAAA;AAAA;AAAA;AAAA;AASA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AANA;AAAA;AAQA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClJA;AACA;AACA;AACA;AACA;;AAOA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;AC5CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AAMA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAPA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AAFA;AAAA;AAIA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAFA;AAIA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAGA;AAGA;AAMA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;AC9FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AACA;;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAAA;AAMA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAAA;AAOA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAOA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAFA;AACA;AAEA;AACA;AACA;AACA;AACA;AAMA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AApBA;AAAA;AAAA;AAAA;AAqBA;AAAA;AAAA;AAAA;AAAA;AACA;AASA;AAAA;AAEA;AAAA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AAGA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;AC/GA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAFA;AACA;AAEA;AACA;AACA;AACA;AACA;AASA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAhBA;AAAA;AAAA;AAAA;AAiBA;AAAA;AAAA;AAAA;AAAA;AACA;AAQA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;AChGA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAQA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAMA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAMA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;ACpDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AACA;;AAEA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAIA;AACA;AAGA;AAGA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAGA;AAAA;AAAA;AAKA;AAJA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAKA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AAIA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1PA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AAHA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAVA;AAAA;AAAA;AAAA;AAAA;AAWA;AAAA;AAAA;AAAA;AACA;AAGA;AAGA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAHA;AAKA;AAEA;AACA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;AC3FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AAJA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAAA;AAMA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAPA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAJA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AACA;AAEA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAFA;AAAA;AAIA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAPA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAHA;AAKA;AAEA;AAAA;AAEA;AAAA;AAAA;AACA;AAAA;AAEA;AAMA;AACA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAAA;AAAA;AAMA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAQA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;AChSA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACVA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AAJA;AACA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAlBA;AAAA;AAAA;AAAA;AAmBA;AAAA;AAAA;AAAA;AAAA;AACA;AAYA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;ACxGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AAJA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AADA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAPA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AAHA;AAAA;AAAA;AAAA;AAIA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAAA;AAAA;AAQA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;AClHA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AACA;AACA;AAMA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAIA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAFA;AAAA;AAIA;AACA;AACA;AAKA;AACA;AAAA;AAdA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAgBA;AAtBA;AAAA;AAAA;AAwBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAPA;AAAA;AASA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAnBA;AAAA;AAAA;AAqBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AArCA;AAAA;AAAA;AAAA;AAAA;AAuCA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;AC/HA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACbA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;ACZA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;;AAEA;AACA;AAIA;AACA;AACA;AAKA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AAEA;AACA;AAIA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AAMA;AAEA;AACA;;;;;;;;;;;ACrJA;;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACpCA;;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACnBA;AACA;;;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAIA;AAEA;AAEA;AACA;AAEA;AAGA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAEA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAQA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AAIA;AAEA;AAEA;AACA;AAEA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AAKA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AAKA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAIA;AAEA;AACA;AACA;AAEA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAKA;AAKA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AAIA;AAKA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAKA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;;AAEA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAKA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;ACzjEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACNA;AACA;AACA;;AAGA;AACA;;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;ACtBA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;;;AAGA;AAEA;AACA;;AAGA;AACA;;AAGA;AACA;AACA;AACA;;;AAGA;;;AAGA;;;AAGA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;;AAGA;;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;AACA;;AAGA;;;AAGA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;;AAGA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrHA;AACA;AAEA;AAEA;AACA;;AAGA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;;;ACvBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BA;;AAEA;AAEA;AACA;;AAGA;AACA;AACA;;ACpCA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;AAGA;AACA;;AAGA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAIA;AACA;AACA;;AAGA;;AAGA;AACA;AACA;;AAGA;AACA;AAEA;AACA;;;AAIA;AACA;AACA;;AAEA;AACA;AAEA;;AAGA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;;;AAIA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;;AAIA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAEA;AACA;;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AC/NA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;;;AAIA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AAEA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;;;AAIA;AACA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;ACrHA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CA;AACA;;;AChDA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiEA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;AC/EA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA;;AAEA;AACA;AACA;AACA;;AC7BA;AACA;;AAGA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2GA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8LA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AC5YA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AAEA;AACA;AACA;AACA;AACA;;;AAIA;AACA;;;AAIA;;;AC9BA;AACA;AACA;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACpFA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACNA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACNA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC1BA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;AC3BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAWA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrKA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACvBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACvBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACZA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AAIA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACXA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC9CA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAKA;;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;AC3DA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7FA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AClBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AClDA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACvEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACZA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;ACfA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;AClCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACvCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC3BA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC3FA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC1CA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACvDA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACVA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACfA;AACA;AAEA;;;;;;;;;;ACHA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACdA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACZA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;ACjBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7CA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACZA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;ACtCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChBA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC5EA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;ACjBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AAEA;;;;;;;;;;;ACxBA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC7BA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;ACdA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC3BA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACZA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AClCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;AClBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;ACzFA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;;AAEA;AACA;AAEA;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;ACnBA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7BA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACdA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACfA;AACA;AAEA;;;;;;;;;;ACHA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC5BA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC5BA;;AAEA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACbA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC1BA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;AClBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC7CA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzDA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC5CA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpBA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;AC7BA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AAEA;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzBA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AChCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;AChCA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrCA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;AClCA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC5BA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;AC7DA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC1BA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;AC5BA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC1BA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACpCA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACnBA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;ACxEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxDA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;;;;;;;;;;AChDA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACjBA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACzCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;ACnCA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACrCA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;;;;;;;;;;AC/DA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC/BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC3BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;;;;;;AClJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAWA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AAKA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAyBA;AAKA;AAKA;AAKA;AAKA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AAKA;AAKA;AAKA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AClkCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAIA;AACA;AACA;AAGA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACz5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACzLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACr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t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eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACjJA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAIA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AAEA;AAIA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAMA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAMA;;AAOA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AC/uCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAKA;AACA;AAGA;AACA;AAEA;AACA;AAGA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAKA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;;;;;;;;;;AC9/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;ACl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nRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAEA;AAEA;AACA;AAGA;AACA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAGA;AAEA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAGA;AAEA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AAIA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACjjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAGA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAIA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AAKA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;AC3uCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACzZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;;;;;;;;;ACrGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAMA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;ACxSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;AClaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;AChPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAAA;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAJA;AAOA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAEA;AAEA;;;;;;;;;;AC9LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAmBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAOA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACz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sBA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAIA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AASA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAKA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AASA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;;;;;;;;;;AC55DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;AC9TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAkBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAIA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACtUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AA2CA;AACA;AACA;AAUA;AAUA;AAUA;;AAWA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;AChjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAn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lFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAGA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AAEA;AACA;AAMA;AAEA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAOA;AAEA;AACA;AAWA;AAEA;AACA;AAIA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAIA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAGA;AACA;AACA;AAGA;AACA;AAKA;AACA;AACA;AACA;AAGA;AACA;AAKA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAIA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAqBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;ACzqGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAUA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAUA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAKA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AASA;AAEA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAKA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACtfA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACrXA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC/RA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAKA;AACA;AAUA;AACA;AACA;AAKA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACnQA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAMA;AACA;AACA;AACA;AACA;AAKA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AChdA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACpQA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;ACrJA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC5MA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAgBA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AC7GA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAKA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACpQA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAGA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACvMA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACpWA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAIA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACjQA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAGA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AAGA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;AClTA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;;;;;;;;;;;AC5FA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;AC5GA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;ACvPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzcA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;;;;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACnXA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACpqBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;ACx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rBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAKA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACxVA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;;;;;;;;;;;AChYA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACv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rBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAKA;AAWA;AAaA;AACA;AACA;AAGA;AACA;AACA;AAGA;AACA;AACA;AAGA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;AC9NA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAQA;AAMA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAMA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;AC5WA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;;;;;;;;;;;AClXA;AACA;AACA;AACA;AACA;AACA;;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;AC9QA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;;AC5FA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACh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zdA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;;;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AC1BA;AACA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACj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laA;;AAAA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AC/CA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AACA;;;;;;;;;;;AC7KA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAGA;;;;;;;;;;;AClDA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;ACnEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AAGA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAGA;;;;;;;;;;;AC1DA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;AAGA;;AAGA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;;AAOA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AAGA;AACA;AACA;AAGA;AAGA;AACA;AAGA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAGA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC//DA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;ACzDA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACvVA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAIA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAIA;AACA;AACA;;AAEA;AACA;AACA;AAGA;AAEA;AAIA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAGA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAAA;AAAA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAGA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACniDA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAIA;AACA;AAKA;AACA;AAKA;AAEA;AACA;;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAMA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;;;;;;;;;;;ACnVA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;;;;;;;;;;;AC/BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAGA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAGA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAGA;;AAEA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC1pCA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;AC9CA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;ACnLA;AACA;AAGA;AACA;AACA;AAQA;AAkBA;AAfA;AAgBA;AACA;AACA;AACA;AAyBA;AACA;AACA;AACA;AACA;AACA;AAuIA;AAIA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AAAA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAoBA;AACA;AACA;AAoCA;AAAA;AAAA;AAAA;;AACA;AACA;AACA;AAEA;AACA;AAQA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAnTA;AACA;AACA;AAkTA;AAxVA;;AAiWA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;AC5XA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AAEA;AACA;AACA;AAKA;AAAA;AACA;AAAA;AAAA;;AAEA;AACA;AAJA;;AAeA;AAAA;AAgBA;AAAA;AAVA;AAEA;AAEA;AAEA;AAEA;;AAIA;AAhBA;AACA;AACA;AAuBA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AA/FA;AACA;AACA;AA8FA;AAvHA;AAAA;AA4HA;AAAA;AACA;AAAA;AAAA;AAEA;;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AApCA;;;;;;;;;;;;;;;;;;;;ACrJA;AAOA;AAAA;AAGA;AAAA;AAAA;AAAA;AAFA;;AAIA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AA7BA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AAEA;AACA;AACA;AACA;AAYA;AAAA;AAuCA;AAAA;AAfA;AACA;AACA;AAEA;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AACA;AAnEA;AAcA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAwDA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA/IA;;AAsJA;AAAA;AAIA;AAAA;AAAA;AAMA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AArIA;;;;;;;;;;;;;;;;;;;;;;ACxKA;AACA;AACA;AACA;AAeA;AAsBA;AAXA;AAGA;AAEA;AAOA;AACA;AACA;AACA;AACA;AAQA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAUA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAsBA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AACA;AACA;AAGA;AACA;AAGA;AACA;AACA;AAEA;AACA;AAGA;AACA;AAEA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAtMA;AACA;AACA;AACA;AAoMA;AAzMA;;AA2MA;AACA;AACA;AAAA;AAAA;;;;;;;;;;;;;;;;AC/NA;AAMA;AAKA;AAUA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACjCA;AAGA;AACA;AA6DA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AARA;AAgBA;AAAA;AASA;AAAA;AANA;AAEA;AAEA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAxDA;;;;;;;;;;;;;;;;ACzFA;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;AAMA;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAWA;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAMA;;;;;;;;;;;;;;;;;AC5BA;AASA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AAAA;AAAA;;;;;;;;;;;;;;;;ACPA;AACA;AACA;;;;;;;;;;;;;;;;ACFA;;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;;;;;;;;;;;;;;;;;ACFA;AACA;AACA;;;;;;;;;;;;;;;;ACDA;;;;;;;;;;;;;;;;;;ACAA;AAiBA;AAAA;AAAA;AAAA;;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;;;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AAGA;AAKA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;ACzBA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;AC9EA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AC9NA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACVA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACPA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AC5CA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACPA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;ACxBA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;;ACvGA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;;AC3CA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;;AC1GA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;;;;;;;;;;;ACfA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;;;;;;;;;;;AC/EA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AAEA;;AAGA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;;AC1CA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;;;;;;;;;;;ACfA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;AChBA;;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzHA;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;ACr5CA;AAGA;AAMA;AAAA;AACA;AA8HA;AACA;AACA;AAwEA;AAzJA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAIA;AACA;AACA;AAAA;AAGA;AACA;AAcA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AACA;AAEA;AAAA;AAAA;AAEA;AAEA;AACA;AAAA;AAEA;AAMA;AAEA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;;ACxLA;AAAA;AACA;;AAMA;AACA;AANA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AACA;AAGA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpDA;AAEA;AACA;AACA;AAOA;AASA;AAeA;AACA;AAAA;AAAA;AACA;AAEA;AAGA;AAAA;AACA;AACA;AAJA;AA6XA;AACA;AACA;AACA;AA2DA;AACA;AA6CA;AACA;AACA;AAIA;AAAA;AAMA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA/gBA;AASA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AAGA;AACA;AACA;AAEA;AAEA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AAAA;AAIA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAGA;AACA;AACA;AAEA;AAAA;AAPA;AASA;AAEA;AACA;AACA;AACA;AACA;AAIA;AACA;AAIA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;AAKA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAGA;;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;;;;;;;AAWA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAAA;;AAEA;;;AAIA;;;;AAKA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAKA;AACA;AAAA;AAAA;AAAA;AAEA;;AAQA;;AAIA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAAA;AACA;;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AAcA;AACA;AACA;AAEA;AAEA;;AACA;;;;AAIA;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AACA;AAEA;AACA;;AACA;;AAEA;;;;AAIA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AAEA;AAAA;AAAA;;AACA;;AAEA;AACA;AACA;AAOA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AAKA;;AAEA;AACA;AACA;AAIA;;AAEA;;AA8CA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAOA;AAEA;AADA;;AAPA;AAUA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;AAGA;;AAGA;AACA;AApDA;AAsDA;AACA;;AAEA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAQA;AAqBA;;AApBA;;AACA;AAIA;AAIA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;;;AACA;AAEA;AACA;AACA;AAAA;AACA;AAMA;AALA;AACA;AACA;;AAIA;;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AACA;AACA;AACA;AACA;;;;;AAUA;;;AAIA;AAGA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAIA;AAEA;AACA;AACA;AAMA;AAGA;AACA;AAAA;;AAGA;AACA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAMA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAvBA;AAyBA;AAKA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACp0BA;AAaA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AAAA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AACA;AACA;AAEA;AAIA;AAGA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAKA;AACA;AAEA;AAAA;AAGA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtKA;AAEA;AACA;AAIA;AACA;AAEA;AAEA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AAAA;AA6BA;AAAA;AAAA;AAAA;AACA;AAzBA;AAKA;AAQA;AACA;AACA;AAOA;AAsVA;AAl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jBA;AAEA;AAOA;AAOA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AAGA;AAEA;AAEA;AACA;;AACA;AAEA;AAGA;AAGA;AACA;AACA;AACA;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;;AAQA;;;AAMA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAIA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;;AAIA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AAEA;;;AAGA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;AAKA;AAEA;AAIA;AACA;AACA;AACA;;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AAAA;AACA;AACA;AACA;;;;;AAKA;;AAGA;AAEA;;AAKA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAEA;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;;;;;;;;;;;;;;;;;;;;;;;AC9QA;AACA;AAKA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAUA;AACA;AACA;AA+FA;AACA;AACA;AAEA;AACA;AACA;AA3GA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAOA;AAAA;;AAOA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpOA;AAeA;AAcA;AASA;AAYA;AACA;AACA;AACA;AACA;AAKA;AAkHA;AACA;AAKA;AA6FA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AAGA;AACA;AAAA;AACA;AAAA;AAAA;AAMA;AAwCA;AACA;AAxCA;AAcA;AAIA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAIA;AAEA;AAGA;AAUA;AACA;AAAA;AAIA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAIA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAAA;AAEA;AAIA;AAEA;AACA;AAAA;AAEA;AACA;AAAA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AAAA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AAAA;AAGA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAWA;AACA;AACA;AAIA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAMA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAIA;AACA;AAEA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AACA;AAIA;AACA;AAEA;AACA;AAaA;AACA;AAIA;AAEA;AACA;AAEA;AAIA;AACA;AACA;AAEA;AAKA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAAA;AAAA;AAIA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AAAA;;AAEA;AAOA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;AAKA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC/iCA;AAaA;AACA;AACA;AAEA;AAQA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxHA;AAGA;AAEA;AAQA;AAyBA;AAIA;AASA;AACA;AAgDA;AAGA;AAIA;AACA;AACA;AAEA;AAEA;AAiCA;AAAA;AAVA;AAWA;AACA;AACA;AACA;AAEA;AAEA;;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AAGA;AAEA;AAIA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAlFA;AACA;AACA;AAkFA;;;;AAIA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AAAA;AAEA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAMA;AAIA;AAIA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAKA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;;AACA;AACA;AAGA;AACA;AACA;AAEA;AAEA;;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AAOA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAGA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpiBA;AACA;AACA;AAEA;AASA;AAsBA;AAWA;AACA;AAkCA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AAOA;AACA;AAAA;AAGA;AACA;AACA;AAUA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AAMA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAGA;AAAA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAGA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAGA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;AACA;AACA;AAIA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAKA;AACA;AACA;AACA;AAEA;AAKA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AANA;AAAA;AAQA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAAA;AAMA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAcA;AAAA;AAAA;AAEA;AACA;AAEA;AAYA;AAKA;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AAKA;AACA;AAIA;AAEA;AASA;AAIA;AACA;AACA;AACA;AAEA;AACA;AAEA;;AAAA;AAOA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AAOA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAOA;AAEA;AACA;AACA;AAAA;;AAEA;AAEA;AACA;AAGA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AAIA;AACA;AAEA;AAQA;AACA;AAKA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAGA;AACA;AAEA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AA0BA;;;;;;;;;;;;;;;;;;;;;;;;;;;AC92BA;AAKA;AAGA;AAEA;AAEA;AAuBA;AAQA;AA2EA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;AAMA;AAeA;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BA;AAAA;AA9BA;AACA;AA8BA;AACA;;AAGA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAGA;AAOA;AACA;AACA;AACA;AAHA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAWA;AAEA;AAAA;AAAA;AAAA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;AAEA;;;AAIA;;AAEA;;AAGA;AACA;AAEA;AACA;AAIA;AAKA;;;;;;AASA;AACA;AACA;AAKA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;;;AAGA;AACA;;;AAOA;;;AAGA;AACA;;;;;;AAMA;;AAEA;AACA;;;;;;;AAKA;AACA;;;;;;;;;;;;;;;;;;;;;AAsBA;AACA;AAIA;;AAEA;AAKA;AAAA;AAAA;;AAGA;;;;;;;;;;;;AAcA;AACA;AAIA;AACA;AACA;AAEA;AACA;AACA;;AAEA;;;;;;;;;;;;;AAiBA;AACA;;;;;AAcA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgDA;;;;AAIA;AACA;;;;;;;;;;;;;;;;;AAsBA;AACA;;AAKA;AACA;;AAGA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;AAuBA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;;;;;AAMA;AAEA;;AAGA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;;;;;;;AAQA;;;;AAIA;AAAA;AAAA;AACA;;;;;;;AASA;;;;AAIA;AAAA;AAAA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAqCA;AACA;AAMA;AAGA;AACA;AAEA;;AAEA;AACA;AAEA;AAIA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;AA0BA;AACA;AAEA;;;;;;;;;;;;;;AAeA;AACA;AAEA;;;;AAIA;AACA;AAEA;;;;AAIA;AACA;AAEA;;;;AAIA;AACA;AAEA;;;;AAIA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/tBA;AAeA;AAIA;AAkBA;AAsCA;AAUA;AACA;AACA;AACA;AACA;AATA;AAWA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;AAQA;AACA;AAOA;AAEA;AAAA;AAFA;AAIA;AAEA;;;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;;;AAEA;AACA;AAKA;AAAA;AAIA;AAEA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;;AAEA;AAGA;AACA;AACA;AAKA;AAEA;AAMA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AAHA;;;AAIA;AAEA;;;;;AAMA;AACA;AAEA;AAAA;;;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAMA;AACA;AAGA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;;;;AACA;AAEA;AACA;AACA;;;AACA;AAEA;;;;;AAMA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAAA;AAAA;AAGA;AACA;AACA;AAEA;;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AAMA;AAEA;AACA;AACA;AAMA;AACA;;;AACA;AAEA;AAAA;AAMA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAMA;AAEA;AACA;AACA;AAMA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAIA;AAEA;AAAA;AACA;AAEA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnjBA;AAEA;AAEA;AAMA;AA0BA;AAGA;AAAA;AAyBA;AAGA;AAwCA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAhEA;AACA;AAiEA;AACA;AACA;AAEA;AACA;AACA;AAGA;AAAA;AAAA;AAAA;AAIA;AAAA;AACA;AACA;AADA;AACA;AAKA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAGA;AAEA;AACA;;AACA;AAnHA;AAJA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AAIA;AAFA;AACA;AACA;AACA;AACA;;;;AA6GA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AAKA;AAEA;AACA;AAAA;AAGA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AAEA;AAQA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAIA;AACA;AACA;AAEA;AAKA;AAGA;AAEA;AAIA;AACA;AAKA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;AAOA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAWA;AAIA;AAEA;AACA;AACA;AAEA;AAAA;AAcA;;AAaA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAGA;AAEA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;;;;AAKA;AAIA;AACA;AACA;AACA;AAEA;AAEA;AACA;;AAEA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;;;;AAIA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;;;;AAIA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;AAYA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AAEA;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AAGA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;AAwBA;AACA;AACA;AAEA;AAEA;AACA;;AAEA;AAEA;AAEA;AACA;;AAGA;AAEA;AAEA;AAMA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;AAQA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAGA;AAEA;AAKA;AACA;;AAEA;AAMA;AAEA;AACA;AAAA;;;AAGA;AACA;AAEA;AAKA;AACA;;AAEA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;AAKA;AAEA;AAEA;AACA;AAGA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAGA;AACA;AAIA;AAEA;AAAA;AAIA;AAAA;AAAA;AAAA;;AAGA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;;AAEA;AAEA;AACA;AACA;AAEA;;;AAGA;AAGA;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AAIA;AACA;AACA;AAYA;AAAA;;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;;;;AAIA;AACA;AACA;AAGA;AAEA;AAIA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AASA;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAn8BA;;AAq8BA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AAOA;AACA;AAAA;AAAA;AACA;AACA;AAKA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AACA;;AAEA;AAEA;AAGA;;;AAKA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtkCA;AAGA;AACA;AAGA;AAGA;AAKA;AAeA;AAKA;AAIA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAYA;AAEA;AAAA;AAAA;AAAA;AAbA;AACA;AACA;AAKA;AAiEA;AAmEA;AA5HA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAUA;AACA;AAKA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAMA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAOA;AAIA;AAGA;AACA;AACA;AAEA;AAEA;;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAKA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAIA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAKA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AAEA;AAIA;AACA;AAEA;AACA;AACA;AACA;AAIA;AAEA;AAAA;AASA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtgBA;AAKA;AAGA;AACA;AAOA;AAMA;AAiBA;AACA;AAaA;AACA;AAWA;AAGA;AAMA;AACA;AAGA;AAuBA;AA4BA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAAA;AAVA;AAlBA;AAQA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AA0gBA;AAoIA;AAKA;AAKA;AA8QA;AACA;AACA;AA/4BA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAAA;AAIA;AACA;AACA;AACA;AAEA;;;;AAIA;AAAA;AACA;AACA;AACA;AAEA;AAGA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAEA;;AAMA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;;;;;;AAIA;AAKA;AAKA;AAEA;AACA;AAEA;AACA;AACA;;AAAA;;;AAOA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AACA;AAKA;AAAA;AAOA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAGA;AACA;AAGA;AACA;AACA;;;;AACA;AAEA;AAAA;AAsBA;AAAA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AAAA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAOA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAmBA;AAKA;AACA;AACA;AAGA;AAAA;AAAA;AAAA;AAIA;AACA;AACA;AACA;AACA;AAEA;AAKA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAOA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAIA;AAGA;AACA;AACA;AAEA;AACA;AAIA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AAEA;AACA;AAEA;AAIA;AAIA;AAEA;AAIA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAEA;AAAA;AAAA;AAEA;AAGA;AAGA;AAKA;AAKA;AAEA;AACA;AAAA;AAAA;;AAMA;AAGA;;AAEA;AAGA;;AAEA;AAGA;;AAEA;AAEA;AACA;;AAEA;AAEA;AACA;;AAEA;AAEA;AAAA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AAEA;AAAA;;;AAGA;AAEA;;AAEA;AAEA;;AAEA;AAEA;AAAA;AAwFA;AAAA;AAv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fA;AAGA;AAcA;AAEA;;AAEA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAEA;AAEA;AAEA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAOA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AAAA;AAAA;;;;AAIA;AAEA;AACA;AAIA;;AAEA;;AAGA;AAEA;AACA;AAAA;AAQA;;AAGA;AAEA;AACA;AACA;AACA;;;AAGA;AAKA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;;AAEA;AAAA;AAAA;;AAEA;AAAA;AAEA;AACA;AAEA;AACA;AAEA;AACA;;;AAEA;AAAA;AAAA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;AAEA;AAAA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;;;;AAGA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;;;AAKA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACvoDA;AAgBA;AAUA;AACA;AACA;AAEA;AAAA;AACA;AAAA;AAGA;AAGA;AACA;AACA;AAEA;AASA;AAMA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;AAOA;AAGA;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;AC3JA;;;AAGA;AAAA;AACA;;;;;AAKA;AAEA;;;;AAIA;AAEA;;;;AAIA;AAEA;;;;AAIA;AAEA;;;;;AAKA;AAEA;;;AAGA;AAEA;;;AAGA;AACA;AAEA;;;;AAIA;AAGA;AACA;AAEA;;;;AAIA;AAGA;AACA;;;;;;;;;;;;;;;;;;;;;;ACjEA;AAIA;AAKA;AACA;AACA;AACA;AAkBA;AAGA;AACA;AAKA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AAEA;AAAA;AAGA;AAAA;AAIA;AAMA;AAAA;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;;;;;ACjHA;AAGA;AAQA;AAMA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAgFA;AACA;AACA;AAjFA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AAKA;AACA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AAIA;AAQA;AAEA;AAIA;AACA;AACA;AAIA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAAA;AAFA;AAKA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAMA;AAKA;AAGA;AAEA;AACA;AACA;AAEA;AAIA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;AC5JA;AAEA;;;;;;;;;;;;;;;;;;;ACFA;AAEA;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AADA;;AAEA;AACA;AAAA;;;;;;;;;;;;;;;;;ACRA;AAEA;AACA;AACA;AAYA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjBA;AAIA;AACA;AACA;AACA;AACA;AAKA;AAEA;AAKA;AACA;AACA;AAMA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AAQA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;;AAEA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACxNA;;;;AAKA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;ACjBA;;;;AAMA;AAOA;AAGA;AACA;AACA;AACA;AAEA;AASA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;AC9FA;;;;AAKA;AAOA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;AC1CA;;;;AAKA;AAOA;AAGA;AACA;AACA;AAMA;AACA;AAEA;AACA;AAIA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACpCA;AAEA;AACA;AACA;AAGA;AAQA;;;;;;;;AAGA;AACA;AAGA;AACA;AACA;AACA;AAMA;AASA;AACA;AACA;AACA;;;AAEA;AACA;;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAIA;AACA;AACA;AACA;AAIA;AAGA;AAGA;AAEA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;;;;;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAAA;AAEA;AAKA;AACA;AAKA;AAAA;AAIA;AACA;AACA;AArBA;AAsBA;;;;;;;;;;;;;;;;;;;;ACjOA;;;;AAOA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AAIA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAGA;AAEA;AAEA;AAEA;AAGA;;;;;;;;;;;;;;;;ACrEA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AACA;;;;;;;;;;;;;;;;;;;;;AC5DA;AAkGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAEA;AAGA;AAAA;AAAA;;AAEA;AACA;AAKA;AAEA;AAGA;AAAA;AAAA;;AAEA;AACA;AAEA;AACA;AAGA;AAEA;AAIA;AACA;AACA;AAEA;AAIA;AAEA;AACA;AAIA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrOA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChBA;AAOA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnBA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;AC1BA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC3BA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACAA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChBA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAIA;AAEA;AACA;;;;;;;;;;;;;;;;ACpBA;AAGA;AACA;AAOA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;AClBA;AACA;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACLA;AAEA;AAEA;AAAA;AAEA;AAEA;AAGA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjCA;AAEA;;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACpCA;;;;AAIA;AACA;AAAA;AAAA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;ACrBA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AAEA;AAGA;AACA;AAEA;AAGA;AACA;AAEA;AAGA;AAIA;AAEA;AACA;AACA;AACA;AAGA;AACA;AAEA;AAIA;AACA;AACA;AAIA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC/DA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACRA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AClCA;AAEA;AAyBA;AACA;AAAA;AAAA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAUA;AAKA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAqCA;AAEA;AAtCA;AAEA;AAAA;AAAA;AAAA;AAAA;;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;;;ACvHA;AAOA;AAOA;AAIA;AAIA;AAEA;;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AAEA;AACA;AAMA;;;;;;;;;;;;;;;;ACXA;AAEA;AAAA;AAAA;AAAA;AACA;AACA;AAGA;AACA;AAKA;;;;;;;;;;;;;ACbA;AASA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;;;;;;AAMA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA;AAMA;AACA;AACA;AAEA;;;;AAIA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAgDA;AAIA;AAAA;AAAA;;AAEA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AACA;AAGA;;;;;;;;;;AAUA;AAEA;AAAA;AAAA;;AAEA;AAIA;AAEA;AAWA;AACA;AAGA;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AAIA;AAEA;AAEA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;ACnJA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AAcA;AACA;AACA;AAEA;AA4CA;AAEA;AAAA;AAAA;AA3CA;AA6CA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAhDA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAEA;AAGA;AAAA;AAAA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AAkBA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AAEA;AAGA;AACA;AACA;AAAA;AAAA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;AClIA;AAcA;AAMA;AACA;AAGA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAOA;AAAA;AACA;AACA;AAEA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAMA;AACA;AAMA;AAEA;AACA;AAOA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;ACtIA;AAYA;;;;;;;;;;;;;;;;;;;;;;AAsBA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;;AAEA;AACA;AAEA;AACA;AACA;;;AAOA;AAEA;AACA;AACA;;;AAKA;AAAA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AAaA;AACA;AACA;;;AAIA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AAIA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;AChJA;AASA;AAMA;AACA;AACA;AAMA;AACA;AAAA;AAEA;AACA;AAIA;AACA;AACA;AAEA;AAMA;AACA;AAEA;AAGA;AACA;AAEA;AAAA;AAEA;AAEA;AACA;AAIA;AAAA;AAEA;AAAA;AAEA;AAEA;AACA;AAGA;AAEA;AAAA;AAEA;AAEA;AACA;AAEA;AAKA;AACA;AAEA;AAGA;AAMA;AAKA;AAEA;AAKA;AACA;AAEA;;;;;AAKA;AAGA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAGA;AAEA;AAGA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACtKA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACbA;AAuBA;AAEA;AAMA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAGA;AAoCA;AACA;AAKA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAOA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AAEA;AAAA;AACA;;;;;AASA;AACA;AAEA;AACA;AACA;AAAA;AACA;;;AAEA;;AAGA;AAgBA;AACA;AAWA;AAIA;AAKA;AACA;AACA;AAEA;AACA;AACA;AAGA;AACA;;;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAEA;AAAA;AACA;AAEA;;;;AAGA;;AAGA;AAEA;AACA;AACA;;;;;AAOA;AACA;AACA;AACA;AACA;AAEA;AAGA;AACA;AAEA;;AAGA;;AAGA;AACA;AAEA;AAIA;AACA;AAAA;AACA;;AACA;;AAEA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAKA;;;;AAIA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpWA;AAiBA;AAEA;AAOA;AAEA;AACA;AA6BA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AAIA;AAIA;AAAA;AAIA;AAEA;AACA;AAQA;AAEA;AAGA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAc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psBA;AACA;AACA;AAIA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAYA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAjBA;AACA;AACA;AACA;AAiGA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AA+BA;AACA;AACA;AACA;AACA;AACA;AA1LA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;;AACA;AASA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA8EA;AAIA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AAAA;;AAOA;AACA;AACA;;;;;;;;;;;;;;;;ACzQA;AAEA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AAAA;AAIA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;;;;;;;;;;;;;;;ACtDA;AAKA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;;;;;;;;;;ACbA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC5BA;;;;;;;;;;;;;;;;;;;;;ACSA;AAEA;AAKA;AAEA;AADA;AACA;AADA;AACA;AANA;AACA;AACA;AAKA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AAEA;AACA;AAAA;AAEA;AACA;;AAGA;AACA;;AAGA;AACA;AAEA;AACA;AAEA;AACA;;;AAIA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;;AAEA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;;AAGA;AACA;;AAGA;AACA;;AAGA;AACA;;AAGA;AACA;AAEA;;AAGA;AACA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;ACvHA;AACA;AACA;AAAA;AAUA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAQA;AACA;AAOA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;ACjFA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAoGA;AAAA;AAAA;AAAA;AA5FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;;AAEA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;AAGA;AACA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAIA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;ADtLA;AAAA;AAAA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;AACA;;;AAIA;;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;;;AAIA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;;AAGA;;AAGA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AAzNA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AAQA;AAEA;AADA;AACA;AADA;AACA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AACA;AAGA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAAA;AAAA;AAGA;AAEA;AACA;AACA;;AAGA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAAA;AAAA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AAGA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;AEvGA;AACA;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAKA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AAOA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC7MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AACA;AAAA;AAAA;AAQA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AAIA;AAAA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAKA;;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;ACjLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;AC/DA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACxDA;AACA;AACA;AAKA;AACA;AACA;AAIA;AACA;AACA;AAKA;AACA;AACA;AAWA;AACA;AACA;AAKA;AAAA;AAGA;AACA;AACA;AAKA;AACA;AACA;AAKA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AAQA;;;;;;;;;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;;AAEA;AAgDA;AACA;AAeA;AACA;AAeA;AACA;AAeA;AACA;AAeA;AACA;;;;;;;;;;;;;;;;;;AC/HA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAQA;;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AASA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAWA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAQA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAWA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AASA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AASA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAEA;AAGA;AAAA;AAIA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;;AAEA;;AAEA;AACA;AAGA;AAAA;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA;AACA;AAEA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAGA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AASA;AAKA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAhEA;AAAA;AAaA;AAqDA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AAAA;AAAA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACxWA;AAGA;AAEA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;ACPA;AACA;AAQA;AACA;AACA;AACA;AACA;AAWA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AAEA;AAIA;AACA;AACA;AAIA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;AAEA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACnEA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAEA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;;AAEA;AAEA;AACA;AACA;AAIA;AAmBA;AACA;AAAA;AAbA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAuEA;AAlEA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAGA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAKA;AACA;AACA;;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;;AAEA;AAAA;AAAA;AAAA;AAxGA;AA2GA;AACA;AACA;AACA;AAEA;AACA;;AAGA;AACA;AACA;AACA;;AAGA;;AAEA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;;AAIA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AAEA;AACA;AACA;AACA;;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;AAGA;AAEA;AACA;;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAIA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACjXA;AAEA;AAEA;AAGA;AACA;AAAA;AAAA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AfxBA;AAEA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAHA;AAAA;AAIA;AACA;AAEA;AACA;AACA;AACA;AAqFA;AAEA;AAEA;AAYA;AAAA;AANA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AAEA;AAEA;AAAA;AAGA;AACA;AAKA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;AAGA;AAIA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;;AAGA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;;;;;;;;;;;;;;;;;;AgBrPA;AAEA;AAAA;AACA;AACA;AACA;AAGA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAFA;AACA;AAOA;;AACA;AACA;AAAA;;AAEA;AAIA;AACA;;AAEA;AAEA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AAEA;AACA;;AAEA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjXA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC7jBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;AACA;AACA;AACA;AACA;;;;;ACJA;;;;;;;;;;;;;;;;ACAA;AACA;AACA;;AAEA;AACA","sources":["webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/images/ sync ^\\.\\/.*$","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/client.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/graphql-client.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/message-identifier.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/message-parser.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/election/election.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/index.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/key-ceremony/key-ceremony.component.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/tally/tally.component.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/trustee/event_manager.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/trustee/identification_keys.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/trustee/trustee.component.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/trustee/trustee.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/utils.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/vote/vote.component.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/voter/voter.js","webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/src/decidim/elections/admin/pending_action.js","webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/src/decidim/elections/admin/trustees_process.js","webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/src/decidim/elections/admin/vote_statistics.js","webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/src/decidim/elections/broken_promises_handler.js","webpack://decidim-base/./node_modules/base64-js/index.js","webpack://decidim-base/./node_modules/base64url/dist/base64url.js","webpack://decidim-base/./node_modules/base64url/dist/pad-string.js","webpack://decidim-base/./node_modules/base64url/index.js","webpack://decidim-base/./node_modules/buffer/index.js","webpack://decidim-base/config/versionTemplate.txt","webpack://decidim-base/lib/es6-promise/utils.js","webpack://decidim-base/lib/es6-promise/asap.js","webpack://decidim-base/lib/es6-promise/then.js","webpack://decidim-base/lib/es6-promise/promise/resolve.js","webpack://decidim-base/lib/es6-promise/-internal.js","webpack://decidim-base/lib/es6-promise/enumerator.js","webpack://decidim-base/lib/es6-promise/promise/all.js","webpack://decidim-base/lib/es6-promise/promise/race.js","webpack://decidim-base/lib/es6-promise/promise/reject.js","webpack://decidim-base/lib/es6-promise/promise.js","webpack://decidim-base/lib/es6-promise/polyfill.js","webpack://decidim-base/lib/es6-promise.js","webpack://decidim-base/./node_modules/ieee754/index.js","webpack://decidim-base/./node_modules/lodash/_DataView.js","webpack://decidim-base/./node_modules/lodash/_Hash.js","webpack://decidim-base/./node_modules/lodash/_LazyWrapper.js","webpack://decidim-base/./node_modules/lodash/_ListCache.js","webpack://decidim-base/./node_modules/lodash/_LodashWrapper.js","webpack://decidim-base/./node_modules/lodash/_Map.js","webpack://decidim-base/./node_modules/lodash/_MapCache.js","webpack://decidim-base/./node_modules/lodash/_Promise.js","webpack://decidim-base/./node_modules/lodash/_Set.js","webpack://decidim-base/./node_modules/lodash/_SetCache.js","webpack://decidim-base/./node_modules/lodash/_Stack.js","webpack://decidim-base/./node_modules/lodash/_Symbol.js","webpack://decidim-base/./node_modules/lodash/_Uint8Array.js","webpack://decidim-base/./node_modules/lodash/_WeakMap.js","webpack://decidim-base/./node_modules/lodash/_apply.js","webpack://decidim-base/./node_modules/lodash/_arrayEach.js","webpack://decidim-base/./node_modules/lodash/_arrayFilter.js","webpack://decidim-base/./node_modules/lodash/_arrayIncludes.js","webpack://decidim-base/./node_modules/lodash/_arrayIncludesWith.js","webpack://decidim-base/./node_modules/lodash/_arrayLikeKeys.js","webpack://decidim-base/./node_modules/lodash/_arrayMap.js","webpack://decidim-base/./node_modules/lodash/_arrayPush.js","webpack://decidim-base/./node_modules/lodash/_assignMergeValue.js","webpack://decidim-base/./node_modules/lodash/_assignValue.js","webpack://decidim-base/./node_modules/lodash/_assocIndexOf.js","webpack://decidim-base/./node_modules/lodash/_baseAssign.js","webpack://decidim-base/./node_modules/lodash/_baseAssignIn.js","webpack://decidim-base/./node_modules/lodash/_baseAssignValue.js","webpack://decidim-base/./node_modules/lodash/_baseClamp.js","webpack://decidim-base/./node_modules/lodash/_baseClone.js","webpack://decidim-base/./node_modules/lodash/_baseCreate.js","webpack://decidim-base/./node_modules/lodash/_baseFill.js","webpack://decidim-base/./node_modules/lodash/_baseFindIndex.js","webpack://decidim-base/./node_modules/lodash/_baseFlatten.js","webpack://decidim-base/./node_modules/lodash/_baseFor.js","webpack://decidim-base/./node_modules/lodash/_baseGet.js","webpack://decidim-base/./node_modules/lodash/_baseGetAllKeys.js","webpack://decidim-base/./node_modules/lodash/_baseGetTag.js","webpack://decidim-base/./node_modules/lodash/_baseHasIn.js","webpack://decidim-base/./node_modules/lodash/_baseIndexOf.js","webpack://decidim-base/./node_modules/lodash/_baseIntersection.js","webpack://decidim-base/./node_modules/lodash/_baseIsArguments.js","webpack://decidim-base/./node_modules/lodash/_baseIsMap.js","webpack://decidim-base/./node_modules/lodash/_baseIsNaN.js","webpack://decidim-base/./node_modules/lodash/_baseIsNative.js","webpack://decidim-base/./node_modules/lodash/_baseIsSet.js","webpack://decidim-base/./node_modules/lodash/_baseIsTypedArray.js","webpack://decidim-base/./node_modules/lodash/_baseKeys.js","webpack://decidim-base/./node_modules/lodash/_baseKeysIn.js","webpack://decidim-base/./node_modules/lodash/_baseLodash.js","webpack://decidim-base/./node_modules/lodash/_baseMerge.js","webpack://decidim-base/./node_modules/lodash/_baseMergeDeep.js","webpack://decidim-base/./node_modules/lodash/_basePick.js","webpack://decidim-base/./node_modules/lodash/_basePickBy.js","webpack://decidim-base/./node_modules/lodash/_baseRest.js","webpack://decidim-base/./node_modules/lodash/_baseSet.js","webpack://decidim-base/./node_modules/lodash/_baseSetData.js","webpack://decidim-base/./node_modules/lodash/_baseSetToString.js","webpack://decidim-base/./node_modules/lodash/_baseSlice.js","webpack://decidim-base/./node_modules/lodash/_baseTimes.js","webpack://decidim-base/./node_modules/lodash/_baseToString.js","webpack://decidim-base/./node_modules/lodash/_baseTrim.js","webpack://decidim-base/./node_modules/lodash/_baseUnary.js","webpack://decidim-base/./node_modules/lodash/_baseUniq.js","webpack://decidim-base/./node_modules/lodash/_baseUnset.js","webpack://decidim-base/./node_modules/lodash/_cacheHas.js","webpack://decidim-base/./node_modules/lodash/_castArrayLikeObject.js","webpack://decidim-base/./node_modules/lodash/_castPath.js","webpack://decidim-base/./node_modules/lodash/_cloneArrayBuffer.js","webpack://decidim-base/./node_modules/lodash/_cloneBuffer.js","webpack://decidim-base/./node_modules/lodash/_cloneDataView.js","webpack://decidim-base/./node_modules/lodash/_cloneRegExp.js","webpack://decidim-base/./node_modules/lodash/_cloneSymbol.js","webpack://decidim-base/./node_modules/lodash/_cloneTypedArray.js","webpack://decidim-base/./node_modules/lodash/_composeArgs.js","webpack://decidim-base/./node_modules/lodash/_composeArgsRight.js","webpack://decidim-base/./node_modules/lodash/_copyArray.js","webpack://decidim-base/./node_modules/lodash/_copyObject.js","webpack://decidim-base/./node_modules/lodash/_copySymbols.js","webpack://decidim-base/./node_modules/lodash/_copySymbolsIn.js","webpack://decidim-base/./node_modules/lodash/_coreJsData.js","webpack://decidim-base/./node_modules/lodash/_countHolders.js","webpack://decidim-base/./node_modules/lodash/_createAssigner.js","webpack://decidim-base/./node_modules/lodash/_createBaseFor.js","webpack://decidim-base/./node_modules/lodash/_createBind.js","webpack://decidim-base/./node_modules/lodash/_createCtor.js","webpack://decidim-base/./node_modules/lodash/_createCurry.js","webpack://decidim-base/./node_modules/lodash/_createHybrid.js","webpack://decidim-base/./node_modules/lodash/_createPartial.js","webpack://decidim-base/./node_modules/lodash/_createRecurry.js","webpack://decidim-base/./node_modules/lodash/_createSet.js","webpack://decidim-base/./node_modules/lodash/_createWrap.js","webpack://decidim-base/./node_modules/lodash/_customOmitClone.js","webpack://decidim-base/./node_modules/lodash/_defineProperty.js","webpack://decidim-base/./node_modules/lodash/_flatRest.js","webpack://decidim-base/./node_modules/lodash/_freeGlobal.js","webpack://decidim-base/./node_modules/lodash/_getAllKeys.js","webpack://decidim-base/./node_modules/lodash/_getAllKeysIn.js","webpack://decidim-base/./node_modules/lodash/_getData.js","webpack://decidim-base/./node_modules/lodash/_getFuncName.js","webpack://decidim-base/./node_modules/lodash/_getHolder.js","webpack://decidim-base/./node_modules/lodash/_getMapData.js","webpack://decidim-base/./node_modules/lodash/_getNative.js","webpack://decidim-base/./node_modules/lodash/_getPrototype.js","webpack://decidim-base/./node_modules/lodash/_getRawTag.js","webpack://decidim-base/./node_modules/lodash/_getSymbols.js","webpack://decidim-base/./node_modules/lodash/_getSymbolsIn.js","webpack://decidim-base/./node_modules/lodash/_getTag.js","webpack://decidim-base/./node_modules/lodash/_getValue.js","webpack://decidim-base/./node_modules/lodash/_getWrapDetails.js","webpack://decidim-base/./node_modules/lodash/_hasPath.js","webpack://decidim-base/./node_modules/lodash/_hashClear.js","webpack://decidim-base/./node_modules/lodash/_hashDelete.js","webpack://decidim-base/./node_modules/lodash/_hashGet.js","webpack://decidim-base/./node_modules/lodash/_hashHas.js","webpack://decidim-base/./node_modules/lodash/_hashSet.js","webpack://decidim-base/./node_modules/lodash/_initCloneArray.js","webpack://decidim-base/./node_modules/lodash/_initCloneByTag.js","webpack://decidim-base/./node_modules/lodash/_initCloneObject.js","webpack://decidim-base/./node_modules/lodash/_insertWrapDetails.js","webpack://decidim-base/./node_modules/lodash/_isFlattenable.js","webpack://decidim-base/./node_modules/lodash/_isIndex.js","webpack://decidim-base/./node_modules/lodash/_isIterateeCall.js","webpack://decidim-base/./node_modules/lodash/_isKey.js","webpack://decidim-base/./node_modules/lodash/_isKeyable.js","webpack://decidim-base/./node_modules/lodash/_isLaziable.js","webpack://decidim-base/./node_modules/lodash/_isMasked.js","webpack://decidim-base/./node_modules/lodash/_isPrototype.js","webpack://decidim-base/./node_modules/lodash/_listCacheClear.js","webpack://decidim-base/./node_modules/lodash/_listCacheDelete.js","webpack://decidim-base/./node_modules/lodash/_listCacheGet.js","webpack://decidim-base/./node_modules/lodash/_listCacheHas.js","webpack://decidim-base/./node_modules/lodash/_listCacheSet.js","webpack://decidim-base/./node_modules/lodash/_mapCacheClear.js","webpack://decidim-base/./node_modules/lodash/_mapCacheDelete.js","webpack://decidim-base/./node_modules/lodash/_mapCacheGet.js","webpack://decidim-base/./node_modules/lodash/_mapCacheHas.js","webpack://decidim-base/./node_modules/lodash/_mapCacheSet.js","webpack://decidim-base/./node_modules/lodash/_memoizeCapped.js","webpack://decidim-base/./node_modules/lodash/_mergeData.js","webpack://decidim-base/./node_modules/lodash/_metaMap.js","webpack://decidim-base/./node_modules/lodash/_nativeCreate.js","webpack://decidim-base/./node_modules/lodash/_nativeKeys.js","webpack://decidim-base/./node_modules/lodash/_nativeKeysIn.js","webpack://decidim-base/./node_modules/lodash/_nodeUtil.js","webpack://decidim-base/./node_modules/lodash/_objectToString.js","webpack://decidim-base/./node_modules/lodash/_overArg.js","webpack://decidim-base/./node_modules/lodash/_overRest.js","webpack://decidim-base/./node_modules/lodash/_parent.js","webpack://decidim-base/./node_modules/lodash/_realNames.js","webpack://decidim-base/./node_modules/lodash/_reorder.js","webpack://decidim-base/./node_modules/lodash/_replaceHolders.js","webpack://decidim-base/./node_modules/lodash/_root.js","webpack://decidim-base/./node_modules/lodash/_safeGet.js","webpack://decidim-base/./node_modules/lodash/_setCacheAdd.js","webpack://decidim-base/./node_modules/lodash/_setCacheHas.js","webpack://decidim-base/./node_modules/lodash/_setData.js","webpack://decidim-base/./node_modules/lodash/_setToArray.js","webpack://decidim-base/./node_modules/lodash/_setToString.js","webpack://decidim-base/./node_modules/lodash/_setWrapToString.js","webpack://decidim-base/./node_modules/lodash/_shortOut.js","webpack://decidim-base/./node_modules/lodash/_stackClear.js","webpack://decidim-base/./node_modules/lodash/_stackDelete.js","webpack://decidim-base/./node_modules/lodash/_stackGet.js","webpack://decidim-base/./node_modules/lodash/_stackHas.js","webpack://decidim-base/./node_modules/lodash/_stackSet.js","webpack://decidim-base/./node_modules/lodash/_strictIndexOf.js","webpack://decidim-base/./node_modules/lodash/_stringToPath.js","webpack://decidim-base/./node_modules/lodash/_toKey.js","webpack://decidim-base/./node_modules/lodash/_toSource.js","webpack://decidim-base/./node_modules/lodash/_trimmedEndIndex.js","webpack://decidim-base/./node_modules/lodash/_updateWrapDetails.js","webpack://decidim-base/./node_modules/lodash/_wrapperClone.js","webpack://decidim-base/./node_modules/lodash/assign.js","webpack://decidim-base/./node_modules/lodash/clone.js","webpack://decidim-base/./node_modules/lodash/constant.js","webpack://decidim-base/./node_modules/lodash/eq.js","webpack://decidim-base/./node_modules/lodash/fill.js","webpack://decidim-base/./node_modules/lodash/flatten.js","webpack://decidim-base/./node_modules/lodash/hasIn.js","webpack://decidim-base/./node_modules/lodash/identity.js","webpack://decidim-base/./node_modules/lodash/intersection.js","webpack://decidim-base/./node_modules/lodash/isArguments.js","webpack://decidim-base/./node_modules/lodash/isArray.js","webpack://decidim-base/./node_modules/lodash/isArrayLike.js","webpack://decidim-base/./node_modules/lodash/isArrayLikeObject.js","webpack://decidim-base/./node_modules/lodash/isBuffer.js","webpack://decidim-base/./node_modules/lodash/isFunction.js","webpack://decidim-base/./node_modules/lodash/isLength.js","webpack://decidim-base/./node_modules/lodash/isMap.js","webpack://decidim-base/./node_modules/lodash/isObject.js","webpack://decidim-base/./node_modules/lodash/isObjectLike.js","webpack://decidim-base/./node_modules/lodash/isPlainObject.js","webpack://decidim-base/./node_modules/lodash/isSet.js","webpack://decidim-base/./node_modules/lodash/isSymbol.js","webpack://decidim-base/./node_modules/lodash/isTypedArray.js","webpack://decidim-base/./node_modules/lodash/keys.js","webpack://decidim-base/./node_modules/lodash/keysIn.js","webpack://decidim-base/./node_modules/lodash/last.js","webpack://decidim-base/./node_modules/lodash/memoize.js","webpack://decidim-base/./node_modules/lodash/merge.js","webpack://decidim-base/./node_modules/lodash/noop.js","webpack://decidim-base/./node_modules/lodash/omit.js","webpack://decidim-base/./node_modules/lodash/partialRight.js","webpack://decidim-base/./node_modules/lodash/pick.js","webpack://decidim-base/./node_modules/lodash/stubArray.js","webpack://decidim-base/./node_modules/lodash/stubFalse.js","webpack://decidim-base/./node_modules/lodash/toFinite.js","webpack://decidim-base/./node_modules/lodash/toInteger.js","webpack://decidim-base/./node_modules/lodash/toLength.js","webpack://decidim-base/./node_modules/lodash/toNumber.js","webpack://decidim-base/./node_modules/lodash/toPlainObject.js","webpack://decidim-base/./node_modules/lodash/toString.js","webpack://decidim-base/./node_modules/lodash/uniq.js","webpack://decidim-base/./node_modules/lodash/wrapperLodash.js","webpack://decidim-base/./node_modules/node-forge/lib/aes.js","webpack://decidim-base/./node_modules/node-forge/lib/asn1.js","webpack://decidim-base/./node_modules/node-forge/lib/baseN.js","webpack://decidim-base/./node_modules/node-forge/lib/cipher.js","webpack://decidim-base/./node_modules/node-forge/lib/cipherModes.js","webpack://decidim-base/./node_modules/node-forge/lib/des.js","webpack://decidim-base/./node_modules/node-forge/lib/forge.js","webpack://decidim-base/./node_modules/node-forge/lib/hmac.js","webpack://decidim-base/./node_modules/node-forge/lib/jsbn.js","webpack://decidim-base/./node_modules/node-forge/lib/md.js","webpack://decidim-base/./node_modules/node-forge/lib/mgf.js","webpack://decidim-base/./node_modules/node-forge/lib/mgf1.js","webpack://decidim-base/./node_modules/node-forge/lib/oids.js","webpack://decidim-base/./node_modules/node-forge/lib/pbe.js","webpack://decidim-base/./node_modules/node-forge/lib/pbkdf2.js","webpack://decidim-base/./node_modules/node-forge/lib/pem.js","webpack://decidim-base/./node_modules/node-forge/lib/pkcs1.js","webpack://decidim-base/./node_modules/node-forge/lib/pkcs12.js","webpack://decidim-base/./node_modules/node-forge/lib/pkcs7.js","webpack://decidim-base/./node_modules/node-forge/lib/pkcs7asn1.js","webpack://decidim-base/./node_modules/node-forge/lib/pki.js","webpack://decidim-base/./node_modules/node-forge/lib/prime.js","webpack://decidim-base/./node_modules/node-forge/lib/prng.js","webpack://decidim-base/./node_modules/node-forge/lib/pss.js","webpack://decidim-base/./node_modules/node-forge/lib/random.js","webpack://decidim-base/./node_modules/node-forge/lib/rc2.js","webpack://decidim-base/./node_modules/node-forge/lib/rsa.js","webpack://decidim-base/./node_modules/node-forge/lib/sha1.js","webpack://decidim-base/./node_modules/node-forge/lib/sha256.js","webpack://decidim-base/./node_modules/node-forge/lib/sha512.js","webpack://decidim-base/./node_modules/node-forge/lib/util.js","webpack://decidim-base/./node_modules/node-forge/lib/x509.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/aes-cbc-hmac-sha2.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/aes-gcm.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/aes-kw.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/concat.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/constants.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/dir.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/ec-util.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/ecdh.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/ecdsa.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/hkdf.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/hmac.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/index.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/pbes2.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/rsa-util.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/rsaes.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/rsassa.js","webpack://decidim-base/./node_modules/node-jose/lib/algorithms/sha.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ciphermodes/gcm/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ciphermodes/gcm/index.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ciphermodes/gcm/multipliers.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ciphermodes/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ciphermodes/pack.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ecc/curves.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ecc/index.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/ecc/math.js","webpack://decidim-base/./node_modules/node-jose/lib/deps/forge.js","webpack://decidim-base/./node_modules/node-jose/lib/index.js","webpack://decidim-base/./node_modules/node-jose/lib/jwe/decrypt.js","webpack://decidim-base/./node_modules/node-jose/lib/jwe/defaults.js","webpack://decidim-base/./node_modules/node-jose/lib/jwe/encrypt.js","webpack://decidim-base/./node_modules/node-jose/lib/jwe/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/jwe/index.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/basekey.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/constants.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/eckey.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/index.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/keystore.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/octkey.js","webpack://decidim-base/./node_modules/node-jose/lib/jwk/rsakey.js","webpack://decidim-base/./node_modules/node-jose/lib/jws/defaults.js","webpack://decidim-base/./node_modules/node-jose/lib/jws/helpers.js","webpack://decidim-base/./node_modules/node-jose/lib/jws/index.js","webpack://decidim-base/./node_modules/node-jose/lib/jws/sign.js","webpack://decidim-base/./node_modules/node-jose/lib/jws/verify.js","webpack://decidim-base/./node_modules/node-jose/lib/parse/compact.js","webpack://decidim-base/./node_modules/node-jose/lib/parse/index.js","webpack://decidim-base/./node_modules/node-jose/lib/parse/json.js","webpack://decidim-base/./node_modules/node-jose/lib/util/algconfig.js","webpack://decidim-base/./node_modules/node-jose/lib/util/base64url.js","webpack://decidim-base/./node_modules/node-jose/lib/util/databuffer.js","webpack://decidim-base/./node_modules/node-jose/lib/util/index.js","webpack://decidim-base/./node_modules/node-jose/lib/util/merge.js","webpack://decidim-base/./node_modules/node-jose/lib/util/utf8.js","webpack://decidim-base/./node_modules/pako/index.js","webpack://decidim-base/./node_modules/pako/lib/deflate.js","webpack://decidim-base/./node_modules/pako/lib/inflate.js","webpack://decidim-base/./node_modules/pako/lib/utils/common.js","webpack://decidim-base/./node_modules/pako/lib/utils/strings.js","webpack://decidim-base/./node_modules/pako/lib/zlib/adler32.js","webpack://decidim-base/./node_modules/pako/lib/zlib/constants.js","webpack://decidim-base/./node_modules/pako/lib/zlib/crc32.js","webpack://decidim-base/./node_modules/pako/lib/zlib/deflate.js","webpack://decidim-base/./node_modules/pako/lib/zlib/gzheader.js","webpack://decidim-base/./node_modules/pako/lib/zlib/inffast.js","webpack://decidim-base/./node_modules/pako/lib/zlib/inflate.js","webpack://decidim-base/./node_modules/pako/lib/zlib/inftrees.js","webpack://decidim-base/./node_modules/pako/lib/zlib/messages.js","webpack://decidim-base/./node_modules/pako/lib/zlib/trees.js","webpack://decidim-base/./node_modules/pako/lib/zlib/zstream.js","webpack://decidim-base/./node_modules/process/browser.js","webpack://decidim-base/../../src/internal/Observable.ts","webpack://decidim-base/../../src/internal/Observer.ts","webpack://decidim-base/../../src/internal/Subject.ts","webpack://decidim-base/../../src/internal/SubjectSubscription.ts","webpack://decidim-base/../../src/internal/Subscriber.ts","webpack://decidim-base/../../src/internal/Subscription.ts","webpack://decidim-base/../../src/internal/config.ts","webpack://decidim-base/../../../src/internal/operators/tap.ts","webpack://decidim-base/../../../src/internal/symbol/observable.ts","webpack://decidim-base/../../../src/internal/symbol/rxSubscriber.ts","webpack://decidim-base/../../../src/internal/util/ObjectUnsubscribedError.ts","webpack://decidim-base/../../../src/internal/util/UnsubscriptionError.ts","webpack://decidim-base/../../../src/internal/util/canReportError.ts","webpack://decidim-base/../../../src/internal/util/hostReportError.ts","webpack://decidim-base/../../../src/internal/util/identity.ts","webpack://decidim-base/../../../src/internal/util/isArray.ts","webpack://decidim-base/../../../src/internal/util/isFunction.ts","webpack://decidim-base/../../../src/internal/util/isObject.ts","webpack://decidim-base/../../../src/internal/util/noop.ts","webpack://decidim-base/../../../src/internal/util/pipe.ts","webpack://decidim-base/../../../src/internal/util/toSubscriber.ts","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/index.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/md5.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/native.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/nil.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/parse.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/regex.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/rng.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/sha1.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/stringify.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/v1.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/v3.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/v35.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/v4.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/v5.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/validate.js","webpack://decidim-base/./node_modules/uuid/dist/commonjs-browser/version.js","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/operations/get_election_log_entries.gql","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/operations/get_log_entry.gql","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/operations/get_pending_message_by_message_id.gql","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/operations/process_key_ceremony_step.gql","webpack://decidim-base/./node_modules/@decidim/decidim-bulletin_board/src/client/operations/process_tally_step.gql","webpack://decidim-base/ignored|/home/contagem/decidim_base/node_modules/node-forge/lib|crypto","webpack://decidim-base/ignored|/home/contagem/decidim_base/node_modules/node-jose/lib/algorithms|crypto","webpack://decidim-base/./node_modules/long/umd/index.js","webpack://decidim-base/../../../src/cache/core/cache.ts","webpack://decidim-base/../../../src/cache/core/types/common.ts","webpack://decidim-base/../../../src/cache/inmemory/entityStore.ts","webpack://decidim-base/../../../src/cache/inmemory/helpers.ts","webpack://decidim-base/../../../src/cache/inmemory/inMemoryCache.ts","webpack://decidim-base/../../../src/cache/inmemory/key-extractor.ts","webpack://decidim-base/../../../src/cache/inmemory/object-canon.ts","webpack://decidim-base/../../../src/cache/inmemory/policies.ts","webpack://decidim-base/../../../src/cache/inmemory/reactiveVars.ts","webpack://decidim-base/../../../src/cache/inmemory/readFromStore.ts","webpack://decidim-base/../../../src/cache/inmemory/writeToStore.ts","webpack://decidim-base/../../src/core/ApolloClient.ts","webpack://decidim-base/../../src/core/LocalState.ts","webpack://decidim-base/../../src/core/ObservableQuery.ts","webpack://decidim-base/../../src/core/QueryInfo.ts","webpack://decidim-base/../../src/core/QueryManager.ts","webpack://decidim-base/../../src/core/equalByQuery.ts","webpack://decidim-base/../../src/core/networkStatus.ts","webpack://decidim-base/../../src/errors/index.ts","webpack://decidim-base/../../../src/link/core/ApolloLink.ts","webpack://decidim-base/../../../src/link/core/execute.ts","webpack://decidim-base/../../../src/link/http/HttpLink.ts","webpack://decidim-base/../../../src/link/http/checkFetcher.ts","webpack://decidim-base/../../../src/link/http/createHttpLink.ts","webpack://decidim-base/../../../src/link/http/iterators/async.ts","webpack://decidim-base/../../../src/link/http/iterators/nodeStream.ts","webpack://decidim-base/../../../src/link/http/iterators/promise.ts","webpack://decidim-base/../../../src/link/http/iterators/reader.ts","webpack://decidim-base/../../../src/link/http/parseAndCheckHttpResponse.ts","webpack://decidim-base/../../../src/link/http/responseIterator.ts","webpack://decidim-base/../../../src/link/http/rewriteURIForGET.ts","webpack://decidim-base/../../../src/link/http/selectHttpOptionsAndBody.ts","webpack://decidim-base/../../../src/link/http/selectURI.ts","webpack://decidim-base/../../../src/link/http/serializeFetchParameter.ts","webpack://decidim-base/../../../src/link/utils/createOperation.ts","webpack://decidim-base/../../../src/link/utils/filterOperationVariables.ts","webpack://decidim-base/../../../src/link/utils/fromError.ts","webpack://decidim-base/../../../src/link/utils/throwServerError.ts","webpack://decidim-base/../../../src/link/utils/transformOperation.ts","webpack://decidim-base/../../../src/link/utils/validateOperation.ts","webpack://decidim-base/../../../src/utilities/common/arrays.ts","webpack://decidim-base/../../../src/utilities/common/canUse.ts","webpack://decidim-base/../../../src/utilities/common/cloneDeep.ts","webpack://decidim-base/../../../src/utilities/common/compact.ts","webpack://decidim-base/../../../src/utilities/common/errorHandling.ts","webpack://decidim-base/../../../src/utilities/common/incrementalResult.ts","webpack://decidim-base/../../../src/utilities/common/makeUniqueId.ts","webpack://decidim-base/../../../src/utilities/common/maybeDeepFreeze.ts","webpack://decidim-base/../../../src/utilities/common/mergeDeep.ts","webpack://decidim-base/../../../src/utilities/common/mergeOptions.ts","webpack://decidim-base/../../../src/utilities/common/objects.ts","webpack://decidim-base/../../../src/utilities/common/stringifyForDisplay.ts","webpack://decidim-base/../../../src/utilities/globals/global.ts","webpack://decidim-base/../../../src/utilities/globals/index.ts","webpack://decidim-base/../../../src/utilities/globals/invariantWrappers.ts","webpack://decidim-base/../../../src/utilities/globals/maybe.ts","webpack://decidim-base/../../../src/utilities/graphql/DocumentTransform.ts","webpack://decidim-base/../../../src/utilities/graphql/directives.ts","webpack://decidim-base/../../../src/utilities/graphql/fragments.ts","webpack://decidim-base/../../../src/utilities/graphql/getFromAST.ts","webpack://decidim-base/../../../src/utilities/graphql/print.ts","webpack://decidim-base/../../../src/utilities/graphql/storeUtils.ts","webpack://decidim-base/../../../src/utilities/graphql/transform.ts","webpack://decidim-base/../../../src/utilities/observables/Concast.ts","webpack://decidim-base/../../../src/utilities/observables/asyncMap.ts","webpack://decidim-base/../../../src/utilities/observables/iteration.ts","webpack://decidim-base/../../../src/utilities/observables/subclassing.ts","webpack://decidim-base/../src/version.ts","webpack://decidim-base/../src/strong.ts","webpack://decidim-base/../src/index.ts","webpack://decidim-base/../src/slot.ts","webpack://decidim-base/./node_modules/graphql/jsutils/devAssert.mjs","webpack://decidim-base/./node_modules/graphql/jsutils/inspect.mjs","webpack://decidim-base/./node_modules/graphql/language/ast.mjs","webpack://decidim-base/./node_modules/graphql/language/blockString.mjs","webpack://decidim-base/./node_modules/graphql/language/characterClasses.mjs","webpack://decidim-base/./node_modules/graphql/language/kinds.mjs","webpack://decidim-base/./node_modules/graphql/language/predicates.mjs","webpack://decidim-base/./node_modules/graphql/language/printString.mjs","webpack://decidim-base/./node_modules/graphql/language/printer.mjs","webpack://decidim-base/./node_modules/graphql/language/visitor.mjs","webpack://decidim-base/../src/context.ts","webpack://decidim-base/../src/dep.ts","webpack://decidim-base/../src/entry.ts","webpack://decidim-base/../src/helpers.ts","webpack://decidim-base/../src/invariant.ts","webpack://decidim-base/./node_modules/tslib/tslib.es6.mjs","webpack://decidim-base/./node_modules/zen-observable-ts/module.js","webpack://decidim-base/webpack/bootstrap","webpack://decidim-base/webpack/runtime/compat get default export","webpack://decidim-base/webpack/runtime/define property getters","webpack://decidim-base/webpack/runtime/global","webpack://decidim-base/webpack/runtime/hasOwnProperty shorthand","webpack://decidim-base/webpack/runtime/make namespace object","webpack://decidim-base/webpack/runtime/node module decorator","webpack://decidim-base/webpack/runtime/publicPath","webpack://decidim-base/../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/entrypoints/decidim_elections_admin.js"],"sourcesContent":["var map = {\n\t\"./decidim/elections/decidim_elections.svg\": \"../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/images/decidim/elections/decidim_elections.svg\",\n\t\"./decidim/votings/decidim_votings.svg\": \"../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/images/decidim/votings/decidim_votings.svg\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"../.rbenv/versions/3.1.1/lib/ruby/gems/3.1.0/gems/decidim-elections-0.28.0/app/packs/images sync recursive ^\\\\.\\\\/.*$\";","import { GraphQLClient } from \"./graphql-client\";\n\nexport const WAIT_TIME_MS = 1_000; // 1s\n\n/**\n * This is a facade over the API client specific implementation.\n */\nexport class Client {\n  /**\n   * Initializes the API client using the same params.\n   *\n   * @constructor\n   * @param {Object} params - An object that include the same params as the API client.\n   */\n  constructor(params) {\n    this.apiClient = new GraphQLClient(params);\n  }\n\n  /**\n   * Query a log entry for the given election unique id and the given content hash.\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} electionUniqueId - The election's unique id.\n   *  - {String} contentHash - The log entry content hash.\n   * @returns {Promise<Array<Object>>} - A log entry.\n   * @throws Will throw an error if the request is rejected.\n   */\n  getLogEntry({ electionUniqueId, contentHash }) {\n    return this.apiClient.getLogEntry({ electionUniqueId, contentHash });\n  }\n\n  /**\n   * Query all log entries for the given election id.\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} electionUniqueId - The election's unique id.\n   *  - {String} after - The last log entry id received, to avoid including those entries again.\n   *  - {Array<String>} types - The list of type of messages to retrieve.\n   * @returns {Promise<Array<Object>>} - A collection of log entries.\n   * @throws Will throw an error if the request is rejected.\n   */\n  getElectionLogEntries(params) {\n    return this.apiClient.getElectionLogEntries(params);\n  }\n\n  /**\n   * Process a key ceremony step sending a signed message.\n   *\n   * @param {Object} params - An object that includes the data to perform the operation.\n   * @returns {Promise<Object>} - A pending message created.\n   * @throws Will throw an error if the request is rejected or the data contains an error.\n   */\n  processKeyCeremonyStep(params) {\n    return this.apiClient.processKeyCeremonyStep(params);\n  }\n\n  /**\n   * Process a tally step sending a signed message.\n   *\n   * @param {Object} params - An object that includes the data to perform the operation.\n   * @returns {Promise<Object>} - A pending message created.\n   * @throws Will throw an error if the request is rejected or the data contains an error.\n   */\n  processTallyStep(params) {\n    return this.apiClient.processTallyStep(params);\n  }\n\n  /**\n   * Wait until a pending message is processed\n   *\n   * @param {String} messageId - the unique identifier of a message\n   * @param {Integer} [waitTime=WAIT_TIME_MS] - the interval to wait for the pending message to be processed\n   * @returns {Promise<Object>} - Returns the PendingMessage\n   */\n  waitForPendingMessageToBeProcessed(messageId, waitTime = WAIT_TIME_MS) {\n    return new Promise((resolve) => {\n      const intervalId = setInterval(() => {\n        this.apiClient\n          .getPendingMessageByMessageId({\n            messageId,\n          })\n          .then((pendingMessage) => {\n            if (pendingMessage.status !== \"enqueued\") {\n              clearInterval(intervalId);\n              resolve(pendingMessage);\n            }\n          });\n      }, waitTime);\n    });\n  }\n}\n","import { ApolloClient, InMemoryCache, HttpLink } from \"@apollo/client/core\";\n\nimport GET_ELECTION_LOG_ENTRIES from \"./operations/get_election_log_entries\";\nimport PROCESS_KEY_CEREMONY_STEP from \"./operations/process_key_ceremony_step\";\nimport PROCESS_TALLY_STEP from \"./operations/process_tally_step\";\nimport GET_LOG_ENTRY from \"./operations/get_log_entry\";\nimport GET_PENDING_MESSAGE_BY_MESSAGE_ID from \"./operations/get_pending_message_by_message_id\";\n\n/**\n * This is the Bulletin Board API client that will use Apollo's client to\n * interact with our GraphQL schema using both http and websocket connections.\n */\nexport class GraphQLClient {\n  /**\n   * Initializes the class given the correct params. Since we need to handle\n   * both http and websocket connections we need to create two links and use either\n   * of them depending on the GraphQL operation.\n   *\n   * @constructor\n   * @param {Object} params - An object that include the following options.\n   *  - {String} apiEndpointUrl - The http endpoint used to perform queries and mutations.\n   *  - {Object?} headers - An optional object of headers to be included on http requests.\n   */\n  constructor({ apiEndpointUrl, headers }) {\n    const httpLink = new HttpLink({\n      uri: apiEndpointUrl,\n      headers,\n    });\n\n    this.apolloClient = new ApolloClient({\n      link: httpLink,\n      cache: new InMemoryCache(),\n    });\n  }\n\n  /**\n   * Query a log entry for the given election unique id and the given content hash.\n   *\n   * @param {Object} params - An object that includes the following options.\n   *  - {String} electionUniqueId - The election's unique id.\n   *  - {String} contentHash - The log entry content hash.\n   * @returns {Promise<Array<Object>>} - A log entry.\n   * @throws Will throw an error if the request is rejected.\n   */\n  async getLogEntry({ electionUniqueId, contentHash }) {\n    const result = await this.apolloClient.query({\n      query: GET_LOG_ENTRY,\n      variables: {\n        electionUniqueId,\n        contentHash,\n      },\n    });\n    return result.data.logEntry;\n  }\n\n  /**\n   * Query all log entries for the given election unique id.\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} electionUniqueId - The election's unique id.\n   *  - {String} after - The last log entry id received, to avoid including those entries again.\n   *  - {Array<String>} types - The list of type of messages to retrieve.\n   * @returns {Promise<Array<Object>>} - A collection of log entries.\n   * @throws Will throw an error if the request is rejected.\n   */\n  async getElectionLogEntries({ electionUniqueId, after, types }) {\n    const result = await this.apolloClient.query({\n      query: GET_ELECTION_LOG_ENTRIES,\n      variables: {\n        electionUniqueId,\n        after,\n        types,\n      },\n      fetchPolicy: \"no-cache\",\n    });\n\n    return result.data.election.logEntries;\n  }\n\n  /**\n   * Process a key ceremony step sending a signed message.\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} messageId - The message id.\n   *  - {String} signedData - The signed data to be processed.\n   * @returns {Promise<Object>} - A pending message created.\n   * @throws Will throw an error if the request is rejected or the data contains an error.\n   */\n  async processKeyCeremonyStep({ messageId, signedData }) {\n    const result = await this.apolloClient.mutate({\n      mutation: PROCESS_KEY_CEREMONY_STEP,\n      variables: {\n        messageId,\n        signedData,\n      },\n    });\n\n    if (result.data.processKeyCeremonyStep.error) {\n      throw new Error(result.data.processKeyCeremonyStep.error);\n    }\n\n    return result.data.processKeyCeremonyStep.pendingMessage;\n  }\n\n  /**\n   * Query PendingMessages for a given messageId\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} messageId - The messageId\n   * @returns {Promise<Object>} - The pending message received.\n   * @throws Will throw an error if the request is rejected.\n   */\n  async getPendingMessageByMessageId({ messageId }) {\n    const result = await this.apolloClient.query({\n      query: GET_PENDING_MESSAGE_BY_MESSAGE_ID,\n      variables: {\n        messageId,\n      },\n    });\n\n    return result.data.pendingMessage;\n  }\n\n  /**\n   * Process a tally step sending a signed message.\n   *\n   * @param {Object} params - An object that include the following options.\n   *  - {String} messageId - The message id.\n   *  - {String} signedData - The signed data to be processed.\n   * @returns {Promise<Object>} - A pending message created.\n   * @throws Will throw an error if the request is rejected or the data contains an error.\n   */\n  async processTallyStep({ messageId, signedData }) {\n    const result = await this.apolloClient.mutate({\n      mutation: PROCESS_TALLY_STEP,\n      variables: {\n        messageId,\n        signedData,\n      },\n    });\n\n    if (result.data.processTallyStep.error) {\n      throw new Error(result.data.processTallyStep.error);\n    }\n\n    return result.data.processTallyStep.pendingMessage;\n  }\n}\n","export const AUTHORITY_TYPE = \"a\";\nexport const BULLETIN_BOARD_TYPE = \"b\";\nexport const VOTER_TYPE = \"v\";\nexport const TRUSTEE_TYPE = \"t\";\nexport const VALID_TYPES = [\n  AUTHORITY_TYPE,\n  BULLETIN_BOARD_TYPE,\n  VOTER_TYPE,\n  TRUSTEE_TYPE,\n];\n\n/**\n * This is a class that handles message id strings.\n */\nexport class MessageIdentifier {\n  /**\n   * Parses a message id string into a JS object.\n   *\n   * @param {String} messageId - A string with a message id.\n   * @returns {Object} - An object with the message id values.\n   */\n  static parse(messageId) {\n    const [elements, author] = messageId.split(\"+\");\n    const [authority, electionId, type, subtype] = elements.split(\".\", 4);\n    const [authorType, authorId] = author.split(\".\", 2);\n    const dotSubtype = subtype ? `.${subtype}` : \"\";\n\n    if (!VALID_TYPES.includes(authorType)) {\n      throw new Error(\"Invalid message identifier format\");\n    }\n\n    return {\n      electionId: `${authority}.${electionId}`,\n      type,\n      subtype,\n      typeSubtype: `${type}${dotSubtype}`,\n      author: {\n        type: authorType,\n        id: authorId,\n      },\n    };\n  }\n\n  static format(electionId, typeSubtype, authorType, authorId) {\n    return `${electionId}.${typeSubtype}+${authorType}.${authorId}`;\n  }\n}\n","import { JWS, JWK } from \"node-jose\";\nimport {\n  MessageIdentifier,\n  AUTHORITY_TYPE,\n  BULLETIN_BOARD_TYPE,\n  TRUSTEE_TYPE,\n} from \"./message-identifier\";\nimport { samePublicKeys } from \"../utils\";\n\n/**\n * Verify and parses JWT tokens.\n */\nexport class MessageParser {\n  /**\n   * Initializes the class with the given params.\n   *\n   * @constructor\n   * @param {Object} params - An object that contains the initialization params.\n   * - {String} authorityPublicKeyJSON - The public key of the authority\n   */\n  constructor({ authorityPublicKeyJSON }) {\n    this.authorityPublicKeyJSON = authorityPublicKeyJSON;\n    this.authorityPublicKey = JWK.asKey(authorityPublicKeyJSON, \"json\");\n    this.keys = null;\n  }\n\n  /**\n   * Parses the given token only if it can be verified.\n   *\n   * @param {String} token - A JWT token.\n   * @returns {Promise<Object>} - The payload included in the token.\n   * @throws An error is thrown if the payload is not a valid JSON or the token\n   *         cannot be verified.\n   */\n  async parse({ messageId, signedData }) {\n    const messageIdentifier = MessageIdentifier.parse(messageId);\n    const senderKey = await (this.keys\n      ? this.keys[messageIdentifier.author.type][messageIdentifier.author.id]\n      : this.authorityPublicKey);\n\n    if (!signedData) {\n      return { messageIdentifier, decodedData: null };\n    }\n\n    const result = await JWS.createVerify(senderKey).verify(signedData, {\n      algorithms: [\"RS256\"],\n    });\n\n    const decodedData = JSON.parse(\n      new TextDecoder(\"utf-8\").decode(result.payload),\n    );\n\n    if (!this.keys) {\n      this.keys = await this.parseCreateElection(decodedData);\n    }\n\n    return { messageIdentifier, decodedData };\n  }\n\n  /* eslint-disable camelcase */\n  async parseCreateElection({ authority, bulletin_board, trustees }) {\n    if (!samePublicKeys(authority.public_key, this.authorityPublicKeyJSON)) {\n      throw new Error(\n        \"The authority public key doesn't match the election's authority public key.\",\n      );\n    }\n\n    const result = {\n      [AUTHORITY_TYPE]: { [authority.slug]: this.authorityPublicKey },\n      [BULLETIN_BOARD_TYPE]: {},\n      [TRUSTEE_TYPE]: {},\n    };\n\n    const promises = [];\n    promises.push(\n      this.loadKey(bulletin_board).then((key) => {\n        result[BULLETIN_BOARD_TYPE][bulletin_board.slug] = key;\n      }),\n    );\n    for (const trustee of trustees) {\n      promises.push(\n        this.loadKey(trustee).then((key) => {\n          result[TRUSTEE_TYPE][trustee.slug] = key;\n        }),\n      );\n    }\n\n    await Promise.all(promises);\n\n    return result;\n  }\n  /* eslint-enable camelcase */\n\n  loadKey(client) {\n    return JWK.asKey(client.public_key, \"json\");\n  }\n}\n","import { MessageIdentifier, TRUSTEE_TYPE } from \"../client/message-identifier\";\n\nexport const WAIT_TIME_MS = 2_000; // 2s\n\n/**\n * Handles the election state and includes some methods to interact with the election log.\n */\nexport class Election {\n  /**\n   * Initializes the class with the given params.\n   *\n   * @constructor\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {String} uniqueId - The unique identifier of an election.\n   *  - {Client} bulletinBoardClient - An instance of the Bulletin Board Client\n   *  - {Array<String>} typesFilter - The list of type of messages to retrieve.\n   *  - {Object?} options - An optional object with some extra options.\n   */\n  constructor({ uniqueId, bulletinBoardClient, typesFilter, options }) {\n    this.uniqueId = uniqueId;\n    this.bulletinBoardClient = bulletinBoardClient;\n    this.logEntries = [];\n    this.typesFilter = typesFilter;\n    this.subscriptionId = null;\n    this.options = options || { waitUntilNextCheck: WAIT_TIME_MS };\n  }\n\n  /**\n   * Store the election log entries and periodically check if there are new entries.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async subscribeToLogEntriesChanges() {\n    this.unsubscribeToLogEntriesChanges();\n\n    // Ensure that we get the current log entries before starting the subscription.\n    await this.getLogEntries();\n\n    this.subscriptionId = setInterval(() => {\n      this.getLogEntries();\n    }, this.options.waitUntilNextCheck);\n  }\n\n  /**\n   * Clear the periodically checks of new log entries.\n   *\n   * @returns {undefined}\n   */\n  unsubscribeToLogEntriesChanges() {\n    if (this.subscriptionId !== null) {\n      clearInterval(this.subscriptionId);\n      this.subscriptionId = null;\n    }\n  }\n\n  /**\n   * Return the last message stored in the log sent by the given trustee.\n   *\n   * @param {String} trusteeId - The unique identifier of a trustee.\n   * @returns {Object|null}\n   */\n  getLastMessageFromTrustee(trusteeId) {\n    for (let i = this.logEntries.length - 1; i >= 0; i--) {\n      const logEntry = this.logEntries[i];\n      const messageIdentifier = MessageIdentifier.parse(logEntry.messageId);\n      if (\n        messageIdentifier.author.type === TRUSTEE_TYPE &&\n        messageIdentifier.author.id === trusteeId\n      ) {\n        return logEntry;\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Uses the bulletin board client to get all the election log entries after the\n   * last log entry stored in the election's state.\n   *\n   * @private\n   * @returns {Promise<nothing>}\n   */\n  getLogEntries() {\n    const lastLogEntry = this.logEntries[this.logEntries.length - 1];\n    const after = (lastLogEntry && lastLogEntry.id) || null;\n\n    return new Promise((resolve) => {\n      this.bulletinBoardClient\n        .getElectionLogEntries({\n          electionUniqueId: this.uniqueId,\n          after,\n          types: this.typesFilter,\n        })\n        .then((logEntries) => {\n          if (logEntries.length) {\n            this.logEntries = [...this.logEntries, ...logEntries];\n          }\n          resolve();\n        });\n    });\n  }\n}\n","import { Client } from \"./client/client\";\nimport { Election } from \"./election/election\";\nimport { Trustee } from \"./trustee/trustee\";\nimport { Voter } from \"./voter/voter\";\nimport { MessageParser } from \"./client/message-parser\";\nimport { MessageIdentifier } from \"./client/message-identifier\";\nimport { MESSAGE_RECEIVED, MESSAGE_PROCESSED } from \"./trustee/event_manager\";\nimport { IdentificationKeys } from \"./trustee/identification_keys\";\nimport { KeyCeremonyComponent } from \"./key-ceremony/key-ceremony.component\";\nimport { TallyComponent } from \"./tally/tally.component\";\nimport { VoteComponent } from \"./vote/vote.component\";\n\nexport {\n  Client,\n  Election,\n  Trustee,\n  Voter,\n  MessageParser,\n  MessageIdentifier,\n  MESSAGE_PROCESSED,\n  MESSAGE_RECEIVED,\n  IdentificationKeys,\n  KeyCeremonyComponent,\n  TallyComponent,\n  VoteComponent,\n};\n","// Components\nimport { TrusteeComponent } from \"../trustee/trustee.component\";\n\n/**\n * This class is used to bind any UI elements to a key ceremony process.\n */\nexport class KeyCeremonyComponent extends TrusteeComponent {\n  /**\n   * Setup the election for the trustee.\n   *\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {Object} bulletinBoardClientParams - An object to configure the bulletin board client.\n   *  - {String} electionUniqueId - The unique identifier of an election.\n   *  - {Number} authorizationExpirationTimestamp - The timestamp until the authorization header is no longer valid.\n   *\n   * @returns {Promise<undefined>}\n   */\n  setupElection({\n    bulletinBoardClientParams,\n    electionUniqueId,\n    authorizationExpirationTimestamp,\n  }) {\n    return this.setupElectionWithTypesFilter({\n      electionUniqueId,\n      bulletinBoardClientParams,\n      authorizationExpirationTimestamp,\n      typesFilter: [\n        \"create_election\",\n        \"start_key_ceremony\",\n        \"key_ceremony\",\n        \"end_key_ceremony\",\n      ],\n    });\n  }\n\n  /**\n   * Bind UI events to the key ceremony process.\n   *\n   * @method bindEvents\n   * @param {Object} eventCallbacks - An object that contains event callback functions.\n   * - {Function} onEvent - a function that is called when an event is emitted from the trustee.\n   * - {Function} onBindRestoreButton - a function that receives a callback function that will be called when\n   *                                    the restore process must be started.\n   * - {Function} onBindStartButton - a function that receives a callback function that will be called when\n   *                                  the key ceremony must be started.\n   * - {Function} onRestore - a function that is called when the trustee is restored.\n   * - {Function} onComplete - a function that is called when the key ceremony is done.\n   * - {Function} onStart - a function that is called when the key ceremony has started.\n   * - {Function} onTrusteeNeedsToBeRestored - a function that is called when the trustee must be restored.\n   * - {Function} onBackupNeeded - a function that is called when the trustee backup is required.\n   * - {Function} onBindBackupButton - a function that receives a callback function that will be called when\n   *                                   the trustee backup must be started.\n   * - {Function} onBackupStarted - a function that is called when the backup has started.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async bindEvents({\n    onEvent,\n    onBindRestoreButton,\n    onBindStartButton,\n    onRestore,\n    onComplete,\n    onStart,\n    onTrusteeNeedsToBeRestored,\n    onBackupNeeded,\n    onBindBackupButton,\n    onBackupStarted,\n  }) {\n    const onSetupDone = await this.trustee.setup();\n\n    this.trustee.events.subscribe(onEvent);\n\n    onBindStartButton(async (event) => {\n      onStart();\n      event.preventDefault();\n\n      await onSetupDone;\n\n      if (await this.trustee.needsToBeRestored()) {\n        onTrusteeNeedsToBeRestored();\n      } else {\n        const keyCeremonySetup = this.trustee.setupKeyCeremony();\n        const { value: backupData } = await keyCeremonySetup.next();\n\n        onBackupNeeded();\n        onBindBackupButton(\n          backupData,\n          `${this.trustee.uniqueId}-election-${this.trustee.election.uniqueId}.bak`,\n          async () => {\n            onBackupStarted();\n            await keyCeremonySetup.next();\n            await this.trustee.runKeyCeremony();\n            onComplete();\n          },\n        );\n      }\n    });\n\n    onBindRestoreButton(async (event) => {\n      await onSetupDone;\n      const file = event.target.files[0];\n      const reader = new FileReader();\n      reader.onload = async ({ target }) => {\n        const content = target.result;\n        if (await this.trustee.restore(content)) {\n          onRestore();\n          await this.trustee.runKeyCeremony();\n          onComplete();\n        }\n      };\n      reader.readAsText(file);\n    });\n  }\n}\n","// Components\nimport { TrusteeComponent } from \"../trustee/trustee.component\";\n\n/**\n * This class is used to bind any UI elements to a tally process.\n */\nexport class TallyComponent extends TrusteeComponent {\n  /**\n   * Setup the election for the trustee.\n   *\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {Object} bulletinBoardClientParams - An object to configure the bulletin board client.\n   *  - {String} electionUniqueId - The unique identifier of an election.\n   *  - {Number} authorizationExpirationTimestamp - The timestamp until the authorization header is no longer valid.\n   *\n   * @returns {Promise<undefined>}\n   */\n  setupElection({\n    bulletinBoardClientParams,\n    electionUniqueId,\n    authorizationExpirationTimestamp,\n  }) {\n    return this.setupElectionWithTypesFilter({\n      electionUniqueId,\n      bulletinBoardClientParams,\n      authorizationExpirationTimestamp,\n      typesFilter: [\n        \"create_election\",\n        \"start_key_ceremony\",\n        \"key_ceremony\",\n        \"end_key_ceremony\",\n        \"start_tally\",\n        \"tally\",\n        \"end_tally\",\n      ],\n    });\n  }\n\n  /**\n   * Bind UI events to the key ceremony process.\n   *\n   * @method bindEvents\n   * @param {Object} eventCallbacks - An object that contains event callback functions.\n   * - {Function} onEvent - a function that is called when an event is emitted from the trustee.\n   * - {Function} onBindRestoreButton - a function that receives a callback function that will be called when\n   *                                    the restore process must be started.\n   * - {Function} onBindStartButton - a function that receives a callback function that will be called when\n   *                                  the key ceremony must be started.\n   * - {Function} onRestore - a function that is called when the trustee is restored.\n   * - {Function} onComplete - a function that is called when the key ceremony is done.\n   * - {Function} onStart - a function that is called when the key ceremony has started.\n   * - {Function} onTrusteeNeedsToBeRestored - a function that is called when the trustee must be restored.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async bindEvents({\n    onEvent,\n    onBindRestoreButton,\n    onBindStartButton,\n    onRestore,\n    onComplete,\n    onStart,\n    onTrusteeNeedsToBeRestored,\n  }) {\n    const onSetupDone = this.trustee.setup();\n\n    this.trustee.events.subscribe(onEvent);\n\n    onBindStartButton(async (event) => {\n      onStart();\n      event.preventDefault();\n\n      await onSetupDone;\n\n      if (await this.trustee.needsToBeRestored()) {\n        onTrusteeNeedsToBeRestored();\n      } else {\n        await this.trustee.runTally();\n        onComplete();\n      }\n    });\n\n    onBindRestoreButton(async (event) => {\n      await onSetupDone;\n      const file = event.target.files[0];\n      const reader = new FileReader();\n      reader.onload = async ({ target }) => {\n        const content = target.result;\n        if (await this.trustee.restore(content)) {\n          onRestore();\n          await this.trustee.runTally();\n          onComplete();\n        }\n      };\n      reader.readAsText(file);\n    });\n  }\n}\n","import { Subject } from \"rxjs\";\nimport { tap } from \"rxjs/operators\";\n\nexport const MESSAGE_RECEIVED = \"[Message] Received\";\nexport const MESSAGE_PROCESSED = \"[Message] Processed\";\n\n/**\n * This class encapsulates a stream of events that can be used by other classes.\n */\nexport class EventManager {\n  /**\n   * Initializes an empty stream of events.\n   *\n   * @constructor\n   */\n  constructor() {\n    this.events = new Subject();\n  }\n\n  /**\n   * Receives a callback function and creates a new stream that will call\n   * that function whenever a new event is emitted.\n   *\n   * @param {fn} Function - A callback function.\n   * @returns {Subscription}\n   */\n  subscribe(fn) {\n    return this.events.pipe(tap(fn)).subscribe();\n  }\n\n  /**\n   * Emits a new \"message received\" event through the stream.\n   *\n   * @returns {undefined}\n   */\n  broadcastMessageReceived(message) {\n    this.events.next({\n      type: MESSAGE_RECEIVED,\n      message,\n    });\n  }\n\n  /**\n   * Emits a new \"message processed\" event through the stream.\n   *\n   * @returns {undefined}\n   */\n  broadcastMessageProcessed(message, result) {\n    this.events.next({\n      type: MESSAGE_PROCESSED,\n      message,\n      result,\n    });\n  }\n}\n","/**\n * IdentificationKeys component.\n */\n\nimport { samePublicKeys } from \"../utils\";\n\nexport class IdentificationKeys {\n  constructor(trusteeUniqueId, storedPublicKey) {\n    this.format = \"jwk\";\n    this.algorithm = {\n      name: \"RSASSA-PKCS1-v1_5\",\n      modulusLength: 4096,\n      publicExponent: new Uint8Array([0x01, 0x00, 0x01]),\n      hash: { name: \"SHA-256\" },\n    };\n    this.usages = [\"sign\"];\n    this.publicKeyAttrs = [\"alg\", \"e\", \"kty\", \"n\"];\n    this.jwtHeader = this._encode64(\n      JSON.stringify({ alg: \"RS256\", typ: \"JWT\" }),\n    );\n\n    this.trusteeUniqueId = trusteeUniqueId;\n    this.privateKey = null;\n    this.publicKey = null;\n    this.storedPublicKey = JSON.parse(storedPublicKey || null);\n    this.keyIdentifier = `${trusteeUniqueId}-private-key`;\n    this.browserSupport = this._checkBrowserSupport();\n    this.textEncoder = new TextEncoder(\"utf-8\");\n\n    this.dbName = \"identification_keys\";\n    this.dbVersion = 1;\n    this.presentPromise = this._read();\n  }\n\n  present(then) {\n    this.presentPromise.then(() => {\n      if (this._matchesStoredPublicKey(this.publicKey)) {\n        then(this.browserSupport && this.privateKey !== null);\n      } else {\n        this.reset().then(then(false));\n      }\n    });\n  }\n\n  async generate() {\n    if (!this.browserSupport || this.storedPublicKey) {\n      return false;\n    }\n\n    return new Promise((resolve, reject) => {\n      try {\n        return this.crypto.subtle\n          .generateKey(this.algorithm, true, this.usages)\n          .then((keyPair) => {\n            return this.crypto.subtle\n              .exportKey(this.format, keyPair.privateKey)\n              .then((jwk) => {\n                this.publicKey = this._publicKeyFromPrivateKey(jwk);\n                const element = document.createElement(\"a\");\n                element.setAttribute(\n                  \"href\",\n                  `data:text/plain;charset=utf-8,${encodeURIComponent(\n                    JSON.stringify(jwk),\n                  )}`,\n                );\n                element.setAttribute(\"download\", `${this.keyIdentifier}.jwk`);\n                element.style.display = \"none\";\n                document.body.appendChild(element);\n                element.click();\n                document.body.removeChild(element);\n                return resolve();\n              })\n              .catch(this._handleErrors);\n          });\n      } catch (error) {\n        return reject(error);\n      }\n    });\n  }\n\n  async upload(event) {\n    if (!this.browserSupport || this.privateKey !== null) {\n      return false;\n    }\n\n    return new Promise((resolve, reject) => {\n      if (event) {\n        this.onUploadInputChange(event, resolve, reject);\n      } else {\n        const element = document.createElement(\"input\");\n        element.setAttribute(\"type\", \"file\");\n        element.setAttribute(\"accept\", \".jwk\");\n        element.style.display = \"none\";\n        document.body.appendChild(element);\n\n        element.addEventListener(\"change\", (event) => {\n          document.body.removeChild(element);\n          this.onUploadInputChange(event, resolve, reject);\n        });\n        element.click();\n      }\n    });\n  }\n\n  onUploadInputChange(event, resolve, reject) {\n    const reader = new FileReader();\n    reader.readAsText(event.target.files[0]);\n    reader.onload = (readEvent) => {\n      let jwk = \"\";\n      try {\n        jwk = JSON.parse(readEvent.target.result);\n      } catch (error) {\n        return reject(\"invalid_format\");\n      }\n\n      return this.crypto.subtle\n        .importKey(this.format, jwk, this.algorithm, false, this.usages)\n        .then((privateKey) => {\n          const uploadedPublicKey = this._publicKeyFromPrivateKey(jwk);\n          if (this._matchesStoredPublicKey(uploadedPublicKey)) {\n            this.publicKey = uploadedPublicKey;\n            this.privateKey = privateKey;\n            this._save()\n              .then(() => resolve(true))\n              .catch(() => {\n                reject(\"could not be saved\");\n              });\n          } else {\n            reject(\"invalid_public_key\");\n          }\n        })\n        .catch(() => {\n          reject(\"invalid_key\");\n        });\n    };\n  }\n\n  reset() {\n    this.privateKey = this.publicKey = null;\n    return this._clear();\n  }\n\n  async sign(payload) {\n    if (!this.browserSupport || this.privateKey === null) {\n      return false;\n    }\n\n    const data = `${this.jwtHeader}.${this._encode64(JSON.stringify(payload))}`;\n    const signature = await this.crypto.subtle.sign(\n      this.algorithm,\n      this.privateKey,\n      this.textEncoder.encode(data),\n    );\n    return `${data}.${btoa(\n      Reflect.apply(String.fromCharCode, null, new Uint8Array(signature)),\n    )\n      .replace(/[=]/g, \"\")\n      .replace(/\\+/g, \"-\")\n      .replace(/\\//g, \"_\")}`;\n  }\n\n  _checkBrowserSupport() {\n    this.indexedDB =\n      window.indexedDB ||\n      window.mozIndexedDB ||\n      window.webkitIndexedDB ||\n      window.msIndexedDB;\n    this.crypto = window.crypto || window.msCrypto;\n    return window.indexedDB && window.crypto;\n  }\n\n  _handleErrors(error) {\n    throw error;\n  }\n\n  _publicKeyFromPrivateKey(jwk) {\n    return Object.keys(jwk)\n      .filter((key) => this.publicKeyAttrs.includes(key))\n      .reduce((obj, key) => {\n        obj[key] = jwk[key];\n        return obj;\n      }, {});\n  }\n\n  _matchesStoredPublicKey(publicKey) {\n    return samePublicKeys(publicKey, this.storedPublicKey);\n  }\n\n  _encode64(payload) {\n    return btoa(unescape(encodeURIComponent(payload)))\n      .replace(/[=]/g, \"\")\n      .replace(/\\+/g, \"-\")\n      .replace(/\\//g, \"_\");\n  }\n\n  async _read() {\n    return this._useDb(\"readonly\", (store) => {\n      store.get(this.keyIdentifier).onsuccess = (event) => {\n        if (event.target.result) {\n          this.privateKey = event.target.result.privateKey;\n          this.publicKey = event.target.result.publicKey;\n        }\n      };\n    });\n  }\n\n  async _save() {\n    return this._useDb(\"readwrite\", (store) => {\n      store.add(\n        {\n          privateKey: this.privateKey,\n          publicKey: this.publicKey,\n        },\n        this.keyIdentifier,\n      );\n    });\n  }\n\n  async _clear() {\n    return this._useDb(\"readwrite\", (store) => {\n      store.delete(this.keyIdentifier);\n    });\n  }\n\n  async _useDb(mode, operation) {\n    return new Promise((resolve, reject) => {\n      let db = null;\n      const dbReq = this.indexedDB.open(this.dbName, this.dbVersion);\n\n      dbReq.onerror = (error) => {\n        db = null;\n        reject(error);\n      };\n\n      dbReq.onupgradeneeded = () => {\n        db = dbReq.result;\n        db.createObjectStore(\"IdentificationKeys\");\n      };\n\n      dbReq.onsuccess = () => {\n        db = dbReq.result;\n        const tx = db.transaction([\"IdentificationKeys\"], mode);\n\n        operation(tx.objectStore(\"IdentificationKeys\"));\n\n        tx.oncomplete = () => {\n          db.close();\n          resolve();\n        };\n      };\n    });\n  }\n}\n","import { Trustee } from \"./trustee\";\nimport { Client } from \"../client/client\";\nimport { Election } from \"../election/election\";\n\n/**\n * This class is used to bind any UI elements to a trustee process.\n * @abstract\n */\nexport class TrusteeComponent {\n  /**\n   * Initialises the class with the given params.\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {String} authorityPublicKeyJSON - The authority identification public key.\n   *  - {String} trusteeUniqueId - The unique identifier of a trustee.\n   *  - {Object} trusteeIdentificationKeys - An object that contains both the public and private key for\n   *                                         the corresponding trustee.\n   *  - {Object} trusteeWrapperAdapter - An object to interact with the trustee wrapper.\n   * @constructor\n   */\n  constructor({\n    authorityPublicKeyJSON,\n    trusteeUniqueId,\n    trusteeIdentificationKeys,\n    trusteeWrapperAdapter,\n  }) {\n    this.trustee = new Trustee({\n      uniqueId: trusteeUniqueId,\n      authorityPublicKeyJSON,\n      identificationKeys: trusteeIdentificationKeys,\n      wrapperAdapter: trusteeWrapperAdapter,\n    });\n  }\n\n  /**\n   * Setup the election for the trustee.\n   *\n   * @abstract\n   * @returns {Promise<undefined>}\n   */\n  async setupElection() {\n    throw new Error(\"not implemented\");\n  }\n\n  /**\n   * Setup the election for the trustee.\n   *\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {Object} bulletinBoardClientParams - An object to configure the bulletin board client.\n   *  - {String} electionUniqueId - The unique identifier of an election.\n   *  - {Number} authorizationExpirationTimestamp - The timestamp until the authorization header is no longer valid.\n   *  - {Array<String>} typesFilter - A collection of message ids to be included in the log entry query.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async setupElectionWithTypesFilter({\n    bulletinBoardClientParams,\n    electionUniqueId,\n    authorizationExpirationTimestamp,\n    typesFilter,\n  }) {\n    const [authorityId] = electionUniqueId.split(\".\");\n    const trusteeUniqueIdHeader = `${authorityId}.${this.trustee.uniqueId}`;\n    const authorizationHeader = await this.trustee.signMessage({\n      trustee_unique_id: trusteeUniqueIdHeader,\n      exp: authorizationExpirationTimestamp,\n    });\n\n    const bulletinBoardClient = new Client({\n      ...bulletinBoardClientParams,\n      headers: {\n        Authorization: authorizationHeader,\n        TrusteeUniqueId: trusteeUniqueIdHeader,\n      },\n    });\n\n    const election = new Election({\n      uniqueId: electionUniqueId,\n      bulletinBoardClient,\n      typesFilter,\n    });\n\n    this.trustee.election = election;\n  }\n\n  /**\n   * Bind UI events to the key ceremony process.\n   *\n   * @abstract\n   * @returns {Promise<undefined>}\n   */\n  async bindEvents() {\n    throw new Error(\"not implemented\");\n  }\n}\n","/* eslint-disable camelcase */\nimport { EventManager } from \"./event_manager\";\nimport { MessageParser } from \"../client/message-parser\";\nimport { MessageIdentifier, TRUSTEE_TYPE } from \"../client/message-identifier\";\n\nexport const WAIT_TIME_MS = 100; // 0.1s\n\n/**\n * This class encapsulates all the behavior that is needed to interact with the evoting\n * system as a Trustee role.\n */\nexport class Trustee {\n  /**\n   * Initializes the class with the given params.\n   *\n   * @constructor\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {String} uniqueId - The trustee identifier.\n   *  - {String} authorityPublicKeyJSON - The authority identification public key.\n   *  - {Object} identificationKeys - A object that contains both the public and private key for\n   *                                  the corresponding trustee.\n   *  - {Object} wrapperAdapter - An object to interact with the trustee wrapper.\n   *  - {Object?} options - An optional object with some extra options.\n   */\n  constructor({\n    uniqueId,\n    authorityPublicKeyJSON,\n    identificationKeys,\n    wrapperAdapter,\n    options,\n  }) {\n    this.uniqueId = uniqueId;\n    this.identificationKeys = identificationKeys;\n    this.election = null;\n    this.options = options || { waitUntilNextCheck: WAIT_TIME_MS };\n    this.wrapperAdapter = wrapperAdapter;\n    this.parser = new MessageParser({ authorityPublicKeyJSON });\n    this.events = new EventManager();\n    this.nextLogEntryIndexToProcess = 0;\n    this.lastMessageProcessedWithResult = null;\n    this.hasSetupKeyCeremony = false;\n  }\n\n  /**\n   * Performs some operations to setup the trustee.\n   *\n   * Initializes a subscription to store new log entries for the given election.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async setup() {\n    if (this.election === null) {\n      throw new Error(\"election is not set.\");\n    }\n    await this.wrapperAdapter.setup();\n    return this.election.subscribeToLogEntriesChanges();\n  }\n\n  /**\n   * Performs some operations to clean up after the key ceremony is done.\n   *\n   * @returns {undefined}\n   */\n  tearDown() {\n    this.election.unsubscribeToLogEntriesChanges();\n  }\n\n  /**\n   * Setup the key ceremony process processing the first log entry and yielding its result.\n   * Then it sends the result to the bulletin board and mark the setup as done.\n   *\n   * @generator\n   * @yields {String} - The state of the trustee to be able to perform future restores.\n   * @returns {Promise<Boolean>}\n   */\n  async *setupKeyCeremony() {\n    let message;\n    while (!message) {\n      message = await this.waitForNextLogEntryResult();\n    }\n\n    yield await this.wrapperAdapter.backup();\n    await this.processKeyCeremonyStep(message);\n    this.hasSetupKeyCeremony = true;\n    return this.hasSetupKeyCeremony;\n  }\n\n  /**\n   * Starts or continues with the key ceremony process.\n   *\n   * @returns {Promise<Object|undefined>}\n   * @throws An exception is raised if the trustee needs to be restored or\n   *         there is a problem with the client.\n   */\n  async runKeyCeremony() {\n    if (!this.hasSetupKeyCeremony) {\n      throw new Error(\"The key ceremony has not been setup yet\");\n    }\n\n    if (await this.needsToBeRestored()) {\n      throw new Error(\"You need to restore the wrapper state to continue\");\n    }\n\n    return this.waitForNextLogEntryResult().then(async (message) => {\n      await this.processKeyCeremonyStep(message);\n\n      if (await this.wrapperAdapter.isKeyCeremonyDone()) {\n        return this.tearDown();\n      }\n\n      return this.runKeyCeremony();\n    });\n  }\n\n  /**\n   * Starts or continues with the tally process.\n   *\n   * @returns {Promise<Object|undefined>}\n   * @throws An exception is raised if the trustee needs to be restored or\n   *         there is a problem with the client.\n   */\n  async runTally() {\n    if (await this.needsToBeRestored()) {\n      throw new Error(\"You need to restore the wrapper state to continue\");\n    }\n\n    return this.waitForNextLogEntryResult().then(async (message) => {\n      await this.processTallyStep(message);\n\n      if (await this.wrapperAdapter.isTallyDone()) {\n        return this.tearDown();\n      }\n\n      return this.runTally();\n    });\n  }\n\n  /**\n   * Whether the trustee state needs to be restored or not.\n   *\n   * @returns {Promise<Boolean>}\n   */\n  async needsToBeRestored() {\n    const lastMessageFromTrustee = this.election.getLastMessageFromTrustee(\n      this.uniqueId,\n    );\n\n    return lastMessageFromTrustee && (await this.wrapperAdapter.isFresh());\n  }\n\n  /**\n   * Restore the trustee state from the given state string. It uses the last message sent to check that the state is valid.\n   *\n   * @param {string} wrapperState - As string with the trustee state retrieved from the backup method.\n   * @returns {Promise<Boolean>}\n   */\n  async restore(wrapperState) {\n    const lastMessageFromTrustee = this.election.getLastMessageFromTrustee(\n      this.uniqueId,\n    );\n\n    this.hasSetupKeyCeremony =\n      lastMessageFromTrustee &&\n      (await this.wrapperAdapter.restore(wrapperState));\n\n    return this.hasSetupKeyCeremony;\n  }\n\n  /**\n   * Creates an interval that will check periodically if there are new log entries\n   * to process. The interval is done when a new log entry is processed and it has\n   * a result.\n   *\n   * @private\n   * @returns {Promise<Object>}\n   */\n  async waitForNextLogEntryResult() {\n    await new Promise((resolve) => {\n      const intervalId = setInterval(async () => {\n        const { logEntries } = this.election;\n\n        if (logEntries.length > this.nextLogEntryIndexToProcess) {\n          clearInterval(intervalId);\n          resolve();\n        }\n      }, this.options.waitUntilNextCheck);\n    });\n\n    return this.processNextLogEntry();\n  }\n\n  /**\n   * Processes the next log entry and outputs the result. It broadcasts an event\n   * when the message is received and another one when it is processed.\n   *\n   * @private\n   * @returns {Promise<Object|null|undefined>}\n   */\n  async processNextLogEntry() {\n    const { logEntries } = this.election;\n    const message = logEntries[this.nextLogEntryIndexToProcess];\n\n    this.events.broadcastMessageReceived(message);\n\n    const { messageIdentifier, decodedData } = await this.parser.parse(message);\n\n    const result = await this.wrapperAdapter.processMessage(\n      messageIdentifier.typeSubtype,\n      decodedData,\n    );\n\n    this.events.broadcastMessageProcessed(message, result);\n\n    this.nextLogEntryIndexToProcess += 1;\n\n    if (result) {\n      const { messageType, content } = result;\n      return {\n        message_id: MessageIdentifier.format(\n          this.election.uniqueId,\n          messageType,\n          TRUSTEE_TYPE,\n          this.uniqueId,\n        ),\n        content,\n      };\n    }\n\n    return result;\n  }\n\n  /**\n   * If there is a message to be sent that has not been sent already it is signed\n   * and send it to the bulletin board as a key ceremony step.\n   *\n   * @private\n   * @returns {Promise<Object|undefined>}\n   */\n  async processKeyCeremonyStep(message) {\n    if (message && !this.isMessageAlreadyLogged(message)) {\n      const signedData = await this.signMessage(message);\n      return this.election.bulletinBoardClient.processKeyCeremonyStep({\n        messageId: message.message_id,\n        signedData,\n      });\n    }\n  }\n\n  /**\n   * If there is a message to be sent that has not been sent already it is signed\n   * and send it to the bulletin board as a trustee step.\n   *\n   * @private\n   * @returns {Promise<Object|undefined>}\n   */\n  async processTallyStep(message) {\n    if (message && !this.isMessageAlreadyLogged(message)) {\n      const signedData = await this.signMessage(message);\n      return this.election.bulletinBoardClient.processTallyStep({\n        messageId: message.message_id,\n        signedData,\n      });\n    }\n  }\n\n  /**\n   * Whether the message is already in the election log or not.\n   *\n   * @private\n   * @returns {Boolean}\n   */\n  isMessageAlreadyLogged({ message_id }) {\n    const { logEntries } = this.election;\n    return logEntries.find((logEntry) => logEntry.messageId === message_id);\n  }\n\n  /**\n   * Signs a message using the trustee identification keys.\n   *\n   * @private\n   * @param {Object} message - The message to be signed.\n   * @returns {Promise<String>}\n   */\n  signMessage(message) {\n    return this.identificationKeys.sign({\n      iat: Math.floor(new Date() / 1000),\n      ...message,\n    });\n  }\n}\n","export function samePublicKeys(key1, key2) {\n  const jwk1 = typeof key1 === \"string\" ? JSON.parse(key1) : key1;\n  const jwk2 = typeof key2 === \"string\" ? JSON.parse(key2) : key2;\n\n  if (jwk1 && jwk2) {\n    const { n: n1, e: e1, kty: kty1 } = jwk1;\n    const { n: n2, e: e2, kty: kty2 } = jwk2;\n\n    return n1 === n2 && e1 === e2 && kty1 === kty2;\n  }\n  return false;\n}\n","import { Client } from \"../client/client\";\nimport { Election } from \"../election/election\";\nimport { Voter } from \"../voter/voter\";\n\n/**\n * This class is used to bind any UI elements to a vote process.\n */\nexport class VoteComponent {\n  /**\n   * Initialises the class with the given params.\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {Object} bulletinBoardClientParams - An object to configure the bulletin board client.\n   *  - {String} authorityPublicKeyJSON - The authority identification public key.\n   *  - {String} electionUniqueId - The unique identifier of an election.\n   *  - {String} voterUniqueId - The unique identifier of a voter.\n   *  - {Object} voterWrapperAdapter - An object to interact with the voter wrapper.\n   * @constructor\n   */\n  constructor({\n    bulletinBoardClientParams,\n    authorityPublicKeyJSON,\n    electionUniqueId,\n    voterUniqueId,\n    voterWrapperAdapter,\n  }) {\n    this.bulletinBoardClient = new Client(bulletinBoardClientParams);\n\n    const election = new Election({\n      uniqueId: electionUniqueId,\n      bulletinBoardClient: this.bulletinBoardClient,\n    });\n\n    this.voter = new Voter({\n      bulletinBoardClient: this.bulletinBoardClient,\n      authorityPublicKeyJSON,\n      election,\n      uniqueId: voterUniqueId,\n      wrapperAdapter: voterWrapperAdapter,\n    });\n  }\n\n  /**\n   * Bind UI events to the vote process.\n   *\n   * @method bindEvents\n   * @param {Object} eventCallbacks - An object that contains event callback functions.\n   * - {Function} onBindEncryptButton - a function that receives a callback function that will be called when encrypting the vote must be started\n   * - {Function} onVoteEncryption - a function that is called when the vote gets encrypted\n   * - {Function} castOrAuditBallot - a function that is called to cast or audit a ballot\n   * - {Function} onStart - a function that is called when the vote has started.\n   * - {Function} onBindAuditBallotButton - a function that called when the ballot should get audited\n   * - {Function} onBindCastBallotButton - a function that called when the ballot should get casted\n   * - {Function} onAuditBallot - a function that is called to audit a vote before encrypting it.\n   * - {Function} onAuditComplete - a function that is called when the auditable vote is audited.\n   * - {Function} onCastBallot - a function that is called to cast the ballot.\n   * - {Function} onCastComplete - a function that is called when the vote is casted.\n   * - {Function} onInvalid - a function that is called when the vote is not valid.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async bindEvents({\n    onBindEncryptButton,\n    onStart,\n    onVoteEncryption,\n    castOrAuditBallot,\n    onBindAuditBallotButton,\n    onBindCastBallotButton,\n    onAuditBallot,\n    onCastBallot,\n    onAuditComplete,\n    onCastComplete,\n    onInvalid,\n  }) {\n    const onSetupDone = this.voter.setup();\n\n    onBindEncryptButton(async () => {\n      onStart();\n      await onSetupDone;\n      onVoteEncryption(\n        (plainVote, ballotStyle) => {\n          this.voter.encrypt(plainVote, ballotStyle).then((ballot) => {\n            castOrAuditBallot(ballot);\n            onBindAuditBallotButton(() => {\n              onAuditBallot(\n                ballot,\n                `${this.voter.uniqueId}-election-${this.voter.election.uniqueId}.txt`,\n              );\n              onAuditComplete();\n            });\n\n            onBindCastBallotButton(async () => {\n              try {\n                const result = await onCastBallot(ballot);\n                onCastComplete(result);\n              } catch {\n                onInvalid();\n              }\n            });\n          });\n        },\n        () => {\n          onInvalid();\n        },\n      );\n    });\n  }\n}\n","import { MessageParser } from \"../client/message-parser\";\n\n/**\n * This is a facade class that will use the corresponding `VoterWrapper` to encrypt\n * the vote.\n */\nexport class Voter {\n  /**\n   * Initializes the class with the given params.\n   *\n   * @constructor\n   * @param {Object} params - An object that contains the initialization params.\n   *  - {Client} bulletinBoardClient - An instance of the Bulletin Board Client.\n   *  - {String} authorityPublicKeyJSON - The authority identification public key.\n   *  - {Object} election - An object that interacts with a specific election\n   *                        to get some data and perform the vote.\n   *  - {String} uniqueId - The voter identifier.\n   *  - {Object} wrapperAdapter - An object to interact with the voter wrapper.\n   */\n  constructor({\n    bulletinBoardClient,\n    authorityPublicKeyJSON,\n    election,\n    uniqueId,\n    wrapperAdapter,\n  }) {\n    this.uniqueId = uniqueId;\n    this.election = election;\n    this.bulletinBoardClient = bulletinBoardClient;\n    this.wrapperAdapter = wrapperAdapter;\n    this.parser = new MessageParser({ authorityPublicKeyJSON });\n  }\n\n  /**\n   * Performs some operations to setup the voter.\n   *\n   * Retrieves the key ceremony messages needed to cast a vote in the given election.\n   *\n   * @returns {Promise<undefined>}\n   */\n  async setup() {\n    await this.wrapperAdapter.setup();\n    return this.bulletinBoardClient\n      .getElectionLogEntries({\n        electionUniqueId: this.election.uniqueId,\n        types: [\"create_election\", \"end_key_ceremony\"],\n      })\n      .then(async (logEntries) => {\n        for (const logEntry of logEntries) {\n          const { messageIdentifier, decodedData } =\n            await this.parser.parse(logEntry);\n\n          await this.wrapperAdapter.processMessage(\n            messageIdentifier.typeSubtype,\n            decodedData,\n          );\n        }\n      });\n  }\n\n  /**\n   * Encrypts the data using the wrapper.\n   *\n   * @param {Object} plainVote - An object with the choosen answers for each question.\n   * @param {String} ballotStyle - The ballot style identifier.\n   *\n   * @returns {Promise<Object>} - The ballot.\n   */\n  async encrypt(plainVote, ballotStyle) {\n    const { encryptedData, auditableData } = await this.wrapperAdapter.encrypt(\n      plainVote,\n      ballotStyle,\n    );\n    const encryptedDataHash = await this.hash(encryptedData);\n\n    return {\n      encryptedData,\n      encryptedDataHash,\n      auditableData,\n      plainVote,\n      electionUniqueId: this.election.uniqueId,\n    };\n  }\n\n  /**\n   * Generates the hash from the given data.\n   *\n   * @private\n   * @param {Object} data - The data to be digested.\n   * @returns {Promise<Object>} - The hash value.\n   */\n  async hash(data) {\n    return window.crypto.subtle\n      .digest(\"SHA-256\", new TextEncoder().encode(data))\n      .then((hashBuffer) => {\n        const hashArray = Array.from(new Uint8Array(hashBuffer));\n        return hashArray.map((b) => b.toString(16).padStart(2, \"0\")).join(\"\");\n      });\n  }\n\n  /**\n   * Verifies a vote\n   *\n   * @param {String} contentHash - An object that includes the following options.\n   *  - {String} contentHash - the contentHash of a vote\n   * @returns {Promise<Object>} - Returns a logEntry\n   */\n  verifyVote(contentHash) {\n    const { uniqueId: electionUniqueId } = this.election;\n\n    return this.bulletinBoardClient.getLogEntry({\n      electionUniqueId,\n      contentHash,\n    });\n  }\n}\n","// show a message to the user if comunication is lost\nimport \"src/decidim/elections/broken_promises_handler\";\nimport { Client } from \"@decidim/decidim-bulletin_board\";\n\n$(() => {\n  const $form = $(\"form.step\");\n  const $pendingAction = $form.find(\"#pending_action\");\n\n  if ($pendingAction.length) {\n    const bulletinBoardClient = new Client({\n      apiEndpointUrl: $pendingAction.data(\"apiEndpointUrl\")\n    });\n    const messageId = $pendingAction.data(\"messageId\");\n\n    bulletinBoardClient.waitForPendingMessageToBeProcessed(messageId).then(() => {\n      $form.trigger(\"submit\");\n    });\n  }\n});\n","// show a message to the user if comunication is lost\nimport \"src/decidim/elections/broken_promises_handler\";\nimport {\n  Client,\n  Election,\n  MessageParser\n} from \"@decidim/decidim-bulletin_board\";\n\nconst WAIT_TIME_MS = 10 * 1_000;\n\n$(async () => {\n  const $trusteesProcess = $(\"#trustees_process\");\n\n  if ($trusteesProcess.length) {\n    const $checkingTrustees = $trusteesProcess.find(\".trustee\");\n    const electionUniqueId = $trusteesProcess.data(\"electionUniqueId\");\n    const processType = $trusteesProcess.data(\"processType\");\n    const bulletinBoardClient = new Client({\n      apiEndpointUrl: $trusteesProcess.data(\"apiEndpointUrl\")\n    });\n    const election = new Election({\n      uniqueId: electionUniqueId,\n      bulletinBoardClient,\n      typesFilter: [\"create_election\", processType]\n    });\n\n    const authorityPublicKeyJSON = JSON.stringify(\n      $trusteesProcess.data(\"authorityPublicKey\")\n    );\n    const parser = new MessageParser({ authorityPublicKeyJSON });\n    const trusteesStatuses = {};\n    let lastMessageIndex = 0;\n\n    const missingTrusteesAllowed = $trusteesProcess.data(\"missingTrusteesAllowed\") || 0;\n    const checkPendingActionPath = $trusteesProcess.data(\"checkPendingActionPath\");\n\n    // Fix buttons formaction, that is not working properly\n    const $form = $(\"form.step\");\n    $form.find(\"button\").on(\"click\", (event) => {\n      $form.attr(\"action\", $(event.currentTarget).attr(\"formaction\"));\n      $form.trigger(\"submit\");\n    });\n\n    const updateTrusteesStatuses = async () => {\n      await election.getLogEntries();\n\n      for (\n        ;\n        lastMessageIndex < election.logEntries.length;\n        lastMessageIndex += 1\n      ) {\n        const { messageIdentifier, decodedData } = await parser.parse(\n          election.logEntries[lastMessageIndex]\n        );\n\n        if (messageIdentifier.author.type === \"t\") {\n          trusteesStatuses[messageIdentifier.author.id] = true;\n        } else if (\n          messageIdentifier.type === \"tally\" &&\n          messageIdentifier.subtype === \"missing_trustee\" &&\n          !(decodedData.trustee_id in trusteesStatuses)\n        ) {\n          trusteesStatuses[decodedData.trustee_id] = false;\n        }\n      }\n    }\n\n    const checkPendingAction = async () => {\n      if (!checkPendingActionPath) {\n        return false\n      }\n\n      try {\n        const response = await $.ajax({\n          url: checkPendingActionPath,\n          method: \"PATCH\",\n          contentType: \"application/json\",\n          headers: {\n            \"X-CSRF-Token\": $(\"meta[name=csrf-token]\").attr(\"content\")\n          }\n        })\n\n        return response && response.status === \"pending\";\n      } catch (err) {\n        return true;\n      }\n    }\n\n    const checkTrusteesActivity = async () => {\n      await updateTrusteesStatuses();\n      const pendingAction = await checkPendingAction();\n      const missingTrustees = Object.values(trusteesStatuses).filter(\n        (present) => !present\n      ).length;\n      const allowReportMissing = missingTrustees < missingTrusteesAllowed;\n\n      $checkingTrustees.each((_index, trustee) => {\n        const $trustee = $(trustee);\n        const trusteeSlug = $trustee.data(\"trusteeSlug\");\n\n        if (trusteeSlug in trusteesStatuses) {\n          if (missingTrusteesAllowed > 0) {\n            $trustee.find(\".js-report-missing-trustee\").addClass(\"hide\");\n          }\n          $trustee.removeClass(\"loading\");\n          $trustee.find(\".loading\").hide();\n          if (trusteesStatuses[trusteeSlug]) {\n            $trustee.find(\".active\").removeClass(\"hide\");\n            $trustee.find(\".missing\").addClass(\"hide\");\n          } else {\n            $trustee.find(\".missing\").removeClass(\"hide\");\n          }\n        } else if (allowReportMissing && !pendingAction) {\n          $trustee.find(\".js-report-missing-trustee\").removeClass(\"hide\");\n        }\n      });\n\n      if (\n        Object.keys(trusteesStatuses).length === $checkingTrustees.length &&\n        missingTrustees <= missingTrusteesAllowed && !pendingAction\n      ) {\n        $(\".js-continue-link\").removeClass(\"disabled\");\n      } else {\n        setTimeout(checkTrusteesActivity, WAIT_TIME_MS);\n      }\n    };\n\n    await checkTrusteesActivity();\n  }\n});\n","/* eslint-disable no-inline-comments */\n/* eslint-disable line-comment-position */\n// fetches Vote stats every 3 seconds\n\n$(() => {\n  const WAIT_TIME_MS = 3000; // 3s\n  const url = $(\"#vote-stats\").data(\"refreshUrl\");\n\n  if (url) {\n    setInterval(function() {\n      $(\"#vote-stats\").load(url);\n    }, WAIT_TIME_MS);\n  }\n})\n","/* Fallback for non-handled failed promises */\nwindow.addEventListener(\"unhandledrejection\", (event) => {\n  if (window.Decidim.currentDialogs[\"server-failure\"]) {\n    document.getElementById(\"tech-info\").innerHTML = event.reason\n\n    if (event.reason.toString().indexOf(\"fetch\") === -1) {\n      document.getElementById(\"communication_error\").hidden = true\n      document.getElementById(\"generic_error\").hidden = false\n    }\n\n    window.Decidim.currentDialogs[\"server-failure\"].open()\n  }\n});\n","'use strict'\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar pad_string_1 = require(\"./pad-string\");\nfunction encode(input, encoding) {\n    if (encoding === void 0) { encoding = \"utf8\"; }\n    if (Buffer.isBuffer(input)) {\n        return fromBase64(input.toString(\"base64\"));\n    }\n    return fromBase64(Buffer.from(input, encoding).toString(\"base64\"));\n}\n;\nfunction decode(base64url, encoding) {\n    if (encoding === void 0) { encoding = \"utf8\"; }\n    return Buffer.from(toBase64(base64url), \"base64\").toString(encoding);\n}\nfunction toBase64(base64url) {\n    base64url = base64url.toString();\n    return pad_string_1.default(base64url)\n        .replace(/\\-/g, \"+\")\n        .replace(/_/g, \"/\");\n}\nfunction fromBase64(base64) {\n    return base64\n        .replace(/=/g, \"\")\n        .replace(/\\+/g, \"-\")\n        .replace(/\\//g, \"_\");\n}\nfunction toBuffer(base64url) {\n    return Buffer.from(toBase64(base64url), \"base64\");\n}\nvar base64url = encode;\nbase64url.encode = encode;\nbase64url.decode = decode;\nbase64url.toBase64 = toBase64;\nbase64url.fromBase64 = fromBase64;\nbase64url.toBuffer = toBuffer;\nexports.default = base64url;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction padString(input) {\n    var segmentLength = 4;\n    var stringLength = input.length;\n    var diff = stringLength % segmentLength;\n    if (!diff) {\n        return input;\n    }\n    var position = stringLength;\n    var padLength = segmentLength - diff;\n    var paddedStringLength = stringLength + padLength;\n    var buffer = Buffer.alloc(paddedStringLength);\n    buffer.write(input);\n    while (padLength--) {\n        buffer.write(\"=\", position++);\n    }\n    return buffer.toString();\n}\nexports.default = padString;\n","module.exports = require('./dist/base64url').default;\nmodule.exports.default = module.exports;\n","/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n'use strict'\n\nconst base64 = require('base64-js')\nconst ieee754 = require('ieee754')\nconst customInspectSymbol =\n  (typeof Symbol === 'function' && typeof Symbol['for'] === 'function') // eslint-disable-line dot-notation\n    ? Symbol['for']('nodejs.util.inspect.custom') // eslint-disable-line dot-notation\n    : null\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\nconst K_MAX_LENGTH = 0x7fffffff\nexports.kMaxLength = K_MAX_LENGTH\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Print warning and recommend using `buffer` v4.x which has an Object\n *               implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * We report that the browser does not support typed arrays if the are not subclassable\n * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`\n * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support\n * for __proto__ and has a buggy typed array implementation.\n */\nBuffer.TYPED_ARRAY_SUPPORT = typedArraySupport()\n\nif (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&\n    typeof console.error === 'function') {\n  console.error(\n    'This browser lacks typed array (Uint8Array) support which is required by ' +\n    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'\n  )\n}\n\nfunction typedArraySupport () {\n  // Can typed array instances can be augmented?\n  try {\n    const arr = new Uint8Array(1)\n    const proto = { foo: function () { return 42 } }\n    Object.setPrototypeOf(proto, Uint8Array.prototype)\n    Object.setPrototypeOf(arr, proto)\n    return arr.foo() === 42\n  } catch (e) {\n    return false\n  }\n}\n\nObject.defineProperty(Buffer.prototype, 'parent', {\n  enumerable: true,\n  get: function () {\n    if (!Buffer.isBuffer(this)) return undefined\n    return this.buffer\n  }\n})\n\nObject.defineProperty(Buffer.prototype, 'offset', {\n  enumerable: true,\n  get: function () {\n    if (!Buffer.isBuffer(this)) return undefined\n    return this.byteOffset\n  }\n})\n\nfunction createBuffer (length) {\n  if (length > K_MAX_LENGTH) {\n    throw new RangeError('The value \"' + length + '\" is invalid for option \"size\"')\n  }\n  // Return an augmented `Uint8Array` instance\n  const buf = new Uint8Array(length)\n  Object.setPrototypeOf(buf, Buffer.prototype)\n  return buf\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new TypeError(\n        'The \"string\" argument must be of type string. Received type number'\n      )\n    }\n    return allocUnsafe(arg)\n  }\n  return from(arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\nfunction from (value, encodingOrOffset, length) {\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  if (ArrayBuffer.isView(value)) {\n    return fromArrayView(value)\n  }\n\n  if (value == null) {\n    throw new TypeError(\n      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +\n      'or Array-like Object. Received type ' + (typeof value)\n    )\n  }\n\n  if (isInstance(value, ArrayBuffer) ||\n      (value && isInstance(value.buffer, ArrayBuffer))) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof SharedArrayBuffer !== 'undefined' &&\n      (isInstance(value, SharedArrayBuffer) ||\n      (value && isInstance(value.buffer, SharedArrayBuffer)))) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'number') {\n    throw new TypeError(\n      'The \"value\" argument must not be of type number. Received type number'\n    )\n  }\n\n  const valueOf = value.valueOf && value.valueOf()\n  if (valueOf != null && valueOf !== value) {\n    return Buffer.from(valueOf, encodingOrOffset, length)\n  }\n\n  const b = fromObject(value)\n  if (b) return b\n\n  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&\n      typeof value[Symbol.toPrimitive] === 'function') {\n    return Buffer.from(value[Symbol.toPrimitive]('string'), encodingOrOffset, length)\n  }\n\n  throw new TypeError(\n    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +\n    'or Array-like Object. Received type ' + (typeof value)\n  )\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(value, encodingOrOffset, length)\n}\n\n// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:\n// https://github.com/feross/buffer/pull/148\nObject.setPrototypeOf(Buffer.prototype, Uint8Array.prototype)\nObject.setPrototypeOf(Buffer, Uint8Array)\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be of type number')\n  } else if (size < 0) {\n    throw new RangeError('The value \"' + size + '\" is invalid for option \"size\"')\n  }\n}\n\nfunction alloc (size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpreted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(size).fill(fill, encoding)\n      : createBuffer(size).fill(fill)\n  }\n  return createBuffer(size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(size, fill, encoding)\n}\n\nfunction allocUnsafe (size) {\n  assertSize(size)\n  return createBuffer(size < 0 ? 0 : checked(size) | 0)\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(size)\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('Unknown encoding: ' + encoding)\n  }\n\n  const length = byteLength(string, encoding) | 0\n  let buf = createBuffer(length)\n\n  const actual = buf.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    buf = buf.slice(0, actual)\n  }\n\n  return buf\n}\n\nfunction fromArrayLike (array) {\n  const length = array.length < 0 ? 0 : checked(array.length) | 0\n  const buf = createBuffer(length)\n  for (let i = 0; i < length; i += 1) {\n    buf[i] = array[i] & 255\n  }\n  return buf\n}\n\nfunction fromArrayView (arrayView) {\n  if (isInstance(arrayView, Uint8Array)) {\n    const copy = new Uint8Array(arrayView)\n    return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength)\n  }\n  return fromArrayLike(arrayView)\n}\n\nfunction fromArrayBuffer (array, byteOffset, length) {\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\"offset\" is outside of buffer bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\"length\" is outside of buffer bounds')\n  }\n\n  let buf\n  if (byteOffset === undefined && length === undefined) {\n    buf = new Uint8Array(array)\n  } else if (length === undefined) {\n    buf = new Uint8Array(array, byteOffset)\n  } else {\n    buf = new Uint8Array(array, byteOffset, length)\n  }\n\n  // Return an augmented `Uint8Array` instance\n  Object.setPrototypeOf(buf, Buffer.prototype)\n\n  return buf\n}\n\nfunction fromObject (obj) {\n  if (Buffer.isBuffer(obj)) {\n    const len = checked(obj.length) | 0\n    const buf = createBuffer(len)\n\n    if (buf.length === 0) {\n      return buf\n    }\n\n    obj.copy(buf, 0, 0, len)\n    return buf\n  }\n\n  if (obj.length !== undefined) {\n    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {\n      return createBuffer(0)\n    }\n    return fromArrayLike(obj)\n  }\n\n  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {\n    return fromArrayLike(obj.data)\n  }\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= K_MAX_LENGTH) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return b != null && b._isBuffer === true &&\n    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false\n}\n\nBuffer.compare = function compare (a, b) {\n  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)\n  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError(\n      'The \"buf1\", \"buf2\" arguments must be one of type Buffer or Uint8Array'\n    )\n  }\n\n  if (a === b) return 0\n\n  let x = a.length\n  let y = b.length\n\n  for (let i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!Array.isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  let i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  const buffer = Buffer.allocUnsafe(length)\n  let pos = 0\n  for (i = 0; i < list.length; ++i) {\n    let buf = list[i]\n    if (isInstance(buf, Uint8Array)) {\n      if (pos + buf.length > buffer.length) {\n        if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf)\n        buf.copy(buffer, pos)\n      } else {\n        Uint8Array.prototype.set.call(\n          buffer,\n          buf,\n          pos\n        )\n      }\n    } else if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    } else {\n      buf.copy(buffer, pos)\n    }\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    throw new TypeError(\n      'The \"string\" argument must be one of type string, Buffer, or ArrayBuffer. ' +\n      'Received type ' + typeof string\n    )\n  }\n\n  const len = string.length\n  const mustMatch = (arguments.length > 2 && arguments[2] === true)\n  if (!mustMatch && len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  let loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) {\n          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8\n        }\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  let loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coercion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)\n// to detect a Buffer instance. It's not possible to use `instanceof Buffer`\n// reliably in a browserify context because there could be multiple different\n// copies of the 'buffer' package in use. This method works even for Buffer\n// instances that were created from another copy of the `buffer` package.\n// See: https://github.com/feross/buffer/issues/154\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  const i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  const len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (let i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  const len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (let i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  const len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (let i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  const length = this.length\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.toLocaleString = Buffer.prototype.toString\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  let str = ''\n  const max = exports.INSPECT_MAX_BYTES\n  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()\n  if (this.length > max) str += ' ... '\n  return '<Buffer ' + str + '>'\n}\nif (customInspectSymbol) {\n  Buffer.prototype[customInspectSymbol] = Buffer.prototype.inspect\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (isInstance(target, Uint8Array)) {\n    target = Buffer.from(target, target.offset, target.byteLength)\n  }\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError(\n      'The \"target\" argument must be one of type Buffer or Uint8Array. ' +\n      'Received type ' + (typeof target)\n    )\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  let x = thisEnd - thisStart\n  let y = end - start\n  const len = Math.min(x, y)\n\n  const thisCopy = this.slice(thisStart, thisEnd)\n  const targetCopy = target.slice(start, end)\n\n  for (let i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset // Coerce to Number.\n  if (numberIsNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [val], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  let indexSize = 1\n  let arrLength = arr.length\n  let valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  let i\n  if (dir) {\n    let foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      let found = true\n      for (let j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  const remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  const strLen = string.length\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  let i\n  for (i = 0; i < length; ++i) {\n    const parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (numberIsNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset >>> 0\n    if (isFinite(length)) {\n      length = length >>> 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  const remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  let loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return asciiWrite(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  const res = []\n\n  let i = start\n  while (i < end) {\n    const firstByte = buf[i]\n    let codePoint = null\n    let bytesPerSequence = (firstByte > 0xEF)\n      ? 4\n      : (firstByte > 0xDF)\n          ? 3\n          : (firstByte > 0xBF)\n              ? 2\n              : 1\n\n    if (i + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nconst MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  const len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  let res = ''\n  let i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  let ret = ''\n  end = Math.min(buf.length, end)\n\n  for (let i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  let ret = ''\n  end = Math.min(buf.length, end)\n\n  for (let i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  const len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  let out = ''\n  for (let i = start; i < end; ++i) {\n    out += hexSliceLookupTable[buf[i]]\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  const bytes = buf.slice(start, end)\n  let res = ''\n  // If bytes.length is odd, the last 8 bits must be ignored (same as node.js)\n  for (let i = 0; i < bytes.length - 1; i += 2) {\n    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  const len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  const newBuf = this.subarray(start, end)\n  // Return an augmented `Uint8Array` instance\n  Object.setPrototypeOf(newBuf, Buffer.prototype)\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUintLE =\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let val = this[offset]\n  let mul = 1\n  let i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUintBE =\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  let val = this[offset + --byteLength]\n  let mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUint8 =\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUint16LE =\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUint16BE =\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUint32LE =\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUint32BE =\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readBigUInt64LE = defineBigIntMethod(function readBigUInt64LE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const lo = first +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 24\n\n  const hi = this[++offset] +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    last * 2 ** 24\n\n  return BigInt(lo) + (BigInt(hi) << BigInt(32))\n})\n\nBuffer.prototype.readBigUInt64BE = defineBigIntMethod(function readBigUInt64BE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const hi = first * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    this[++offset]\n\n  const lo = this[++offset] * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    last\n\n  return (BigInt(hi) << BigInt(32)) + BigInt(lo)\n})\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let val = this[offset]\n  let mul = 1\n  let i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let i = byteLength\n  let mul = 1\n  let val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  const val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  const val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readBigInt64LE = defineBigIntMethod(function readBigInt64LE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const val = this[offset + 4] +\n    this[offset + 5] * 2 ** 8 +\n    this[offset + 6] * 2 ** 16 +\n    (last << 24) // Overflow\n\n  return (BigInt(val) << BigInt(32)) +\n    BigInt(first +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 24)\n})\n\nBuffer.prototype.readBigInt64BE = defineBigIntMethod(function readBigInt64BE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const val = (first << 24) + // Overflow\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    this[++offset]\n\n  return (BigInt(val) << BigInt(32)) +\n    BigInt(this[++offset] * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    last)\n})\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUintLE =\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    const maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  let mul = 1\n  let i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUintBE =\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    const maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  let i = byteLength - 1\n  let mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUint8 =\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeUint16LE =\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  return offset + 2\n}\n\nBuffer.prototype.writeUint16BE =\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  this[offset] = (value >>> 8)\n  this[offset + 1] = (value & 0xff)\n  return offset + 2\n}\n\nBuffer.prototype.writeUint32LE =\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  this[offset + 3] = (value >>> 24)\n  this[offset + 2] = (value >>> 16)\n  this[offset + 1] = (value >>> 8)\n  this[offset] = (value & 0xff)\n  return offset + 4\n}\n\nBuffer.prototype.writeUint32BE =\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  this[offset] = (value >>> 24)\n  this[offset + 1] = (value >>> 16)\n  this[offset + 2] = (value >>> 8)\n  this[offset + 3] = (value & 0xff)\n  return offset + 4\n}\n\nfunction wrtBigUInt64LE (buf, value, offset, min, max) {\n  checkIntBI(value, min, max, buf, offset, 7)\n\n  let lo = Number(value & BigInt(0xffffffff))\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff))\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  return offset\n}\n\nfunction wrtBigUInt64BE (buf, value, offset, min, max) {\n  checkIntBI(value, min, max, buf, offset, 7)\n\n  let lo = Number(value & BigInt(0xffffffff))\n  buf[offset + 7] = lo\n  lo = lo >> 8\n  buf[offset + 6] = lo\n  lo = lo >> 8\n  buf[offset + 5] = lo\n  lo = lo >> 8\n  buf[offset + 4] = lo\n  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff))\n  buf[offset + 3] = hi\n  hi = hi >> 8\n  buf[offset + 2] = hi\n  hi = hi >> 8\n  buf[offset + 1] = hi\n  hi = hi >> 8\n  buf[offset] = hi\n  return offset + 8\n}\n\nBuffer.prototype.writeBigUInt64LE = defineBigIntMethod(function writeBigUInt64LE (value, offset = 0) {\n  return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))\n})\n\nBuffer.prototype.writeBigUInt64BE = defineBigIntMethod(function writeBigUInt64BE (value, offset = 0) {\n  return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))\n})\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    const limit = Math.pow(2, (8 * byteLength) - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  let i = 0\n  let mul = 1\n  let sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    const limit = Math.pow(2, (8 * byteLength) - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  let i = byteLength - 1\n  let mul = 1\n  let sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  this[offset] = (value >>> 8)\n  this[offset + 1] = (value & 0xff)\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  this[offset + 2] = (value >>> 16)\n  this[offset + 3] = (value >>> 24)\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  this[offset] = (value >>> 24)\n  this[offset + 1] = (value >>> 16)\n  this[offset + 2] = (value >>> 8)\n  this[offset + 3] = (value & 0xff)\n  return offset + 4\n}\n\nBuffer.prototype.writeBigInt64LE = defineBigIntMethod(function writeBigInt64LE (value, offset = 0) {\n  return wrtBigUInt64LE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))\n})\n\nBuffer.prototype.writeBigInt64BE = defineBigIntMethod(function writeBigInt64BE (value, offset = 0) {\n  return wrtBigUInt64BE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))\n})\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  const len = end - start\n\n  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {\n    // Use built-in when available, missing from IE11\n    this.copyWithin(targetStart, start, end)\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, end),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n    if (val.length === 1) {\n      const code = val.charCodeAt(0)\n      if ((encoding === 'utf8' && code < 128) ||\n          encoding === 'latin1') {\n        // Fast path: If `val` fits into a single byte, use that numeric value.\n        val = code\n      }\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  } else if (typeof val === 'boolean') {\n    val = Number(val)\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  let i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    const bytes = Buffer.isBuffer(val)\n      ? val\n      : Buffer.from(val, encoding)\n    const len = bytes.length\n    if (len === 0) {\n      throw new TypeError('The value \"' + val +\n        '\" is invalid for argument \"value\"')\n    }\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// CUSTOM ERRORS\n// =============\n\n// Simplified versions from Node, changed for Buffer-only usage\nconst errors = {}\nfunction E (sym, getMessage, Base) {\n  errors[sym] = class NodeError extends Base {\n    constructor () {\n      super()\n\n      Object.defineProperty(this, 'message', {\n        value: getMessage.apply(this, arguments),\n        writable: true,\n        configurable: true\n      })\n\n      // Add the error code to the name to include it in the stack trace.\n      this.name = `${this.name} [${sym}]`\n      // Access the stack to generate the error message including the error code\n      // from the name.\n      this.stack // eslint-disable-line no-unused-expressions\n      // Reset the name to the actual name.\n      delete this.name\n    }\n\n    get code () {\n      return sym\n    }\n\n    set code (value) {\n      Object.defineProperty(this, 'code', {\n        configurable: true,\n        enumerable: true,\n        value,\n        writable: true\n      })\n    }\n\n    toString () {\n      return `${this.name} [${sym}]: ${this.message}`\n    }\n  }\n}\n\nE('ERR_BUFFER_OUT_OF_BOUNDS',\n  function (name) {\n    if (name) {\n      return `${name} is outside of buffer bounds`\n    }\n\n    return 'Attempt to access memory outside buffer bounds'\n  }, RangeError)\nE('ERR_INVALID_ARG_TYPE',\n  function (name, actual) {\n    return `The \"${name}\" argument must be of type number. Received type ${typeof actual}`\n  }, TypeError)\nE('ERR_OUT_OF_RANGE',\n  function (str, range, input) {\n    let msg = `The value of \"${str}\" is out of range.`\n    let received = input\n    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {\n      received = addNumericalSeparator(String(input))\n    } else if (typeof input === 'bigint') {\n      received = String(input)\n      if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) {\n        received = addNumericalSeparator(received)\n      }\n      received += 'n'\n    }\n    msg += ` It must be ${range}. Received ${received}`\n    return msg\n  }, RangeError)\n\nfunction addNumericalSeparator (val) {\n  let res = ''\n  let i = val.length\n  const start = val[0] === '-' ? 1 : 0\n  for (; i >= start + 4; i -= 3) {\n    res = `_${val.slice(i - 3, i)}${res}`\n  }\n  return `${val.slice(0, i)}${res}`\n}\n\n// CHECK FUNCTIONS\n// ===============\n\nfunction checkBounds (buf, offset, byteLength) {\n  validateNumber(offset, 'offset')\n  if (buf[offset] === undefined || buf[offset + byteLength] === undefined) {\n    boundsError(offset, buf.length - (byteLength + 1))\n  }\n}\n\nfunction checkIntBI (value, min, max, buf, offset, byteLength) {\n  if (value > max || value < min) {\n    const n = typeof min === 'bigint' ? 'n' : ''\n    let range\n    if (byteLength > 3) {\n      if (min === 0 || min === BigInt(0)) {\n        range = `>= 0${n} and < 2${n} ** ${(byteLength + 1) * 8}${n}`\n      } else {\n        range = `>= -(2${n} ** ${(byteLength + 1) * 8 - 1}${n}) and < 2 ** ` +\n                `${(byteLength + 1) * 8 - 1}${n}`\n      }\n    } else {\n      range = `>= ${min}${n} and <= ${max}${n}`\n    }\n    throw new errors.ERR_OUT_OF_RANGE('value', range, value)\n  }\n  checkBounds(buf, offset, byteLength)\n}\n\nfunction validateNumber (value, name) {\n  if (typeof value !== 'number') {\n    throw new errors.ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n}\n\nfunction boundsError (value, length, type) {\n  if (Math.floor(value) !== value) {\n    validateNumber(value, type)\n    throw new errors.ERR_OUT_OF_RANGE(type || 'offset', 'an integer', value)\n  }\n\n  if (length < 0) {\n    throw new errors.ERR_BUFFER_OUT_OF_BOUNDS()\n  }\n\n  throw new errors.ERR_OUT_OF_RANGE(type || 'offset',\n                                    `>= ${type ? 1 : 0} and <= ${length}`,\n                                    value)\n}\n\n// HELPER FUNCTIONS\n// ================\n\nconst INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node takes equal signs as end of the Base64 encoding\n  str = str.split('=')[0]\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = str.trim().replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  let codePoint\n  const length = string.length\n  let leadSurrogate = null\n  const bytes = []\n\n  for (let i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  const byteArray = []\n  for (let i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  let c, hi, lo\n  const byteArray = []\n  for (let i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  let i\n  for (i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\n// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass\n// the `instanceof` check but they should be treated as of that type.\n// See: https://github.com/feross/buffer/issues/166\nfunction isInstance (obj, type) {\n  return obj instanceof type ||\n    (obj != null && obj.constructor != null && obj.constructor.name != null &&\n      obj.constructor.name === type.name)\n}\nfunction numberIsNaN (obj) {\n  // For IE11 support\n  return obj !== obj // eslint-disable-line no-self-compare\n}\n\n// Create lookup table for `toString('hex')`\n// See: https://github.com/feross/buffer/issues/219\nconst hexSliceLookupTable = (function () {\n  const alphabet = '0123456789abcdef'\n  const table = new Array(256)\n  for (let i = 0; i < 16; ++i) {\n    const i16 = i * 16\n    for (let j = 0; j < 16; ++j) {\n      table[i16 + j] = alphabet[i] + alphabet[j]\n    }\n  }\n  return table\n})()\n\n// Return not function with Error if BigInt not supported\nfunction defineBigIntMethod (fn) {\n  return typeof BigInt === 'undefined' ? BufferBigIntNotDefined : fn\n}\n\nfunction BufferBigIntNotDefined () {\n  throw new Error('BigInt not supported')\n}\n","/*!\n * @overview es6-promise - a tiny implementation of Promises/A+.\n * @copyright Copyright (c) 2014 Yehuda Katz, Tom Dale, Stefan Penner and contributors (Conversion to ES6 API by Jake Archibald)\n * @license   Licensed under MIT license\n *            See https://raw.githubusercontent.com/stefanpenner/es6-promise/master/LICENSE\n * @version   v4.2.8+1e68dce6\n */\n","export function objectOrFunction(x) {\n  var type = typeof x;\n  return x !== null && (type === 'object' || type === 'function');\n}\n\nexport function isFunction(x) {\n  return typeof x === 'function';\n}\n\nexport function isMaybeThenable(x) {\n  return x !== null && typeof x === 'object';\n}\n\nvar _isArray = void 0;\nif (Array.isArray) {\n  _isArray = Array.isArray;\n} else {\n  _isArray = function (x) {\n    return Object.prototype.toString.call(x) === '[object Array]';\n  };\n}\n\nexport var isArray = _isArray;","var len = 0;\nvar vertxNext = void 0;\nvar customSchedulerFn = void 0;\n\nexport var asap = function asap(callback, arg) {\n  queue[len] = callback;\n  queue[len + 1] = arg;\n  len += 2;\n  if (len === 2) {\n    // If len is 2, that means that we need to schedule an async flush.\n    // If additional callbacks are queued before the queue is flushed, they\n    // will be processed by this flush that we are scheduling.\n    if (customSchedulerFn) {\n      customSchedulerFn(flush);\n    } else {\n      scheduleFlush();\n    }\n  }\n};\n\nexport function setScheduler(scheduleFn) {\n  customSchedulerFn = scheduleFn;\n}\n\nexport function setAsap(asapFn) {\n  asap = asapFn;\n}\n\nvar browserWindow = typeof window !== 'undefined' ? window : undefined;\nvar browserGlobal = browserWindow || {};\nvar BrowserMutationObserver = browserGlobal.MutationObserver || browserGlobal.WebKitMutationObserver;\nvar isNode = typeof self === 'undefined' && typeof process !== 'undefined' && {}.toString.call(process) === '[object process]';\n\n// test for web worker but not in IE10\nvar isWorker = typeof Uint8ClampedArray !== 'undefined' && typeof importScripts !== 'undefined' && typeof MessageChannel !== 'undefined';\n\n// node\nfunction useNextTick() {\n  // node version 0.10.x displays a deprecation warning when nextTick is used recursively\n  // see https://github.com/cujojs/when/issues/410 for details\n  return function () {\n    return process.nextTick(flush);\n  };\n}\n\n// vertx\nfunction useVertxTimer() {\n  if (typeof vertxNext !== 'undefined') {\n    return function () {\n      vertxNext(flush);\n    };\n  }\n\n  return useSetTimeout();\n}\n\nfunction useMutationObserver() {\n  var iterations = 0;\n  var observer = new BrowserMutationObserver(flush);\n  var node = document.createTextNode('');\n  observer.observe(node, { characterData: true });\n\n  return function () {\n    node.data = iterations = ++iterations % 2;\n  };\n}\n\n// web worker\nfunction useMessageChannel() {\n  var channel = new MessageChannel();\n  channel.port1.onmessage = flush;\n  return function () {\n    return channel.port2.postMessage(0);\n  };\n}\n\nfunction useSetTimeout() {\n  // Store setTimeout reference so es6-promise will be unaffected by\n  // other code modifying setTimeout (like sinon.useFakeTimers())\n  var globalSetTimeout = setTimeout;\n  return function () {\n    return globalSetTimeout(flush, 1);\n  };\n}\n\nvar queue = new Array(1000);\nfunction flush() {\n  for (var i = 0; i < len; i += 2) {\n    var callback = queue[i];\n    var arg = queue[i + 1];\n\n    callback(arg);\n\n    queue[i] = undefined;\n    queue[i + 1] = undefined;\n  }\n\n  len = 0;\n}\n\nfunction attemptVertx() {\n  try {\n    var vertx = Function('return this')().require('vertx');\n    vertxNext = vertx.runOnLoop || vertx.runOnContext;\n    return useVertxTimer();\n  } catch (e) {\n    return useSetTimeout();\n  }\n}\n\nvar scheduleFlush = void 0;\n// Decide what async method to use to triggering processing of queued callbacks:\nif (isNode) {\n  scheduleFlush = useNextTick();\n} else if (BrowserMutationObserver) {\n  scheduleFlush = useMutationObserver();\n} else if (isWorker) {\n  scheduleFlush = useMessageChannel();\n} else if (browserWindow === undefined && typeof require === 'function') {\n  scheduleFlush = attemptVertx();\n} else {\n  scheduleFlush = useSetTimeout();\n}","import { invokeCallback, subscribe, FULFILLED, REJECTED, noop, makePromise, PROMISE_ID } from './-internal';\n\nimport { asap } from './asap';\n\nexport default function then(onFulfillment, onRejection) {\n  var parent = this;\n\n  var child = new this.constructor(noop);\n\n  if (child[PROMISE_ID] === undefined) {\n    makePromise(child);\n  }\n\n  var _state = parent._state;\n\n\n  if (_state) {\n    var callback = arguments[_state - 1];\n    asap(function () {\n      return invokeCallback(_state, child, callback, parent._result);\n    });\n  } else {\n    subscribe(parent, child, onFulfillment, onRejection);\n  }\n\n  return child;\n}","import { noop, resolve as _resolve } from '../-internal';\n\n/**\n  `Promise.resolve` returns a promise that will become resolved with the\n  passed `value`. It is shorthand for the following:\n\n  ```javascript\n  let promise = new Promise(function(resolve, reject){\n    resolve(1);\n  });\n\n  promise.then(function(value){\n    // value === 1\n  });\n  ```\n\n  Instead of writing the above, your code now simply becomes the following:\n\n  ```javascript\n  let promise = Promise.resolve(1);\n\n  promise.then(function(value){\n    // value === 1\n  });\n  ```\n\n  @method resolve\n  @static\n  @param {Any} value value that the returned promise will be resolved with\n  Useful for tooling.\n  @return {Promise} a promise that will become fulfilled with the given\n  `value`\n*/\nexport default function resolve(object) {\n  /*jshint validthis:true */\n  var Constructor = this;\n\n  if (object && typeof object === 'object' && object.constructor === Constructor) {\n    return object;\n  }\n\n  var promise = new Constructor(noop);\n  _resolve(promise, object);\n  return promise;\n}","import { objectOrFunction, isFunction } from './utils';\n\nimport { asap } from './asap';\n\nimport originalThen from './then';\nimport originalResolve from './promise/resolve';\n\nexport var PROMISE_ID = Math.random().toString(36).substring(2);\n\nfunction noop() {}\n\nvar PENDING = void 0;\nvar FULFILLED = 1;\nvar REJECTED = 2;\n\nfunction selfFulfillment() {\n  return new TypeError(\"You cannot resolve a promise with itself\");\n}\n\nfunction cannotReturnOwn() {\n  return new TypeError('A promises callback cannot return that same promise.');\n}\n\nfunction tryThen(then, value, fulfillmentHandler, rejectionHandler) {\n  try {\n    then.call(value, fulfillmentHandler, rejectionHandler);\n  } catch (e) {\n    return e;\n  }\n}\n\nfunction handleForeignThenable(promise, thenable, then) {\n  asap(function (promise) {\n    var sealed = false;\n    var error = tryThen(then, thenable, function (value) {\n      if (sealed) {\n        return;\n      }\n      sealed = true;\n      if (thenable !== value) {\n        resolve(promise, value);\n      } else {\n        fulfill(promise, value);\n      }\n    }, function (reason) {\n      if (sealed) {\n        return;\n      }\n      sealed = true;\n\n      reject(promise, reason);\n    }, 'Settle: ' + (promise._label || ' unknown promise'));\n\n    if (!sealed && error) {\n      sealed = true;\n      reject(promise, error);\n    }\n  }, promise);\n}\n\nfunction handleOwnThenable(promise, thenable) {\n  if (thenable._state === FULFILLED) {\n    fulfill(promise, thenable._result);\n  } else if (thenable._state === REJECTED) {\n    reject(promise, thenable._result);\n  } else {\n    subscribe(thenable, undefined, function (value) {\n      return resolve(promise, value);\n    }, function (reason) {\n      return reject(promise, reason);\n    });\n  }\n}\n\nfunction handleMaybeThenable(promise, maybeThenable, then) {\n  if (maybeThenable.constructor === promise.constructor && then === originalThen && maybeThenable.constructor.resolve === originalResolve) {\n    handleOwnThenable(promise, maybeThenable);\n  } else {\n    if (then === undefined) {\n      fulfill(promise, maybeThenable);\n    } else if (isFunction(then)) {\n      handleForeignThenable(promise, maybeThenable, then);\n    } else {\n      fulfill(promise, maybeThenable);\n    }\n  }\n}\n\nfunction resolve(promise, value) {\n  if (promise === value) {\n    reject(promise, selfFulfillment());\n  } else if (objectOrFunction(value)) {\n    var then = void 0;\n    try {\n      then = value.then;\n    } catch (error) {\n      reject(promise, error);\n      return;\n    }\n    handleMaybeThenable(promise, value, then);\n  } else {\n    fulfill(promise, value);\n  }\n}\n\nfunction publishRejection(promise) {\n  if (promise._onerror) {\n    promise._onerror(promise._result);\n  }\n\n  publish(promise);\n}\n\nfunction fulfill(promise, value) {\n  if (promise._state !== PENDING) {\n    return;\n  }\n\n  promise._result = value;\n  promise._state = FULFILLED;\n\n  if (promise._subscribers.length !== 0) {\n    asap(publish, promise);\n  }\n}\n\nfunction reject(promise, reason) {\n  if (promise._state !== PENDING) {\n    return;\n  }\n  promise._state = REJECTED;\n  promise._result = reason;\n\n  asap(publishRejection, promise);\n}\n\nfunction subscribe(parent, child, onFulfillment, onRejection) {\n  var _subscribers = parent._subscribers;\n  var length = _subscribers.length;\n\n\n  parent._onerror = null;\n\n  _subscribers[length] = child;\n  _subscribers[length + FULFILLED] = onFulfillment;\n  _subscribers[length + REJECTED] = onRejection;\n\n  if (length === 0 && parent._state) {\n    asap(publish, parent);\n  }\n}\n\nfunction publish(promise) {\n  var subscribers = promise._subscribers;\n  var settled = promise._state;\n\n  if (subscribers.length === 0) {\n    return;\n  }\n\n  var child = void 0,\n      callback = void 0,\n      detail = promise._result;\n\n  for (var i = 0; i < subscribers.length; i += 3) {\n    child = subscribers[i];\n    callback = subscribers[i + settled];\n\n    if (child) {\n      invokeCallback(settled, child, callback, detail);\n    } else {\n      callback(detail);\n    }\n  }\n\n  promise._subscribers.length = 0;\n}\n\nfunction invokeCallback(settled, promise, callback, detail) {\n  var hasCallback = isFunction(callback),\n      value = void 0,\n      error = void 0,\n      succeeded = true;\n\n  if (hasCallback) {\n    try {\n      value = callback(detail);\n    } catch (e) {\n      succeeded = false;\n      error = e;\n    }\n\n    if (promise === value) {\n      reject(promise, cannotReturnOwn());\n      return;\n    }\n  } else {\n    value = detail;\n  }\n\n  if (promise._state !== PENDING) {\n    // noop\n  } else if (hasCallback && succeeded) {\n    resolve(promise, value);\n  } else if (succeeded === false) {\n    reject(promise, error);\n  } else if (settled === FULFILLED) {\n    fulfill(promise, value);\n  } else if (settled === REJECTED) {\n    reject(promise, value);\n  }\n}\n\nfunction initializePromise(promise, resolver) {\n  try {\n    resolver(function resolvePromise(value) {\n      resolve(promise, value);\n    }, function rejectPromise(reason) {\n      reject(promise, reason);\n    });\n  } catch (e) {\n    reject(promise, e);\n  }\n}\n\nvar id = 0;\nfunction nextId() {\n  return id++;\n}\n\nfunction makePromise(promise) {\n  promise[PROMISE_ID] = id++;\n  promise._state = undefined;\n  promise._result = undefined;\n  promise._subscribers = [];\n}\n\nexport { nextId, makePromise, noop, resolve, reject, fulfill, subscribe, publish, publishRejection, initializePromise, invokeCallback, FULFILLED, REJECTED, PENDING, handleMaybeThenable };","function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nimport { isArray, isMaybeThenable } from './utils';\nimport { noop, reject, fulfill, subscribe, FULFILLED, REJECTED, PENDING, handleMaybeThenable } from './-internal';\n\nimport then from './then';\nimport Promise from './promise';\nimport originalResolve from './promise/resolve';\nimport originalThen from './then';\nimport { makePromise, PROMISE_ID } from './-internal';\n\nfunction validationError() {\n  return new Error('Array Methods must be provided an Array');\n};\n\nvar Enumerator = function () {\n  function Enumerator(Constructor, input) {\n    this._instanceConstructor = Constructor;\n    this.promise = new Constructor(noop);\n\n    if (!this.promise[PROMISE_ID]) {\n      makePromise(this.promise);\n    }\n\n    if (isArray(input)) {\n      this.length = input.length;\n      this._remaining = input.length;\n\n      this._result = new Array(this.length);\n\n      if (this.length === 0) {\n        fulfill(this.promise, this._result);\n      } else {\n        this.length = this.length || 0;\n        this._enumerate(input);\n        if (this._remaining === 0) {\n          fulfill(this.promise, this._result);\n        }\n      }\n    } else {\n      reject(this.promise, validationError());\n    }\n  }\n\n  Enumerator.prototype._enumerate = function _enumerate(input) {\n    for (var i = 0; this._state === PENDING && i < input.length; i++) {\n      this._eachEntry(input[i], i);\n    }\n  };\n\n  Enumerator.prototype._eachEntry = function _eachEntry(entry, i) {\n    var c = this._instanceConstructor;\n    var resolve = c.resolve;\n\n\n    if (resolve === originalResolve) {\n      var _then = void 0;\n      var error = void 0;\n      var didError = false;\n      try {\n        _then = entry.then;\n      } catch (e) {\n        didError = true;\n        error = e;\n      }\n\n      if (_then === originalThen && entry._state !== PENDING) {\n        this._settledAt(entry._state, i, entry._result);\n      } else if (typeof _then !== 'function') {\n        this._remaining--;\n        this._result[i] = entry;\n      } else if (c === Promise) {\n        var promise = new c(noop);\n        if (didError) {\n          reject(promise, error);\n        } else {\n          handleMaybeThenable(promise, entry, _then);\n        }\n        this._willSettleAt(promise, i);\n      } else {\n        this._willSettleAt(new c(function (resolve) {\n          return resolve(entry);\n        }), i);\n      }\n    } else {\n      this._willSettleAt(resolve(entry), i);\n    }\n  };\n\n  Enumerator.prototype._settledAt = function _settledAt(state, i, value) {\n    var promise = this.promise;\n\n\n    if (promise._state === PENDING) {\n      this._remaining--;\n\n      if (state === REJECTED) {\n        reject(promise, value);\n      } else {\n        this._result[i] = value;\n      }\n    }\n\n    if (this._remaining === 0) {\n      fulfill(promise, this._result);\n    }\n  };\n\n  Enumerator.prototype._willSettleAt = function _willSettleAt(promise, i) {\n    var enumerator = this;\n\n    subscribe(promise, undefined, function (value) {\n      return enumerator._settledAt(FULFILLED, i, value);\n    }, function (reason) {\n      return enumerator._settledAt(REJECTED, i, reason);\n    });\n  };\n\n  return Enumerator;\n}();\n\nexport default Enumerator;\n;","import Enumerator from '../enumerator';\n\n/**\n  `Promise.all` accepts an array of promises, and returns a new promise which\n  is fulfilled with an array of fulfillment values for the passed promises, or\n  rejected with the reason of the first passed promise to be rejected. It casts all\n  elements of the passed iterable to promises as it runs this algorithm.\n\n  Example:\n\n  ```javascript\n  let promise1 = resolve(1);\n  let promise2 = resolve(2);\n  let promise3 = resolve(3);\n  let promises = [ promise1, promise2, promise3 ];\n\n  Promise.all(promises).then(function(array){\n    // The array here would be [ 1, 2, 3 ];\n  });\n  ```\n\n  If any of the `promises` given to `all` are rejected, the first promise\n  that is rejected will be given as an argument to the returned promises's\n  rejection handler. For example:\n\n  Example:\n\n  ```javascript\n  let promise1 = resolve(1);\n  let promise2 = reject(new Error(\"2\"));\n  let promise3 = reject(new Error(\"3\"));\n  let promises = [ promise1, promise2, promise3 ];\n\n  Promise.all(promises).then(function(array){\n    // Code here never runs because there are rejected promises!\n  }, function(error) {\n    // error.message === \"2\"\n  });\n  ```\n\n  @method all\n  @static\n  @param {Array} entries array of promises\n  @param {String} label optional string for labeling the promise.\n  Useful for tooling.\n  @return {Promise} promise that is fulfilled when all `promises` have been\n  fulfilled, or rejected if any of them become rejected.\n  @static\n*/\nexport default function all(entries) {\n  return new Enumerator(this, entries).promise;\n}","import { isArray } from \"../utils\";\n\n/**\n  `Promise.race` returns a new promise which is settled in the same way as the\n  first passed promise to settle.\n\n  Example:\n\n  ```javascript\n  let promise1 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 1');\n    }, 200);\n  });\n\n  let promise2 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 2');\n    }, 100);\n  });\n\n  Promise.race([promise1, promise2]).then(function(result){\n    // result === 'promise 2' because it was resolved before promise1\n    // was resolved.\n  });\n  ```\n\n  `Promise.race` is deterministic in that only the state of the first\n  settled promise matters. For example, even if other promises given to the\n  `promises` array argument are resolved, but the first settled promise has\n  become rejected before the other promises became fulfilled, the returned\n  promise will become rejected:\n\n  ```javascript\n  let promise1 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      resolve('promise 1');\n    }, 200);\n  });\n\n  let promise2 = new Promise(function(resolve, reject){\n    setTimeout(function(){\n      reject(new Error('promise 2'));\n    }, 100);\n  });\n\n  Promise.race([promise1, promise2]).then(function(result){\n    // Code here never runs\n  }, function(reason){\n    // reason.message === 'promise 2' because promise 2 became rejected before\n    // promise 1 became fulfilled\n  });\n  ```\n\n  An example real-world use case is implementing timeouts:\n\n  ```javascript\n  Promise.race([ajax('foo.json'), timeout(5000)])\n  ```\n\n  @method race\n  @static\n  @param {Array} promises array of promises to observe\n  Useful for tooling.\n  @return {Promise} a promise which settles in the same way as the first passed\n  promise to settle.\n*/\nexport default function race(entries) {\n  /*jshint validthis:true */\n  var Constructor = this;\n\n  if (!isArray(entries)) {\n    return new Constructor(function (_, reject) {\n      return reject(new TypeError('You must pass an array to race.'));\n    });\n  } else {\n    return new Constructor(function (resolve, reject) {\n      var length = entries.length;\n      for (var i = 0; i < length; i++) {\n        Constructor.resolve(entries[i]).then(resolve, reject);\n      }\n    });\n  }\n}","import { noop, reject as _reject } from '../-internal';\n\n/**\n  `Promise.reject` returns a promise rejected with the passed `reason`.\n  It is shorthand for the following:\n\n  ```javascript\n  let promise = new Promise(function(resolve, reject){\n    reject(new Error('WHOOPS'));\n  });\n\n  promise.then(function(value){\n    // Code here doesn't run because the promise is rejected!\n  }, function(reason){\n    // reason.message === 'WHOOPS'\n  });\n  ```\n\n  Instead of writing the above, your code now simply becomes the following:\n\n  ```javascript\n  let promise = Promise.reject(new Error('WHOOPS'));\n\n  promise.then(function(value){\n    // Code here doesn't run because the promise is rejected!\n  }, function(reason){\n    // reason.message === 'WHOOPS'\n  });\n  ```\n\n  @method reject\n  @static\n  @param {Any} reason value that the returned promise will be rejected with.\n  Useful for tooling.\n  @return {Promise} a promise rejected with the given `reason`.\n*/\nexport default function reject(reason) {\n  /*jshint validthis:true */\n  var Constructor = this;\n  var promise = new Constructor(noop);\n  _reject(promise, reason);\n  return promise;\n}","function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nimport { isFunction } from './utils';\nimport { noop, nextId, PROMISE_ID, initializePromise } from './-internal';\nimport { asap, setAsap, setScheduler } from './asap';\n\nimport all from './promise/all';\nimport race from './promise/race';\nimport Resolve from './promise/resolve';\nimport Reject from './promise/reject';\nimport then from './then';\n\nfunction needsResolver() {\n  throw new TypeError('You must pass a resolver function as the first argument to the promise constructor');\n}\n\nfunction needsNew() {\n  throw new TypeError(\"Failed to construct 'Promise': Please use the 'new' operator, this object constructor cannot be called as a function.\");\n}\n\n/**\n  Promise objects represent the eventual result of an asynchronous operation. The\n  primary way of interacting with a promise is through its `then` method, which\n  registers callbacks to receive either a promise's eventual value or the reason\n  why the promise cannot be fulfilled.\n\n  Terminology\n  -----------\n\n  - `promise` is an object or function with a `then` method whose behavior conforms to this specification.\n  - `thenable` is an object or function that defines a `then` method.\n  - `value` is any legal JavaScript value (including undefined, a thenable, or a promise).\n  - `exception` is a value that is thrown using the throw statement.\n  - `reason` is a value that indicates why a promise was rejected.\n  - `settled` the final resting state of a promise, fulfilled or rejected.\n\n  A promise can be in one of three states: pending, fulfilled, or rejected.\n\n  Promises that are fulfilled have a fulfillment value and are in the fulfilled\n  state.  Promises that are rejected have a rejection reason and are in the\n  rejected state.  A fulfillment value is never a thenable.\n\n  Promises can also be said to *resolve* a value.  If this value is also a\n  promise, then the original promise's settled state will match the value's\n  settled state.  So a promise that *resolves* a promise that rejects will\n  itself reject, and a promise that *resolves* a promise that fulfills will\n  itself fulfill.\n\n\n  Basic Usage:\n  ------------\n\n  ```js\n  let promise = new Promise(function(resolve, reject) {\n    // on success\n    resolve(value);\n\n    // on failure\n    reject(reason);\n  });\n\n  promise.then(function(value) {\n    // on fulfillment\n  }, function(reason) {\n    // on rejection\n  });\n  ```\n\n  Advanced Usage:\n  ---------------\n\n  Promises shine when abstracting away asynchronous interactions such as\n  `XMLHttpRequest`s.\n\n  ```js\n  function getJSON(url) {\n    return new Promise(function(resolve, reject){\n      let xhr = new XMLHttpRequest();\n\n      xhr.open('GET', url);\n      xhr.onreadystatechange = handler;\n      xhr.responseType = 'json';\n      xhr.setRequestHeader('Accept', 'application/json');\n      xhr.send();\n\n      function handler() {\n        if (this.readyState === this.DONE) {\n          if (this.status === 200) {\n            resolve(this.response);\n          } else {\n            reject(new Error('getJSON: `' + url + '` failed with status: [' + this.status + ']'));\n          }\n        }\n      };\n    });\n  }\n\n  getJSON('/posts.json').then(function(json) {\n    // on fulfillment\n  }, function(reason) {\n    // on rejection\n  });\n  ```\n\n  Unlike callbacks, promises are great composable primitives.\n\n  ```js\n  Promise.all([\n    getJSON('/posts'),\n    getJSON('/comments')\n  ]).then(function(values){\n    values[0] // => postsJSON\n    values[1] // => commentsJSON\n\n    return values;\n  });\n  ```\n\n  @class Promise\n  @param {Function} resolver\n  Useful for tooling.\n  @constructor\n*/\n\nvar Promise = function () {\n  function Promise(resolver) {\n    this[PROMISE_ID] = nextId();\n    this._result = this._state = undefined;\n    this._subscribers = [];\n\n    if (noop !== resolver) {\n      typeof resolver !== 'function' && needsResolver();\n      this instanceof Promise ? initializePromise(this, resolver) : needsNew();\n    }\n  }\n\n  /**\n  The primary way of interacting with a promise is through its `then` method,\n  which registers callbacks to receive either a promise's eventual value or the\n  reason why the promise cannot be fulfilled.\n   ```js\n  findUser().then(function(user){\n    // user is available\n  }, function(reason){\n    // user is unavailable, and you are given the reason why\n  });\n  ```\n   Chaining\n  --------\n   The return value of `then` is itself a promise.  This second, 'downstream'\n  promise is resolved with the return value of the first promise's fulfillment\n  or rejection handler, or rejected if the handler throws an exception.\n   ```js\n  findUser().then(function (user) {\n    return user.name;\n  }, function (reason) {\n    return 'default name';\n  }).then(function (userName) {\n    // If `findUser` fulfilled, `userName` will be the user's name, otherwise it\n    // will be `'default name'`\n  });\n   findUser().then(function (user) {\n    throw new Error('Found user, but still unhappy');\n  }, function (reason) {\n    throw new Error('`findUser` rejected and we're unhappy');\n  }).then(function (value) {\n    // never reached\n  }, function (reason) {\n    // if `findUser` fulfilled, `reason` will be 'Found user, but still unhappy'.\n    // If `findUser` rejected, `reason` will be '`findUser` rejected and we're unhappy'.\n  });\n  ```\n  If the downstream promise does not specify a rejection handler, rejection reasons will be propagated further downstream.\n   ```js\n  findUser().then(function (user) {\n    throw new PedagogicalException('Upstream error');\n  }).then(function (value) {\n    // never reached\n  }).then(function (value) {\n    // never reached\n  }, function (reason) {\n    // The `PedgagocialException` is propagated all the way down to here\n  });\n  ```\n   Assimilation\n  ------------\n   Sometimes the value you want to propagate to a downstream promise can only be\n  retrieved asynchronously. This can be achieved by returning a promise in the\n  fulfillment or rejection handler. The downstream promise will then be pending\n  until the returned promise is settled. This is called *assimilation*.\n   ```js\n  findUser().then(function (user) {\n    return findCommentsByAuthor(user);\n  }).then(function (comments) {\n    // The user's comments are now available\n  });\n  ```\n   If the assimliated promise rejects, then the downstream promise will also reject.\n   ```js\n  findUser().then(function (user) {\n    return findCommentsByAuthor(user);\n  }).then(function (comments) {\n    // If `findCommentsByAuthor` fulfills, we'll have the value here\n  }, function (reason) {\n    // If `findCommentsByAuthor` rejects, we'll have the reason here\n  });\n  ```\n   Simple Example\n  --------------\n   Synchronous Example\n   ```javascript\n  let result;\n   try {\n    result = findResult();\n    // success\n  } catch(reason) {\n    // failure\n  }\n  ```\n   Errback Example\n   ```js\n  findResult(function(result, err){\n    if (err) {\n      // failure\n    } else {\n      // success\n    }\n  });\n  ```\n   Promise Example;\n   ```javascript\n  findResult().then(function(result){\n    // success\n  }, function(reason){\n    // failure\n  });\n  ```\n   Advanced Example\n  --------------\n   Synchronous Example\n   ```javascript\n  let author, books;\n   try {\n    author = findAuthor();\n    books  = findBooksByAuthor(author);\n    // success\n  } catch(reason) {\n    // failure\n  }\n  ```\n   Errback Example\n   ```js\n   function foundBooks(books) {\n   }\n   function failure(reason) {\n   }\n   findAuthor(function(author, err){\n    if (err) {\n      failure(err);\n      // failure\n    } else {\n      try {\n        findBoooksByAuthor(author, function(books, err) {\n          if (err) {\n            failure(err);\n          } else {\n            try {\n              foundBooks(books);\n            } catch(reason) {\n              failure(reason);\n            }\n          }\n        });\n      } catch(error) {\n        failure(err);\n      }\n      // success\n    }\n  });\n  ```\n   Promise Example;\n   ```javascript\n  findAuthor().\n    then(findBooksByAuthor).\n    then(function(books){\n      // found books\n  }).catch(function(reason){\n    // something went wrong\n  });\n  ```\n   @method then\n  @param {Function} onFulfilled\n  @param {Function} onRejected\n  Useful for tooling.\n  @return {Promise}\n  */\n\n  /**\n  `catch` is simply sugar for `then(undefined, onRejection)` which makes it the same\n  as the catch block of a try/catch statement.\n  ```js\n  function findAuthor(){\n  throw new Error('couldn't find that author');\n  }\n  // synchronous\n  try {\n  findAuthor();\n  } catch(reason) {\n  // something went wrong\n  }\n  // async with promises\n  findAuthor().catch(function(reason){\n  // something went wrong\n  });\n  ```\n  @method catch\n  @param {Function} onRejection\n  Useful for tooling.\n  @return {Promise}\n  */\n\n\n  Promise.prototype.catch = function _catch(onRejection) {\n    return this.then(null, onRejection);\n  };\n\n  /**\n    `finally` will be invoked regardless of the promise's fate just as native\n    try/catch/finally behaves\n  \n    Synchronous example:\n  \n    ```js\n    findAuthor() {\n      if (Math.random() > 0.5) {\n        throw new Error();\n      }\n      return new Author();\n    }\n  \n    try {\n      return findAuthor(); // succeed or fail\n    } catch(error) {\n      return findOtherAuther();\n    } finally {\n      // always runs\n      // doesn't affect the return value\n    }\n    ```\n  \n    Asynchronous example:\n  \n    ```js\n    findAuthor().catch(function(reason){\n      return findOtherAuther();\n    }).finally(function(){\n      // author was either found, or not\n    });\n    ```\n  \n    @method finally\n    @param {Function} callback\n    @return {Promise}\n  */\n\n\n  Promise.prototype.finally = function _finally(callback) {\n    var promise = this;\n    var constructor = promise.constructor;\n\n    if (isFunction(callback)) {\n      return promise.then(function (value) {\n        return constructor.resolve(callback()).then(function () {\n          return value;\n        });\n      }, function (reason) {\n        return constructor.resolve(callback()).then(function () {\n          throw reason;\n        });\n      });\n    }\n\n    return promise.then(callback, callback);\n  };\n\n  return Promise;\n}();\n\nPromise.prototype.then = then;\nexport default Promise;\nPromise.all = all;\nPromise.race = race;\nPromise.resolve = Resolve;\nPromise.reject = Reject;\nPromise._setScheduler = setScheduler;\nPromise._setAsap = setAsap;\nPromise._asap = asap;","/*global self*/\nimport Promise from './promise';\n\nexport default function polyfill() {\n  var local = void 0;\n\n  if (typeof global !== 'undefined') {\n    local = global;\n  } else if (typeof self !== 'undefined') {\n    local = self;\n  } else {\n    try {\n      local = Function('return this')();\n    } catch (e) {\n      throw new Error('polyfill failed because global object is unavailable in this environment');\n    }\n  }\n\n  var P = local.Promise;\n\n  if (P) {\n    var promiseToString = null;\n    try {\n      promiseToString = Object.prototype.toString.call(P.resolve());\n    } catch (e) {\n      // silently ignored\n    }\n\n    if (promiseToString === '[object Promise]' && !P.cast) {\n      return;\n    }\n  }\n\n  local.Promise = Promise;\n}","import Promise from './es6-promise/promise';\nimport polyfill from './es6-promise/polyfill';\n\n// Strange compat..\nPromise.polyfill = polyfill;\nPromise.Promise = Promise;\nexport default Promise;","/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */\nexports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView');\n\nmodule.exports = DataView;\n","var hashClear = require('./_hashClear'),\n    hashDelete = require('./_hashDelete'),\n    hashGet = require('./_hashGet'),\n    hashHas = require('./_hashHas'),\n    hashSet = require('./_hashSet');\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\nmodule.exports = Hash;\n","var baseCreate = require('./_baseCreate'),\n    baseLodash = require('./_baseLodash');\n\n/** Used as references for the maximum length and index of an array. */\nvar MAX_ARRAY_LENGTH = 4294967295;\n\n/**\n * Creates a lazy wrapper object which wraps `value` to enable lazy evaluation.\n *\n * @private\n * @constructor\n * @param {*} value The value to wrap.\n */\nfunction LazyWrapper(value) {\n  this.__wrapped__ = value;\n  this.__actions__ = [];\n  this.__dir__ = 1;\n  this.__filtered__ = false;\n  this.__iteratees__ = [];\n  this.__takeCount__ = MAX_ARRAY_LENGTH;\n  this.__views__ = [];\n}\n\n// Ensure `LazyWrapper` is an instance of `baseLodash`.\nLazyWrapper.prototype = baseCreate(baseLodash.prototype);\nLazyWrapper.prototype.constructor = LazyWrapper;\n\nmodule.exports = LazyWrapper;\n","var listCacheClear = require('./_listCacheClear'),\n    listCacheDelete = require('./_listCacheDelete'),\n    listCacheGet = require('./_listCacheGet'),\n    listCacheHas = require('./_listCacheHas'),\n    listCacheSet = require('./_listCacheSet');\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\nmodule.exports = ListCache;\n","var baseCreate = require('./_baseCreate'),\n    baseLodash = require('./_baseLodash');\n\n/**\n * The base constructor for creating `lodash` wrapper objects.\n *\n * @private\n * @param {*} value The value to wrap.\n * @param {boolean} [chainAll] Enable explicit method chain sequences.\n */\nfunction LodashWrapper(value, chainAll) {\n  this.__wrapped__ = value;\n  this.__actions__ = [];\n  this.__chain__ = !!chainAll;\n  this.__index__ = 0;\n  this.__values__ = undefined;\n}\n\nLodashWrapper.prototype = baseCreate(baseLodash.prototype);\nLodashWrapper.prototype.constructor = LodashWrapper;\n\nmodule.exports = LodashWrapper;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar Map = getNative(root, 'Map');\n\nmodule.exports = Map;\n","var mapCacheClear = require('./_mapCacheClear'),\n    mapCacheDelete = require('./_mapCacheDelete'),\n    mapCacheGet = require('./_mapCacheGet'),\n    mapCacheHas = require('./_mapCacheHas'),\n    mapCacheSet = require('./_mapCacheSet');\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\nmodule.exports = MapCache;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar Promise = getNative(root, 'Promise');\n\nmodule.exports = Promise;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar Set = getNative(root, 'Set');\n\nmodule.exports = Set;\n","var MapCache = require('./_MapCache'),\n    setCacheAdd = require('./_setCacheAdd'),\n    setCacheHas = require('./_setCacheHas');\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values == null ? 0 : values.length;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\nmodule.exports = SetCache;\n","var ListCache = require('./_ListCache'),\n    stackClear = require('./_stackClear'),\n    stackDelete = require('./_stackDelete'),\n    stackGet = require('./_stackGet'),\n    stackHas = require('./_stackHas'),\n    stackSet = require('./_stackSet');\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  var data = this.__data__ = new ListCache(entries);\n  this.size = data.size;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\nmodule.exports = Stack;\n","var root = require('./_root');\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\nmodule.exports = Symbol;\n","var root = require('./_root');\n\n/** Built-in value references. */\nvar Uint8Array = root.Uint8Array;\n\nmodule.exports = Uint8Array;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar WeakMap = getNative(root, 'WeakMap');\n\nmodule.exports = WeakMap;\n","/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\nmodule.exports = apply;\n","/**\n * A specialized version of `_.forEach` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns `array`.\n */\nfunction arrayEach(array, iteratee) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (iteratee(array[index], index, array) === false) {\n      break;\n    }\n  }\n  return array;\n}\n\nmodule.exports = arrayEach;\n","/**\n * A specialized version of `_.filter` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n */\nfunction arrayFilter(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (predicate(value, index, array)) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nmodule.exports = arrayFilter;\n","var baseIndexOf = require('./_baseIndexOf');\n\n/**\n * A specialized version of `_.includes` for arrays without support for\n * specifying an index to search from.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludes(array, value) {\n  var length = array == null ? 0 : array.length;\n  return !!length && baseIndexOf(array, value, 0) > -1;\n}\n\nmodule.exports = arrayIncludes;\n","/**\n * This function is like `arrayIncludes` except that it accepts a comparator.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @param {Function} comparator The comparator invoked per element.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludesWith(array, value, comparator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (comparator(value, array[index])) {\n      return true;\n    }\n  }\n  return false;\n}\n\nmodule.exports = arrayIncludesWith;\n","var baseTimes = require('./_baseTimes'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray'),\n    isBuffer = require('./isBuffer'),\n    isIndex = require('./_isIndex'),\n    isTypedArray = require('./isTypedArray');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  var isArr = isArray(value),\n      isArg = !isArr && isArguments(value),\n      isBuff = !isArr && !isArg && isBuffer(value),\n      isType = !isArr && !isArg && !isBuff && isTypedArray(value),\n      skipIndexes = isArr || isArg || isBuff || isType,\n      result = skipIndexes ? baseTimes(value.length, String) : [],\n      length = result.length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (\n           // Safari 9 has enumerable `arguments.length` in strict mode.\n           key == 'length' ||\n           // Node.js 0.10 has enumerable non-index properties on buffers.\n           (isBuff && (key == 'offset' || key == 'parent')) ||\n           // PhantomJS 2 has enumerable non-index properties on typed arrays.\n           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||\n           // Skip index properties.\n           isIndex(key, length)\n        ))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = arrayLikeKeys;\n","/**\n * A specialized version of `_.map` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction arrayMap(array, iteratee) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      result = Array(length);\n\n  while (++index < length) {\n    result[index] = iteratee(array[index], index, array);\n  }\n  return result;\n}\n\nmodule.exports = arrayMap;\n","/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\nmodule.exports = arrayPush;\n","var baseAssignValue = require('./_baseAssignValue'),\n    eq = require('./eq');\n\n/**\n * This function is like `assignValue` except that it doesn't assign\n * `undefined` values.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignMergeValue(object, key, value) {\n  if ((value !== undefined && !eq(object[key], value)) ||\n      (value === undefined && !(key in object))) {\n    baseAssignValue(object, key, value);\n  }\n}\n\nmodule.exports = assignMergeValue;\n","var baseAssignValue = require('./_baseAssignValue'),\n    eq = require('./eq');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns `value` to `key` of `object` if the existing value is not equivalent\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignValue(object, key, value) {\n  var objValue = object[key];\n  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||\n      (value === undefined && !(key in object))) {\n    baseAssignValue(object, key, value);\n  }\n}\n\nmodule.exports = assignValue;\n","var eq = require('./eq');\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = assocIndexOf;\n","var copyObject = require('./_copyObject'),\n    keys = require('./keys');\n\n/**\n * The base implementation of `_.assign` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssign(object, source) {\n  return object && copyObject(source, keys(source), object);\n}\n\nmodule.exports = baseAssign;\n","var copyObject = require('./_copyObject'),\n    keysIn = require('./keysIn');\n\n/**\n * The base implementation of `_.assignIn` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssignIn(object, source) {\n  return object && copyObject(source, keysIn(source), object);\n}\n\nmodule.exports = baseAssignIn;\n","var defineProperty = require('./_defineProperty');\n\n/**\n * The base implementation of `assignValue` and `assignMergeValue` without\n * value checks.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction baseAssignValue(object, key, value) {\n  if (key == '__proto__' && defineProperty) {\n    defineProperty(object, key, {\n      'configurable': true,\n      'enumerable': true,\n      'value': value,\n      'writable': true\n    });\n  } else {\n    object[key] = value;\n  }\n}\n\nmodule.exports = baseAssignValue;\n","/**\n * The base implementation of `_.clamp` which doesn't coerce arguments.\n *\n * @private\n * @param {number} number The number to clamp.\n * @param {number} [lower] The lower bound.\n * @param {number} upper The upper bound.\n * @returns {number} Returns the clamped number.\n */\nfunction baseClamp(number, lower, upper) {\n  if (number === number) {\n    if (upper !== undefined) {\n      number = number <= upper ? number : upper;\n    }\n    if (lower !== undefined) {\n      number = number >= lower ? number : lower;\n    }\n  }\n  return number;\n}\n\nmodule.exports = baseClamp;\n","var Stack = require('./_Stack'),\n    arrayEach = require('./_arrayEach'),\n    assignValue = require('./_assignValue'),\n    baseAssign = require('./_baseAssign'),\n    baseAssignIn = require('./_baseAssignIn'),\n    cloneBuffer = require('./_cloneBuffer'),\n    copyArray = require('./_copyArray'),\n    copySymbols = require('./_copySymbols'),\n    copySymbolsIn = require('./_copySymbolsIn'),\n    getAllKeys = require('./_getAllKeys'),\n    getAllKeysIn = require('./_getAllKeysIn'),\n    getTag = require('./_getTag'),\n    initCloneArray = require('./_initCloneArray'),\n    initCloneByTag = require('./_initCloneByTag'),\n    initCloneObject = require('./_initCloneObject'),\n    isArray = require('./isArray'),\n    isBuffer = require('./isBuffer'),\n    isMap = require('./isMap'),\n    isObject = require('./isObject'),\n    isSet = require('./isSet'),\n    keys = require('./keys'),\n    keysIn = require('./keysIn');\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_DEEP_FLAG = 1,\n    CLONE_FLAT_FLAG = 2,\n    CLONE_SYMBOLS_FLAG = 4;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/** Used to identify `toStringTag` values supported by `_.clone`. */\nvar cloneableTags = {};\ncloneableTags[argsTag] = cloneableTags[arrayTag] =\ncloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =\ncloneableTags[boolTag] = cloneableTags[dateTag] =\ncloneableTags[float32Tag] = cloneableTags[float64Tag] =\ncloneableTags[int8Tag] = cloneableTags[int16Tag] =\ncloneableTags[int32Tag] = cloneableTags[mapTag] =\ncloneableTags[numberTag] = cloneableTags[objectTag] =\ncloneableTags[regexpTag] = cloneableTags[setTag] =\ncloneableTags[stringTag] = cloneableTags[symbolTag] =\ncloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =\ncloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\ncloneableTags[errorTag] = cloneableTags[funcTag] =\ncloneableTags[weakMapTag] = false;\n\n/**\n * The base implementation of `_.clone` and `_.cloneDeep` which tracks\n * traversed objects.\n *\n * @private\n * @param {*} value The value to clone.\n * @param {boolean} bitmask The bitmask flags.\n *  1 - Deep clone\n *  2 - Flatten inherited properties\n *  4 - Clone symbols\n * @param {Function} [customizer] The function to customize cloning.\n * @param {string} [key] The key of `value`.\n * @param {Object} [object] The parent object of `value`.\n * @param {Object} [stack] Tracks traversed objects and their clone counterparts.\n * @returns {*} Returns the cloned value.\n */\nfunction baseClone(value, bitmask, customizer, key, object, stack) {\n  var result,\n      isDeep = bitmask & CLONE_DEEP_FLAG,\n      isFlat = bitmask & CLONE_FLAT_FLAG,\n      isFull = bitmask & CLONE_SYMBOLS_FLAG;\n\n  if (customizer) {\n    result = object ? customizer(value, key, object, stack) : customizer(value);\n  }\n  if (result !== undefined) {\n    return result;\n  }\n  if (!isObject(value)) {\n    return value;\n  }\n  var isArr = isArray(value);\n  if (isArr) {\n    result = initCloneArray(value);\n    if (!isDeep) {\n      return copyArray(value, result);\n    }\n  } else {\n    var tag = getTag(value),\n        isFunc = tag == funcTag || tag == genTag;\n\n    if (isBuffer(value)) {\n      return cloneBuffer(value, isDeep);\n    }\n    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {\n      result = (isFlat || isFunc) ? {} : initCloneObject(value);\n      if (!isDeep) {\n        return isFlat\n          ? copySymbolsIn(value, baseAssignIn(result, value))\n          : copySymbols(value, baseAssign(result, value));\n      }\n    } else {\n      if (!cloneableTags[tag]) {\n        return object ? value : {};\n      }\n      result = initCloneByTag(value, tag, isDeep);\n    }\n  }\n  // Check for circular references and return its corresponding clone.\n  stack || (stack = new Stack);\n  var stacked = stack.get(value);\n  if (stacked) {\n    return stacked;\n  }\n  stack.set(value, result);\n\n  if (isSet(value)) {\n    value.forEach(function(subValue) {\n      result.add(baseClone(subValue, bitmask, customizer, subValue, value, stack));\n    });\n  } else if (isMap(value)) {\n    value.forEach(function(subValue, key) {\n      result.set(key, baseClone(subValue, bitmask, customizer, key, value, stack));\n    });\n  }\n\n  var keysFunc = isFull\n    ? (isFlat ? getAllKeysIn : getAllKeys)\n    : (isFlat ? keysIn : keys);\n\n  var props = isArr ? undefined : keysFunc(value);\n  arrayEach(props || value, function(subValue, key) {\n    if (props) {\n      key = subValue;\n      subValue = value[key];\n    }\n    // Recursively populate clone (susceptible to call stack limits).\n    assignValue(result, key, baseClone(subValue, bitmask, customizer, key, value, stack));\n  });\n  return result;\n}\n\nmodule.exports = baseClone;\n","var isObject = require('./isObject');\n\n/** Built-in value references. */\nvar objectCreate = Object.create;\n\n/**\n * The base implementation of `_.create` without support for assigning\n * properties to the created object.\n *\n * @private\n * @param {Object} proto The object to inherit from.\n * @returns {Object} Returns the new object.\n */\nvar baseCreate = (function() {\n  function object() {}\n  return function(proto) {\n    if (!isObject(proto)) {\n      return {};\n    }\n    if (objectCreate) {\n      return objectCreate(proto);\n    }\n    object.prototype = proto;\n    var result = new object;\n    object.prototype = undefined;\n    return result;\n  };\n}());\n\nmodule.exports = baseCreate;\n","var toInteger = require('./toInteger'),\n    toLength = require('./toLength');\n\n/**\n * The base implementation of `_.fill` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to fill.\n * @param {*} value The value to fill `array` with.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns `array`.\n */\nfunction baseFill(array, value, start, end) {\n  var length = array.length;\n\n  start = toInteger(start);\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = (end === undefined || end > length) ? length : toInteger(end);\n  if (end < 0) {\n    end += length;\n  }\n  end = start > end ? 0 : toLength(end);\n  while (start < end) {\n    array[start++] = value;\n  }\n  return array;\n}\n\nmodule.exports = baseFill;\n","/**\n * The base implementation of `_.findIndex` and `_.findLastIndex` without\n * support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} predicate The function invoked per iteration.\n * @param {number} fromIndex The index to search from.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseFindIndex(array, predicate, fromIndex, fromRight) {\n  var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n\n  while ((fromRight ? index-- : ++index < length)) {\n    if (predicate(array[index], index, array)) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = baseFindIndex;\n","var arrayPush = require('./_arrayPush'),\n    isFlattenable = require('./_isFlattenable');\n\n/**\n * The base implementation of `_.flatten` with support for restricting flattening.\n *\n * @private\n * @param {Array} array The array to flatten.\n * @param {number} depth The maximum recursion depth.\n * @param {boolean} [predicate=isFlattenable] The function invoked per iteration.\n * @param {boolean} [isStrict] Restrict to values that pass `predicate` checks.\n * @param {Array} [result=[]] The initial result value.\n * @returns {Array} Returns the new flattened array.\n */\nfunction baseFlatten(array, depth, predicate, isStrict, result) {\n  var index = -1,\n      length = array.length;\n\n  predicate || (predicate = isFlattenable);\n  result || (result = []);\n\n  while (++index < length) {\n    var value = array[index];\n    if (depth > 0 && predicate(value)) {\n      if (depth > 1) {\n        // Recursively flatten arrays (susceptible to call stack limits).\n        baseFlatten(value, depth - 1, predicate, isStrict, result);\n      } else {\n        arrayPush(result, value);\n      }\n    } else if (!isStrict) {\n      result[result.length] = value;\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseFlatten;\n","var createBaseFor = require('./_createBaseFor');\n\n/**\n * The base implementation of `baseForOwn` which iterates over `object`\n * properties returned by `keysFunc` and invokes `iteratee` for each property.\n * Iteratee functions may exit iteration early by explicitly returning `false`.\n *\n * @private\n * @param {Object} object The object to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @returns {Object} Returns `object`.\n */\nvar baseFor = createBaseFor();\n\nmodule.exports = baseFor;\n","var castPath = require('./_castPath'),\n    toKey = require('./_toKey');\n\n/**\n * The base implementation of `_.get` without support for default values.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array|string} path The path of the property to get.\n * @returns {*} Returns the resolved value.\n */\nfunction baseGet(object, path) {\n  path = castPath(path, object);\n\n  var index = 0,\n      length = path.length;\n\n  while (object != null && index < length) {\n    object = object[toKey(path[index++])];\n  }\n  return (index && index == length) ? object : undefined;\n}\n\nmodule.exports = baseGet;\n","var arrayPush = require('./_arrayPush'),\n    isArray = require('./isArray');\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\nmodule.exports = baseGetAllKeys;\n","var Symbol = require('./_Symbol'),\n    getRawTag = require('./_getRawTag'),\n    objectToString = require('./_objectToString');\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\nmodule.exports = baseGetTag;\n","/**\n * The base implementation of `_.hasIn` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHasIn(object, key) {\n  return object != null && key in Object(object);\n}\n\nmodule.exports = baseHasIn;\n","var baseFindIndex = require('./_baseFindIndex'),\n    baseIsNaN = require('./_baseIsNaN'),\n    strictIndexOf = require('./_strictIndexOf');\n\n/**\n * The base implementation of `_.indexOf` without `fromIndex` bounds checks.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseIndexOf(array, value, fromIndex) {\n  return value === value\n    ? strictIndexOf(array, value, fromIndex)\n    : baseFindIndex(array, baseIsNaN, fromIndex);\n}\n\nmodule.exports = baseIndexOf;\n","var SetCache = require('./_SetCache'),\n    arrayIncludes = require('./_arrayIncludes'),\n    arrayIncludesWith = require('./_arrayIncludesWith'),\n    arrayMap = require('./_arrayMap'),\n    baseUnary = require('./_baseUnary'),\n    cacheHas = require('./_cacheHas');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMin = Math.min;\n\n/**\n * The base implementation of methods like `_.intersection`, without support\n * for iteratee shorthands, that accepts an array of arrays to inspect.\n *\n * @private\n * @param {Array} arrays The arrays to inspect.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of shared values.\n */\nfunction baseIntersection(arrays, iteratee, comparator) {\n  var includes = comparator ? arrayIncludesWith : arrayIncludes,\n      length = arrays[0].length,\n      othLength = arrays.length,\n      othIndex = othLength,\n      caches = Array(othLength),\n      maxLength = Infinity,\n      result = [];\n\n  while (othIndex--) {\n    var array = arrays[othIndex];\n    if (othIndex && iteratee) {\n      array = arrayMap(array, baseUnary(iteratee));\n    }\n    maxLength = nativeMin(array.length, maxLength);\n    caches[othIndex] = !comparator && (iteratee || (length >= 120 && array.length >= 120))\n      ? new SetCache(othIndex && array)\n      : undefined;\n  }\n  array = arrays[0];\n\n  var index = -1,\n      seen = caches[0];\n\n  outer:\n  while (++index < length && result.length < maxLength) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (!(seen\n          ? cacheHas(seen, computed)\n          : includes(result, computed, comparator)\n        )) {\n      othIndex = othLength;\n      while (--othIndex) {\n        var cache = caches[othIndex];\n        if (!(cache\n              ? cacheHas(cache, computed)\n              : includes(arrays[othIndex], computed, comparator))\n            ) {\n          continue outer;\n        }\n      }\n      if (seen) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseIntersection;\n","var baseGetTag = require('./_baseGetTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]';\n\n/**\n * The base implementation of `_.isArguments`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n */\nfunction baseIsArguments(value) {\n  return isObjectLike(value) && baseGetTag(value) == argsTag;\n}\n\nmodule.exports = baseIsArguments;\n","var getTag = require('./_getTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar mapTag = '[object Map]';\n\n/**\n * The base implementation of `_.isMap` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a map, else `false`.\n */\nfunction baseIsMap(value) {\n  return isObjectLike(value) && getTag(value) == mapTag;\n}\n\nmodule.exports = baseIsMap;\n","/**\n * The base implementation of `_.isNaN` without support for number objects.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `NaN`, else `false`.\n */\nfunction baseIsNaN(value) {\n  return value !== value;\n}\n\nmodule.exports = baseIsNaN;\n","var isFunction = require('./isFunction'),\n    isMasked = require('./_isMasked'),\n    isObject = require('./isObject'),\n    toSource = require('./_toSource');\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used for built-in method references. */\nvar funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\nmodule.exports = baseIsNative;\n","var getTag = require('./_getTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar setTag = '[object Set]';\n\n/**\n * The base implementation of `_.isSet` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a set, else `false`.\n */\nfunction baseIsSet(value) {\n  return isObjectLike(value) && getTag(value) == setTag;\n}\n\nmodule.exports = baseIsSet;\n","var baseGetTag = require('./_baseGetTag'),\n    isLength = require('./isLength'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];\n}\n\nmodule.exports = baseIsTypedArray;\n","var isPrototype = require('./_isPrototype'),\n    nativeKeys = require('./_nativeKeys');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseKeys;\n","var isObject = require('./isObject'),\n    isPrototype = require('./_isPrototype'),\n    nativeKeysIn = require('./_nativeKeysIn');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.keysIn` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeysIn(object) {\n  if (!isObject(object)) {\n    return nativeKeysIn(object);\n  }\n  var isProto = isPrototype(object),\n      result = [];\n\n  for (var key in object) {\n    if (!(key == 'constructor' && (isProto || !hasOwnProperty.call(object, key)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseKeysIn;\n","/**\n * The function whose prototype chain sequence wrappers inherit from.\n *\n * @private\n */\nfunction baseLodash() {\n  // No operation performed.\n}\n\nmodule.exports = baseLodash;\n","var Stack = require('./_Stack'),\n    assignMergeValue = require('./_assignMergeValue'),\n    baseFor = require('./_baseFor'),\n    baseMergeDeep = require('./_baseMergeDeep'),\n    isObject = require('./isObject'),\n    keysIn = require('./keysIn'),\n    safeGet = require('./_safeGet');\n\n/**\n * The base implementation of `_.merge` without support for multiple sources.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} [customizer] The function to customize merged values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMerge(object, source, srcIndex, customizer, stack) {\n  if (object === source) {\n    return;\n  }\n  baseFor(source, function(srcValue, key) {\n    stack || (stack = new Stack);\n    if (isObject(srcValue)) {\n      baseMergeDeep(object, source, key, srcIndex, baseMerge, customizer, stack);\n    }\n    else {\n      var newValue = customizer\n        ? customizer(safeGet(object, key), srcValue, (key + ''), object, source, stack)\n        : undefined;\n\n      if (newValue === undefined) {\n        newValue = srcValue;\n      }\n      assignMergeValue(object, key, newValue);\n    }\n  }, keysIn);\n}\n\nmodule.exports = baseMerge;\n","var assignMergeValue = require('./_assignMergeValue'),\n    cloneBuffer = require('./_cloneBuffer'),\n    cloneTypedArray = require('./_cloneTypedArray'),\n    copyArray = require('./_copyArray'),\n    initCloneObject = require('./_initCloneObject'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray'),\n    isArrayLikeObject = require('./isArrayLikeObject'),\n    isBuffer = require('./isBuffer'),\n    isFunction = require('./isFunction'),\n    isObject = require('./isObject'),\n    isPlainObject = require('./isPlainObject'),\n    isTypedArray = require('./isTypedArray'),\n    safeGet = require('./_safeGet'),\n    toPlainObject = require('./toPlainObject');\n\n/**\n * A specialized version of `baseMerge` for arrays and objects which performs\n * deep merges and tracks traversed objects enabling objects with circular\n * references to be merged.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {string} key The key of the value to merge.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} mergeFunc The function to merge values.\n * @param {Function} [customizer] The function to customize assigned values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMergeDeep(object, source, key, srcIndex, mergeFunc, customizer, stack) {\n  var objValue = safeGet(object, key),\n      srcValue = safeGet(source, key),\n      stacked = stack.get(srcValue);\n\n  if (stacked) {\n    assignMergeValue(object, key, stacked);\n    return;\n  }\n  var newValue = customizer\n    ? customizer(objValue, srcValue, (key + ''), object, source, stack)\n    : undefined;\n\n  var isCommon = newValue === undefined;\n\n  if (isCommon) {\n    var isArr = isArray(srcValue),\n        isBuff = !isArr && isBuffer(srcValue),\n        isTyped = !isArr && !isBuff && isTypedArray(srcValue);\n\n    newValue = srcValue;\n    if (isArr || isBuff || isTyped) {\n      if (isArray(objValue)) {\n        newValue = objValue;\n      }\n      else if (isArrayLikeObject(objValue)) {\n        newValue = copyArray(objValue);\n      }\n      else if (isBuff) {\n        isCommon = false;\n        newValue = cloneBuffer(srcValue, true);\n      }\n      else if (isTyped) {\n        isCommon = false;\n        newValue = cloneTypedArray(srcValue, true);\n      }\n      else {\n        newValue = [];\n      }\n    }\n    else if (isPlainObject(srcValue) || isArguments(srcValue)) {\n      newValue = objValue;\n      if (isArguments(objValue)) {\n        newValue = toPlainObject(objValue);\n      }\n      else if (!isObject(objValue) || isFunction(objValue)) {\n        newValue = initCloneObject(srcValue);\n      }\n    }\n    else {\n      isCommon = false;\n    }\n  }\n  if (isCommon) {\n    // Recursively merge objects and arrays (susceptible to call stack limits).\n    stack.set(srcValue, newValue);\n    mergeFunc(newValue, srcValue, srcIndex, customizer, stack);\n    stack['delete'](srcValue);\n  }\n  assignMergeValue(object, key, newValue);\n}\n\nmodule.exports = baseMergeDeep;\n","var basePickBy = require('./_basePickBy'),\n    hasIn = require('./hasIn');\n\n/**\n * The base implementation of `_.pick` without support for individual\n * property identifiers.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @returns {Object} Returns the new object.\n */\nfunction basePick(object, paths) {\n  return basePickBy(object, paths, function(value, path) {\n    return hasIn(object, path);\n  });\n}\n\nmodule.exports = basePick;\n","var baseGet = require('./_baseGet'),\n    baseSet = require('./_baseSet'),\n    castPath = require('./_castPath');\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nmodule.exports = basePickBy;\n","var identity = require('./identity'),\n    overRest = require('./_overRest'),\n    setToString = require('./_setToString');\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  return setToString(overRest(func, start, identity), func + '');\n}\n\nmodule.exports = baseRest;\n","var assignValue = require('./_assignValue'),\n    castPath = require('./_castPath'),\n    isIndex = require('./_isIndex'),\n    isObject = require('./isObject'),\n    toKey = require('./_toKey');\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nmodule.exports = baseSet;\n","var identity = require('./identity'),\n    metaMap = require('./_metaMap');\n\n/**\n * The base implementation of `setData` without support for hot loop shorting.\n *\n * @private\n * @param {Function} func The function to associate metadata with.\n * @param {*} data The metadata.\n * @returns {Function} Returns `func`.\n */\nvar baseSetData = !metaMap ? identity : function(func, data) {\n  metaMap.set(func, data);\n  return func;\n};\n\nmodule.exports = baseSetData;\n","var constant = require('./constant'),\n    defineProperty = require('./_defineProperty'),\n    identity = require('./identity');\n\n/**\n * The base implementation of `setToString` without support for hot loop shorting.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar baseSetToString = !defineProperty ? identity : function(func, string) {\n  return defineProperty(func, 'toString', {\n    'configurable': true,\n    'enumerable': false,\n    'value': constant(string),\n    'writable': true\n  });\n};\n\nmodule.exports = baseSetToString;\n","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nmodule.exports = baseSlice;\n","/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\nmodule.exports = baseTimes;\n","var Symbol = require('./_Symbol'),\n    arrayMap = require('./_arrayMap'),\n    isArray = require('./isArray'),\n    isSymbol = require('./isSymbol');\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolToString = symbolProto ? symbolProto.toString : undefined;\n\n/**\n * The base implementation of `_.toString` which doesn't convert nullish\n * values to empty strings.\n *\n * @private\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n */\nfunction baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value == 'string') {\n    return value;\n  }\n  if (isArray(value)) {\n    // Recursively convert values (susceptible to call stack limits).\n    return arrayMap(value, baseToString) + '';\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : '';\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\nmodule.exports = baseToString;\n","var trimmedEndIndex = require('./_trimmedEndIndex');\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nmodule.exports = baseTrim;\n","/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\nmodule.exports = baseUnary;\n","var SetCache = require('./_SetCache'),\n    arrayIncludes = require('./_arrayIncludes'),\n    arrayIncludesWith = require('./_arrayIncludesWith'),\n    cacheHas = require('./_cacheHas'),\n    createSet = require('./_createSet'),\n    setToArray = require('./_setToArray');\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of `_.uniqBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n */\nfunction baseUniq(array, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      length = array.length,\n      isCommon = true,\n      result = [],\n      seen = result;\n\n  if (comparator) {\n    isCommon = false;\n    includes = arrayIncludesWith;\n  }\n  else if (length >= LARGE_ARRAY_SIZE) {\n    var set = iteratee ? null : createSet(array);\n    if (set) {\n      return setToArray(set);\n    }\n    isCommon = false;\n    includes = cacheHas;\n    seen = new SetCache;\n  }\n  else {\n    seen = iteratee ? [] : result;\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var seenIndex = seen.length;\n      while (seenIndex--) {\n        if (seen[seenIndex] === computed) {\n          continue outer;\n        }\n      }\n      if (iteratee) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n    else if (!includes(seen, computed, comparator)) {\n      if (seen !== result) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseUniq;\n","var castPath = require('./_castPath'),\n    last = require('./last'),\n    parent = require('./_parent'),\n    toKey = require('./_toKey');\n\n/**\n * The base implementation of `_.unset`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The property path to unset.\n * @returns {boolean} Returns `true` if the property is deleted, else `false`.\n */\nfunction baseUnset(object, path) {\n  path = castPath(path, object);\n  object = parent(object, path);\n  return object == null || delete object[toKey(last(path))];\n}\n\nmodule.exports = baseUnset;\n","/**\n * Checks if a `cache` value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\nmodule.exports = cacheHas;\n","var isArrayLikeObject = require('./isArrayLikeObject');\n\n/**\n * Casts `value` to an empty array if it's not an array like object.\n *\n * @private\n * @param {*} value The value to inspect.\n * @returns {Array|Object} Returns the cast array-like object.\n */\nfunction castArrayLikeObject(value) {\n  return isArrayLikeObject(value) ? value : [];\n}\n\nmodule.exports = castArrayLikeObject;\n","var isArray = require('./isArray'),\n    isKey = require('./_isKey'),\n    stringToPath = require('./_stringToPath'),\n    toString = require('./toString');\n\n/**\n * Casts `value` to a path array if it's not one.\n *\n * @private\n * @param {*} value The value to inspect.\n * @param {Object} [object] The object to query keys on.\n * @returns {Array} Returns the cast property path array.\n */\nfunction castPath(value, object) {\n  if (isArray(value)) {\n    return value;\n  }\n  return isKey(value, object) ? [value] : stringToPath(toString(value));\n}\n\nmodule.exports = castPath;\n","var Uint8Array = require('./_Uint8Array');\n\n/**\n * Creates a clone of `arrayBuffer`.\n *\n * @private\n * @param {ArrayBuffer} arrayBuffer The array buffer to clone.\n * @returns {ArrayBuffer} Returns the cloned array buffer.\n */\nfunction cloneArrayBuffer(arrayBuffer) {\n  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n  new Uint8Array(result).set(new Uint8Array(arrayBuffer));\n  return result;\n}\n\nmodule.exports = cloneArrayBuffer;\n","var root = require('./_root');\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    allocUnsafe = Buffer ? Buffer.allocUnsafe : undefined;\n\n/**\n * Creates a clone of  `buffer`.\n *\n * @private\n * @param {Buffer} buffer The buffer to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Buffer} Returns the cloned buffer.\n */\nfunction cloneBuffer(buffer, isDeep) {\n  if (isDeep) {\n    return buffer.slice();\n  }\n  var length = buffer.length,\n      result = allocUnsafe ? allocUnsafe(length) : new buffer.constructor(length);\n\n  buffer.copy(result);\n  return result;\n}\n\nmodule.exports = cloneBuffer;\n","var cloneArrayBuffer = require('./_cloneArrayBuffer');\n\n/**\n * Creates a clone of `dataView`.\n *\n * @private\n * @param {Object} dataView The data view to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned data view.\n */\nfunction cloneDataView(dataView, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n}\n\nmodule.exports = cloneDataView;\n","/** Used to match `RegExp` flags from their coerced string values. */\nvar reFlags = /\\w*$/;\n\n/**\n * Creates a clone of `regexp`.\n *\n * @private\n * @param {Object} regexp The regexp to clone.\n * @returns {Object} Returns the cloned regexp.\n */\nfunction cloneRegExp(regexp) {\n  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n  result.lastIndex = regexp.lastIndex;\n  return result;\n}\n\nmodule.exports = cloneRegExp;\n","var Symbol = require('./_Symbol');\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a clone of the `symbol` object.\n *\n * @private\n * @param {Object} symbol The symbol object to clone.\n * @returns {Object} Returns the cloned symbol object.\n */\nfunction cloneSymbol(symbol) {\n  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};\n}\n\nmodule.exports = cloneSymbol;\n","var cloneArrayBuffer = require('./_cloneArrayBuffer');\n\n/**\n * Creates a clone of `typedArray`.\n *\n * @private\n * @param {Object} typedArray The typed array to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned typed array.\n */\nfunction cloneTypedArray(typedArray, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n}\n\nmodule.exports = cloneTypedArray;\n","/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Creates an array that is the composition of partially applied arguments,\n * placeholders, and provided arguments into a single array of arguments.\n *\n * @private\n * @param {Array} args The provided arguments.\n * @param {Array} partials The arguments to prepend to those provided.\n * @param {Array} holders The `partials` placeholder indexes.\n * @params {boolean} [isCurried] Specify composing for a curried function.\n * @returns {Array} Returns the new array of composed arguments.\n */\nfunction composeArgs(args, partials, holders, isCurried) {\n  var argsIndex = -1,\n      argsLength = args.length,\n      holdersLength = holders.length,\n      leftIndex = -1,\n      leftLength = partials.length,\n      rangeLength = nativeMax(argsLength - holdersLength, 0),\n      result = Array(leftLength + rangeLength),\n      isUncurried = !isCurried;\n\n  while (++leftIndex < leftLength) {\n    result[leftIndex] = partials[leftIndex];\n  }\n  while (++argsIndex < holdersLength) {\n    if (isUncurried || argsIndex < argsLength) {\n      result[holders[argsIndex]] = args[argsIndex];\n    }\n  }\n  while (rangeLength--) {\n    result[leftIndex++] = args[argsIndex++];\n  }\n  return result;\n}\n\nmodule.exports = composeArgs;\n","/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This function is like `composeArgs` except that the arguments composition\n * is tailored for `_.partialRight`.\n *\n * @private\n * @param {Array} args The provided arguments.\n * @param {Array} partials The arguments to append to those provided.\n * @param {Array} holders The `partials` placeholder indexes.\n * @params {boolean} [isCurried] Specify composing for a curried function.\n * @returns {Array} Returns the new array of composed arguments.\n */\nfunction composeArgsRight(args, partials, holders, isCurried) {\n  var argsIndex = -1,\n      argsLength = args.length,\n      holdersIndex = -1,\n      holdersLength = holders.length,\n      rightIndex = -1,\n      rightLength = partials.length,\n      rangeLength = nativeMax(argsLength - holdersLength, 0),\n      result = Array(rangeLength + rightLength),\n      isUncurried = !isCurried;\n\n  while (++argsIndex < rangeLength) {\n    result[argsIndex] = args[argsIndex];\n  }\n  var offset = argsIndex;\n  while (++rightIndex < rightLength) {\n    result[offset + rightIndex] = partials[rightIndex];\n  }\n  while (++holdersIndex < holdersLength) {\n    if (isUncurried || argsIndex < argsLength) {\n      result[offset + holders[holdersIndex]] = args[argsIndex++];\n    }\n  }\n  return result;\n}\n\nmodule.exports = composeArgsRight;\n","/**\n * Copies the values of `source` to `array`.\n *\n * @private\n * @param {Array} source The array to copy values from.\n * @param {Array} [array=[]] The array to copy values to.\n * @returns {Array} Returns `array`.\n */\nfunction copyArray(source, array) {\n  var index = -1,\n      length = source.length;\n\n  array || (array = Array(length));\n  while (++index < length) {\n    array[index] = source[index];\n  }\n  return array;\n}\n\nmodule.exports = copyArray;\n","var assignValue = require('./_assignValue'),\n    baseAssignValue = require('./_baseAssignValue');\n\n/**\n * Copies properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy properties from.\n * @param {Array} props The property identifiers to copy.\n * @param {Object} [object={}] The object to copy properties to.\n * @param {Function} [customizer] The function to customize copied values.\n * @returns {Object} Returns `object`.\n */\nfunction copyObject(source, props, object, customizer) {\n  var isNew = !object;\n  object || (object = {});\n\n  var index = -1,\n      length = props.length;\n\n  while (++index < length) {\n    var key = props[index];\n\n    var newValue = customizer\n      ? customizer(object[key], source[key], key, object, source)\n      : undefined;\n\n    if (newValue === undefined) {\n      newValue = source[key];\n    }\n    if (isNew) {\n      baseAssignValue(object, key, newValue);\n    } else {\n      assignValue(object, key, newValue);\n    }\n  }\n  return object;\n}\n\nmodule.exports = copyObject;\n","var copyObject = require('./_copyObject'),\n    getSymbols = require('./_getSymbols');\n\n/**\n * Copies own symbols of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbols(source, object) {\n  return copyObject(source, getSymbols(source), object);\n}\n\nmodule.exports = copySymbols;\n","var copyObject = require('./_copyObject'),\n    getSymbolsIn = require('./_getSymbolsIn');\n\n/**\n * Copies own and inherited symbols of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbolsIn(source, object) {\n  return copyObject(source, getSymbolsIn(source), object);\n}\n\nmodule.exports = copySymbolsIn;\n","var root = require('./_root');\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\nmodule.exports = coreJsData;\n","/**\n * Gets the number of `placeholder` occurrences in `array`.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} placeholder The placeholder to search for.\n * @returns {number} Returns the placeholder count.\n */\nfunction countHolders(array, placeholder) {\n  var length = array.length,\n      result = 0;\n\n  while (length--) {\n    if (array[length] === placeholder) {\n      ++result;\n    }\n  }\n  return result;\n}\n\nmodule.exports = countHolders;\n","var baseRest = require('./_baseRest'),\n    isIterateeCall = require('./_isIterateeCall');\n\n/**\n * Creates a function like `_.assign`.\n *\n * @private\n * @param {Function} assigner The function to assign values.\n * @returns {Function} Returns the new assigner function.\n */\nfunction createAssigner(assigner) {\n  return baseRest(function(object, sources) {\n    var index = -1,\n        length = sources.length,\n        customizer = length > 1 ? sources[length - 1] : undefined,\n        guard = length > 2 ? sources[2] : undefined;\n\n    customizer = (assigner.length > 3 && typeof customizer == 'function')\n      ? (length--, customizer)\n      : undefined;\n\n    if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n      customizer = length < 3 ? undefined : customizer;\n      length = 1;\n    }\n    object = Object(object);\n    while (++index < length) {\n      var source = sources[index];\n      if (source) {\n        assigner(object, source, index, customizer);\n      }\n    }\n    return object;\n  });\n}\n\nmodule.exports = createAssigner;\n","/**\n * Creates a base function for methods like `_.forIn` and `_.forOwn`.\n *\n * @private\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {Function} Returns the new base function.\n */\nfunction createBaseFor(fromRight) {\n  return function(object, iteratee, keysFunc) {\n    var index = -1,\n        iterable = Object(object),\n        props = keysFunc(object),\n        length = props.length;\n\n    while (length--) {\n      var key = props[fromRight ? length : ++index];\n      if (iteratee(iterable[key], key, iterable) === false) {\n        break;\n      }\n    }\n    return object;\n  };\n}\n\nmodule.exports = createBaseFor;\n","var createCtor = require('./_createCtor'),\n    root = require('./_root');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1;\n\n/**\n * Creates a function that wraps `func` to invoke it with the optional `this`\n * binding of `thisArg`.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @param {*} [thisArg] The `this` binding of `func`.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createBind(func, bitmask, thisArg) {\n  var isBind = bitmask & WRAP_BIND_FLAG,\n      Ctor = createCtor(func);\n\n  function wrapper() {\n    var fn = (this && this !== root && this instanceof wrapper) ? Ctor : func;\n    return fn.apply(isBind ? thisArg : this, arguments);\n  }\n  return wrapper;\n}\n\nmodule.exports = createBind;\n","var baseCreate = require('./_baseCreate'),\n    isObject = require('./isObject');\n\n/**\n * Creates a function that produces an instance of `Ctor` regardless of\n * whether it was invoked as part of a `new` expression or by `call` or `apply`.\n *\n * @private\n * @param {Function} Ctor The constructor to wrap.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createCtor(Ctor) {\n  return function() {\n    // Use a `switch` statement to work with class constructors. See\n    // http://ecma-international.org/ecma-262/7.0/#sec-ecmascript-function-objects-call-thisargument-argumentslist\n    // for more details.\n    var args = arguments;\n    switch (args.length) {\n      case 0: return new Ctor;\n      case 1: return new Ctor(args[0]);\n      case 2: return new Ctor(args[0], args[1]);\n      case 3: return new Ctor(args[0], args[1], args[2]);\n      case 4: return new Ctor(args[0], args[1], args[2], args[3]);\n      case 5: return new Ctor(args[0], args[1], args[2], args[3], args[4]);\n      case 6: return new Ctor(args[0], args[1], args[2], args[3], args[4], args[5]);\n      case 7: return new Ctor(args[0], args[1], args[2], args[3], args[4], args[5], args[6]);\n    }\n    var thisBinding = baseCreate(Ctor.prototype),\n        result = Ctor.apply(thisBinding, args);\n\n    // Mimic the constructor's `return` behavior.\n    // See https://es5.github.io/#x13.2.2 for more details.\n    return isObject(result) ? result : thisBinding;\n  };\n}\n\nmodule.exports = createCtor;\n","var apply = require('./_apply'),\n    createCtor = require('./_createCtor'),\n    createHybrid = require('./_createHybrid'),\n    createRecurry = require('./_createRecurry'),\n    getHolder = require('./_getHolder'),\n    replaceHolders = require('./_replaceHolders'),\n    root = require('./_root');\n\n/**\n * Creates a function that wraps `func` to enable currying.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @param {number} arity The arity of `func`.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createCurry(func, bitmask, arity) {\n  var Ctor = createCtor(func);\n\n  function wrapper() {\n    var length = arguments.length,\n        args = Array(length),\n        index = length,\n        placeholder = getHolder(wrapper);\n\n    while (index--) {\n      args[index] = arguments[index];\n    }\n    var holders = (length < 3 && args[0] !== placeholder && args[length - 1] !== placeholder)\n      ? []\n      : replaceHolders(args, placeholder);\n\n    length -= holders.length;\n    if (length < arity) {\n      return createRecurry(\n        func, bitmask, createHybrid, wrapper.placeholder, undefined,\n        args, holders, undefined, undefined, arity - length);\n    }\n    var fn = (this && this !== root && this instanceof wrapper) ? Ctor : func;\n    return apply(fn, this, args);\n  }\n  return wrapper;\n}\n\nmodule.exports = createCurry;\n","var composeArgs = require('./_composeArgs'),\n    composeArgsRight = require('./_composeArgsRight'),\n    countHolders = require('./_countHolders'),\n    createCtor = require('./_createCtor'),\n    createRecurry = require('./_createRecurry'),\n    getHolder = require('./_getHolder'),\n    reorder = require('./_reorder'),\n    replaceHolders = require('./_replaceHolders'),\n    root = require('./_root');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1,\n    WRAP_BIND_KEY_FLAG = 2,\n    WRAP_CURRY_FLAG = 8,\n    WRAP_CURRY_RIGHT_FLAG = 16,\n    WRAP_ARY_FLAG = 128,\n    WRAP_FLIP_FLAG = 512;\n\n/**\n * Creates a function that wraps `func` to invoke it with optional `this`\n * binding of `thisArg`, partial application, and currying.\n *\n * @private\n * @param {Function|string} func The function or method name to wrap.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @param {*} [thisArg] The `this` binding of `func`.\n * @param {Array} [partials] The arguments to prepend to those provided to\n *  the new function.\n * @param {Array} [holders] The `partials` placeholder indexes.\n * @param {Array} [partialsRight] The arguments to append to those provided\n *  to the new function.\n * @param {Array} [holdersRight] The `partialsRight` placeholder indexes.\n * @param {Array} [argPos] The argument positions of the new function.\n * @param {number} [ary] The arity cap of `func`.\n * @param {number} [arity] The arity of `func`.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createHybrid(func, bitmask, thisArg, partials, holders, partialsRight, holdersRight, argPos, ary, arity) {\n  var isAry = bitmask & WRAP_ARY_FLAG,\n      isBind = bitmask & WRAP_BIND_FLAG,\n      isBindKey = bitmask & WRAP_BIND_KEY_FLAG,\n      isCurried = bitmask & (WRAP_CURRY_FLAG | WRAP_CURRY_RIGHT_FLAG),\n      isFlip = bitmask & WRAP_FLIP_FLAG,\n      Ctor = isBindKey ? undefined : createCtor(func);\n\n  function wrapper() {\n    var length = arguments.length,\n        args = Array(length),\n        index = length;\n\n    while (index--) {\n      args[index] = arguments[index];\n    }\n    if (isCurried) {\n      var placeholder = getHolder(wrapper),\n          holdersCount = countHolders(args, placeholder);\n    }\n    if (partials) {\n      args = composeArgs(args, partials, holders, isCurried);\n    }\n    if (partialsRight) {\n      args = composeArgsRight(args, partialsRight, holdersRight, isCurried);\n    }\n    length -= holdersCount;\n    if (isCurried && length < arity) {\n      var newHolders = replaceHolders(args, placeholder);\n      return createRecurry(\n        func, bitmask, createHybrid, wrapper.placeholder, thisArg,\n        args, newHolders, argPos, ary, arity - length\n      );\n    }\n    var thisBinding = isBind ? thisArg : this,\n        fn = isBindKey ? thisBinding[func] : func;\n\n    length = args.length;\n    if (argPos) {\n      args = reorder(args, argPos);\n    } else if (isFlip && length > 1) {\n      args.reverse();\n    }\n    if (isAry && ary < length) {\n      args.length = ary;\n    }\n    if (this && this !== root && this instanceof wrapper) {\n      fn = Ctor || createCtor(fn);\n    }\n    return fn.apply(thisBinding, args);\n  }\n  return wrapper;\n}\n\nmodule.exports = createHybrid;\n","var apply = require('./_apply'),\n    createCtor = require('./_createCtor'),\n    root = require('./_root');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1;\n\n/**\n * Creates a function that wraps `func` to invoke it with the `this` binding\n * of `thisArg` and `partials` prepended to the arguments it receives.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} partials The arguments to prepend to those provided to\n *  the new function.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createPartial(func, bitmask, thisArg, partials) {\n  var isBind = bitmask & WRAP_BIND_FLAG,\n      Ctor = createCtor(func);\n\n  function wrapper() {\n    var argsIndex = -1,\n        argsLength = arguments.length,\n        leftIndex = -1,\n        leftLength = partials.length,\n        args = Array(leftLength + argsLength),\n        fn = (this && this !== root && this instanceof wrapper) ? Ctor : func;\n\n    while (++leftIndex < leftLength) {\n      args[leftIndex] = partials[leftIndex];\n    }\n    while (argsLength--) {\n      args[leftIndex++] = arguments[++argsIndex];\n    }\n    return apply(fn, isBind ? thisArg : this, args);\n  }\n  return wrapper;\n}\n\nmodule.exports = createPartial;\n","var isLaziable = require('./_isLaziable'),\n    setData = require('./_setData'),\n    setWrapToString = require('./_setWrapToString');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1,\n    WRAP_BIND_KEY_FLAG = 2,\n    WRAP_CURRY_BOUND_FLAG = 4,\n    WRAP_CURRY_FLAG = 8,\n    WRAP_PARTIAL_FLAG = 32,\n    WRAP_PARTIAL_RIGHT_FLAG = 64;\n\n/**\n * Creates a function that wraps `func` to continue currying.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @param {Function} wrapFunc The function to create the `func` wrapper.\n * @param {*} placeholder The placeholder value.\n * @param {*} [thisArg] The `this` binding of `func`.\n * @param {Array} [partials] The arguments to prepend to those provided to\n *  the new function.\n * @param {Array} [holders] The `partials` placeholder indexes.\n * @param {Array} [argPos] The argument positions of the new function.\n * @param {number} [ary] The arity cap of `func`.\n * @param {number} [arity] The arity of `func`.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createRecurry(func, bitmask, wrapFunc, placeholder, thisArg, partials, holders, argPos, ary, arity) {\n  var isCurry = bitmask & WRAP_CURRY_FLAG,\n      newHolders = isCurry ? holders : undefined,\n      newHoldersRight = isCurry ? undefined : holders,\n      newPartials = isCurry ? partials : undefined,\n      newPartialsRight = isCurry ? undefined : partials;\n\n  bitmask |= (isCurry ? WRAP_PARTIAL_FLAG : WRAP_PARTIAL_RIGHT_FLAG);\n  bitmask &= ~(isCurry ? WRAP_PARTIAL_RIGHT_FLAG : WRAP_PARTIAL_FLAG);\n\n  if (!(bitmask & WRAP_CURRY_BOUND_FLAG)) {\n    bitmask &= ~(WRAP_BIND_FLAG | WRAP_BIND_KEY_FLAG);\n  }\n  var newData = [\n    func, bitmask, thisArg, newPartials, newHolders, newPartialsRight,\n    newHoldersRight, argPos, ary, arity\n  ];\n\n  var result = wrapFunc.apply(undefined, newData);\n  if (isLaziable(func)) {\n    setData(result, newData);\n  }\n  result.placeholder = placeholder;\n  return setWrapToString(result, func, bitmask);\n}\n\nmodule.exports = createRecurry;\n","var Set = require('./_Set'),\n    noop = require('./noop'),\n    setToArray = require('./_setToArray');\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/**\n * Creates a set object of `values`.\n *\n * @private\n * @param {Array} values The values to add to the set.\n * @returns {Object} Returns the new set.\n */\nvar createSet = !(Set && (1 / setToArray(new Set([,-0]))[1]) == INFINITY) ? noop : function(values) {\n  return new Set(values);\n};\n\nmodule.exports = createSet;\n","var baseSetData = require('./_baseSetData'),\n    createBind = require('./_createBind'),\n    createCurry = require('./_createCurry'),\n    createHybrid = require('./_createHybrid'),\n    createPartial = require('./_createPartial'),\n    getData = require('./_getData'),\n    mergeData = require('./_mergeData'),\n    setData = require('./_setData'),\n    setWrapToString = require('./_setWrapToString'),\n    toInteger = require('./toInteger');\n\n/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1,\n    WRAP_BIND_KEY_FLAG = 2,\n    WRAP_CURRY_FLAG = 8,\n    WRAP_CURRY_RIGHT_FLAG = 16,\n    WRAP_PARTIAL_FLAG = 32,\n    WRAP_PARTIAL_RIGHT_FLAG = 64;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Creates a function that either curries or invokes `func` with optional\n * `this` binding and partially applied arguments.\n *\n * @private\n * @param {Function|string} func The function or method name to wrap.\n * @param {number} bitmask The bitmask flags.\n *    1 - `_.bind`\n *    2 - `_.bindKey`\n *    4 - `_.curry` or `_.curryRight` of a bound function\n *    8 - `_.curry`\n *   16 - `_.curryRight`\n *   32 - `_.partial`\n *   64 - `_.partialRight`\n *  128 - `_.rearg`\n *  256 - `_.ary`\n *  512 - `_.flip`\n * @param {*} [thisArg] The `this` binding of `func`.\n * @param {Array} [partials] The arguments to be partially applied.\n * @param {Array} [holders] The `partials` placeholder indexes.\n * @param {Array} [argPos] The argument positions of the new function.\n * @param {number} [ary] The arity cap of `func`.\n * @param {number} [arity] The arity of `func`.\n * @returns {Function} Returns the new wrapped function.\n */\nfunction createWrap(func, bitmask, thisArg, partials, holders, argPos, ary, arity) {\n  var isBindKey = bitmask & WRAP_BIND_KEY_FLAG;\n  if (!isBindKey && typeof func != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  var length = partials ? partials.length : 0;\n  if (!length) {\n    bitmask &= ~(WRAP_PARTIAL_FLAG | WRAP_PARTIAL_RIGHT_FLAG);\n    partials = holders = undefined;\n  }\n  ary = ary === undefined ? ary : nativeMax(toInteger(ary), 0);\n  arity = arity === undefined ? arity : toInteger(arity);\n  length -= holders ? holders.length : 0;\n\n  if (bitmask & WRAP_PARTIAL_RIGHT_FLAG) {\n    var partialsRight = partials,\n        holdersRight = holders;\n\n    partials = holders = undefined;\n  }\n  var data = isBindKey ? undefined : getData(func);\n\n  var newData = [\n    func, bitmask, thisArg, partials, holders, partialsRight, holdersRight,\n    argPos, ary, arity\n  ];\n\n  if (data) {\n    mergeData(newData, data);\n  }\n  func = newData[0];\n  bitmask = newData[1];\n  thisArg = newData[2];\n  partials = newData[3];\n  holders = newData[4];\n  arity = newData[9] = newData[9] === undefined\n    ? (isBindKey ? 0 : func.length)\n    : nativeMax(newData[9] - length, 0);\n\n  if (!arity && bitmask & (WRAP_CURRY_FLAG | WRAP_CURRY_RIGHT_FLAG)) {\n    bitmask &= ~(WRAP_CURRY_FLAG | WRAP_CURRY_RIGHT_FLAG);\n  }\n  if (!bitmask || bitmask == WRAP_BIND_FLAG) {\n    var result = createBind(func, bitmask, thisArg);\n  } else if (bitmask == WRAP_CURRY_FLAG || bitmask == WRAP_CURRY_RIGHT_FLAG) {\n    result = createCurry(func, bitmask, arity);\n  } else if ((bitmask == WRAP_PARTIAL_FLAG || bitmask == (WRAP_BIND_FLAG | WRAP_PARTIAL_FLAG)) && !holders.length) {\n    result = createPartial(func, bitmask, thisArg, partials);\n  } else {\n    result = createHybrid.apply(undefined, newData);\n  }\n  var setter = data ? baseSetData : setData;\n  return setWrapToString(setter(result, newData), func, bitmask);\n}\n\nmodule.exports = createWrap;\n","var isPlainObject = require('./isPlainObject');\n\n/**\n * Used by `_.omit` to customize its `_.cloneDeep` use to only clone plain\n * objects.\n *\n * @private\n * @param {*} value The value to inspect.\n * @param {string} key The key of the property to inspect.\n * @returns {*} Returns the uncloned value or `undefined` to defer cloning to `_.cloneDeep`.\n */\nfunction customOmitClone(value) {\n  return isPlainObject(value) ? undefined : value;\n}\n\nmodule.exports = customOmitClone;\n","var getNative = require('./_getNative');\n\nvar defineProperty = (function() {\n  try {\n    var func = getNative(Object, 'defineProperty');\n    func({}, '', {});\n    return func;\n  } catch (e) {}\n}());\n\nmodule.exports = defineProperty;\n","var flatten = require('./flatten'),\n    overRest = require('./_overRest'),\n    setToString = require('./_setToString');\n\n/**\n * A specialized version of `baseRest` which flattens the rest array.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @returns {Function} Returns the new function.\n */\nfunction flatRest(func) {\n  return setToString(overRest(func, undefined, flatten), func + '');\n}\n\nmodule.exports = flatRest;\n","/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\nmodule.exports = freeGlobal;\n","var baseGetAllKeys = require('./_baseGetAllKeys'),\n    getSymbols = require('./_getSymbols'),\n    keys = require('./keys');\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\nmodule.exports = getAllKeys;\n","var baseGetAllKeys = require('./_baseGetAllKeys'),\n    getSymbolsIn = require('./_getSymbolsIn'),\n    keysIn = require('./keysIn');\n\n/**\n * Creates an array of own and inherited enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeysIn(object) {\n  return baseGetAllKeys(object, keysIn, getSymbolsIn);\n}\n\nmodule.exports = getAllKeysIn;\n","var metaMap = require('./_metaMap'),\n    noop = require('./noop');\n\n/**\n * Gets metadata for `func`.\n *\n * @private\n * @param {Function} func The function to query.\n * @returns {*} Returns the metadata for `func`.\n */\nvar getData = !metaMap ? noop : function(func) {\n  return metaMap.get(func);\n};\n\nmodule.exports = getData;\n","var realNames = require('./_realNames');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Gets the name of `func`.\n *\n * @private\n * @param {Function} func The function to query.\n * @returns {string} Returns the function name.\n */\nfunction getFuncName(func) {\n  var result = (func.name + ''),\n      array = realNames[result],\n      length = hasOwnProperty.call(realNames, result) ? array.length : 0;\n\n  while (length--) {\n    var data = array[length],\n        otherFunc = data.func;\n    if (otherFunc == null || otherFunc == func) {\n      return data.name;\n    }\n  }\n  return result;\n}\n\nmodule.exports = getFuncName;\n","/**\n * Gets the argument placeholder value for `func`.\n *\n * @private\n * @param {Function} func The function to inspect.\n * @returns {*} Returns the placeholder value.\n */\nfunction getHolder(func) {\n  var object = func;\n  return object.placeholder;\n}\n\nmodule.exports = getHolder;\n","var isKeyable = require('./_isKeyable');\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\nmodule.exports = getMapData;\n","var baseIsNative = require('./_baseIsNative'),\n    getValue = require('./_getValue');\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\nmodule.exports = getNative;\n","var overArg = require('./_overArg');\n\n/** Built-in value references. */\nvar getPrototype = overArg(Object.getPrototypeOf, Object);\n\nmodule.exports = getPrototype;\n","var Symbol = require('./_Symbol');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\nmodule.exports = getRawTag;\n","var arrayFilter = require('./_arrayFilter'),\n    stubArray = require('./stubArray');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols;\n\n/**\n * Creates an array of the own enumerable symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = !nativeGetSymbols ? stubArray : function(object) {\n  if (object == null) {\n    return [];\n  }\n  object = Object(object);\n  return arrayFilter(nativeGetSymbols(object), function(symbol) {\n    return propertyIsEnumerable.call(object, symbol);\n  });\n};\n\nmodule.exports = getSymbols;\n","var arrayPush = require('./_arrayPush'),\n    getPrototype = require('./_getPrototype'),\n    getSymbols = require('./_getSymbols'),\n    stubArray = require('./stubArray');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols;\n\n/**\n * Creates an array of the own and inherited enumerable symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbolsIn = !nativeGetSymbols ? stubArray : function(object) {\n  var result = [];\n  while (object) {\n    arrayPush(result, getSymbols(object));\n    object = getPrototype(object);\n  }\n  return result;\n};\n\nmodule.exports = getSymbolsIn;\n","var DataView = require('./_DataView'),\n    Map = require('./_Map'),\n    Promise = require('./_Promise'),\n    Set = require('./_Set'),\n    WeakMap = require('./_WeakMap'),\n    baseGetTag = require('./_baseGetTag'),\n    toSource = require('./_toSource');\n\n/** `Object#toString` result references. */\nvar mapTag = '[object Map]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    setTag = '[object Set]',\n    weakMapTag = '[object WeakMap]';\n\nvar dataViewTag = '[object DataView]';\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = baseGetTag(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : '';\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\nmodule.exports = getTag;\n","/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\nmodule.exports = getValue;\n","/** Used to match wrap detail comments. */\nvar reWrapDetails = /\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,\n    reSplitDetails = /,? & /;\n\n/**\n * Extracts wrapper details from the `source` body comment.\n *\n * @private\n * @param {string} source The source to inspect.\n * @returns {Array} Returns the wrapper details.\n */\nfunction getWrapDetails(source) {\n  var match = source.match(reWrapDetails);\n  return match ? match[1].split(reSplitDetails) : [];\n}\n\nmodule.exports = getWrapDetails;\n","var castPath = require('./_castPath'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray'),\n    isIndex = require('./_isIndex'),\n    isLength = require('./isLength'),\n    toKey = require('./_toKey');\n\n/**\n * Checks if `path` exists on `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @param {Function} hasFunc The function to check properties.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n */\nfunction hasPath(object, path, hasFunc) {\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      result = false;\n\n  while (++index < length) {\n    var key = toKey(path[index]);\n    if (!(result = object != null && hasFunc(object, key))) {\n      break;\n    }\n    object = object[key];\n  }\n  if (result || ++index != length) {\n    return result;\n  }\n  length = object == null ? 0 : object.length;\n  return !!length && isLength(length) && isIndex(key, length) &&\n    (isArray(object) || isArguments(object));\n}\n\nmodule.exports = hasPath;\n","var nativeCreate = require('./_nativeCreate');\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n  this.size = 0;\n}\n\nmodule.exports = hashClear;\n","/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  var result = this.has(key) && delete this.__data__[key];\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nmodule.exports = hashDelete;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\nmodule.exports = hashGet;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty.call(data, key);\n}\n\nmodule.exports = hashHas;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  this.size += this.has(key) ? 0 : 1;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\nmodule.exports = hashSet;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Initializes an array clone.\n *\n * @private\n * @param {Array} array The array to clone.\n * @returns {Array} Returns the initialized clone.\n */\nfunction initCloneArray(array) {\n  var length = array.length,\n      result = new array.constructor(length);\n\n  // Add properties assigned by `RegExp#exec`.\n  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {\n    result.index = array.index;\n    result.input = array.input;\n  }\n  return result;\n}\n\nmodule.exports = initCloneArray;\n","var cloneArrayBuffer = require('./_cloneArrayBuffer'),\n    cloneDataView = require('./_cloneDataView'),\n    cloneRegExp = require('./_cloneRegExp'),\n    cloneSymbol = require('./_cloneSymbol'),\n    cloneTypedArray = require('./_cloneTypedArray');\n\n/** `Object#toString` result references. */\nvar boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Initializes an object clone based on its `toStringTag`.\n *\n * **Note:** This function only supports cloning values with tags of\n * `Boolean`, `Date`, `Error`, `Map`, `Number`, `RegExp`, `Set`, or `String`.\n *\n * @private\n * @param {Object} object The object to clone.\n * @param {string} tag The `toStringTag` of the object to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneByTag(object, tag, isDeep) {\n  var Ctor = object.constructor;\n  switch (tag) {\n    case arrayBufferTag:\n      return cloneArrayBuffer(object);\n\n    case boolTag:\n    case dateTag:\n      return new Ctor(+object);\n\n    case dataViewTag:\n      return cloneDataView(object, isDeep);\n\n    case float32Tag: case float64Tag:\n    case int8Tag: case int16Tag: case int32Tag:\n    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:\n      return cloneTypedArray(object, isDeep);\n\n    case mapTag:\n      return new Ctor;\n\n    case numberTag:\n    case stringTag:\n      return new Ctor(object);\n\n    case regexpTag:\n      return cloneRegExp(object);\n\n    case setTag:\n      return new Ctor;\n\n    case symbolTag:\n      return cloneSymbol(object);\n  }\n}\n\nmodule.exports = initCloneByTag;\n","var baseCreate = require('./_baseCreate'),\n    getPrototype = require('./_getPrototype'),\n    isPrototype = require('./_isPrototype');\n\n/**\n * Initializes an object clone.\n *\n * @private\n * @param {Object} object The object to clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneObject(object) {\n  return (typeof object.constructor == 'function' && !isPrototype(object))\n    ? baseCreate(getPrototype(object))\n    : {};\n}\n\nmodule.exports = initCloneObject;\n","/** Used to match wrap detail comments. */\nvar reWrapComment = /\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/;\n\n/**\n * Inserts wrapper `details` in a comment at the top of the `source` body.\n *\n * @private\n * @param {string} source The source to modify.\n * @returns {Array} details The details to insert.\n * @returns {string} Returns the modified source.\n */\nfunction insertWrapDetails(source, details) {\n  var length = details.length;\n  if (!length) {\n    return source;\n  }\n  var lastIndex = length - 1;\n  details[lastIndex] = (length > 1 ? '& ' : '') + details[lastIndex];\n  details = details.join(length > 2 ? ', ' : ' ');\n  return source.replace(reWrapComment, '{\\n/* [wrapped with ' + details + '] */\\n');\n}\n\nmodule.exports = insertWrapDetails;\n","var Symbol = require('./_Symbol'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray');\n\n/** Built-in value references. */\nvar spreadableSymbol = Symbol ? Symbol.isConcatSpreadable : undefined;\n\n/**\n * Checks if `value` is a flattenable `arguments` object or array.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is flattenable, else `false`.\n */\nfunction isFlattenable(value) {\n  return isArray(value) || isArguments(value) ||\n    !!(spreadableSymbol && value && value[spreadableSymbol]);\n}\n\nmodule.exports = isFlattenable;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  var type = typeof value;\n  length = length == null ? MAX_SAFE_INTEGER : length;\n\n  return !!length &&\n    (type == 'number' ||\n      (type != 'symbol' && reIsUint.test(value))) &&\n        (value > -1 && value % 1 == 0 && value < length);\n}\n\nmodule.exports = isIndex;\n","var eq = require('./eq'),\n    isArrayLike = require('./isArrayLike'),\n    isIndex = require('./_isIndex'),\n    isObject = require('./isObject');\n\n/**\n * Checks if the given arguments are from an iteratee call.\n *\n * @private\n * @param {*} value The potential iteratee value argument.\n * @param {*} index The potential iteratee index or key argument.\n * @param {*} object The potential iteratee object argument.\n * @returns {boolean} Returns `true` if the arguments are from an iteratee call,\n *  else `false`.\n */\nfunction isIterateeCall(value, index, object) {\n  if (!isObject(object)) {\n    return false;\n  }\n  var type = typeof index;\n  if (type == 'number'\n        ? (isArrayLike(object) && isIndex(index, object.length))\n        : (type == 'string' && index in object)\n      ) {\n    return eq(object[index], value);\n  }\n  return false;\n}\n\nmodule.exports = isIterateeCall;\n","var isArray = require('./isArray'),\n    isSymbol = require('./isSymbol');\n\n/** Used to match property names within property paths. */\nvar reIsDeepProp = /\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,\n    reIsPlainProp = /^\\w*$/;\n\n/**\n * Checks if `value` is a property name and not a property path.\n *\n * @private\n * @param {*} value The value to check.\n * @param {Object} [object] The object to query keys on.\n * @returns {boolean} Returns `true` if `value` is a property name, else `false`.\n */\nfunction isKey(value, object) {\n  if (isArray(value)) {\n    return false;\n  }\n  var type = typeof value;\n  if (type == 'number' || type == 'symbol' || type == 'boolean' ||\n      value == null || isSymbol(value)) {\n    return true;\n  }\n  return reIsPlainProp.test(value) || !reIsDeepProp.test(value) ||\n    (object != null && value in Object(object));\n}\n\nmodule.exports = isKey;\n","/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\nmodule.exports = isKeyable;\n","var LazyWrapper = require('./_LazyWrapper'),\n    getData = require('./_getData'),\n    getFuncName = require('./_getFuncName'),\n    lodash = require('./wrapperLodash');\n\n/**\n * Checks if `func` has a lazy counterpart.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` has a lazy counterpart,\n *  else `false`.\n */\nfunction isLaziable(func) {\n  var funcName = getFuncName(func),\n      other = lodash[funcName];\n\n  if (typeof other != 'function' || !(funcName in LazyWrapper.prototype)) {\n    return false;\n  }\n  if (func === other) {\n    return true;\n  }\n  var data = getData(other);\n  return !!data && func === data[0];\n}\n\nmodule.exports = isLaziable;\n","var coreJsData = require('./_coreJsData');\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\nmodule.exports = isMasked;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\nmodule.exports = isPrototype;\n","/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n  this.size = 0;\n}\n\nmodule.exports = listCacheClear;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype;\n\n/** Built-in value references. */\nvar splice = arrayProto.splice;\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  --this.size;\n  return true;\n}\n\nmodule.exports = listCacheDelete;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\nmodule.exports = listCacheGet;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\nmodule.exports = listCacheHas;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    ++this.size;\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\nmodule.exports = listCacheSet;\n","var Hash = require('./_Hash'),\n    ListCache = require('./_ListCache'),\n    Map = require('./_Map');\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.size = 0;\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\nmodule.exports = mapCacheClear;\n","var getMapData = require('./_getMapData');\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  var result = getMapData(this, key)['delete'](key);\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nmodule.exports = mapCacheDelete;\n","var getMapData = require('./_getMapData');\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\nmodule.exports = mapCacheGet;\n","var getMapData = require('./_getMapData');\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\nmodule.exports = mapCacheHas;\n","var getMapData = require('./_getMapData');\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  var data = getMapData(this, key),\n      size = data.size;\n\n  data.set(key, value);\n  this.size += data.size == size ? 0 : 1;\n  return this;\n}\n\nmodule.exports = mapCacheSet;\n","var memoize = require('./memoize');\n\n/** Used as the maximum memoize cache size. */\nvar MAX_MEMOIZE_SIZE = 500;\n\n/**\n * A specialized version of `_.memoize` which clears the memoized function's\n * cache when it exceeds `MAX_MEMOIZE_SIZE`.\n *\n * @private\n * @param {Function} func The function to have its output memoized.\n * @returns {Function} Returns the new memoized function.\n */\nfunction memoizeCapped(func) {\n  var result = memoize(func, function(key) {\n    if (cache.size === MAX_MEMOIZE_SIZE) {\n      cache.clear();\n    }\n    return key;\n  });\n\n  var cache = result.cache;\n  return result;\n}\n\nmodule.exports = memoizeCapped;\n","var composeArgs = require('./_composeArgs'),\n    composeArgsRight = require('./_composeArgsRight'),\n    replaceHolders = require('./_replaceHolders');\n\n/** Used as the internal argument placeholder. */\nvar PLACEHOLDER = '__lodash_placeholder__';\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1,\n    WRAP_BIND_KEY_FLAG = 2,\n    WRAP_CURRY_BOUND_FLAG = 4,\n    WRAP_CURRY_FLAG = 8,\n    WRAP_ARY_FLAG = 128,\n    WRAP_REARG_FLAG = 256;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMin = Math.min;\n\n/**\n * Merges the function metadata of `source` into `data`.\n *\n * Merging metadata reduces the number of wrappers used to invoke a function.\n * This is possible because methods like `_.bind`, `_.curry`, and `_.partial`\n * may be applied regardless of execution order. Methods like `_.ary` and\n * `_.rearg` modify function arguments, making the order in which they are\n * executed important, preventing the merging of metadata. However, we make\n * an exception for a safe combined case where curried functions have `_.ary`\n * and or `_.rearg` applied.\n *\n * @private\n * @param {Array} data The destination metadata.\n * @param {Array} source The source metadata.\n * @returns {Array} Returns `data`.\n */\nfunction mergeData(data, source) {\n  var bitmask = data[1],\n      srcBitmask = source[1],\n      newBitmask = bitmask | srcBitmask,\n      isCommon = newBitmask < (WRAP_BIND_FLAG | WRAP_BIND_KEY_FLAG | WRAP_ARY_FLAG);\n\n  var isCombo =\n    ((srcBitmask == WRAP_ARY_FLAG) && (bitmask == WRAP_CURRY_FLAG)) ||\n    ((srcBitmask == WRAP_ARY_FLAG) && (bitmask == WRAP_REARG_FLAG) && (data[7].length <= source[8])) ||\n    ((srcBitmask == (WRAP_ARY_FLAG | WRAP_REARG_FLAG)) && (source[7].length <= source[8]) && (bitmask == WRAP_CURRY_FLAG));\n\n  // Exit early if metadata can't be merged.\n  if (!(isCommon || isCombo)) {\n    return data;\n  }\n  // Use source `thisArg` if available.\n  if (srcBitmask & WRAP_BIND_FLAG) {\n    data[2] = source[2];\n    // Set when currying a bound function.\n    newBitmask |= bitmask & WRAP_BIND_FLAG ? 0 : WRAP_CURRY_BOUND_FLAG;\n  }\n  // Compose partial arguments.\n  var value = source[3];\n  if (value) {\n    var partials = data[3];\n    data[3] = partials ? composeArgs(partials, value, source[4]) : value;\n    data[4] = partials ? replaceHolders(data[3], PLACEHOLDER) : source[4];\n  }\n  // Compose partial right arguments.\n  value = source[5];\n  if (value) {\n    partials = data[5];\n    data[5] = partials ? composeArgsRight(partials, value, source[6]) : value;\n    data[6] = partials ? replaceHolders(data[5], PLACEHOLDER) : source[6];\n  }\n  // Use source `argPos` if available.\n  value = source[7];\n  if (value) {\n    data[7] = value;\n  }\n  // Use source `ary` if it's smaller.\n  if (srcBitmask & WRAP_ARY_FLAG) {\n    data[8] = data[8] == null ? source[8] : nativeMin(data[8], source[8]);\n  }\n  // Use source `arity` if one is not provided.\n  if (data[9] == null) {\n    data[9] = source[9];\n  }\n  // Use source `func` and merge bitmasks.\n  data[0] = source[0];\n  data[1] = newBitmask;\n\n  return data;\n}\n\nmodule.exports = mergeData;\n","var WeakMap = require('./_WeakMap');\n\n/** Used to store function metadata. */\nvar metaMap = WeakMap && new WeakMap;\n\nmodule.exports = metaMap;\n","var getNative = require('./_getNative');\n\n/* Built-in method references that are verified to be native. */\nvar nativeCreate = getNative(Object, 'create');\n\nmodule.exports = nativeCreate;\n","var overArg = require('./_overArg');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeKeys = overArg(Object.keys, Object);\n\nmodule.exports = nativeKeys;\n","/**\n * This function is like\n * [`Object.keys`](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * except that it includes inherited enumerable properties.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction nativeKeysIn(object) {\n  var result = [];\n  if (object != null) {\n    for (var key in Object(object)) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = nativeKeysIn;\n","var freeGlobal = require('./_freeGlobal');\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    // Use `util.types` for Node.js 10+.\n    var types = freeModule && freeModule.require && freeModule.require('util').types;\n\n    if (types) {\n      return types;\n    }\n\n    // Legacy `process.binding('util')` for Node.js < 10.\n    return freeProcess && freeProcess.binding && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\nmodule.exports = nodeUtil;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\nmodule.exports = objectToString;\n","/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\nmodule.exports = overArg;\n","var apply = require('./_apply');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * A specialized version of `baseRest` which transforms the rest array.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @param {Function} transform The rest array transform.\n * @returns {Function} Returns the new function.\n */\nfunction overRest(func, start, transform) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = transform(array);\n    return apply(func, this, otherArgs);\n  };\n}\n\nmodule.exports = overRest;\n","var baseGet = require('./_baseGet'),\n    baseSlice = require('./_baseSlice');\n\n/**\n * Gets the parent value at `path` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array} path The path to get the parent value of.\n * @returns {*} Returns the parent value.\n */\nfunction parent(object, path) {\n  return path.length < 2 ? object : baseGet(object, baseSlice(path, 0, -1));\n}\n\nmodule.exports = parent;\n","/** Used to lookup unminified function names. */\nvar realNames = {};\n\nmodule.exports = realNames;\n","var copyArray = require('./_copyArray'),\n    isIndex = require('./_isIndex');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMin = Math.min;\n\n/**\n * Reorder `array` according to the specified indexes where the element at\n * the first index is assigned as the first element, the element at\n * the second index is assigned as the second element, and so on.\n *\n * @private\n * @param {Array} array The array to reorder.\n * @param {Array} indexes The arranged array indexes.\n * @returns {Array} Returns `array`.\n */\nfunction reorder(array, indexes) {\n  var arrLength = array.length,\n      length = nativeMin(indexes.length, arrLength),\n      oldArray = copyArray(array);\n\n  while (length--) {\n    var index = indexes[length];\n    array[length] = isIndex(index, arrLength) ? oldArray[index] : undefined;\n  }\n  return array;\n}\n\nmodule.exports = reorder;\n","/** Used as the internal argument placeholder. */\nvar PLACEHOLDER = '__lodash_placeholder__';\n\n/**\n * Replaces all `placeholder` elements in `array` with an internal placeholder\n * and returns an array of their indexes.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {*} placeholder The placeholder to replace.\n * @returns {Array} Returns the new array of placeholder indexes.\n */\nfunction replaceHolders(array, placeholder) {\n  var index = -1,\n      length = array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value === placeholder || value === PLACEHOLDER) {\n      array[index] = PLACEHOLDER;\n      result[resIndex++] = index;\n    }\n  }\n  return result;\n}\n\nmodule.exports = replaceHolders;\n","var freeGlobal = require('./_freeGlobal');\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\nmodule.exports = root;\n","/**\n * Gets the value at `key`, unless `key` is \"__proto__\" or \"constructor\".\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction safeGet(object, key) {\n  if (key === 'constructor' && typeof object[key] === 'function') {\n    return;\n  }\n\n  if (key == '__proto__') {\n    return;\n  }\n\n  return object[key];\n}\n\nmodule.exports = safeGet;\n","/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\nmodule.exports = setCacheAdd;\n","/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\nmodule.exports = setCacheHas;\n","var baseSetData = require('./_baseSetData'),\n    shortOut = require('./_shortOut');\n\n/**\n * Sets metadata for `func`.\n *\n * **Note:** If this function becomes hot, i.e. is invoked a lot in a short\n * period of time, it will trip its breaker and transition to an identity\n * function to avoid garbage collection pauses in V8. See\n * [V8 issue 2070](https://bugs.chromium.org/p/v8/issues/detail?id=2070)\n * for more details.\n *\n * @private\n * @param {Function} func The function to associate metadata with.\n * @param {*} data The metadata.\n * @returns {Function} Returns `func`.\n */\nvar setData = shortOut(baseSetData);\n\nmodule.exports = setData;\n","/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nmodule.exports = setToArray;\n","var baseSetToString = require('./_baseSetToString'),\n    shortOut = require('./_shortOut');\n\n/**\n * Sets the `toString` method of `func` to return `string`.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar setToString = shortOut(baseSetToString);\n\nmodule.exports = setToString;\n","var getWrapDetails = require('./_getWrapDetails'),\n    insertWrapDetails = require('./_insertWrapDetails'),\n    setToString = require('./_setToString'),\n    updateWrapDetails = require('./_updateWrapDetails');\n\n/**\n * Sets the `toString` method of `wrapper` to mimic the source of `reference`\n * with wrapper details in a comment at the top of the source body.\n *\n * @private\n * @param {Function} wrapper The function to modify.\n * @param {Function} reference The reference function.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @returns {Function} Returns `wrapper`.\n */\nfunction setWrapToString(wrapper, reference, bitmask) {\n  var source = (reference + '');\n  return setToString(wrapper, insertWrapDetails(source, updateWrapDetails(getWrapDetails(source), bitmask)));\n}\n\nmodule.exports = setWrapToString;\n","/** Used to detect hot functions by number of calls within a span of milliseconds. */\nvar HOT_COUNT = 800,\n    HOT_SPAN = 16;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeNow = Date.now;\n\n/**\n * Creates a function that'll short out and invoke `identity` instead\n * of `func` when it's called `HOT_COUNT` or more times in `HOT_SPAN`\n * milliseconds.\n *\n * @private\n * @param {Function} func The function to restrict.\n * @returns {Function} Returns the new shortable function.\n */\nfunction shortOut(func) {\n  var count = 0,\n      lastCalled = 0;\n\n  return function() {\n    var stamp = nativeNow(),\n        remaining = HOT_SPAN - (stamp - lastCalled);\n\n    lastCalled = stamp;\n    if (remaining > 0) {\n      if (++count >= HOT_COUNT) {\n        return arguments[0];\n      }\n    } else {\n      count = 0;\n    }\n    return func.apply(undefined, arguments);\n  };\n}\n\nmodule.exports = shortOut;\n","var ListCache = require('./_ListCache');\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n  this.size = 0;\n}\n\nmodule.exports = stackClear;\n","/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  var data = this.__data__,\n      result = data['delete'](key);\n\n  this.size = data.size;\n  return result;\n}\n\nmodule.exports = stackDelete;\n","/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\nmodule.exports = stackGet;\n","/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\nmodule.exports = stackHas;\n","var ListCache = require('./_ListCache'),\n    Map = require('./_Map'),\n    MapCache = require('./_MapCache');\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var data = this.__data__;\n  if (data instanceof ListCache) {\n    var pairs = data.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      this.size = ++data.size;\n      return this;\n    }\n    data = this.__data__ = new MapCache(pairs);\n  }\n  data.set(key, value);\n  this.size = data.size;\n  return this;\n}\n\nmodule.exports = stackSet;\n","/**\n * A specialized version of `_.indexOf` which performs strict equality\n * comparisons of values, i.e. `===`.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction strictIndexOf(array, value, fromIndex) {\n  var index = fromIndex - 1,\n      length = array.length;\n\n  while (++index < length) {\n    if (array[index] === value) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = strictIndexOf;\n","var memoizeCapped = require('./_memoizeCapped');\n\n/** Used to match property names within property paths. */\nvar rePropName = /[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g;\n\n/** Used to match backslashes in property paths. */\nvar reEscapeChar = /\\\\(\\\\)?/g;\n\n/**\n * Converts `string` to a property path array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the property path array.\n */\nvar stringToPath = memoizeCapped(function(string) {\n  var result = [];\n  if (string.charCodeAt(0) === 46 /* . */) {\n    result.push('');\n  }\n  string.replace(rePropName, function(match, number, quote, subString) {\n    result.push(quote ? subString.replace(reEscapeChar, '$1') : (number || match));\n  });\n  return result;\n});\n\nmodule.exports = stringToPath;\n","var isSymbol = require('./isSymbol');\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/**\n * Converts `value` to a string key if it's not a string or symbol.\n *\n * @private\n * @param {*} value The value to inspect.\n * @returns {string|symbol} Returns the key.\n */\nfunction toKey(value) {\n  if (typeof value == 'string' || isSymbol(value)) {\n    return value;\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\nmodule.exports = toKey;\n","/** Used for built-in method references. */\nvar funcProto = Function.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to convert.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\nmodule.exports = toSource;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nmodule.exports = trimmedEndIndex;\n","var arrayEach = require('./_arrayEach'),\n    arrayIncludes = require('./_arrayIncludes');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_BIND_FLAG = 1,\n    WRAP_BIND_KEY_FLAG = 2,\n    WRAP_CURRY_FLAG = 8,\n    WRAP_CURRY_RIGHT_FLAG = 16,\n    WRAP_PARTIAL_FLAG = 32,\n    WRAP_PARTIAL_RIGHT_FLAG = 64,\n    WRAP_ARY_FLAG = 128,\n    WRAP_REARG_FLAG = 256,\n    WRAP_FLIP_FLAG = 512;\n\n/** Used to associate wrap methods with their bit flags. */\nvar wrapFlags = [\n  ['ary', WRAP_ARY_FLAG],\n  ['bind', WRAP_BIND_FLAG],\n  ['bindKey', WRAP_BIND_KEY_FLAG],\n  ['curry', WRAP_CURRY_FLAG],\n  ['curryRight', WRAP_CURRY_RIGHT_FLAG],\n  ['flip', WRAP_FLIP_FLAG],\n  ['partial', WRAP_PARTIAL_FLAG],\n  ['partialRight', WRAP_PARTIAL_RIGHT_FLAG],\n  ['rearg', WRAP_REARG_FLAG]\n];\n\n/**\n * Updates wrapper `details` based on `bitmask` flags.\n *\n * @private\n * @returns {Array} details The details to modify.\n * @param {number} bitmask The bitmask flags. See `createWrap` for more details.\n * @returns {Array} Returns `details`.\n */\nfunction updateWrapDetails(details, bitmask) {\n  arrayEach(wrapFlags, function(pair) {\n    var value = '_.' + pair[0];\n    if ((bitmask & pair[1]) && !arrayIncludes(details, value)) {\n      details.push(value);\n    }\n  });\n  return details.sort();\n}\n\nmodule.exports = updateWrapDetails;\n","var LazyWrapper = require('./_LazyWrapper'),\n    LodashWrapper = require('./_LodashWrapper'),\n    copyArray = require('./_copyArray');\n\n/**\n * Creates a clone of `wrapper`.\n *\n * @private\n * @param {Object} wrapper The wrapper to clone.\n * @returns {Object} Returns the cloned wrapper.\n */\nfunction wrapperClone(wrapper) {\n  if (wrapper instanceof LazyWrapper) {\n    return wrapper.clone();\n  }\n  var result = new LodashWrapper(wrapper.__wrapped__, wrapper.__chain__);\n  result.__actions__ = copyArray(wrapper.__actions__);\n  result.__index__  = wrapper.__index__;\n  result.__values__ = wrapper.__values__;\n  return result;\n}\n\nmodule.exports = wrapperClone;\n","var assignValue = require('./_assignValue'),\n    copyObject = require('./_copyObject'),\n    createAssigner = require('./_createAssigner'),\n    isArrayLike = require('./isArrayLike'),\n    isPrototype = require('./_isPrototype'),\n    keys = require('./keys');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nmodule.exports = assign;\n","var baseClone = require('./_baseClone');\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nmodule.exports = clone;\n","/**\n * Creates a function that returns `value`.\n *\n * @static\n * @memberOf _\n * @since 2.4.0\n * @category Util\n * @param {*} value The value to return from the new function.\n * @returns {Function} Returns the new constant function.\n * @example\n *\n * var objects = _.times(2, _.constant({ 'a': 1 }));\n *\n * console.log(objects);\n * // => [{ 'a': 1 }, { 'a': 1 }]\n *\n * console.log(objects[0] === objects[1]);\n * // => true\n */\nfunction constant(value) {\n  return function() {\n    return value;\n  };\n}\n\nmodule.exports = constant;\n","/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\nmodule.exports = eq;\n","var baseFill = require('./_baseFill'),\n    isIterateeCall = require('./_isIterateeCall');\n\n/**\n * Fills elements of `array` with `value` from `start` up to, but not\n * including, `end`.\n *\n * **Note:** This method mutates `array`.\n *\n * @static\n * @memberOf _\n * @since 3.2.0\n * @category Array\n * @param {Array} array The array to fill.\n * @param {*} value The value to fill `array` with.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns `array`.\n * @example\n *\n * var array = [1, 2, 3];\n *\n * _.fill(array, 'a');\n * console.log(array);\n * // => ['a', 'a', 'a']\n *\n * _.fill(Array(3), 2);\n * // => [2, 2, 2]\n *\n * _.fill([4, 6, 8, 10], '*', 1, 3);\n * // => [4, '*', '*', 10]\n */\nfunction fill(array, value, start, end) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  if (start && typeof start != 'number' && isIterateeCall(array, value, start)) {\n    start = 0;\n    end = length;\n  }\n  return baseFill(array, value, start, end);\n}\n\nmodule.exports = fill;\n","var baseFlatten = require('./_baseFlatten');\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nmodule.exports = flatten;\n","var baseHasIn = require('./_baseHasIn'),\n    hasPath = require('./_hasPath');\n\n/**\n * Checks if `path` is a direct or inherited property of `object`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.hasIn(object, 'a');\n * // => true\n *\n * _.hasIn(object, 'a.b');\n * // => true\n *\n * _.hasIn(object, ['a', 'b']);\n * // => true\n *\n * _.hasIn(object, 'b');\n * // => false\n */\nfunction hasIn(object, path) {\n  return object != null && hasPath(object, path, baseHasIn);\n}\n\nmodule.exports = hasIn;\n","/**\n * This method returns the first argument it receives.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Util\n * @param {*} value Any value.\n * @returns {*} Returns `value`.\n * @example\n *\n * var object = { 'a': 1 };\n *\n * console.log(_.identity(object) === object);\n * // => true\n */\nfunction identity(value) {\n  return value;\n}\n\nmodule.exports = identity;\n","var arrayMap = require('./_arrayMap'),\n    baseIntersection = require('./_baseIntersection'),\n    baseRest = require('./_baseRest'),\n    castArrayLikeObject = require('./_castArrayLikeObject');\n\n/**\n * Creates an array of unique values that are included in all given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {...Array} [arrays] The arrays to inspect.\n * @returns {Array} Returns the new array of intersecting values.\n * @example\n *\n * _.intersection([2, 1], [2, 3]);\n * // => [2]\n */\nvar intersection = baseRest(function(arrays) {\n  var mapped = arrayMap(arrays, castArrayLikeObject);\n  return (mapped.length && mapped[0] === arrays[0])\n    ? baseIntersection(mapped)\n    : [];\n});\n\nmodule.exports = intersection;\n","var baseIsArguments = require('./_baseIsArguments'),\n    isObjectLike = require('./isObjectLike');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nvar isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {\n  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&\n    !propertyIsEnumerable.call(value, 'callee');\n};\n\nmodule.exports = isArguments;\n","/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\nmodule.exports = isArray;\n","var isFunction = require('./isFunction'),\n    isLength = require('./isLength');\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\nmodule.exports = isArrayLike;\n","var isArrayLike = require('./isArrayLike'),\n    isObjectLike = require('./isObjectLike');\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\nmodule.exports = isArrayLikeObject;\n","var root = require('./_root'),\n    stubFalse = require('./stubFalse');\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined;\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\nmodule.exports = isBuffer;\n","var baseGetTag = require('./_baseGetTag'),\n    isObject = require('./isObject');\n\n/** `Object#toString` result references. */\nvar asyncTag = '[object AsyncFunction]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    proxyTag = '[object Proxy]';\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  if (!isObject(value)) {\n    return false;\n  }\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 9 which returns 'object' for typed arrays and other constructors.\n  var tag = baseGetTag(value);\n  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;\n}\n\nmodule.exports = isFunction;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\nmodule.exports = isLength;\n","var baseIsMap = require('./_baseIsMap'),\n    baseUnary = require('./_baseUnary'),\n    nodeUtil = require('./_nodeUtil');\n\n/* Node.js helper references. */\nvar nodeIsMap = nodeUtil && nodeUtil.isMap;\n\n/**\n * Checks if `value` is classified as a `Map` object.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a map, else `false`.\n * @example\n *\n * _.isMap(new Map);\n * // => true\n *\n * _.isMap(new WeakMap);\n * // => false\n */\nvar isMap = nodeIsMap ? baseUnary(nodeIsMap) : baseIsMap;\n\nmodule.exports = isMap;\n","/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return value != null && (type == 'object' || type == 'function');\n}\n\nmodule.exports = isObject;\n","/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\nmodule.exports = isObjectLike;\n","var baseGetTag = require('./_baseGetTag'),\n    getPrototype = require('./_getPrototype'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar objectTag = '[object Object]';\n\n/** Used for built-in method references. */\nvar funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to infer the `Object` constructor. */\nvar objectCtorString = funcToString.call(Object);\n\n/**\n * Checks if `value` is a plain object, that is, an object created by the\n * `Object` constructor or one with a `[[Prototype]]` of `null`.\n *\n * @static\n * @memberOf _\n * @since 0.8.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a plain object, else `false`.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * _.isPlainObject(new Foo);\n * // => false\n *\n * _.isPlainObject([1, 2, 3]);\n * // => false\n *\n * _.isPlainObject({ 'x': 0, 'y': 0 });\n * // => true\n *\n * _.isPlainObject(Object.create(null));\n * // => true\n */\nfunction isPlainObject(value) {\n  if (!isObjectLike(value) || baseGetTag(value) != objectTag) {\n    return false;\n  }\n  var proto = getPrototype(value);\n  if (proto === null) {\n    return true;\n  }\n  var Ctor = hasOwnProperty.call(proto, 'constructor') && proto.constructor;\n  return typeof Ctor == 'function' && Ctor instanceof Ctor &&\n    funcToString.call(Ctor) == objectCtorString;\n}\n\nmodule.exports = isPlainObject;\n","var baseIsSet = require('./_baseIsSet'),\n    baseUnary = require('./_baseUnary'),\n    nodeUtil = require('./_nodeUtil');\n\n/* Node.js helper references. */\nvar nodeIsSet = nodeUtil && nodeUtil.isSet;\n\n/**\n * Checks if `value` is classified as a `Set` object.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a set, else `false`.\n * @example\n *\n * _.isSet(new Set);\n * // => true\n *\n * _.isSet(new WeakSet);\n * // => false\n */\nvar isSet = nodeIsSet ? baseUnary(nodeIsSet) : baseIsSet;\n\nmodule.exports = isSet;\n","var baseGetTag = require('./_baseGetTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && baseGetTag(value) == symbolTag);\n}\n\nmodule.exports = isSymbol;\n","var baseIsTypedArray = require('./_baseIsTypedArray'),\n    baseUnary = require('./_baseUnary'),\n    nodeUtil = require('./_nodeUtil');\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\nmodule.exports = isTypedArray;\n","var arrayLikeKeys = require('./_arrayLikeKeys'),\n    baseKeys = require('./_baseKeys'),\n    isArrayLike = require('./isArrayLike');\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\nmodule.exports = keys;\n","var arrayLikeKeys = require('./_arrayLikeKeys'),\n    baseKeysIn = require('./_baseKeysIn'),\n    isArrayLike = require('./isArrayLike');\n\n/**\n * Creates an array of the own and inherited enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keysIn(new Foo);\n * // => ['a', 'b', 'c'] (iteration order is not guaranteed)\n */\nfunction keysIn(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n}\n\nmodule.exports = keysIn;\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nmodule.exports = last;\n","var MapCache = require('./_MapCache');\n\n/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that memoizes the result of `func`. If `resolver` is\n * provided, it determines the cache key for storing the result based on the\n * arguments provided to the memoized function. By default, the first argument\n * provided to the memoized function is used as the map cache key. The `func`\n * is invoked with the `this` binding of the memoized function.\n *\n * **Note:** The cache is exposed as the `cache` property on the memoized\n * function. Its creation may be customized by replacing the `_.memoize.Cache`\n * constructor with one whose instances implement the\n * [`Map`](http://ecma-international.org/ecma-262/7.0/#sec-properties-of-the-map-prototype-object)\n * method interface of `clear`, `delete`, `get`, `has`, and `set`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Function\n * @param {Function} func The function to have its output memoized.\n * @param {Function} [resolver] The function to resolve the cache key.\n * @returns {Function} Returns the new memoized function.\n * @example\n *\n * var object = { 'a': 1, 'b': 2 };\n * var other = { 'c': 3, 'd': 4 };\n *\n * var values = _.memoize(_.values);\n * values(object);\n * // => [1, 2]\n *\n * values(other);\n * // => [3, 4]\n *\n * object.a = 2;\n * values(object);\n * // => [1, 2]\n *\n * // Modify the result cache.\n * values.cache.set(object, ['a', 'b']);\n * values(object);\n * // => ['a', 'b']\n *\n * // Replace `_.memoize.Cache`.\n * _.memoize.Cache = WeakMap;\n */\nfunction memoize(func, resolver) {\n  if (typeof func != 'function' || (resolver != null && typeof resolver != 'function')) {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  var memoized = function() {\n    var args = arguments,\n        key = resolver ? resolver.apply(this, args) : args[0],\n        cache = memoized.cache;\n\n    if (cache.has(key)) {\n      return cache.get(key);\n    }\n    var result = func.apply(this, args);\n    memoized.cache = cache.set(key, result) || cache;\n    return result;\n  };\n  memoized.cache = new (memoize.Cache || MapCache);\n  return memoized;\n}\n\n// Expose `MapCache`.\nmemoize.Cache = MapCache;\n\nmodule.exports = memoize;\n","var baseMerge = require('./_baseMerge'),\n    createAssigner = require('./_createAssigner');\n\n/**\n * This method is like `_.assign` except that it recursively merges own and\n * inherited enumerable string keyed properties of source objects into the\n * destination object. Source properties that resolve to `undefined` are\n * skipped if a destination value exists. Array and plain object properties\n * are merged recursively. Other objects and value types are overridden by\n * assignment. Source objects are applied from left to right. Subsequent\n * sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @example\n *\n * var object = {\n *   'a': [{ 'b': 2 }, { 'd': 4 }]\n * };\n *\n * var other = {\n *   'a': [{ 'c': 3 }, { 'e': 5 }]\n * };\n *\n * _.merge(object, other);\n * // => { 'a': [{ 'b': 2, 'c': 3 }, { 'd': 4, 'e': 5 }] }\n */\nvar merge = createAssigner(function(object, source, srcIndex) {\n  baseMerge(object, source, srcIndex);\n});\n\nmodule.exports = merge;\n","/**\n * This method returns `undefined`.\n *\n * @static\n * @memberOf _\n * @since 2.3.0\n * @category Util\n * @example\n *\n * _.times(2, _.noop);\n * // => [undefined, undefined]\n */\nfunction noop() {\n  // No operation performed.\n}\n\nmodule.exports = noop;\n","var arrayMap = require('./_arrayMap'),\n    baseClone = require('./_baseClone'),\n    baseUnset = require('./_baseUnset'),\n    castPath = require('./_castPath'),\n    copyObject = require('./_copyObject'),\n    customOmitClone = require('./_customOmitClone'),\n    flatRest = require('./_flatRest'),\n    getAllKeysIn = require('./_getAllKeysIn');\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_DEEP_FLAG = 1,\n    CLONE_FLAT_FLAG = 2,\n    CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * The opposite of `_.pick`; this method creates an object composed of the\n * own and inherited enumerable property paths of `object` that are not omitted.\n *\n * **Note:** This method is considerably slower than `_.pick`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The source object.\n * @param {...(string|string[])} [paths] The property paths to omit.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.omit(object, ['a', 'c']);\n * // => { 'b': '2' }\n */\nvar omit = flatRest(function(object, paths) {\n  var result = {};\n  if (object == null) {\n    return result;\n  }\n  var isDeep = false;\n  paths = arrayMap(paths, function(path) {\n    path = castPath(path, object);\n    isDeep || (isDeep = path.length > 1);\n    return path;\n  });\n  copyObject(object, getAllKeysIn(object), result);\n  if (isDeep) {\n    result = baseClone(result, CLONE_DEEP_FLAG | CLONE_FLAT_FLAG | CLONE_SYMBOLS_FLAG, customOmitClone);\n  }\n  var length = paths.length;\n  while (length--) {\n    baseUnset(result, paths[length]);\n  }\n  return result;\n});\n\nmodule.exports = omit;\n","var baseRest = require('./_baseRest'),\n    createWrap = require('./_createWrap'),\n    getHolder = require('./_getHolder'),\n    replaceHolders = require('./_replaceHolders');\n\n/** Used to compose bitmasks for function metadata. */\nvar WRAP_PARTIAL_RIGHT_FLAG = 64;\n\n/**\n * This method is like `_.partial` except that partially applied arguments\n * are appended to the arguments it receives.\n *\n * The `_.partialRight.placeholder` value, which defaults to `_` in monolithic\n * builds, may be used as a placeholder for partially applied arguments.\n *\n * **Note:** This method doesn't set the \"length\" property of partially\n * applied functions.\n *\n * @static\n * @memberOf _\n * @since 1.0.0\n * @category Function\n * @param {Function} func The function to partially apply arguments to.\n * @param {...*} [partials] The arguments to be partially applied.\n * @returns {Function} Returns the new partially applied function.\n * @example\n *\n * function greet(greeting, name) {\n *   return greeting + ' ' + name;\n * }\n *\n * var greetFred = _.partialRight(greet, 'fred');\n * greetFred('hi');\n * // => 'hi fred'\n *\n * // Partially applied with placeholders.\n * var sayHelloTo = _.partialRight(greet, 'hello', _);\n * sayHelloTo('fred');\n * // => 'hello fred'\n */\nvar partialRight = baseRest(function(func, partials) {\n  var holders = replaceHolders(partials, getHolder(partialRight));\n  return createWrap(func, WRAP_PARTIAL_RIGHT_FLAG, undefined, partials, holders);\n});\n\n// Assign default placeholders.\npartialRight.placeholder = {};\n\nmodule.exports = partialRight;\n","var basePick = require('./_basePick'),\n    flatRest = require('./_flatRest');\n\n/**\n * Creates an object composed of the picked `object` properties.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The source object.\n * @param {...(string|string[])} [paths] The property paths to pick.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pick(object, ['a', 'c']);\n * // => { 'a': 1, 'c': 3 }\n */\nvar pick = flatRest(function(object, paths) {\n  return object == null ? {} : basePick(object, paths);\n});\n\nmodule.exports = pick;\n","/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\nmodule.exports = stubArray;\n","/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = stubFalse;\n","var toNumber = require('./toNumber');\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nmodule.exports = toFinite;\n","var toFinite = require('./toFinite');\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nmodule.exports = toInteger;\n","var baseClamp = require('./_baseClamp'),\n    toInteger = require('./toInteger');\n\n/** Used as references for the maximum length and index of an array. */\nvar MAX_ARRAY_LENGTH = 4294967295;\n\n/**\n * Converts `value` to an integer suitable for use as the length of an\n * array-like object.\n *\n * **Note:** This method is based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toLength(3.2);\n * // => 3\n *\n * _.toLength(Number.MIN_VALUE);\n * // => 0\n *\n * _.toLength(Infinity);\n * // => 4294967295\n *\n * _.toLength('3.2');\n * // => 3\n */\nfunction toLength(value) {\n  return value ? baseClamp(toInteger(value), 0, MAX_ARRAY_LENGTH) : 0;\n}\n\nmodule.exports = toLength;\n","var baseTrim = require('./_baseTrim'),\n    isObject = require('./isObject'),\n    isSymbol = require('./isSymbol');\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nmodule.exports = toNumber;\n","var copyObject = require('./_copyObject'),\n    keysIn = require('./keysIn');\n\n/**\n * Converts `value` to a plain object flattening inherited enumerable string\n * keyed properties of `value` to own properties of the plain object.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {Object} Returns the converted plain object.\n * @example\n *\n * function Foo() {\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.assign({ 'a': 1 }, new Foo);\n * // => { 'a': 1, 'b': 2 }\n *\n * _.assign({ 'a': 1 }, _.toPlainObject(new Foo));\n * // => { 'a': 1, 'b': 2, 'c': 3 }\n */\nfunction toPlainObject(value) {\n  return copyObject(value, keysIn(value));\n}\n\nmodule.exports = toPlainObject;\n","var baseToString = require('./_baseToString');\n\n/**\n * Converts `value` to a string. An empty string is returned for `null`\n * and `undefined` values. The sign of `-0` is preserved.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n * @example\n *\n * _.toString(null);\n * // => ''\n *\n * _.toString(-0);\n * // => '-0'\n *\n * _.toString([1, 2, 3]);\n * // => '1,2,3'\n */\nfunction toString(value) {\n  return value == null ? '' : baseToString(value);\n}\n\nmodule.exports = toString;\n","var baseUniq = require('./_baseUniq');\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nmodule.exports = uniq;\n","var LazyWrapper = require('./_LazyWrapper'),\n    LodashWrapper = require('./_LodashWrapper'),\n    baseLodash = require('./_baseLodash'),\n    isArray = require('./isArray'),\n    isObjectLike = require('./isObjectLike'),\n    wrapperClone = require('./_wrapperClone');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates a `lodash` object which wraps `value` to enable implicit method\n * chain sequences. Methods that operate on and return arrays, collections,\n * and functions can be chained together. Methods that retrieve a single value\n * or may return a primitive value will automatically end the chain sequence\n * and return the unwrapped value. Otherwise, the value must be unwrapped\n * with `_#value`.\n *\n * Explicit chain sequences, which must be unwrapped with `_#value`, may be\n * enabled using `_.chain`.\n *\n * The execution of chained methods is lazy, that is, it's deferred until\n * `_#value` is implicitly or explicitly called.\n *\n * Lazy evaluation allows several methods to support shortcut fusion.\n * Shortcut fusion is an optimization to merge iteratee calls; this avoids\n * the creation of intermediate arrays and can greatly reduce the number of\n * iteratee executions. Sections of a chain sequence qualify for shortcut\n * fusion if the section is applied to an array and iteratees accept only\n * one argument. The heuristic for whether a section qualifies for shortcut\n * fusion is subject to change.\n *\n * Chaining is supported in custom builds as long as the `_#value` method is\n * directly or indirectly included in the build.\n *\n * In addition to lodash methods, wrappers have `Array` and `String` methods.\n *\n * The wrapper `Array` methods are:\n * `concat`, `join`, `pop`, `push`, `shift`, `sort`, `splice`, and `unshift`\n *\n * The wrapper `String` methods are:\n * `replace` and `split`\n *\n * The wrapper methods that support shortcut fusion are:\n * `at`, `compact`, `drop`, `dropRight`, `dropWhile`, `filter`, `find`,\n * `findLast`, `head`, `initial`, `last`, `map`, `reject`, `reverse`, `slice`,\n * `tail`, `take`, `takeRight`, `takeRightWhile`, `takeWhile`, and `toArray`\n *\n * The chainable wrapper methods are:\n * `after`, `ary`, `assign`, `assignIn`, `assignInWith`, `assignWith`, `at`,\n * `before`, `bind`, `bindAll`, `bindKey`, `castArray`, `chain`, `chunk`,\n * `commit`, `compact`, `concat`, `conforms`, `constant`, `countBy`, `create`,\n * `curry`, `debounce`, `defaults`, `defaultsDeep`, `defer`, `delay`,\n * `difference`, `differenceBy`, `differenceWith`, `drop`, `dropRight`,\n * `dropRightWhile`, `dropWhile`, `extend`, `extendWith`, `fill`, `filter`,\n * `flatMap`, `flatMapDeep`, `flatMapDepth`, `flatten`, `flattenDeep`,\n * `flattenDepth`, `flip`, `flow`, `flowRight`, `fromPairs`, `functions`,\n * `functionsIn`, `groupBy`, `initial`, `intersection`, `intersectionBy`,\n * `intersectionWith`, `invert`, `invertBy`, `invokeMap`, `iteratee`, `keyBy`,\n * `keys`, `keysIn`, `map`, `mapKeys`, `mapValues`, `matches`, `matchesProperty`,\n * `memoize`, `merge`, `mergeWith`, `method`, `methodOf`, `mixin`, `negate`,\n * `nthArg`, `omit`, `omitBy`, `once`, `orderBy`, `over`, `overArgs`,\n * `overEvery`, `overSome`, `partial`, `partialRight`, `partition`, `pick`,\n * `pickBy`, `plant`, `property`, `propertyOf`, `pull`, `pullAll`, `pullAllBy`,\n * `pullAllWith`, `pullAt`, `push`, `range`, `rangeRight`, `rearg`, `reject`,\n * `remove`, `rest`, `reverse`, `sampleSize`, `set`, `setWith`, `shuffle`,\n * `slice`, `sort`, `sortBy`, `splice`, `spread`, `tail`, `take`, `takeRight`,\n * `takeRightWhile`, `takeWhile`, `tap`, `throttle`, `thru`, `toArray`,\n * `toPairs`, `toPairsIn`, `toPath`, `toPlainObject`, `transform`, `unary`,\n * `union`, `unionBy`, `unionWith`, `uniq`, `uniqBy`, `uniqWith`, `unset`,\n * `unshift`, `unzip`, `unzipWith`, `update`, `updateWith`, `values`,\n * `valuesIn`, `without`, `wrap`, `xor`, `xorBy`, `xorWith`, `zip`,\n * `zipObject`, `zipObjectDeep`, and `zipWith`\n *\n * The wrapper methods that are **not** chainable by default are:\n * `add`, `attempt`, `camelCase`, `capitalize`, `ceil`, `clamp`, `clone`,\n * `cloneDeep`, `cloneDeepWith`, `cloneWith`, `conformsTo`, `deburr`,\n * `defaultTo`, `divide`, `each`, `eachRight`, `endsWith`, `eq`, `escape`,\n * `escapeRegExp`, `every`, `find`, `findIndex`, `findKey`, `findLast`,\n * `findLastIndex`, `findLastKey`, `first`, `floor`, `forEach`, `forEachRight`,\n * `forIn`, `forInRight`, `forOwn`, `forOwnRight`, `get`, `gt`, `gte`, `has`,\n * `hasIn`, `head`, `identity`, `includes`, `indexOf`, `inRange`, `invoke`,\n * `isArguments`, `isArray`, `isArrayBuffer`, `isArrayLike`, `isArrayLikeObject`,\n * `isBoolean`, `isBuffer`, `isDate`, `isElement`, `isEmpty`, `isEqual`,\n * `isEqualWith`, `isError`, `isFinite`, `isFunction`, `isInteger`, `isLength`,\n * `isMap`, `isMatch`, `isMatchWith`, `isNaN`, `isNative`, `isNil`, `isNull`,\n * `isNumber`, `isObject`, `isObjectLike`, `isPlainObject`, `isRegExp`,\n * `isSafeInteger`, `isSet`, `isString`, `isUndefined`, `isTypedArray`,\n * `isWeakMap`, `isWeakSet`, `join`, `kebabCase`, `last`, `lastIndexOf`,\n * `lowerCase`, `lowerFirst`, `lt`, `lte`, `max`, `maxBy`, `mean`, `meanBy`,\n * `min`, `minBy`, `multiply`, `noConflict`, `noop`, `now`, `nth`, `pad`,\n * `padEnd`, `padStart`, `parseInt`, `pop`, `random`, `reduce`, `reduceRight`,\n * `repeat`, `result`, `round`, `runInContext`, `sample`, `shift`, `size`,\n * `snakeCase`, `some`, `sortedIndex`, `sortedIndexBy`, `sortedLastIndex`,\n * `sortedLastIndexBy`, `startCase`, `startsWith`, `stubArray`, `stubFalse`,\n * `stubObject`, `stubString`, `stubTrue`, `subtract`, `sum`, `sumBy`,\n * `template`, `times`, `toFinite`, `toInteger`, `toJSON`, `toLength`,\n * `toLower`, `toNumber`, `toSafeInteger`, `toString`, `toUpper`, `trim`,\n * `trimEnd`, `trimStart`, `truncate`, `unescape`, `uniqueId`, `upperCase`,\n * `upperFirst`, `value`, and `words`\n *\n * @name _\n * @constructor\n * @category Seq\n * @param {*} value The value to wrap in a `lodash` instance.\n * @returns {Object} Returns the new `lodash` wrapper instance.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * var wrapped = _([1, 2, 3]);\n *\n * // Returns an unwrapped value.\n * wrapped.reduce(_.add);\n * // => 6\n *\n * // Returns a wrapped value.\n * var squares = wrapped.map(square);\n *\n * _.isArray(squares);\n * // => false\n *\n * _.isArray(squares.value());\n * // => true\n */\nfunction lodash(value) {\n  if (isObjectLike(value) && !isArray(value) && !(value instanceof LazyWrapper)) {\n    if (value instanceof LodashWrapper) {\n      return value;\n    }\n    if (hasOwnProperty.call(value, '__wrapped__')) {\n      return wrapperClone(value);\n    }\n  }\n  return new LodashWrapper(value);\n}\n\n// Ensure wrappers are instances of `baseLodash`.\nlodash.prototype = baseLodash.prototype;\nlodash.prototype.constructor = lodash;\n\nmodule.exports = lodash;\n","/**\n * Advanced Encryption Standard (AES) implementation.\n *\n * This implementation is based on the public domain library 'jscrypto' which\n * was written by:\n *\n * Emily Stark (estark@stanford.edu)\n * Mike Hamburg (mhamburg@stanford.edu)\n * Dan Boneh (dabo@cs.stanford.edu)\n *\n * Parts of this code are based on the OpenSSL implementation of AES:\n * http://www.openssl.org\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./cipher');\nrequire('./cipherModes');\nrequire('./util');\n\n/* AES API */\nmodule.exports = forge.aes = forge.aes || {};\n\n/**\n * Deprecated. Instead, use:\n *\n * var cipher = forge.cipher.createCipher('AES-<mode>', key);\n * cipher.start({iv: iv});\n *\n * Creates an AES cipher object to encrypt data using the given symmetric key.\n * The output will be stored in the 'output' member of the returned cipher.\n *\n * The key and iv may be given as a string of bytes, an array of bytes,\n * a byte buffer, or an array of 32-bit words.\n *\n * @param key the symmetric key to use.\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.aes.startEncrypting = function(key, iv, output, mode) {\n  var cipher = _createCipher({\n    key: key,\n    output: output,\n    decrypt: false,\n    mode: mode\n  });\n  cipher.start(iv);\n  return cipher;\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var cipher = forge.cipher.createCipher('AES-<mode>', key);\n *\n * Creates an AES cipher object to encrypt data using the given symmetric key.\n *\n * The key may be given as a string of bytes, an array of bytes, a\n * byte buffer, or an array of 32-bit words.\n *\n * @param key the symmetric key to use.\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.aes.createEncryptionCipher = function(key, mode) {\n  return _createCipher({\n    key: key,\n    output: null,\n    decrypt: false,\n    mode: mode\n  });\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var decipher = forge.cipher.createDecipher('AES-<mode>', key);\n * decipher.start({iv: iv});\n *\n * Creates an AES cipher object to decrypt data using the given symmetric key.\n * The output will be stored in the 'output' member of the returned cipher.\n *\n * The key and iv may be given as a string of bytes, an array of bytes,\n * a byte buffer, or an array of 32-bit words.\n *\n * @param key the symmetric key to use.\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.aes.startDecrypting = function(key, iv, output, mode) {\n  var cipher = _createCipher({\n    key: key,\n    output: output,\n    decrypt: true,\n    mode: mode\n  });\n  cipher.start(iv);\n  return cipher;\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var decipher = forge.cipher.createDecipher('AES-<mode>', key);\n *\n * Creates an AES cipher object to decrypt data using the given symmetric key.\n *\n * The key may be given as a string of bytes, an array of bytes, a\n * byte buffer, or an array of 32-bit words.\n *\n * @param key the symmetric key to use.\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.aes.createDecryptionCipher = function(key, mode) {\n  return _createCipher({\n    key: key,\n    output: null,\n    decrypt: true,\n    mode: mode\n  });\n};\n\n/**\n * Creates a new AES cipher algorithm object.\n *\n * @param name the name of the algorithm.\n * @param mode the mode factory function.\n *\n * @return the AES algorithm object.\n */\nforge.aes.Algorithm = function(name, mode) {\n  if(!init) {\n    initialize();\n  }\n  var self = this;\n  self.name = name;\n  self.mode = new mode({\n    blockSize: 16,\n    cipher: {\n      encrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._w, inBlock, outBlock, false);\n      },\n      decrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._w, inBlock, outBlock, true);\n      }\n    }\n  });\n  self._init = false;\n};\n\n/**\n * Initializes this AES algorithm by expanding its key.\n *\n * @param options the options to use.\n *          key the key to use with this algorithm.\n *          decrypt true if the algorithm should be initialized for decryption,\n *            false for encryption.\n */\nforge.aes.Algorithm.prototype.initialize = function(options) {\n  if(this._init) {\n    return;\n  }\n\n  var key = options.key;\n  var tmp;\n\n  /* Note: The key may be a string of bytes, an array of bytes, a byte\n    buffer, or an array of 32-bit integers. If the key is in bytes, then\n    it must be 16, 24, or 32 bytes in length. If it is in 32-bit\n    integers, it must be 4, 6, or 8 integers long. */\n\n  if(typeof key === 'string' &&\n    (key.length === 16 || key.length === 24 || key.length === 32)) {\n    // convert key string into byte buffer\n    key = forge.util.createBuffer(key);\n  } else if(forge.util.isArray(key) &&\n    (key.length === 16 || key.length === 24 || key.length === 32)) {\n    // convert key integer array into byte buffer\n    tmp = key;\n    key = forge.util.createBuffer();\n    for(var i = 0; i < tmp.length; ++i) {\n      key.putByte(tmp[i]);\n    }\n  }\n\n  // convert key byte buffer into 32-bit integer array\n  if(!forge.util.isArray(key)) {\n    tmp = key;\n    key = [];\n\n    // key lengths of 16, 24, 32 bytes allowed\n    var len = tmp.length();\n    if(len === 16 || len === 24 || len === 32) {\n      len = len >>> 2;\n      for(var i = 0; i < len; ++i) {\n        key.push(tmp.getInt32());\n      }\n    }\n  }\n\n  // key must be an array of 32-bit integers by now\n  if(!forge.util.isArray(key) ||\n    !(key.length === 4 || key.length === 6 || key.length === 8)) {\n    throw new Error('Invalid key parameter.');\n  }\n\n  // encryption operation is always used for these modes\n  var mode = this.mode.name;\n  var encryptOp = (['CFB', 'OFB', 'CTR', 'GCM'].indexOf(mode) !== -1);\n\n  // do key expansion\n  this._w = _expandKey(key, options.decrypt && !encryptOp);\n  this._init = true;\n};\n\n/**\n * Expands a key. Typically only used for testing.\n *\n * @param key the symmetric key to expand, as an array of 32-bit words.\n * @param decrypt true to expand for decryption, false for encryption.\n *\n * @return the expanded key.\n */\nforge.aes._expandKey = function(key, decrypt) {\n  if(!init) {\n    initialize();\n  }\n  return _expandKey(key, decrypt);\n};\n\n/**\n * Updates a single block. Typically only used for testing.\n *\n * @param w the expanded key to use.\n * @param input an array of block-size 32-bit words.\n * @param output an array of block-size 32-bit words.\n * @param decrypt true to decrypt, false to encrypt.\n */\nforge.aes._updateBlock = _updateBlock;\n\n/** Register AES algorithms **/\n\nregisterAlgorithm('AES-ECB', forge.cipher.modes.ecb);\nregisterAlgorithm('AES-CBC', forge.cipher.modes.cbc);\nregisterAlgorithm('AES-CFB', forge.cipher.modes.cfb);\nregisterAlgorithm('AES-OFB', forge.cipher.modes.ofb);\nregisterAlgorithm('AES-CTR', forge.cipher.modes.ctr);\nregisterAlgorithm('AES-GCM', forge.cipher.modes.gcm);\n\nfunction registerAlgorithm(name, mode) {\n  var factory = function() {\n    return new forge.aes.Algorithm(name, mode);\n  };\n  forge.cipher.registerAlgorithm(name, factory);\n}\n\n/** AES implementation **/\n\nvar init = false; // not yet initialized\nvar Nb = 4;       // number of words comprising the state (AES = 4)\nvar sbox;         // non-linear substitution table used in key expansion\nvar isbox;        // inversion of sbox\nvar rcon;         // round constant word array\nvar mix;          // mix-columns table\nvar imix;         // inverse mix-columns table\n\n/**\n * Performs initialization, ie: precomputes tables to optimize for speed.\n *\n * One way to understand how AES works is to imagine that 'addition' and\n * 'multiplication' are interfaces that require certain mathematical\n * properties to hold true (ie: they are associative) but they might have\n * different implementations and produce different kinds of results ...\n * provided that their mathematical properties remain true. AES defines\n * its own methods of addition and multiplication but keeps some important\n * properties the same, ie: associativity and distributivity. The\n * explanation below tries to shed some light on how AES defines addition\n * and multiplication of bytes and 32-bit words in order to perform its\n * encryption and decryption algorithms.\n *\n * The basics:\n *\n * The AES algorithm views bytes as binary representations of polynomials\n * that have either 1 or 0 as the coefficients. It defines the addition\n * or subtraction of two bytes as the XOR operation. It also defines the\n * multiplication of two bytes as a finite field referred to as GF(2^8)\n * (Note: 'GF' means \"Galois Field\" which is a field that contains a finite\n * number of elements so GF(2^8) has 256 elements).\n *\n * This means that any two bytes can be represented as binary polynomials;\n * when they multiplied together and modularly reduced by an irreducible\n * polynomial of the 8th degree, the results are the field GF(2^8). The\n * specific irreducible polynomial that AES uses in hexadecimal is 0x11b.\n * This multiplication is associative with 0x01 as the identity:\n *\n * (b * 0x01 = GF(b, 0x01) = b).\n *\n * The operation GF(b, 0x02) can be performed at the byte level by left\n * shifting b once and then XOR'ing it (to perform the modular reduction)\n * with 0x11b if b is >= 128. Repeated application of the multiplication\n * of 0x02 can be used to implement the multiplication of any two bytes.\n *\n * For instance, multiplying 0x57 and 0x13, denoted as GF(0x57, 0x13), can\n * be performed by factoring 0x13 into 0x01, 0x02, and 0x10. Then these\n * factors can each be multiplied by 0x57 and then added together. To do\n * the multiplication, values for 0x57 multiplied by each of these 3 factors\n * can be precomputed and stored in a table. To add them, the values from\n * the table are XOR'd together.\n *\n * AES also defines addition and multiplication of words, that is 4-byte\n * numbers represented as polynomials of 3 degrees where the coefficients\n * are the values of the bytes.\n *\n * The word [a0, a1, a2, a3] is a polynomial a3x^3 + a2x^2 + a1x + a0.\n *\n * Addition is performed by XOR'ing like powers of x. Multiplication\n * is performed in two steps, the first is an algebriac expansion as\n * you would do normally (where addition is XOR). But the result is\n * a polynomial larger than 3 degrees and thus it cannot fit in a word. So\n * next the result is modularly reduced by an AES-specific polynomial of\n * degree 4 which will always produce a polynomial of less than 4 degrees\n * such that it will fit in a word. In AES, this polynomial is x^4 + 1.\n *\n * The modular product of two polynomials 'a' and 'b' is thus:\n *\n * d(x) = d3x^3 + d2x^2 + d1x + d0\n * with\n * d0 = GF(a0, b0) ^ GF(a3, b1) ^ GF(a2, b2) ^ GF(a1, b3)\n * d1 = GF(a1, b0) ^ GF(a0, b1) ^ GF(a3, b2) ^ GF(a2, b3)\n * d2 = GF(a2, b0) ^ GF(a1, b1) ^ GF(a0, b2) ^ GF(a3, b3)\n * d3 = GF(a3, b0) ^ GF(a2, b1) ^ GF(a1, b2) ^ GF(a0, b3)\n *\n * As a matrix:\n *\n * [d0] = [a0 a3 a2 a1][b0]\n * [d1]   [a1 a0 a3 a2][b1]\n * [d2]   [a2 a1 a0 a3][b2]\n * [d3]   [a3 a2 a1 a0][b3]\n *\n * Special polynomials defined by AES (0x02 == {02}):\n * a(x)    = {03}x^3 + {01}x^2 + {01}x + {02}\n * a^-1(x) = {0b}x^3 + {0d}x^2 + {09}x + {0e}.\n *\n * These polynomials are used in the MixColumns() and InverseMixColumns()\n * operations, respectively, to cause each element in the state to affect\n * the output (referred to as diffusing).\n *\n * RotWord() uses: a0 = a1 = a2 = {00} and a3 = {01}, which is the\n * polynomial x3.\n *\n * The ShiftRows() method modifies the last 3 rows in the state (where\n * the state is 4 words with 4 bytes per word) by shifting bytes cyclically.\n * The 1st byte in the second row is moved to the end of the row. The 1st\n * and 2nd bytes in the third row are moved to the end of the row. The 1st,\n * 2nd, and 3rd bytes are moved in the fourth row.\n *\n * More details on how AES arithmetic works:\n *\n * In the polynomial representation of binary numbers, XOR performs addition\n * and subtraction and multiplication in GF(2^8) denoted as GF(a, b)\n * corresponds with the multiplication of polynomials modulo an irreducible\n * polynomial of degree 8. In other words, for AES, GF(a, b) will multiply\n * polynomial 'a' with polynomial 'b' and then do a modular reduction by\n * an AES-specific irreducible polynomial of degree 8.\n *\n * A polynomial is irreducible if its only divisors are one and itself. For\n * the AES algorithm, this irreducible polynomial is:\n *\n * m(x) = x^8 + x^4 + x^3 + x + 1,\n *\n * or {01}{1b} in hexadecimal notation, where each coefficient is a bit:\n * 100011011 = 283 = 0x11b.\n *\n * For example, GF(0x57, 0x83) = 0xc1 because\n *\n * 0x57 = 87  = 01010111 = x^6 + x^4 + x^2 + x + 1\n * 0x85 = 131 = 10000101 = x^7 + x + 1\n *\n * (x^6 + x^4 + x^2 + x + 1) * (x^7 + x + 1)\n * =  x^13 + x^11 + x^9 + x^8 + x^7 +\n *    x^7 + x^5 + x^3 + x^2 + x +\n *    x^6 + x^4 + x^2 + x + 1\n * =  x^13 + x^11 + x^9 + x^8 + x^6 + x^5 + x^4 + x^3 + 1 = y\n *    y modulo (x^8 + x^4 + x^3 + x + 1)\n * =  x^7 + x^6 + 1.\n *\n * The modular reduction by m(x) guarantees the result will be a binary\n * polynomial of less than degree 8, so that it can fit in a byte.\n *\n * The operation to multiply a binary polynomial b with x (the polynomial\n * x in binary representation is 00000010) is:\n *\n * b_7x^8 + b_6x^7 + b_5x^6 + b_4x^5 + b_3x^4 + b_2x^3 + b_1x^2 + b_0x^1\n *\n * To get GF(b, x) we must reduce that by m(x). If b_7 is 0 (that is the\n * most significant bit is 0 in b) then the result is already reduced. If\n * it is 1, then we can reduce it by subtracting m(x) via an XOR.\n *\n * It follows that multiplication by x (00000010 or 0x02) can be implemented\n * by performing a left shift followed by a conditional bitwise XOR with\n * 0x1b. This operation on bytes is denoted by xtime(). Multiplication by\n * higher powers of x can be implemented by repeated application of xtime().\n *\n * By adding intermediate results, multiplication by any constant can be\n * implemented. For instance:\n *\n * GF(0x57, 0x13) = 0xfe because:\n *\n * xtime(b) = (b & 128) ? (b << 1 ^ 0x11b) : (b << 1)\n *\n * Note: We XOR with 0x11b instead of 0x1b because in javascript our\n * datatype for b can be larger than 1 byte, so a left shift will not\n * automatically eliminate bits that overflow a byte ... by XOR'ing the\n * overflow bit with 1 (the extra one from 0x11b) we zero it out.\n *\n * GF(0x57, 0x02) = xtime(0x57) = 0xae\n * GF(0x57, 0x04) = xtime(0xae) = 0x47\n * GF(0x57, 0x08) = xtime(0x47) = 0x8e\n * GF(0x57, 0x10) = xtime(0x8e) = 0x07\n *\n * GF(0x57, 0x13) = GF(0x57, (0x01 ^ 0x02 ^ 0x10))\n *\n * And by the distributive property (since XOR is addition and GF() is\n * multiplication):\n *\n * = GF(0x57, 0x01) ^ GF(0x57, 0x02) ^ GF(0x57, 0x10)\n * = 0x57 ^ 0xae ^ 0x07\n * = 0xfe.\n */\nfunction initialize() {\n  init = true;\n\n  /* Populate the Rcon table. These are the values given by\n    [x^(i-1),{00},{00},{00}] where x^(i-1) are powers of x (and x = 0x02)\n    in the field of GF(2^8), where i starts at 1.\n\n    rcon[0] = [0x00, 0x00, 0x00, 0x00]\n    rcon[1] = [0x01, 0x00, 0x00, 0x00] 2^(1-1) = 2^0 = 1\n    rcon[2] = [0x02, 0x00, 0x00, 0x00] 2^(2-1) = 2^1 = 2\n    ...\n    rcon[9]  = [0x1B, 0x00, 0x00, 0x00] 2^(9-1)  = 2^8 = 0x1B\n    rcon[10] = [0x36, 0x00, 0x00, 0x00] 2^(10-1) = 2^9 = 0x36\n\n    We only store the first byte because it is the only one used.\n  */\n  rcon = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1B, 0x36];\n\n  // compute xtime table which maps i onto GF(i, 0x02)\n  var xtime = new Array(256);\n  for(var i = 0; i < 128; ++i) {\n    xtime[i] = i << 1;\n    xtime[i + 128] = (i + 128) << 1 ^ 0x11B;\n  }\n\n  // compute all other tables\n  sbox = new Array(256);\n  isbox = new Array(256);\n  mix = new Array(4);\n  imix = new Array(4);\n  for(var i = 0; i < 4; ++i) {\n    mix[i] = new Array(256);\n    imix[i] = new Array(256);\n  }\n  var e = 0, ei = 0, e2, e4, e8, sx, sx2, me, ime;\n  for(var i = 0; i < 256; ++i) {\n    /* We need to generate the SubBytes() sbox and isbox tables so that\n      we can perform byte substitutions. This requires us to traverse\n      all of the elements in GF, find their multiplicative inverses,\n      and apply to each the following affine transformation:\n\n      bi' = bi ^ b(i + 4) mod 8 ^ b(i + 5) mod 8 ^ b(i + 6) mod 8 ^\n            b(i + 7) mod 8 ^ ci\n      for 0 <= i < 8, where bi is the ith bit of the byte, and ci is the\n      ith bit of a byte c with the value {63} or {01100011}.\n\n      It is possible to traverse every possible value in a Galois field\n      using what is referred to as a 'generator'. There are many\n      generators (128 out of 256): 3,5,6,9,11,82 to name a few. To fully\n      traverse GF we iterate 255 times, multiplying by our generator\n      each time.\n\n      On each iteration we can determine the multiplicative inverse for\n      the current element.\n\n      Suppose there is an element in GF 'e'. For a given generator 'g',\n      e = g^x. The multiplicative inverse of e is g^(255 - x). It turns\n      out that if use the inverse of a generator as another generator\n      it will produce all of the corresponding multiplicative inverses\n      at the same time. For this reason, we choose 5 as our inverse\n      generator because it only requires 2 multiplies and 1 add and its\n      inverse, 82, requires relatively few operations as well.\n\n      In order to apply the affine transformation, the multiplicative\n      inverse 'ei' of 'e' can be repeatedly XOR'd (4 times) with a\n      bit-cycling of 'ei'. To do this 'ei' is first stored in 's' and\n      'x'. Then 's' is left shifted and the high bit of 's' is made the\n      low bit. The resulting value is stored in 's'. Then 'x' is XOR'd\n      with 's' and stored in 'x'. On each subsequent iteration the same\n      operation is performed. When 4 iterations are complete, 'x' is\n      XOR'd with 'c' (0x63) and the transformed value is stored in 'x'.\n      For example:\n\n      s = 01000001\n      x = 01000001\n\n      iteration 1: s = 10000010, x ^= s\n      iteration 2: s = 00000101, x ^= s\n      iteration 3: s = 00001010, x ^= s\n      iteration 4: s = 00010100, x ^= s\n      x ^= 0x63\n\n      This can be done with a loop where s = (s << 1) | (s >> 7). However,\n      it can also be done by using a single 16-bit (in this case 32-bit)\n      number 'sx'. Since XOR is an associative operation, we can set 'sx'\n      to 'ei' and then XOR it with 'sx' left-shifted 1,2,3, and 4 times.\n      The most significant bits will flow into the high 8 bit positions\n      and be correctly XOR'd with one another. All that remains will be\n      to cycle the high 8 bits by XOR'ing them all with the lower 8 bits\n      afterwards.\n\n      At the same time we're populating sbox and isbox we can precompute\n      the multiplication we'll need to do to do MixColumns() later.\n    */\n\n    // apply affine transformation\n    sx = ei ^ (ei << 1) ^ (ei << 2) ^ (ei << 3) ^ (ei << 4);\n    sx = (sx >> 8) ^ (sx & 255) ^ 0x63;\n\n    // update tables\n    sbox[e] = sx;\n    isbox[sx] = e;\n\n    /* Mixing columns is done using matrix multiplication. The columns\n      that are to be mixed are each a single word in the current state.\n      The state has Nb columns (4 columns). Therefore each column is a\n      4 byte word. So to mix the columns in a single column 'c' where\n      its rows are r0, r1, r2, and r3, we use the following matrix\n      multiplication:\n\n      [2 3 1 1]*[r0,c]=[r'0,c]\n      [1 2 3 1] [r1,c] [r'1,c]\n      [1 1 2 3] [r2,c] [r'2,c]\n      [3 1 1 2] [r3,c] [r'3,c]\n\n      r0, r1, r2, and r3 are each 1 byte of one of the words in the\n      state (a column). To do matrix multiplication for each mixed\n      column c' we multiply the corresponding row from the left matrix\n      with the corresponding column from the right matrix. In total, we\n      get 4 equations:\n\n      r0,c' = 2*r0,c + 3*r1,c + 1*r2,c + 1*r3,c\n      r1,c' = 1*r0,c + 2*r1,c + 3*r2,c + 1*r3,c\n      r2,c' = 1*r0,c + 1*r1,c + 2*r2,c + 3*r3,c\n      r3,c' = 3*r0,c + 1*r1,c + 1*r2,c + 2*r3,c\n\n      As usual, the multiplication is as previously defined and the\n      addition is XOR. In order to optimize mixing columns we can store\n      the multiplication results in tables. If you think of the whole\n      column as a word (it might help to visualize by mentally rotating\n      the equations above by counterclockwise 90 degrees) then you can\n      see that it would be useful to map the multiplications performed on\n      each byte (r0, r1, r2, r3) onto a word as well. For instance, we\n      could map 2*r0,1*r0,1*r0,3*r0 onto a word by storing 2*r0 in the\n      highest 8 bits and 3*r0 in the lowest 8 bits (with the other two\n      respectively in the middle). This means that a table can be\n      constructed that uses r0 as an index to the word. We can do the\n      same with r1, r2, and r3, creating a total of 4 tables.\n\n      To construct a full c', we can just look up each byte of c in\n      their respective tables and XOR the results together.\n\n      Also, to build each table we only have to calculate the word\n      for 2,1,1,3 for every byte ... which we can do on each iteration\n      of this loop since we will iterate over every byte. After we have\n      calculated 2,1,1,3 we can get the results for the other tables\n      by cycling the byte at the end to the beginning. For instance\n      we can take the result of table 2,1,1,3 and produce table 3,2,1,1\n      by moving the right most byte to the left most position just like\n      how you can imagine the 3 moved out of 2,1,1,3 and to the front\n      to produce 3,2,1,1.\n\n      There is another optimization in that the same multiples of\n      the current element we need in order to advance our generator\n      to the next iteration can be reused in performing the 2,1,1,3\n      calculation. We also calculate the inverse mix column tables,\n      with e,9,d,b being the inverse of 2,1,1,3.\n\n      When we're done, and we need to actually mix columns, the first\n      byte of each state word should be put through mix[0] (2,1,1,3),\n      the second through mix[1] (3,2,1,1) and so forth. Then they should\n      be XOR'd together to produce the fully mixed column.\n    */\n\n    // calculate mix and imix table values\n    sx2 = xtime[sx];\n    e2 = xtime[e];\n    e4 = xtime[e2];\n    e8 = xtime[e4];\n    me =\n      (sx2 << 24) ^  // 2\n      (sx << 16) ^   // 1\n      (sx << 8) ^    // 1\n      (sx ^ sx2);    // 3\n    ime =\n      (e2 ^ e4 ^ e8) << 24 ^  // E (14)\n      (e ^ e8) << 16 ^        // 9\n      (e ^ e4 ^ e8) << 8 ^    // D (13)\n      (e ^ e2 ^ e8);          // B (11)\n    // produce each of the mix tables by rotating the 2,1,1,3 value\n    for(var n = 0; n < 4; ++n) {\n      mix[n][e] = me;\n      imix[n][sx] = ime;\n      // cycle the right most byte to the left most position\n      // ie: 2,1,1,3 becomes 3,2,1,1\n      me = me << 24 | me >>> 8;\n      ime = ime << 24 | ime >>> 8;\n    }\n\n    // get next element and inverse\n    if(e === 0) {\n      // 1 is the inverse of 1\n      e = ei = 1;\n    } else {\n      // e = 2e + 2*2*2*(10e)) = multiply e by 82 (chosen generator)\n      // ei = ei + 2*2*ei = multiply ei by 5 (inverse generator)\n      e = e2 ^ xtime[xtime[xtime[e2 ^ e8]]];\n      ei ^= xtime[xtime[ei]];\n    }\n  }\n}\n\n/**\n * Generates a key schedule using the AES key expansion algorithm.\n *\n * The AES algorithm takes the Cipher Key, K, and performs a Key Expansion\n * routine to generate a key schedule. The Key Expansion generates a total\n * of Nb*(Nr + 1) words: the algorithm requires an initial set of Nb words,\n * and each of the Nr rounds requires Nb words of key data. The resulting\n * key schedule consists of a linear array of 4-byte words, denoted [wi ],\n * with i in the range 0 <= i < Nb(Nr + 1).\n *\n * KeyExpansion(byte key[4*Nk], word w[Nb*(Nr+1)], Nk)\n * AES-128 (Nb=4, Nk=4, Nr=10)\n * AES-192 (Nb=4, Nk=6, Nr=12)\n * AES-256 (Nb=4, Nk=8, Nr=14)\n * Note: Nr=Nk+6.\n *\n * Nb is the number of columns (32-bit words) comprising the State (or\n * number of bytes in a block). For AES, Nb=4.\n *\n * @param key the key to schedule (as an array of 32-bit words).\n * @param decrypt true to modify the key schedule to decrypt, false not to.\n *\n * @return the generated key schedule.\n */\nfunction _expandKey(key, decrypt) {\n  // copy the key's words to initialize the key schedule\n  var w = key.slice(0);\n\n  /* RotWord() will rotate a word, moving the first byte to the last\n    byte's position (shifting the other bytes left).\n\n    We will be getting the value of Rcon at i / Nk. 'i' will iterate\n    from Nk to (Nb * Nr+1). Nk = 4 (4 byte key), Nb = 4 (4 words in\n    a block), Nr = Nk + 6 (10). Therefore 'i' will iterate from\n    4 to 44 (exclusive). Each time we iterate 4 times, i / Nk will\n    increase by 1. We use a counter iNk to keep track of this.\n   */\n\n  // go through the rounds expanding the key\n  var temp, iNk = 1;\n  var Nk = w.length;\n  var Nr1 = Nk + 6 + 1;\n  var end = Nb * Nr1;\n  for(var i = Nk; i < end; ++i) {\n    temp = w[i - 1];\n    if(i % Nk === 0) {\n      // temp = SubWord(RotWord(temp)) ^ Rcon[i / Nk]\n      temp =\n        sbox[temp >>> 16 & 255] << 24 ^\n        sbox[temp >>> 8 & 255] << 16 ^\n        sbox[temp & 255] << 8 ^\n        sbox[temp >>> 24] ^ (rcon[iNk] << 24);\n      iNk++;\n    } else if(Nk > 6 && (i % Nk === 4)) {\n      // temp = SubWord(temp)\n      temp =\n        sbox[temp >>> 24] << 24 ^\n        sbox[temp >>> 16 & 255] << 16 ^\n        sbox[temp >>> 8 & 255] << 8 ^\n        sbox[temp & 255];\n    }\n    w[i] = w[i - Nk] ^ temp;\n  }\n\n  /* When we are updating a cipher block we always use the code path for\n     encryption whether we are decrypting or not (to shorten code and\n     simplify the generation of look up tables). However, because there\n     are differences in the decryption algorithm, other than just swapping\n     in different look up tables, we must transform our key schedule to\n     account for these changes:\n\n     1. The decryption algorithm gets its key rounds in reverse order.\n     2. The decryption algorithm adds the round key before mixing columns\n       instead of afterwards.\n\n     We don't need to modify our key schedule to handle the first case,\n     we can just traverse the key schedule in reverse order when decrypting.\n\n     The second case requires a little work.\n\n     The tables we built for performing rounds will take an input and then\n     perform SubBytes() and MixColumns() or, for the decrypt version,\n     InvSubBytes() and InvMixColumns(). But the decrypt algorithm requires\n     us to AddRoundKey() before InvMixColumns(). This means we'll need to\n     apply some transformations to the round key to inverse-mix its columns\n     so they'll be correct for moving AddRoundKey() to after the state has\n     had its columns inverse-mixed.\n\n     To inverse-mix the columns of the state when we're decrypting we use a\n     lookup table that will apply InvSubBytes() and InvMixColumns() at the\n     same time. However, the round key's bytes are not inverse-substituted\n     in the decryption algorithm. To get around this problem, we can first\n     substitute the bytes in the round key so that when we apply the\n     transformation via the InvSubBytes()+InvMixColumns() table, it will\n     undo our substitution leaving us with the original value that we\n     want -- and then inverse-mix that value.\n\n     This change will correctly alter our key schedule so that we can XOR\n     each round key with our already transformed decryption state. This\n     allows us to use the same code path as the encryption algorithm.\n\n     We make one more change to the decryption key. Since the decryption\n     algorithm runs in reverse from the encryption algorithm, we reverse\n     the order of the round keys to avoid having to iterate over the key\n     schedule backwards when running the encryption algorithm later in\n     decryption mode. In addition to reversing the order of the round keys,\n     we also swap each round key's 2nd and 4th rows. See the comments\n     section where rounds are performed for more details about why this is\n     done. These changes are done inline with the other substitution\n     described above.\n  */\n  if(decrypt) {\n    var tmp;\n    var m0 = imix[0];\n    var m1 = imix[1];\n    var m2 = imix[2];\n    var m3 = imix[3];\n    var wnew = w.slice(0);\n    end = w.length;\n    for(var i = 0, wi = end - Nb; i < end; i += Nb, wi -= Nb) {\n      // do not sub the first or last round key (round keys are Nb\n      // words) as no column mixing is performed before they are added,\n      // but do change the key order\n      if(i === 0 || i === (end - Nb)) {\n        wnew[i] = w[wi];\n        wnew[i + 1] = w[wi + 3];\n        wnew[i + 2] = w[wi + 2];\n        wnew[i + 3] = w[wi + 1];\n      } else {\n        // substitute each round key byte because the inverse-mix\n        // table will inverse-substitute it (effectively cancel the\n        // substitution because round key bytes aren't sub'd in\n        // decryption mode) and swap indexes 3 and 1\n        for(var n = 0; n < Nb; ++n) {\n          tmp = w[wi + n];\n          wnew[i + (3&-n)] =\n            m0[sbox[tmp >>> 24]] ^\n            m1[sbox[tmp >>> 16 & 255]] ^\n            m2[sbox[tmp >>> 8 & 255]] ^\n            m3[sbox[tmp & 255]];\n        }\n      }\n    }\n    w = wnew;\n  }\n\n  return w;\n}\n\n/**\n * Updates a single block (16 bytes) using AES. The update will either\n * encrypt or decrypt the block.\n *\n * @param w the key schedule.\n * @param input the input block (an array of 32-bit words).\n * @param output the updated output block.\n * @param decrypt true to decrypt the block, false to encrypt it.\n */\nfunction _updateBlock(w, input, output, decrypt) {\n  /*\n  Cipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])\n  begin\n    byte state[4,Nb]\n    state = in\n    AddRoundKey(state, w[0, Nb-1])\n    for round = 1 step 1 to Nr-1\n      SubBytes(state)\n      ShiftRows(state)\n      MixColumns(state)\n      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])\n    end for\n    SubBytes(state)\n    ShiftRows(state)\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n    out = state\n  end\n\n  InvCipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])\n  begin\n    byte state[4,Nb]\n    state = in\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n    for round = Nr-1 step -1 downto 1\n      InvShiftRows(state)\n      InvSubBytes(state)\n      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])\n      InvMixColumns(state)\n    end for\n    InvShiftRows(state)\n    InvSubBytes(state)\n    AddRoundKey(state, w[0, Nb-1])\n    out = state\n  end\n  */\n\n  // Encrypt: AddRoundKey(state, w[0, Nb-1])\n  // Decrypt: AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n  var Nr = w.length / 4 - 1;\n  var m0, m1, m2, m3, sub;\n  if(decrypt) {\n    m0 = imix[0];\n    m1 = imix[1];\n    m2 = imix[2];\n    m3 = imix[3];\n    sub = isbox;\n  } else {\n    m0 = mix[0];\n    m1 = mix[1];\n    m2 = mix[2];\n    m3 = mix[3];\n    sub = sbox;\n  }\n  var a, b, c, d, a2, b2, c2;\n  a = input[0] ^ w[0];\n  b = input[decrypt ? 3 : 1] ^ w[1];\n  c = input[2] ^ w[2];\n  d = input[decrypt ? 1 : 3] ^ w[3];\n  var i = 3;\n\n  /* In order to share code we follow the encryption algorithm when both\n    encrypting and decrypting. To account for the changes required in the\n    decryption algorithm, we use different lookup tables when decrypting\n    and use a modified key schedule to account for the difference in the\n    order of transformations applied when performing rounds. We also get\n    key rounds in reverse order (relative to encryption). */\n  for(var round = 1; round < Nr; ++round) {\n    /* As described above, we'll be using table lookups to perform the\n      column mixing. Each column is stored as a word in the state (the\n      array 'input' has one column as a word at each index). In order to\n      mix a column, we perform these transformations on each row in c,\n      which is 1 byte in each word. The new column for c0 is c'0:\n\n               m0      m1      m2      m3\n      r0,c'0 = 2*r0,c0 + 3*r1,c0 + 1*r2,c0 + 1*r3,c0\n      r1,c'0 = 1*r0,c0 + 2*r1,c0 + 3*r2,c0 + 1*r3,c0\n      r2,c'0 = 1*r0,c0 + 1*r1,c0 + 2*r2,c0 + 3*r3,c0\n      r3,c'0 = 3*r0,c0 + 1*r1,c0 + 1*r2,c0 + 2*r3,c0\n\n      So using mix tables where c0 is a word with r0 being its upper\n      8 bits and r3 being its lower 8 bits:\n\n      m0[c0 >> 24] will yield this word: [2*r0,1*r0,1*r0,3*r0]\n      ...\n      m3[c0 & 255] will yield this word: [1*r3,1*r3,3*r3,2*r3]\n\n      Therefore to mix the columns in each word in the state we\n      do the following (& 255 omitted for brevity):\n      c'0,r0 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r1 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r2 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n      c'0,r3 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]\n\n      However, before mixing, the algorithm requires us to perform\n      ShiftRows(). The ShiftRows() transformation cyclically shifts the\n      last 3 rows of the state over different offsets. The first row\n      (r = 0) is not shifted.\n\n      s'_r,c = s_r,(c + shift(r, Nb) mod Nb\n      for 0 < r < 4 and 0 <= c < Nb and\n      shift(1, 4) = 1\n      shift(2, 4) = 2\n      shift(3, 4) = 3.\n\n      This causes the first byte in r = 1 to be moved to the end of\n      the row, the first 2 bytes in r = 2 to be moved to the end of\n      the row, the first 3 bytes in r = 3 to be moved to the end of\n      the row:\n\n      r1: [c0 c1 c2 c3] => [c1 c2 c3 c0]\n      r2: [c0 c1 c2 c3]    [c2 c3 c0 c1]\n      r3: [c0 c1 c2 c3]    [c3 c0 c1 c2]\n\n      We can make these substitutions inline with our column mixing to\n      generate an updated set of equations to produce each word in the\n      state (note the columns have changed positions):\n\n      c0 c1 c2 c3 => c0 c1 c2 c3\n      c0 c1 c2 c3    c1 c2 c3 c0  (cycled 1 byte)\n      c0 c1 c2 c3    c2 c3 c0 c1  (cycled 2 bytes)\n      c0 c1 c2 c3    c3 c0 c1 c2  (cycled 3 bytes)\n\n      Therefore:\n\n      c'0 = 2*r0,c0 + 3*r1,c1 + 1*r2,c2 + 1*r3,c3\n      c'0 = 1*r0,c0 + 2*r1,c1 + 3*r2,c2 + 1*r3,c3\n      c'0 = 1*r0,c0 + 1*r1,c1 + 2*r2,c2 + 3*r3,c3\n      c'0 = 3*r0,c0 + 1*r1,c1 + 1*r2,c2 + 2*r3,c3\n\n      c'1 = 2*r0,c1 + 3*r1,c2 + 1*r2,c3 + 1*r3,c0\n      c'1 = 1*r0,c1 + 2*r1,c2 + 3*r2,c3 + 1*r3,c0\n      c'1 = 1*r0,c1 + 1*r1,c2 + 2*r2,c3 + 3*r3,c0\n      c'1 = 3*r0,c1 + 1*r1,c2 + 1*r2,c3 + 2*r3,c0\n\n      ... and so forth for c'2 and c'3. The important distinction is\n      that the columns are cycling, with c0 being used with the m0\n      map when calculating c0, but c1 being used with the m0 map when\n      calculating c1 ... and so forth.\n\n      When performing the inverse we transform the mirror image and\n      skip the bottom row, instead of the top one, and move upwards:\n\n      c3 c2 c1 c0 => c0 c3 c2 c1  (cycled 3 bytes) *same as encryption\n      c3 c2 c1 c0    c1 c0 c3 c2  (cycled 2 bytes)\n      c3 c2 c1 c0    c2 c1 c0 c3  (cycled 1 byte)  *same as encryption\n      c3 c2 c1 c0    c3 c2 c1 c0\n\n      If you compare the resulting matrices for ShiftRows()+MixColumns()\n      and for InvShiftRows()+InvMixColumns() the 2nd and 4th columns are\n      different (in encrypt mode vs. decrypt mode). So in order to use\n      the same code to handle both encryption and decryption, we will\n      need to do some mapping.\n\n      If in encryption mode we let a=c0, b=c1, c=c2, d=c3, and r<N> be\n      a row number in the state, then the resulting matrix in encryption\n      mode for applying the above transformations would be:\n\n      r1: a b c d\n      r2: b c d a\n      r3: c d a b\n      r4: d a b c\n\n      If we did the same in decryption mode we would get:\n\n      r1: a d c b\n      r2: b a d c\n      r3: c b a d\n      r4: d c b a\n\n      If instead we swap d and b (set b=c3 and d=c1), then we get:\n\n      r1: a b c d\n      r2: d a b c\n      r3: c d a b\n      r4: b c d a\n\n      Now the 1st and 3rd rows are the same as the encryption matrix. All\n      we need to do then to make the mapping exactly the same is to swap\n      the 2nd and 4th rows when in decryption mode. To do this without\n      having to do it on each iteration, we swapped the 2nd and 4th rows\n      in the decryption key schedule. We also have to do the swap above\n      when we first pull in the input and when we set the final output. */\n    a2 =\n      m0[a >>> 24] ^\n      m1[b >>> 16 & 255] ^\n      m2[c >>> 8 & 255] ^\n      m3[d & 255] ^ w[++i];\n    b2 =\n      m0[b >>> 24] ^\n      m1[c >>> 16 & 255] ^\n      m2[d >>> 8 & 255] ^\n      m3[a & 255] ^ w[++i];\n    c2 =\n      m0[c >>> 24] ^\n      m1[d >>> 16 & 255] ^\n      m2[a >>> 8 & 255] ^\n      m3[b & 255] ^ w[++i];\n    d =\n      m0[d >>> 24] ^\n      m1[a >>> 16 & 255] ^\n      m2[b >>> 8 & 255] ^\n      m3[c & 255] ^ w[++i];\n    a = a2;\n    b = b2;\n    c = c2;\n  }\n\n  /*\n    Encrypt:\n    SubBytes(state)\n    ShiftRows(state)\n    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])\n\n    Decrypt:\n    InvShiftRows(state)\n    InvSubBytes(state)\n    AddRoundKey(state, w[0, Nb-1])\n   */\n  // Note: rows are shifted inline\n  output[0] =\n    (sub[a >>> 24] << 24) ^\n    (sub[b >>> 16 & 255] << 16) ^\n    (sub[c >>> 8 & 255] << 8) ^\n    (sub[d & 255]) ^ w[++i];\n  output[decrypt ? 3 : 1] =\n    (sub[b >>> 24] << 24) ^\n    (sub[c >>> 16 & 255] << 16) ^\n    (sub[d >>> 8 & 255] << 8) ^\n    (sub[a & 255]) ^ w[++i];\n  output[2] =\n    (sub[c >>> 24] << 24) ^\n    (sub[d >>> 16 & 255] << 16) ^\n    (sub[a >>> 8 & 255] << 8) ^\n    (sub[b & 255]) ^ w[++i];\n  output[decrypt ? 1 : 3] =\n    (sub[d >>> 24] << 24) ^\n    (sub[a >>> 16 & 255] << 16) ^\n    (sub[b >>> 8 & 255] << 8) ^\n    (sub[c & 255]) ^ w[++i];\n}\n\n/**\n * Deprecated. Instead, use:\n *\n * forge.cipher.createCipher('AES-<mode>', key);\n * forge.cipher.createDecipher('AES-<mode>', key);\n *\n * Creates a deprecated AES cipher object. This object's mode will default to\n * CBC (cipher-block-chaining).\n *\n * The key and iv may be given as a string of bytes, an array of bytes, a\n * byte buffer, or an array of 32-bit words.\n *\n * @param options the options to use.\n *          key the symmetric key to use.\n *          output the buffer to write to.\n *          decrypt true for decryption, false for encryption.\n *          mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nfunction _createCipher(options) {\n  options = options || {};\n  var mode = (options.mode || 'CBC').toUpperCase();\n  var algorithm = 'AES-' + mode;\n\n  var cipher;\n  if(options.decrypt) {\n    cipher = forge.cipher.createDecipher(algorithm, options.key);\n  } else {\n    cipher = forge.cipher.createCipher(algorithm, options.key);\n  }\n\n  // backwards compatible start API\n  var start = cipher.start;\n  cipher.start = function(iv, options) {\n    // backwards compatibility: support second arg as output buffer\n    var output = null;\n    if(options instanceof forge.util.ByteBuffer) {\n      output = options;\n      options = {};\n    }\n    options = options || {};\n    options.output = output;\n    options.iv = iv;\n    start.call(cipher, options);\n  };\n\n  return cipher;\n}\n","/**\n * Javascript implementation of Abstract Syntax Notation Number One.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2015 Digital Bazaar, Inc.\n *\n * An API for storing data using the Abstract Syntax Notation Number One\n * format using DER (Distinguished Encoding Rules) encoding. This encoding is\n * commonly used to store data for PKI, i.e. X.509 Certificates, and this\n * implementation exists for that purpose.\n *\n * Abstract Syntax Notation Number One (ASN.1) is used to define the abstract\n * syntax of information without restricting the way the information is encoded\n * for transmission. It provides a standard that allows for open systems\n * communication. ASN.1 defines the syntax of information data and a number of\n * simple data types as well as a notation for describing them and specifying\n * values for them.\n *\n * The RSA algorithm creates public and private keys that are often stored in\n * X.509 or PKCS#X formats -- which use ASN.1 (encoded in DER format). This\n * class provides the most basic functionality required to store and load DSA\n * keys that are encoded according to ASN.1.\n *\n * The most common binary encodings for ASN.1 are BER (Basic Encoding Rules)\n * and DER (Distinguished Encoding Rules). DER is just a subset of BER that\n * has stricter requirements for how data must be encoded.\n *\n * Each ASN.1 structure has a tag (a byte identifying the ASN.1 structure type)\n * and a byte array for the value of this ASN1 structure which may be data or a\n * list of ASN.1 structures.\n *\n * Each ASN.1 structure using BER is (Tag-Length-Value):\n *\n * | byte 0 | bytes X | bytes Y |\n * |--------|---------|----------\n * |  tag   | length  |  value  |\n *\n * ASN.1 allows for tags to be of \"High-tag-number form\" which allows a tag to\n * be two or more octets, but that is not supported by this class. A tag is\n * only 1 byte. Bits 1-5 give the tag number (ie the data type within a\n * particular 'class'), 6 indicates whether or not the ASN.1 value is\n * constructed from other ASN.1 values, and bits 7 and 8 give the 'class'. If\n * bits 7 and 8 are both zero, the class is UNIVERSAL. If only bit 7 is set,\n * then the class is APPLICATION. If only bit 8 is set, then the class is\n * CONTEXT_SPECIFIC. If both bits 7 and 8 are set, then the class is PRIVATE.\n * The tag numbers for the data types for the class UNIVERSAL are listed below:\n *\n * UNIVERSAL 0 Reserved for use by the encoding rules\n * UNIVERSAL 1 Boolean type\n * UNIVERSAL 2 Integer type\n * UNIVERSAL 3 Bitstring type\n * UNIVERSAL 4 Octetstring type\n * UNIVERSAL 5 Null type\n * UNIVERSAL 6 Object identifier type\n * UNIVERSAL 7 Object descriptor type\n * UNIVERSAL 8 External type and Instance-of type\n * UNIVERSAL 9 Real type\n * UNIVERSAL 10 Enumerated type\n * UNIVERSAL 11 Embedded-pdv type\n * UNIVERSAL 12 UTF8String type\n * UNIVERSAL 13 Relative object identifier type\n * UNIVERSAL 14-15 Reserved for future editions\n * UNIVERSAL 16 Sequence and Sequence-of types\n * UNIVERSAL 17 Set and Set-of types\n * UNIVERSAL 18-22, 25-30 Character string types\n * UNIVERSAL 23-24 Time types\n *\n * The length of an ASN.1 structure is specified after the tag identifier.\n * There is a definite form and an indefinite form. The indefinite form may\n * be used if the encoding is constructed and not all immediately available.\n * The indefinite form is encoded using a length byte with only the 8th bit\n * set. The end of the constructed object is marked using end-of-contents\n * octets (two zero bytes).\n *\n * The definite form looks like this:\n *\n * The length may take up 1 or more bytes, it depends on the length of the\n * value of the ASN.1 structure. DER encoding requires that if the ASN.1\n * structure has a value that has a length greater than 127, more than 1 byte\n * will be used to store its length, otherwise just one byte will be used.\n * This is strict.\n *\n * In the case that the length of the ASN.1 value is less than 127, 1 octet\n * (byte) is used to store the \"short form\" length. The 8th bit has a value of\n * 0 indicating the length is \"short form\" and not \"long form\" and bits 7-1\n * give the length of the data. (The 8th bit is the left-most, most significant\n * bit: also known as big endian or network format).\n *\n * In the case that the length of the ASN.1 value is greater than 127, 2 to\n * 127 octets (bytes) are used to store the \"long form\" length. The first\n * byte's 8th bit is set to 1 to indicate the length is \"long form.\" Bits 7-1\n * give the number of additional octets. All following octets are in base 256\n * with the most significant digit first (typical big-endian binary unsigned\n * integer storage). So, for instance, if the length of a value was 257, the\n * first byte would be set to:\n *\n * 10000010 = 130 = 0x82.\n *\n * This indicates there are 2 octets (base 256) for the length. The second and\n * third bytes (the octets just mentioned) would store the length in base 256:\n *\n * octet 2: 00000001 = 1 * 256^1 = 256\n * octet 3: 00000001 = 1 * 256^0 = 1\n * total = 257\n *\n * The algorithm for converting a js integer value of 257 to base-256 is:\n *\n * var value = 257;\n * var bytes = [];\n * bytes[0] = (value >>> 8) & 0xFF; // most significant byte first\n * bytes[1] = value & 0xFF;        // least significant byte last\n *\n * On the ASN.1 UNIVERSAL Object Identifier (OID) type:\n *\n * An OID can be written like: \"value1.value2.value3...valueN\"\n *\n * The DER encoding rules:\n *\n * The first byte has the value 40 * value1 + value2.\n * The following bytes, if any, encode the remaining values. Each value is\n * encoded in base 128, most significant digit first (big endian), with as\n * few digits as possible, and the most significant bit of each byte set\n * to 1 except the last in each value's encoding. For example: Given the\n * OID \"1.2.840.113549\", its DER encoding is (remember each byte except the\n * last one in each encoding is OR'd with 0x80):\n *\n * byte 1: 40 * 1 + 2 = 42 = 0x2A.\n * bytes 2-3: 128 * 6 + 72 = 840 = 6 72 = 6 72 = 0x0648 = 0x8648\n * bytes 4-6: 16384 * 6 + 128 * 119 + 13 = 6 119 13 = 0x06770D = 0x86F70D\n *\n * The final value is: 0x2A864886F70D.\n * The full OID (including ASN.1 tag and length of 6 bytes) is:\n * 0x06062A864886F70D\n */\nvar forge = require('./forge');\nrequire('./util');\nrequire('./oids');\n\n/* ASN.1 API */\nvar asn1 = module.exports = forge.asn1 = forge.asn1 || {};\n\n/**\n * ASN.1 classes.\n */\nasn1.Class = {\n  UNIVERSAL:        0x00,\n  APPLICATION:      0x40,\n  CONTEXT_SPECIFIC: 0x80,\n  PRIVATE:          0xC0\n};\n\n/**\n * ASN.1 types. Not all types are supported by this implementation, only\n * those necessary to implement a simple PKI are implemented.\n */\nasn1.Type = {\n  NONE:             0,\n  BOOLEAN:          1,\n  INTEGER:          2,\n  BITSTRING:        3,\n  OCTETSTRING:      4,\n  NULL:             5,\n  OID:              6,\n  ODESC:            7,\n  EXTERNAL:         8,\n  REAL:             9,\n  ENUMERATED:      10,\n  EMBEDDED:        11,\n  UTF8:            12,\n  ROID:            13,\n  SEQUENCE:        16,\n  SET:             17,\n  PRINTABLESTRING: 19,\n  IA5STRING:       22,\n  UTCTIME:         23,\n  GENERALIZEDTIME: 24,\n  BMPSTRING:       30\n};\n\n/**\n * Creates a new asn1 object.\n *\n * @param tagClass the tag class for the object.\n * @param type the data type (tag number) for the object.\n * @param constructed true if the asn1 object is in constructed form.\n * @param value the value for the object, if it is not constructed.\n * @param [options] the options to use:\n *          [bitStringContents] the plain BIT STRING content including padding\n *            byte.\n *\n * @return the asn1 object.\n */\nasn1.create = function(tagClass, type, constructed, value, options) {\n  /* An asn1 object has a tagClass, a type, a constructed flag, and a\n    value. The value's type depends on the constructed flag. If\n    constructed, it will contain a list of other asn1 objects. If not,\n    it will contain the ASN.1 value as an array of bytes formatted\n    according to the ASN.1 data type. */\n\n  // remove undefined values\n  if(forge.util.isArray(value)) {\n    var tmp = [];\n    for(var i = 0; i < value.length; ++i) {\n      if(value[i] !== undefined) {\n        tmp.push(value[i]);\n      }\n    }\n    value = tmp;\n  }\n\n  var obj = {\n    tagClass: tagClass,\n    type: type,\n    constructed: constructed,\n    composed: constructed || forge.util.isArray(value),\n    value: value\n  };\n  if(options && 'bitStringContents' in options) {\n    // TODO: copy byte buffer if it's a buffer not a string\n    obj.bitStringContents = options.bitStringContents;\n    // TODO: add readonly flag to avoid this overhead\n    // save copy to detect changes\n    obj.original = asn1.copy(obj);\n  }\n  return obj;\n};\n\n/**\n * Copies an asn1 object.\n *\n * @param obj the asn1 object.\n * @param [options] copy options:\n *          [excludeBitStringContents] true to not copy bitStringContents\n *\n * @return the a copy of the asn1 object.\n */\nasn1.copy = function(obj, options) {\n  var copy;\n\n  if(forge.util.isArray(obj)) {\n    copy = [];\n    for(var i = 0; i < obj.length; ++i) {\n      copy.push(asn1.copy(obj[i], options));\n    }\n    return copy;\n  }\n\n  if(typeof obj === 'string') {\n    // TODO: copy byte buffer if it's a buffer not a string\n    return obj;\n  }\n\n  copy = {\n    tagClass: obj.tagClass,\n    type: obj.type,\n    constructed: obj.constructed,\n    composed: obj.composed,\n    value: asn1.copy(obj.value, options)\n  };\n  if(options && !options.excludeBitStringContents) {\n    // TODO: copy byte buffer if it's a buffer not a string\n    copy.bitStringContents = obj.bitStringContents;\n  }\n  return copy;\n};\n\n/**\n * Compares asn1 objects for equality.\n *\n * Note this function does not run in constant time.\n *\n * @param obj1 the first asn1 object.\n * @param obj2 the second asn1 object.\n * @param [options] compare options:\n *          [includeBitStringContents] true to compare bitStringContents\n *\n * @return true if the asn1 objects are equal.\n */\nasn1.equals = function(obj1, obj2, options) {\n  if(forge.util.isArray(obj1)) {\n    if(!forge.util.isArray(obj2)) {\n      return false;\n    }\n    if(obj1.length !== obj2.length) {\n      return false;\n    }\n    for(var i = 0; i < obj1.length; ++i) {\n      if(!asn1.equals(obj1[i], obj2[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  if(typeof obj1 !== typeof obj2) {\n    return false;\n  }\n\n  if(typeof obj1 === 'string') {\n    return obj1 === obj2;\n  }\n\n  var equal = obj1.tagClass === obj2.tagClass &&\n    obj1.type === obj2.type &&\n    obj1.constructed === obj2.constructed &&\n    obj1.composed === obj2.composed &&\n    asn1.equals(obj1.value, obj2.value);\n  if(options && options.includeBitStringContents) {\n    equal = equal && (obj1.bitStringContents === obj2.bitStringContents);\n  }\n\n  return equal;\n};\n\n/**\n * Gets the length of a BER-encoded ASN.1 value.\n *\n * In case the length is not specified, undefined is returned.\n *\n * @param b the BER-encoded ASN.1 byte buffer, starting with the first\n *          length byte.\n *\n * @return the length of the BER-encoded ASN.1 value or undefined.\n */\nasn1.getBerValueLength = function(b) {\n  // TODO: move this function and related DER/BER functions to a der.js\n  // file; better abstract ASN.1 away from der/ber.\n  var b2 = b.getByte();\n  if(b2 === 0x80) {\n    return undefined;\n  }\n\n  // see if the length is \"short form\" or \"long form\" (bit 8 set)\n  var length;\n  var longForm = b2 & 0x80;\n  if(!longForm) {\n    // length is just the first byte\n    length = b2;\n  } else {\n    // the number of bytes the length is specified in bits 7 through 1\n    // and each length byte is in big-endian base-256\n    length = b.getInt((b2 & 0x7F) << 3);\n  }\n  return length;\n};\n\n/**\n * Check if the byte buffer has enough bytes. Throws an Error if not.\n *\n * @param bytes the byte buffer to parse from.\n * @param remaining the bytes remaining in the current parsing state.\n * @param n the number of bytes the buffer must have.\n */\nfunction _checkBufferLength(bytes, remaining, n) {\n  if(n > remaining) {\n    var error = new Error('Too few bytes to parse DER.');\n    error.available = bytes.length();\n    error.remaining = remaining;\n    error.requested = n;\n    throw error;\n  }\n}\n\n/**\n * Gets the length of a BER-encoded ASN.1 value.\n *\n * In case the length is not specified, undefined is returned.\n *\n * @param bytes the byte buffer to parse from.\n * @param remaining the bytes remaining in the current parsing state.\n *\n * @return the length of the BER-encoded ASN.1 value or undefined.\n */\nvar _getValueLength = function(bytes, remaining) {\n  // TODO: move this function and related DER/BER functions to a der.js\n  // file; better abstract ASN.1 away from der/ber.\n  // fromDer already checked that this byte exists\n  var b2 = bytes.getByte();\n  remaining--;\n  if(b2 === 0x80) {\n    return undefined;\n  }\n\n  // see if the length is \"short form\" or \"long form\" (bit 8 set)\n  var length;\n  var longForm = b2 & 0x80;\n  if(!longForm) {\n    // length is just the first byte\n    length = b2;\n  } else {\n    // the number of bytes the length is specified in bits 7 through 1\n    // and each length byte is in big-endian base-256\n    var longFormBytes = b2 & 0x7F;\n    _checkBufferLength(bytes, remaining, longFormBytes);\n    length = bytes.getInt(longFormBytes << 3);\n  }\n  // FIXME: this will only happen for 32 bit getInt with high bit set\n  if(length < 0) {\n    throw new Error('Negative length: ' + length);\n  }\n  return length;\n};\n\n/**\n * Parses an asn1 object from a byte buffer in DER format.\n *\n * @param bytes the byte buffer to parse from.\n * @param [strict] true to be strict when checking value lengths, false to\n *          allow truncated values (default: true).\n * @param [options] object with options or boolean strict flag\n *          [strict] true to be strict when checking value lengths, false to\n *            allow truncated values (default: true).\n *          [parseAllBytes] true to ensure all bytes are parsed\n *            (default: true)\n *          [decodeBitStrings] true to attempt to decode the content of\n *            BIT STRINGs (not OCTET STRINGs) using strict mode. Note that\n *            without schema support to understand the data context this can\n *            erroneously decode values that happen to be valid ASN.1. This\n *            flag will be deprecated or removed as soon as schema support is\n *            available. (default: true)\n *\n * @throws Will throw an error for various malformed input conditions.\n *\n * @return the parsed asn1 object.\n */\nasn1.fromDer = function(bytes, options) {\n  if(options === undefined) {\n    options = {\n      strict: true,\n      parseAllBytes: true,\n      decodeBitStrings: true\n    };\n  }\n  if(typeof options === 'boolean') {\n    options = {\n      strict: options,\n      parseAllBytes: true,\n      decodeBitStrings: true\n    };\n  }\n  if(!('strict' in options)) {\n    options.strict = true;\n  }\n  if(!('parseAllBytes' in options)) {\n    options.parseAllBytes = true;\n  }\n  if(!('decodeBitStrings' in options)) {\n    options.decodeBitStrings = true;\n  }\n\n  // wrap in buffer if needed\n  if(typeof bytes === 'string') {\n    bytes = forge.util.createBuffer(bytes);\n  }\n\n  var byteCount = bytes.length();\n  var value = _fromDer(bytes, bytes.length(), 0, options);\n  if(options.parseAllBytes && bytes.length() !== 0) {\n    var error = new Error('Unparsed DER bytes remain after ASN.1 parsing.');\n    error.byteCount = byteCount;\n    error.remaining = bytes.length();\n    throw error;\n  }\n  return value;\n};\n\n/**\n * Internal function to parse an asn1 object from a byte buffer in DER format.\n *\n * @param bytes the byte buffer to parse from.\n * @param remaining the number of bytes remaining for this chunk.\n * @param depth the current parsing depth.\n * @param options object with same options as fromDer().\n *\n * @return the parsed asn1 object.\n */\nfunction _fromDer(bytes, remaining, depth, options) {\n  // temporary storage for consumption calculations\n  var start;\n\n  // minimum length for ASN.1 DER structure is 2\n  _checkBufferLength(bytes, remaining, 2);\n\n  // get the first byte\n  var b1 = bytes.getByte();\n  // consumed one byte\n  remaining--;\n\n  // get the tag class\n  var tagClass = (b1 & 0xC0);\n\n  // get the type (bits 1-5)\n  var type = b1 & 0x1F;\n\n  // get the variable value length and adjust remaining bytes\n  start = bytes.length();\n  var length = _getValueLength(bytes, remaining);\n  remaining -= start - bytes.length();\n\n  // ensure there are enough bytes to get the value\n  if(length !== undefined && length > remaining) {\n    if(options.strict) {\n      var error = new Error('Too few bytes to read ASN.1 value.');\n      error.available = bytes.length();\n      error.remaining = remaining;\n      error.requested = length;\n      throw error;\n    }\n    // Note: be lenient with truncated values and use remaining state bytes\n    length = remaining;\n  }\n\n  // value storage\n  var value;\n  // possible BIT STRING contents storage\n  var bitStringContents;\n\n  // constructed flag is bit 6 (32 = 0x20) of the first byte\n  var constructed = ((b1 & 0x20) === 0x20);\n  if(constructed) {\n    // parse child asn1 objects from the value\n    value = [];\n    if(length === undefined) {\n      // asn1 object of indefinite length, read until end tag\n      for(;;) {\n        _checkBufferLength(bytes, remaining, 2);\n        if(bytes.bytes(2) === String.fromCharCode(0, 0)) {\n          bytes.getBytes(2);\n          remaining -= 2;\n          break;\n        }\n        start = bytes.length();\n        value.push(_fromDer(bytes, remaining, depth + 1, options));\n        remaining -= start - bytes.length();\n      }\n    } else {\n      // parsing asn1 object of definite length\n      while(length > 0) {\n        start = bytes.length();\n        value.push(_fromDer(bytes, length, depth + 1, options));\n        remaining -= start - bytes.length();\n        length -= start - bytes.length();\n      }\n    }\n  }\n\n  // if a BIT STRING, save the contents including padding\n  if(value === undefined && tagClass === asn1.Class.UNIVERSAL &&\n    type === asn1.Type.BITSTRING) {\n    bitStringContents = bytes.bytes(length);\n  }\n\n  // determine if a non-constructed value should be decoded as a composed\n  // value that contains other ASN.1 objects. BIT STRINGs (and OCTET STRINGs)\n  // can be used this way.\n  if(value === undefined && options.decodeBitStrings &&\n    tagClass === asn1.Class.UNIVERSAL &&\n    // FIXME: OCTET STRINGs not yet supported here\n    // .. other parts of forge expect to decode OCTET STRINGs manually\n    (type === asn1.Type.BITSTRING /*|| type === asn1.Type.OCTETSTRING*/) &&\n    length > 1) {\n    // save read position\n    var savedRead = bytes.read;\n    var savedRemaining = remaining;\n    var unused = 0;\n    if(type === asn1.Type.BITSTRING) {\n      /* The first octet gives the number of bits by which the length of the\n        bit string is less than the next multiple of eight (this is called\n        the \"number of unused bits\").\n\n        The second and following octets give the value of the bit string\n        converted to an octet string. */\n      _checkBufferLength(bytes, remaining, 1);\n      unused = bytes.getByte();\n      remaining--;\n    }\n    // if all bits are used, maybe the BIT/OCTET STRING holds ASN.1 objs\n    if(unused === 0) {\n      try {\n        // attempt to parse child asn1 object from the value\n        // (stored in array to signal composed value)\n        start = bytes.length();\n        var subOptions = {\n          // enforce strict mode to avoid parsing ASN.1 from plain data\n          strict: true,\n          decodeBitStrings: true\n        };\n        var composed = _fromDer(bytes, remaining, depth + 1, subOptions);\n        var used = start - bytes.length();\n        remaining -= used;\n        if(type == asn1.Type.BITSTRING) {\n          used++;\n        }\n\n        // if the data all decoded and the class indicates UNIVERSAL or\n        // CONTEXT_SPECIFIC then assume we've got an encapsulated ASN.1 object\n        var tc = composed.tagClass;\n        if(used === length &&\n          (tc === asn1.Class.UNIVERSAL || tc === asn1.Class.CONTEXT_SPECIFIC)) {\n          value = [composed];\n        }\n      } catch(ex) {\n      }\n    }\n    if(value === undefined) {\n      // restore read position\n      bytes.read = savedRead;\n      remaining = savedRemaining;\n    }\n  }\n\n  if(value === undefined) {\n    // asn1 not constructed or composed, get raw value\n    // TODO: do DER to OID conversion and vice-versa in .toDer?\n\n    if(length === undefined) {\n      if(options.strict) {\n        throw new Error('Non-constructed ASN.1 object of indefinite length.');\n      }\n      // be lenient and use remaining state bytes\n      length = remaining;\n    }\n\n    if(type === asn1.Type.BMPSTRING) {\n      value = '';\n      for(; length > 0; length -= 2) {\n        _checkBufferLength(bytes, remaining, 2);\n        value += String.fromCharCode(bytes.getInt16());\n        remaining -= 2;\n      }\n    } else {\n      value = bytes.getBytes(length);\n      remaining -= length;\n    }\n  }\n\n  // add BIT STRING contents if available\n  var asn1Options = bitStringContents === undefined ? null : {\n    bitStringContents: bitStringContents\n  };\n\n  // create and return asn1 object\n  return asn1.create(tagClass, type, constructed, value, asn1Options);\n}\n\n/**\n * Converts the given asn1 object to a buffer of bytes in DER format.\n *\n * @param asn1 the asn1 object to convert to bytes.\n *\n * @return the buffer of bytes.\n */\nasn1.toDer = function(obj) {\n  var bytes = forge.util.createBuffer();\n\n  // build the first byte\n  var b1 = obj.tagClass | obj.type;\n\n  // for storing the ASN.1 value\n  var value = forge.util.createBuffer();\n\n  // use BIT STRING contents if available and data not changed\n  var useBitStringContents = false;\n  if('bitStringContents' in obj) {\n    useBitStringContents = true;\n    if(obj.original) {\n      useBitStringContents = asn1.equals(obj, obj.original);\n    }\n  }\n\n  if(useBitStringContents) {\n    value.putBytes(obj.bitStringContents);\n  } else if(obj.composed) {\n    // if composed, use each child asn1 object's DER bytes as value\n    // turn on 6th bit (0x20 = 32) to indicate asn1 is constructed\n    // from other asn1 objects\n    if(obj.constructed) {\n      b1 |= 0x20;\n    } else {\n      // type is a bit string, add unused bits of 0x00\n      value.putByte(0x00);\n    }\n\n    // add all of the child DER bytes together\n    for(var i = 0; i < obj.value.length; ++i) {\n      if(obj.value[i] !== undefined) {\n        value.putBuffer(asn1.toDer(obj.value[i]));\n      }\n    }\n  } else {\n    // use asn1.value directly\n    if(obj.type === asn1.Type.BMPSTRING) {\n      for(var i = 0; i < obj.value.length; ++i) {\n        value.putInt16(obj.value.charCodeAt(i));\n      }\n    } else {\n      // ensure integer is minimally-encoded\n      // TODO: should all leading bytes be stripped vs just one?\n      // .. ex '00 00 01' => '01'?\n      if(obj.type === asn1.Type.INTEGER &&\n        obj.value.length > 1 &&\n        // leading 0x00 for positive integer\n        ((obj.value.charCodeAt(0) === 0 &&\n        (obj.value.charCodeAt(1) & 0x80) === 0) ||\n        // leading 0xFF for negative integer\n        (obj.value.charCodeAt(0) === 0xFF &&\n        (obj.value.charCodeAt(1) & 0x80) === 0x80))) {\n        value.putBytes(obj.value.substr(1));\n      } else {\n        value.putBytes(obj.value);\n      }\n    }\n  }\n\n  // add tag byte\n  bytes.putByte(b1);\n\n  // use \"short form\" encoding\n  if(value.length() <= 127) {\n    // one byte describes the length\n    // bit 8 = 0 and bits 7-1 = length\n    bytes.putByte(value.length() & 0x7F);\n  } else {\n    // use \"long form\" encoding\n    // 2 to 127 bytes describe the length\n    // first byte: bit 8 = 1 and bits 7-1 = # of additional bytes\n    // other bytes: length in base 256, big-endian\n    var len = value.length();\n    var lenBytes = '';\n    do {\n      lenBytes += String.fromCharCode(len & 0xFF);\n      len = len >>> 8;\n    } while(len > 0);\n\n    // set first byte to # bytes used to store the length and turn on\n    // bit 8 to indicate long-form length is used\n    bytes.putByte(lenBytes.length | 0x80);\n\n    // concatenate length bytes in reverse since they were generated\n    // little endian and we need big endian\n    for(var i = lenBytes.length - 1; i >= 0; --i) {\n      bytes.putByte(lenBytes.charCodeAt(i));\n    }\n  }\n\n  // concatenate value bytes\n  bytes.putBuffer(value);\n  return bytes;\n};\n\n/**\n * Converts an OID dot-separated string to a byte buffer. The byte buffer\n * contains only the DER-encoded value, not any tag or length bytes.\n *\n * @param oid the OID dot-separated string.\n *\n * @return the byte buffer.\n */\nasn1.oidToDer = function(oid) {\n  // split OID into individual values\n  var values = oid.split('.');\n  var bytes = forge.util.createBuffer();\n\n  // first byte is 40 * value1 + value2\n  bytes.putByte(40 * parseInt(values[0], 10) + parseInt(values[1], 10));\n  // other bytes are each value in base 128 with 8th bit set except for\n  // the last byte for each value\n  var last, valueBytes, value, b;\n  for(var i = 2; i < values.length; ++i) {\n    // produce value bytes in reverse because we don't know how many\n    // bytes it will take to store the value\n    last = true;\n    valueBytes = [];\n    value = parseInt(values[i], 10);\n    do {\n      b = value & 0x7F;\n      value = value >>> 7;\n      // if value is not last, then turn on 8th bit\n      if(!last) {\n        b |= 0x80;\n      }\n      valueBytes.push(b);\n      last = false;\n    } while(value > 0);\n\n    // add value bytes in reverse (needs to be in big endian)\n    for(var n = valueBytes.length - 1; n >= 0; --n) {\n      bytes.putByte(valueBytes[n]);\n    }\n  }\n\n  return bytes;\n};\n\n/**\n * Converts a DER-encoded byte buffer to an OID dot-separated string. The\n * byte buffer should contain only the DER-encoded value, not any tag or\n * length bytes.\n *\n * @param bytes the byte buffer.\n *\n * @return the OID dot-separated string.\n */\nasn1.derToOid = function(bytes) {\n  var oid;\n\n  // wrap in buffer if needed\n  if(typeof bytes === 'string') {\n    bytes = forge.util.createBuffer(bytes);\n  }\n\n  // first byte is 40 * value1 + value2\n  var b = bytes.getByte();\n  oid = Math.floor(b / 40) + '.' + (b % 40);\n\n  // other bytes are each value in base 128 with 8th bit set except for\n  // the last byte for each value\n  var value = 0;\n  while(bytes.length() > 0) {\n    b = bytes.getByte();\n    value = value << 7;\n    // not the last byte for the value\n    if(b & 0x80) {\n      value += b & 0x7F;\n    } else {\n      // last byte\n      oid += '.' + (value + b);\n      value = 0;\n    }\n  }\n\n  return oid;\n};\n\n/**\n * Converts a UTCTime value to a date.\n *\n * Note: GeneralizedTime has 4 digits for the year and is used for X.509\n * dates past 2049. Parsing that structure hasn't been implemented yet.\n *\n * @param utc the UTCTime value to convert.\n *\n * @return the date.\n */\nasn1.utcTimeToDate = function(utc) {\n  /* The following formats can be used:\n\n    YYMMDDhhmmZ\n    YYMMDDhhmm+hh'mm'\n    YYMMDDhhmm-hh'mm'\n    YYMMDDhhmmssZ\n    YYMMDDhhmmss+hh'mm'\n    YYMMDDhhmmss-hh'mm'\n\n    Where:\n\n    YY is the least significant two digits of the year\n    MM is the month (01 to 12)\n    DD is the day (01 to 31)\n    hh is the hour (00 to 23)\n    mm are the minutes (00 to 59)\n    ss are the seconds (00 to 59)\n    Z indicates that local time is GMT, + indicates that local time is\n    later than GMT, and - indicates that local time is earlier than GMT\n    hh' is the absolute value of the offset from GMT in hours\n    mm' is the absolute value of the offset from GMT in minutes */\n  var date = new Date();\n\n  // if YY >= 50 use 19xx, if YY < 50 use 20xx\n  var year = parseInt(utc.substr(0, 2), 10);\n  year = (year >= 50) ? 1900 + year : 2000 + year;\n  var MM = parseInt(utc.substr(2, 2), 10) - 1; // use 0-11 for month\n  var DD = parseInt(utc.substr(4, 2), 10);\n  var hh = parseInt(utc.substr(6, 2), 10);\n  var mm = parseInt(utc.substr(8, 2), 10);\n  var ss = 0;\n\n  // not just YYMMDDhhmmZ\n  if(utc.length > 11) {\n    // get character after minutes\n    var c = utc.charAt(10);\n    var end = 10;\n\n    // see if seconds are present\n    if(c !== '+' && c !== '-') {\n      // get seconds\n      ss = parseInt(utc.substr(10, 2), 10);\n      end += 2;\n    }\n  }\n\n  // update date\n  date.setUTCFullYear(year, MM, DD);\n  date.setUTCHours(hh, mm, ss, 0);\n\n  if(end) {\n    // get +/- after end of time\n    c = utc.charAt(end);\n    if(c === '+' || c === '-') {\n      // get hours+minutes offset\n      var hhoffset = parseInt(utc.substr(end + 1, 2), 10);\n      var mmoffset = parseInt(utc.substr(end + 4, 2), 10);\n\n      // calculate offset in milliseconds\n      var offset = hhoffset * 60 + mmoffset;\n      offset *= 60000;\n\n      // apply offset\n      if(c === '+') {\n        date.setTime(+date - offset);\n      } else {\n        date.setTime(+date + offset);\n      }\n    }\n  }\n\n  return date;\n};\n\n/**\n * Converts a GeneralizedTime value to a date.\n *\n * @param gentime the GeneralizedTime value to convert.\n *\n * @return the date.\n */\nasn1.generalizedTimeToDate = function(gentime) {\n  /* The following formats can be used:\n\n    YYYYMMDDHHMMSS\n    YYYYMMDDHHMMSS.fff\n    YYYYMMDDHHMMSSZ\n    YYYYMMDDHHMMSS.fffZ\n    YYYYMMDDHHMMSS+hh'mm'\n    YYYYMMDDHHMMSS.fff+hh'mm'\n    YYYYMMDDHHMMSS-hh'mm'\n    YYYYMMDDHHMMSS.fff-hh'mm'\n\n    Where:\n\n    YYYY is the year\n    MM is the month (01 to 12)\n    DD is the day (01 to 31)\n    hh is the hour (00 to 23)\n    mm are the minutes (00 to 59)\n    ss are the seconds (00 to 59)\n    .fff is the second fraction, accurate to three decimal places\n    Z indicates that local time is GMT, + indicates that local time is\n    later than GMT, and - indicates that local time is earlier than GMT\n    hh' is the absolute value of the offset from GMT in hours\n    mm' is the absolute value of the offset from GMT in minutes */\n  var date = new Date();\n\n  var YYYY = parseInt(gentime.substr(0, 4), 10);\n  var MM = parseInt(gentime.substr(4, 2), 10) - 1; // use 0-11 for month\n  var DD = parseInt(gentime.substr(6, 2), 10);\n  var hh = parseInt(gentime.substr(8, 2), 10);\n  var mm = parseInt(gentime.substr(10, 2), 10);\n  var ss = parseInt(gentime.substr(12, 2), 10);\n  var fff = 0;\n  var offset = 0;\n  var isUTC = false;\n\n  if(gentime.charAt(gentime.length - 1) === 'Z') {\n    isUTC = true;\n  }\n\n  var end = gentime.length - 5, c = gentime.charAt(end);\n  if(c === '+' || c === '-') {\n    // get hours+minutes offset\n    var hhoffset = parseInt(gentime.substr(end + 1, 2), 10);\n    var mmoffset = parseInt(gentime.substr(end + 4, 2), 10);\n\n    // calculate offset in milliseconds\n    offset = hhoffset * 60 + mmoffset;\n    offset *= 60000;\n\n    // apply offset\n    if(c === '+') {\n      offset *= -1;\n    }\n\n    isUTC = true;\n  }\n\n  // check for second fraction\n  if(gentime.charAt(14) === '.') {\n    fff = parseFloat(gentime.substr(14), 10) * 1000;\n  }\n\n  if(isUTC) {\n    date.setUTCFullYear(YYYY, MM, DD);\n    date.setUTCHours(hh, mm, ss, fff);\n\n    // apply offset\n    date.setTime(+date + offset);\n  } else {\n    date.setFullYear(YYYY, MM, DD);\n    date.setHours(hh, mm, ss, fff);\n  }\n\n  return date;\n};\n\n/**\n * Converts a date to a UTCTime value.\n *\n * Note: GeneralizedTime has 4 digits for the year and is used for X.509\n * dates past 2049. Converting to a GeneralizedTime hasn't been\n * implemented yet.\n *\n * @param date the date to convert.\n *\n * @return the UTCTime value.\n */\nasn1.dateToUtcTime = function(date) {\n  // TODO: validate; currently assumes proper format\n  if(typeof date === 'string') {\n    return date;\n  }\n\n  var rval = '';\n\n  // create format YYMMDDhhmmssZ\n  var format = [];\n  format.push(('' + date.getUTCFullYear()).substr(2));\n  format.push('' + (date.getUTCMonth() + 1));\n  format.push('' + date.getUTCDate());\n  format.push('' + date.getUTCHours());\n  format.push('' + date.getUTCMinutes());\n  format.push('' + date.getUTCSeconds());\n\n  // ensure 2 digits are used for each format entry\n  for(var i = 0; i < format.length; ++i) {\n    if(format[i].length < 2) {\n      rval += '0';\n    }\n    rval += format[i];\n  }\n  rval += 'Z';\n\n  return rval;\n};\n\n/**\n * Converts a date to a GeneralizedTime value.\n *\n * @param date the date to convert.\n *\n * @return the GeneralizedTime value as a string.\n */\nasn1.dateToGeneralizedTime = function(date) {\n  // TODO: validate; currently assumes proper format\n  if(typeof date === 'string') {\n    return date;\n  }\n\n  var rval = '';\n\n  // create format YYYYMMDDHHMMSSZ\n  var format = [];\n  format.push('' + date.getUTCFullYear());\n  format.push('' + (date.getUTCMonth() + 1));\n  format.push('' + date.getUTCDate());\n  format.push('' + date.getUTCHours());\n  format.push('' + date.getUTCMinutes());\n  format.push('' + date.getUTCSeconds());\n\n  // ensure 2 digits are used for each format entry\n  for(var i = 0; i < format.length; ++i) {\n    if(format[i].length < 2) {\n      rval += '0';\n    }\n    rval += format[i];\n  }\n  rval += 'Z';\n\n  return rval;\n};\n\n/**\n * Converts a javascript integer to a DER-encoded byte buffer to be used\n * as the value for an INTEGER type.\n *\n * @param x the integer.\n *\n * @return the byte buffer.\n */\nasn1.integerToDer = function(x) {\n  var rval = forge.util.createBuffer();\n  if(x >= -0x80 && x < 0x80) {\n    return rval.putSignedInt(x, 8);\n  }\n  if(x >= -0x8000 && x < 0x8000) {\n    return rval.putSignedInt(x, 16);\n  }\n  if(x >= -0x800000 && x < 0x800000) {\n    return rval.putSignedInt(x, 24);\n  }\n  if(x >= -0x80000000 && x < 0x80000000) {\n    return rval.putSignedInt(x, 32);\n  }\n  var error = new Error('Integer too large; max is 32-bits.');\n  error.integer = x;\n  throw error;\n};\n\n/**\n * Converts a DER-encoded byte buffer to a javascript integer. This is\n * typically used to decode the value of an INTEGER type.\n *\n * @param bytes the byte buffer.\n *\n * @return the integer.\n */\nasn1.derToInteger = function(bytes) {\n  // wrap in buffer if needed\n  if(typeof bytes === 'string') {\n    bytes = forge.util.createBuffer(bytes);\n  }\n\n  var n = bytes.length() * 8;\n  if(n > 32) {\n    throw new Error('Integer too large; max is 32-bits.');\n  }\n  return bytes.getSignedInt(n);\n};\n\n/**\n * Validates that the given ASN.1 object is at least a super set of the\n * given ASN.1 structure. Only tag classes and types are checked. An\n * optional map may also be provided to capture ASN.1 values while the\n * structure is checked.\n *\n * To capture an ASN.1 value, set an object in the validator's 'capture'\n * parameter to the key to use in the capture map. To capture the full\n * ASN.1 object, specify 'captureAsn1'. To capture BIT STRING bytes, including\n * the leading unused bits counter byte, specify 'captureBitStringContents'.\n * To capture BIT STRING bytes, without the leading unused bits counter byte,\n * specify 'captureBitStringValue'.\n *\n * Objects in the validator may set a field 'optional' to true to indicate\n * that it isn't necessary to pass validation.\n *\n * @param obj the ASN.1 object to validate.\n * @param v the ASN.1 structure validator.\n * @param capture an optional map to capture values in.\n * @param errors an optional array for storing validation errors.\n *\n * @return true on success, false on failure.\n */\nasn1.validate = function(obj, v, capture, errors) {\n  var rval = false;\n\n  // ensure tag class and type are the same if specified\n  if((obj.tagClass === v.tagClass || typeof(v.tagClass) === 'undefined') &&\n    (obj.type === v.type || typeof(v.type) === 'undefined')) {\n    // ensure constructed flag is the same if specified\n    if(obj.constructed === v.constructed ||\n      typeof(v.constructed) === 'undefined') {\n      rval = true;\n\n      // handle sub values\n      if(v.value && forge.util.isArray(v.value)) {\n        var j = 0;\n        for(var i = 0; rval && i < v.value.length; ++i) {\n          rval = v.value[i].optional || false;\n          if(obj.value[j]) {\n            rval = asn1.validate(obj.value[j], v.value[i], capture, errors);\n            if(rval) {\n              ++j;\n            } else if(v.value[i].optional) {\n              rval = true;\n            }\n          }\n          if(!rval && errors) {\n            errors.push(\n              '[' + v.name + '] ' +\n              'Tag class \"' + v.tagClass + '\", type \"' +\n              v.type + '\" expected value length \"' +\n              v.value.length + '\", got \"' +\n              obj.value.length + '\"');\n          }\n        }\n      }\n\n      if(rval && capture) {\n        if(v.capture) {\n          capture[v.capture] = obj.value;\n        }\n        if(v.captureAsn1) {\n          capture[v.captureAsn1] = obj;\n        }\n        if(v.captureBitStringContents && 'bitStringContents' in obj) {\n          capture[v.captureBitStringContents] = obj.bitStringContents;\n        }\n        if(v.captureBitStringValue && 'bitStringContents' in obj) {\n          var value;\n          if(obj.bitStringContents.length < 2) {\n            capture[v.captureBitStringValue] = '';\n          } else {\n            // FIXME: support unused bits with data shifting\n            var unused = obj.bitStringContents.charCodeAt(0);\n            if(unused !== 0) {\n              throw new Error(\n                'captureBitStringValue only supported for zero unused bits');\n            }\n            capture[v.captureBitStringValue] = obj.bitStringContents.slice(1);\n          }\n        }\n      }\n    } else if(errors) {\n      errors.push(\n        '[' + v.name + '] ' +\n        'Expected constructed \"' + v.constructed + '\", got \"' +\n        obj.constructed + '\"');\n    }\n  } else if(errors) {\n    if(obj.tagClass !== v.tagClass) {\n      errors.push(\n        '[' + v.name + '] ' +\n        'Expected tag class \"' + v.tagClass + '\", got \"' +\n        obj.tagClass + '\"');\n    }\n    if(obj.type !== v.type) {\n      errors.push(\n        '[' + v.name + '] ' +\n        'Expected type \"' + v.type + '\", got \"' + obj.type + '\"');\n    }\n  }\n  return rval;\n};\n\n// regex for testing for non-latin characters\nvar _nonLatinRegex = /[^\\\\u0000-\\\\u00ff]/;\n\n/**\n * Pretty prints an ASN.1 object to a string.\n *\n * @param obj the object to write out.\n * @param level the level in the tree.\n * @param indentation the indentation to use.\n *\n * @return the string.\n */\nasn1.prettyPrint = function(obj, level, indentation) {\n  var rval = '';\n\n  // set default level and indentation\n  level = level || 0;\n  indentation = indentation || 2;\n\n  // start new line for deep levels\n  if(level > 0) {\n    rval += '\\n';\n  }\n\n  // create indent\n  var indent = '';\n  for(var i = 0; i < level * indentation; ++i) {\n    indent += ' ';\n  }\n\n  // print class:type\n  rval += indent + 'Tag: ';\n  switch(obj.tagClass) {\n  case asn1.Class.UNIVERSAL:\n    rval += 'Universal:';\n    break;\n  case asn1.Class.APPLICATION:\n    rval += 'Application:';\n    break;\n  case asn1.Class.CONTEXT_SPECIFIC:\n    rval += 'Context-Specific:';\n    break;\n  case asn1.Class.PRIVATE:\n    rval += 'Private:';\n    break;\n  }\n\n  if(obj.tagClass === asn1.Class.UNIVERSAL) {\n    rval += obj.type;\n\n    // known types\n    switch(obj.type) {\n    case asn1.Type.NONE:\n      rval += ' (None)';\n      break;\n    case asn1.Type.BOOLEAN:\n      rval += ' (Boolean)';\n      break;\n    case asn1.Type.INTEGER:\n      rval += ' (Integer)';\n      break;\n    case asn1.Type.BITSTRING:\n      rval += ' (Bit string)';\n      break;\n    case asn1.Type.OCTETSTRING:\n      rval += ' (Octet string)';\n      break;\n    case asn1.Type.NULL:\n      rval += ' (Null)';\n      break;\n    case asn1.Type.OID:\n      rval += ' (Object Identifier)';\n      break;\n    case asn1.Type.ODESC:\n      rval += ' (Object Descriptor)';\n      break;\n    case asn1.Type.EXTERNAL:\n      rval += ' (External or Instance of)';\n      break;\n    case asn1.Type.REAL:\n      rval += ' (Real)';\n      break;\n    case asn1.Type.ENUMERATED:\n      rval += ' (Enumerated)';\n      break;\n    case asn1.Type.EMBEDDED:\n      rval += ' (Embedded PDV)';\n      break;\n    case asn1.Type.UTF8:\n      rval += ' (UTF8)';\n      break;\n    case asn1.Type.ROID:\n      rval += ' (Relative Object Identifier)';\n      break;\n    case asn1.Type.SEQUENCE:\n      rval += ' (Sequence)';\n      break;\n    case asn1.Type.SET:\n      rval += ' (Set)';\n      break;\n    case asn1.Type.PRINTABLESTRING:\n      rval += ' (Printable String)';\n      break;\n    case asn1.Type.IA5String:\n      rval += ' (IA5String (ASCII))';\n      break;\n    case asn1.Type.UTCTIME:\n      rval += ' (UTC time)';\n      break;\n    case asn1.Type.GENERALIZEDTIME:\n      rval += ' (Generalized time)';\n      break;\n    case asn1.Type.BMPSTRING:\n      rval += ' (BMP String)';\n      break;\n    }\n  } else {\n    rval += obj.type;\n  }\n\n  rval += '\\n';\n  rval += indent + 'Constructed: ' + obj.constructed + '\\n';\n\n  if(obj.composed) {\n    var subvalues = 0;\n    var sub = '';\n    for(var i = 0; i < obj.value.length; ++i) {\n      if(obj.value[i] !== undefined) {\n        subvalues += 1;\n        sub += asn1.prettyPrint(obj.value[i], level + 1, indentation);\n        if((i + 1) < obj.value.length) {\n          sub += ',';\n        }\n      }\n    }\n    rval += indent + 'Sub values: ' + subvalues + sub;\n  } else {\n    rval += indent + 'Value: ';\n    if(obj.type === asn1.Type.OID) {\n      var oid = asn1.derToOid(obj.value);\n      rval += oid;\n      if(forge.pki && forge.pki.oids) {\n        if(oid in forge.pki.oids) {\n          rval += ' (' + forge.pki.oids[oid] + ') ';\n        }\n      }\n    }\n    if(obj.type === asn1.Type.INTEGER) {\n      try {\n        rval += asn1.derToInteger(obj.value);\n      } catch(ex) {\n        rval += '0x' + forge.util.bytesToHex(obj.value);\n      }\n    } else if(obj.type === asn1.Type.BITSTRING) {\n      // TODO: shift bits as needed to display without padding\n      if(obj.value.length > 1) {\n        // remove unused bits field\n        rval += '0x' + forge.util.bytesToHex(obj.value.slice(1));\n      } else {\n        rval += '(none)';\n      }\n      // show unused bit count\n      if(obj.value.length > 0) {\n        var unused = obj.value.charCodeAt(0);\n        if(unused == 1) {\n          rval += ' (1 unused bit shown)';\n        } else if(unused > 1) {\n          rval += ' (' + unused + ' unused bits shown)';\n        }\n      }\n    } else if(obj.type === asn1.Type.OCTETSTRING) {\n      if(!_nonLatinRegex.test(obj.value)) {\n        rval += '(' + obj.value + ') ';\n      }\n      rval += '0x' + forge.util.bytesToHex(obj.value);\n    } else if(obj.type === asn1.Type.UTF8) {\n      try {\n        rval += forge.util.decodeUtf8(obj.value);\n      } catch(e) {\n        if(e.message === 'URI malformed') {\n          rval +=\n            '0x' + forge.util.bytesToHex(obj.value) + ' (malformed UTF8)';\n        } else {\n          throw e;\n        }\n      }\n    } else if(obj.type === asn1.Type.PRINTABLESTRING ||\n      obj.type === asn1.Type.IA5String) {\n      rval += obj.value;\n    } else if(_nonLatinRegex.test(obj.value)) {\n      rval += '0x' + forge.util.bytesToHex(obj.value);\n    } else if(obj.value.length === 0) {\n      rval += '[null]';\n    } else {\n      rval += obj.value;\n    }\n  }\n\n  return rval;\n};\n","/**\n * Base-N/Base-X encoding/decoding functions.\n *\n * Original implementation from base-x:\n * https://github.com/cryptocoinjs/base-x\n *\n * Which is MIT licensed:\n *\n * The MIT License (MIT)\n *\n * Copyright base-x contributors (c) 2016\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n * DEALINGS IN THE SOFTWARE.\n */\nvar api = {};\nmodule.exports = api;\n\n// baseN alphabet indexes\nvar _reverseAlphabets = {};\n\n/**\n * BaseN-encodes a Uint8Array using the given alphabet.\n *\n * @param input the Uint8Array to encode.\n * @param maxline the maximum number of encoded characters per line to use,\n *          defaults to none.\n *\n * @return the baseN-encoded output string.\n */\napi.encode = function(input, alphabet, maxline) {\n  if(typeof alphabet !== 'string') {\n    throw new TypeError('\"alphabet\" must be a string.');\n  }\n  if(maxline !== undefined && typeof maxline !== 'number') {\n    throw new TypeError('\"maxline\" must be a number.');\n  }\n\n  var output = '';\n\n  if(!(input instanceof Uint8Array)) {\n    // assume forge byte buffer\n    output = _encodeWithByteBuffer(input, alphabet);\n  } else {\n    var i = 0;\n    var base = alphabet.length;\n    var first = alphabet.charAt(0);\n    var digits = [0];\n    for(i = 0; i < input.length; ++i) {\n      for(var j = 0, carry = input[i]; j < digits.length; ++j) {\n        carry += digits[j] << 8;\n        digits[j] = carry % base;\n        carry = (carry / base) | 0;\n      }\n\n      while(carry > 0) {\n        digits.push(carry % base);\n        carry = (carry / base) | 0;\n      }\n    }\n\n    // deal with leading zeros\n    for(i = 0; input[i] === 0 && i < input.length - 1; ++i) {\n      output += first;\n    }\n    // convert digits to a string\n    for(i = digits.length - 1; i >= 0; --i) {\n      output += alphabet[digits[i]];\n    }\n  }\n\n  if(maxline) {\n    var regex = new RegExp('.{1,' + maxline + '}', 'g');\n    output = output.match(regex).join('\\r\\n');\n  }\n\n  return output;\n};\n\n/**\n * Decodes a baseN-encoded (using the given alphabet) string to a\n * Uint8Array.\n *\n * @param input the baseN-encoded input string.\n *\n * @return the Uint8Array.\n */\napi.decode = function(input, alphabet) {\n  if(typeof input !== 'string') {\n    throw new TypeError('\"input\" must be a string.');\n  }\n  if(typeof alphabet !== 'string') {\n    throw new TypeError('\"alphabet\" must be a string.');\n  }\n\n  var table = _reverseAlphabets[alphabet];\n  if(!table) {\n    // compute reverse alphabet\n    table = _reverseAlphabets[alphabet] = [];\n    for(var i = 0; i < alphabet.length; ++i) {\n      table[alphabet.charCodeAt(i)] = i;\n    }\n  }\n\n  // remove whitespace characters\n  input = input.replace(/\\s/g, '');\n\n  var base = alphabet.length;\n  var first = alphabet.charAt(0);\n  var bytes = [0];\n  for(var i = 0; i < input.length; i++) {\n    var value = table[input.charCodeAt(i)];\n    if(value === undefined) {\n      return;\n    }\n\n    for(var j = 0, carry = value; j < bytes.length; ++j) {\n      carry += bytes[j] * base;\n      bytes[j] = carry & 0xff;\n      carry >>= 8;\n    }\n\n    while(carry > 0) {\n      bytes.push(carry & 0xff);\n      carry >>= 8;\n    }\n  }\n\n  // deal with leading zeros\n  for(var k = 0; input[k] === first && k < input.length - 1; ++k) {\n    bytes.push(0);\n  }\n\n  if(typeof Buffer !== 'undefined') {\n    return Buffer.from(bytes.reverse());\n  }\n\n  return new Uint8Array(bytes.reverse());\n};\n\nfunction _encodeWithByteBuffer(input, alphabet) {\n  var i = 0;\n  var base = alphabet.length;\n  var first = alphabet.charAt(0);\n  var digits = [0];\n  for(i = 0; i < input.length(); ++i) {\n    for(var j = 0, carry = input.at(i); j < digits.length; ++j) {\n      carry += digits[j] << 8;\n      digits[j] = carry % base;\n      carry = (carry / base) | 0;\n    }\n\n    while(carry > 0) {\n      digits.push(carry % base);\n      carry = (carry / base) | 0;\n    }\n  }\n\n  var output = '';\n\n  // deal with leading zeros\n  for(i = 0; input.at(i) === 0 && i < input.length() - 1; ++i) {\n    output += first;\n  }\n  // convert digits to a string\n  for(i = digits.length - 1; i >= 0; --i) {\n    output += alphabet[digits[i]];\n  }\n\n  return output;\n}\n","/**\n * Cipher base API.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\n\nmodule.exports = forge.cipher = forge.cipher || {};\n\n// registered algorithms\nforge.cipher.algorithms = forge.cipher.algorithms || {};\n\n/**\n * Creates a cipher object that can be used to encrypt data using the given\n * algorithm and key. The algorithm may be provided as a string value for a\n * previously registered algorithm or it may be given as a cipher algorithm\n * API object.\n *\n * @param algorithm the algorithm to use, either a string or an algorithm API\n *          object.\n * @param key the key to use, as a binary-encoded string of bytes or a\n *          byte buffer.\n *\n * @return the cipher.\n */\nforge.cipher.createCipher = function(algorithm, key) {\n  var api = algorithm;\n  if(typeof api === 'string') {\n    api = forge.cipher.getAlgorithm(api);\n    if(api) {\n      api = api();\n    }\n  }\n  if(!api) {\n    throw new Error('Unsupported algorithm: ' + algorithm);\n  }\n\n  // assume block cipher\n  return new forge.cipher.BlockCipher({\n    algorithm: api,\n    key: key,\n    decrypt: false\n  });\n};\n\n/**\n * Creates a decipher object that can be used to decrypt data using the given\n * algorithm and key. The algorithm may be provided as a string value for a\n * previously registered algorithm or it may be given as a cipher algorithm\n * API object.\n *\n * @param algorithm the algorithm to use, either a string or an algorithm API\n *          object.\n * @param key the key to use, as a binary-encoded string of bytes or a\n *          byte buffer.\n *\n * @return the cipher.\n */\nforge.cipher.createDecipher = function(algorithm, key) {\n  var api = algorithm;\n  if(typeof api === 'string') {\n    api = forge.cipher.getAlgorithm(api);\n    if(api) {\n      api = api();\n    }\n  }\n  if(!api) {\n    throw new Error('Unsupported algorithm: ' + algorithm);\n  }\n\n  // assume block cipher\n  return new forge.cipher.BlockCipher({\n    algorithm: api,\n    key: key,\n    decrypt: true\n  });\n};\n\n/**\n * Registers an algorithm by name. If the name was already registered, the\n * algorithm API object will be overwritten.\n *\n * @param name the name of the algorithm.\n * @param algorithm the algorithm API object.\n */\nforge.cipher.registerAlgorithm = function(name, algorithm) {\n  name = name.toUpperCase();\n  forge.cipher.algorithms[name] = algorithm;\n};\n\n/**\n * Gets a registered algorithm by name.\n *\n * @param name the name of the algorithm.\n *\n * @return the algorithm, if found, null if not.\n */\nforge.cipher.getAlgorithm = function(name) {\n  name = name.toUpperCase();\n  if(name in forge.cipher.algorithms) {\n    return forge.cipher.algorithms[name];\n  }\n  return null;\n};\n\nvar BlockCipher = forge.cipher.BlockCipher = function(options) {\n  this.algorithm = options.algorithm;\n  this.mode = this.algorithm.mode;\n  this.blockSize = this.mode.blockSize;\n  this._finish = false;\n  this._input = null;\n  this.output = null;\n  this._op = options.decrypt ? this.mode.decrypt : this.mode.encrypt;\n  this._decrypt = options.decrypt;\n  this.algorithm.initialize(options);\n};\n\n/**\n * Starts or restarts the encryption or decryption process, whichever\n * was previously configured.\n *\n * For non-GCM mode, the IV may be a binary-encoded string of bytes, an array\n * of bytes, a byte buffer, or an array of 32-bit integers. If the IV is in\n * bytes, then it must be Nb (16) bytes in length. If the IV is given in as\n * 32-bit integers, then it must be 4 integers long.\n *\n * Note: an IV is not required or used in ECB mode.\n *\n * For GCM-mode, the IV must be given as a binary-encoded string of bytes or\n * a byte buffer. The number of bytes should be 12 (96 bits) as recommended\n * by NIST SP-800-38D but another length may be given.\n *\n * @param options the options to use:\n *          iv the initialization vector to use as a binary-encoded string of\n *            bytes, null to reuse the last ciphered block from a previous\n *            update() (this \"residue\" method is for legacy support only).\n *          additionalData additional authentication data as a binary-encoded\n *            string of bytes, for 'GCM' mode, (default: none).\n *          tagLength desired length of authentication tag, in bits, for\n *            'GCM' mode (0-128, default: 128).\n *          tag the authentication tag to check if decrypting, as a\n *             binary-encoded string of bytes.\n *          output the output the buffer to write to, null to create one.\n */\nBlockCipher.prototype.start = function(options) {\n  options = options || {};\n  var opts = {};\n  for(var key in options) {\n    opts[key] = options[key];\n  }\n  opts.decrypt = this._decrypt;\n  this._finish = false;\n  this._input = forge.util.createBuffer();\n  this.output = options.output || forge.util.createBuffer();\n  this.mode.start(opts);\n};\n\n/**\n * Updates the next block according to the cipher mode.\n *\n * @param input the buffer to read from.\n */\nBlockCipher.prototype.update = function(input) {\n  if(input) {\n    // input given, so empty it into the input buffer\n    this._input.putBuffer(input);\n  }\n\n  // do cipher operation until it needs more input and not finished\n  while(!this._op.call(this.mode, this._input, this.output, this._finish) &&\n    !this._finish) {}\n\n  // free consumed memory from input buffer\n  this._input.compact();\n};\n\n/**\n * Finishes encrypting or decrypting.\n *\n * @param pad a padding function to use in CBC mode, null for default,\n *          signature(blockSize, buffer, decrypt).\n *\n * @return true if successful, false on error.\n */\nBlockCipher.prototype.finish = function(pad) {\n  // backwards-compatibility w/deprecated padding API\n  // Note: will overwrite padding functions even after another start() call\n  if(pad && (this.mode.name === 'ECB' || this.mode.name === 'CBC')) {\n    this.mode.pad = function(input) {\n      return pad(this.blockSize, input, false);\n    };\n    this.mode.unpad = function(output) {\n      return pad(this.blockSize, output, true);\n    };\n  }\n\n  // build options for padding and afterFinish functions\n  var options = {};\n  options.decrypt = this._decrypt;\n\n  // get # of bytes that won't fill a block\n  options.overflow = this._input.length() % this.blockSize;\n\n  if(!this._decrypt && this.mode.pad) {\n    if(!this.mode.pad(this._input, options)) {\n      return false;\n    }\n  }\n\n  // do final update\n  this._finish = true;\n  this.update();\n\n  if(this._decrypt && this.mode.unpad) {\n    if(!this.mode.unpad(this.output, options)) {\n      return false;\n    }\n  }\n\n  if(this.mode.afterFinish) {\n    if(!this.mode.afterFinish(this.output, options)) {\n      return false;\n    }\n  }\n\n  return true;\n};\n","/**\n * Supported cipher modes.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\n\nforge.cipher = forge.cipher || {};\n\n// supported cipher modes\nvar modes = module.exports = forge.cipher.modes = forge.cipher.modes || {};\n\n/** Electronic codebook (ECB) (Don't use this; it's not secure) **/\n\nmodes.ecb = function(options) {\n  options = options || {};\n  this.name = 'ECB';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = new Array(this._ints);\n  this._outBlock = new Array(this._ints);\n};\n\nmodes.ecb.prototype.start = function(options) {};\n\nmodes.ecb.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // write output\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n};\n\nmodes.ecb.prototype.decrypt = function(input, output, finish) {\n  // not enough input to decrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // decrypt block\n  this.cipher.decrypt(this._inBlock, this._outBlock);\n\n  // write output\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n};\n\nmodes.ecb.prototype.pad = function(input, options) {\n  // add PKCS#7 padding to block (each pad byte is the\n  // value of the number of pad bytes)\n  var padding = (input.length() === this.blockSize ?\n    this.blockSize : (this.blockSize - input.length()));\n  input.fillWithByte(padding, padding);\n  return true;\n};\n\nmodes.ecb.prototype.unpad = function(output, options) {\n  // check for error: input data not a multiple of blockSize\n  if(options.overflow > 0) {\n    return false;\n  }\n\n  // ensure padding byte count is valid\n  var len = output.length();\n  var count = output.at(len - 1);\n  if(count > (this.blockSize << 2)) {\n    return false;\n  }\n\n  // trim off padding bytes\n  output.truncate(count);\n  return true;\n};\n\n/** Cipher-block Chaining (CBC) **/\n\nmodes.cbc = function(options) {\n  options = options || {};\n  this.name = 'CBC';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = new Array(this._ints);\n  this._outBlock = new Array(this._ints);\n};\n\nmodes.cbc.prototype.start = function(options) {\n  // Note: legacy support for using IV residue (has security flaws)\n  // if IV is null, reuse block from previous processing\n  if(options.iv === null) {\n    // must have a previous block\n    if(!this._prev) {\n      throw new Error('Invalid IV parameter.');\n    }\n    this._iv = this._prev.slice(0);\n  } else if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  } else {\n    // save IV as \"previous\" block\n    this._iv = transformIV(options.iv, this.blockSize);\n    this._prev = this._iv.slice(0);\n  }\n};\n\nmodes.cbc.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  // CBC XOR's IV (or previous block) with plaintext\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = this._prev[i] ^ input.getInt32();\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // write output, save previous block\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n  this._prev = this._outBlock;\n};\n\nmodes.cbc.prototype.decrypt = function(input, output, finish) {\n  // not enough input to decrypt\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  // get next block\n  for(var i = 0; i < this._ints; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // decrypt block\n  this.cipher.decrypt(this._inBlock, this._outBlock);\n\n  // write output, save previous ciphered block\n  // CBC XOR's IV (or previous block) with ciphertext\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._prev[i] ^ this._outBlock[i]);\n  }\n  this._prev = this._inBlock.slice(0);\n};\n\nmodes.cbc.prototype.pad = function(input, options) {\n  // add PKCS#7 padding to block (each pad byte is the\n  // value of the number of pad bytes)\n  var padding = (input.length() === this.blockSize ?\n    this.blockSize : (this.blockSize - input.length()));\n  input.fillWithByte(padding, padding);\n  return true;\n};\n\nmodes.cbc.prototype.unpad = function(output, options) {\n  // check for error: input data not a multiple of blockSize\n  if(options.overflow > 0) {\n    return false;\n  }\n\n  // ensure padding byte count is valid\n  var len = output.length();\n  var count = output.at(len - 1);\n  if(count > (this.blockSize << 2)) {\n    return false;\n  }\n\n  // trim off padding bytes\n  output.truncate(count);\n  return true;\n};\n\n/** Cipher feedback (CFB) **/\n\nmodes.cfb = function(options) {\n  options = options || {};\n  this.name = 'CFB';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = null;\n  this._outBlock = new Array(this._ints);\n  this._partialBlock = new Array(this._ints);\n  this._partialOutput = forge.util.createBuffer();\n  this._partialBytes = 0;\n};\n\nmodes.cfb.prototype.start = function(options) {\n  if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  }\n  // use IV as first input\n  this._iv = transformIV(options.iv, this.blockSize);\n  this._inBlock = this._iv.slice(0);\n  this._partialBytes = 0;\n};\n\nmodes.cfb.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  var inputLength = input.length();\n  if(inputLength === 0) {\n    return true;\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // handle full block\n  if(this._partialBytes === 0 && inputLength >= this.blockSize) {\n    // XOR input with output, write input as output\n    for(var i = 0; i < this._ints; ++i) {\n      this._inBlock[i] = input.getInt32() ^ this._outBlock[i];\n      output.putInt32(this._inBlock[i]);\n    }\n    return;\n  }\n\n  // handle partial block\n  var partialBytes = (this.blockSize - inputLength) % this.blockSize;\n  if(partialBytes > 0) {\n    partialBytes = this.blockSize - partialBytes;\n  }\n\n  // XOR input with output, write input as partial output\n  this._partialOutput.clear();\n  for(var i = 0; i < this._ints; ++i) {\n    this._partialBlock[i] = input.getInt32() ^ this._outBlock[i];\n    this._partialOutput.putInt32(this._partialBlock[i]);\n  }\n\n  if(partialBytes > 0) {\n    // block still incomplete, restore input buffer\n    input.read -= this.blockSize;\n  } else {\n    // block complete, update input block\n    for(var i = 0; i < this._ints; ++i) {\n      this._inBlock[i] = this._partialBlock[i];\n    }\n  }\n\n  // skip any previous partial bytes\n  if(this._partialBytes > 0) {\n    this._partialOutput.getBytes(this._partialBytes);\n  }\n\n  if(partialBytes > 0 && !finish) {\n    output.putBytes(this._partialOutput.getBytes(\n      partialBytes - this._partialBytes));\n    this._partialBytes = partialBytes;\n    return true;\n  }\n\n  output.putBytes(this._partialOutput.getBytes(\n    inputLength - this._partialBytes));\n  this._partialBytes = 0;\n};\n\nmodes.cfb.prototype.decrypt = function(input, output, finish) {\n  // not enough input to decrypt\n  var inputLength = input.length();\n  if(inputLength === 0) {\n    return true;\n  }\n\n  // encrypt block (CFB always uses encryption mode)\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // handle full block\n  if(this._partialBytes === 0 && inputLength >= this.blockSize) {\n    // XOR input with output, write input as output\n    for(var i = 0; i < this._ints; ++i) {\n      this._inBlock[i] = input.getInt32();\n      output.putInt32(this._inBlock[i] ^ this._outBlock[i]);\n    }\n    return;\n  }\n\n  // handle partial block\n  var partialBytes = (this.blockSize - inputLength) % this.blockSize;\n  if(partialBytes > 0) {\n    partialBytes = this.blockSize - partialBytes;\n  }\n\n  // XOR input with output, write input as partial output\n  this._partialOutput.clear();\n  for(var i = 0; i < this._ints; ++i) {\n    this._partialBlock[i] = input.getInt32();\n    this._partialOutput.putInt32(this._partialBlock[i] ^ this._outBlock[i]);\n  }\n\n  if(partialBytes > 0) {\n    // block still incomplete, restore input buffer\n    input.read -= this.blockSize;\n  } else {\n    // block complete, update input block\n    for(var i = 0; i < this._ints; ++i) {\n      this._inBlock[i] = this._partialBlock[i];\n    }\n  }\n\n  // skip any previous partial bytes\n  if(this._partialBytes > 0) {\n    this._partialOutput.getBytes(this._partialBytes);\n  }\n\n  if(partialBytes > 0 && !finish) {\n    output.putBytes(this._partialOutput.getBytes(\n      partialBytes - this._partialBytes));\n    this._partialBytes = partialBytes;\n    return true;\n  }\n\n  output.putBytes(this._partialOutput.getBytes(\n    inputLength - this._partialBytes));\n  this._partialBytes = 0;\n};\n\n/** Output feedback (OFB) **/\n\nmodes.ofb = function(options) {\n  options = options || {};\n  this.name = 'OFB';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = null;\n  this._outBlock = new Array(this._ints);\n  this._partialOutput = forge.util.createBuffer();\n  this._partialBytes = 0;\n};\n\nmodes.ofb.prototype.start = function(options) {\n  if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  }\n  // use IV as first input\n  this._iv = transformIV(options.iv, this.blockSize);\n  this._inBlock = this._iv.slice(0);\n  this._partialBytes = 0;\n};\n\nmodes.ofb.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  var inputLength = input.length();\n  if(input.length() === 0) {\n    return true;\n  }\n\n  // encrypt block (OFB always uses encryption mode)\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // handle full block\n  if(this._partialBytes === 0 && inputLength >= this.blockSize) {\n    // XOR input with output and update next input\n    for(var i = 0; i < this._ints; ++i) {\n      output.putInt32(input.getInt32() ^ this._outBlock[i]);\n      this._inBlock[i] = this._outBlock[i];\n    }\n    return;\n  }\n\n  // handle partial block\n  var partialBytes = (this.blockSize - inputLength) % this.blockSize;\n  if(partialBytes > 0) {\n    partialBytes = this.blockSize - partialBytes;\n  }\n\n  // XOR input with output\n  this._partialOutput.clear();\n  for(var i = 0; i < this._ints; ++i) {\n    this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);\n  }\n\n  if(partialBytes > 0) {\n    // block still incomplete, restore input buffer\n    input.read -= this.blockSize;\n  } else {\n    // block complete, update input block\n    for(var i = 0; i < this._ints; ++i) {\n      this._inBlock[i] = this._outBlock[i];\n    }\n  }\n\n  // skip any previous partial bytes\n  if(this._partialBytes > 0) {\n    this._partialOutput.getBytes(this._partialBytes);\n  }\n\n  if(partialBytes > 0 && !finish) {\n    output.putBytes(this._partialOutput.getBytes(\n      partialBytes - this._partialBytes));\n    this._partialBytes = partialBytes;\n    return true;\n  }\n\n  output.putBytes(this._partialOutput.getBytes(\n    inputLength - this._partialBytes));\n  this._partialBytes = 0;\n};\n\nmodes.ofb.prototype.decrypt = modes.ofb.prototype.encrypt;\n\n/** Counter (CTR) **/\n\nmodes.ctr = function(options) {\n  options = options || {};\n  this.name = 'CTR';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = null;\n  this._outBlock = new Array(this._ints);\n  this._partialOutput = forge.util.createBuffer();\n  this._partialBytes = 0;\n};\n\nmodes.ctr.prototype.start = function(options) {\n  if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  }\n  // use IV as first input\n  this._iv = transformIV(options.iv, this.blockSize);\n  this._inBlock = this._iv.slice(0);\n  this._partialBytes = 0;\n};\n\nmodes.ctr.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  var inputLength = input.length();\n  if(inputLength === 0) {\n    return true;\n  }\n\n  // encrypt block (CTR always uses encryption mode)\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // handle full block\n  if(this._partialBytes === 0 && inputLength >= this.blockSize) {\n    // XOR input with output\n    for(var i = 0; i < this._ints; ++i) {\n      output.putInt32(input.getInt32() ^ this._outBlock[i]);\n    }\n  } else {\n    // handle partial block\n    var partialBytes = (this.blockSize - inputLength) % this.blockSize;\n    if(partialBytes > 0) {\n      partialBytes = this.blockSize - partialBytes;\n    }\n\n    // XOR input with output\n    this._partialOutput.clear();\n    for(var i = 0; i < this._ints; ++i) {\n      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);\n    }\n\n    if(partialBytes > 0) {\n      // block still incomplete, restore input buffer\n      input.read -= this.blockSize;\n    }\n\n    // skip any previous partial bytes\n    if(this._partialBytes > 0) {\n      this._partialOutput.getBytes(this._partialBytes);\n    }\n\n    if(partialBytes > 0 && !finish) {\n      output.putBytes(this._partialOutput.getBytes(\n        partialBytes - this._partialBytes));\n      this._partialBytes = partialBytes;\n      return true;\n    }\n\n    output.putBytes(this._partialOutput.getBytes(\n      inputLength - this._partialBytes));\n    this._partialBytes = 0;\n  }\n\n  // block complete, increment counter (input block)\n  inc32(this._inBlock);\n};\n\nmodes.ctr.prototype.decrypt = modes.ctr.prototype.encrypt;\n\n/** Galois/Counter Mode (GCM) **/\n\nmodes.gcm = function(options) {\n  options = options || {};\n  this.name = 'GCM';\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._ints = this.blockSize / 4;\n  this._inBlock = new Array(this._ints);\n  this._outBlock = new Array(this._ints);\n  this._partialOutput = forge.util.createBuffer();\n  this._partialBytes = 0;\n\n  // R is actually this value concatenated with 120 more zero bits, but\n  // we only XOR against R so the other zeros have no effect -- we just\n  // apply this value to the first integer in a block\n  this._R = 0xE1000000;\n};\n\nmodes.gcm.prototype.start = function(options) {\n  if(!('iv' in options)) {\n    throw new Error('Invalid IV parameter.');\n  }\n  // ensure IV is a byte buffer\n  var iv = forge.util.createBuffer(options.iv);\n\n  // no ciphered data processed yet\n  this._cipherLength = 0;\n\n  // default additional data is none\n  var additionalData;\n  if('additionalData' in options) {\n    additionalData = forge.util.createBuffer(options.additionalData);\n  } else {\n    additionalData = forge.util.createBuffer();\n  }\n\n  // default tag length is 128 bits\n  if('tagLength' in options) {\n    this._tagLength = options.tagLength;\n  } else {\n    this._tagLength = 128;\n  }\n\n  // if tag is given, ensure tag matches tag length\n  this._tag = null;\n  if(options.decrypt) {\n    // save tag to check later\n    this._tag = forge.util.createBuffer(options.tag).getBytes();\n    if(this._tag.length !== (this._tagLength / 8)) {\n      throw new Error('Authentication tag does not match tag length.');\n    }\n  }\n\n  // create tmp storage for hash calculation\n  this._hashBlock = new Array(this._ints);\n\n  // no tag generated yet\n  this.tag = null;\n\n  // generate hash subkey\n  // (apply block cipher to \"zero\" block)\n  this._hashSubkey = new Array(this._ints);\n  this.cipher.encrypt([0, 0, 0, 0], this._hashSubkey);\n\n  // generate table M\n  // use 4-bit tables (32 component decomposition of a 16 byte value)\n  // 8-bit tables take more space and are known to have security\n  // vulnerabilities (in native implementations)\n  this.componentBits = 4;\n  this._m = this.generateHashTable(this._hashSubkey, this.componentBits);\n\n  // Note: support IV length different from 96 bits? (only supporting\n  // 96 bits is recommended by NIST SP-800-38D)\n  // generate J_0\n  var ivLength = iv.length();\n  if(ivLength === 12) {\n    // 96-bit IV\n    this._j0 = [iv.getInt32(), iv.getInt32(), iv.getInt32(), 1];\n  } else {\n    // IV is NOT 96-bits\n    this._j0 = [0, 0, 0, 0];\n    while(iv.length() > 0) {\n      this._j0 = this.ghash(\n        this._hashSubkey, this._j0,\n        [iv.getInt32(), iv.getInt32(), iv.getInt32(), iv.getInt32()]);\n    }\n    this._j0 = this.ghash(\n      this._hashSubkey, this._j0, [0, 0].concat(from64To32(ivLength * 8)));\n  }\n\n  // generate ICB (initial counter block)\n  this._inBlock = this._j0.slice(0);\n  inc32(this._inBlock);\n  this._partialBytes = 0;\n\n  // consume authentication data\n  additionalData = forge.util.createBuffer(additionalData);\n  // save additional data length as a BE 64-bit number\n  this._aDataLength = from64To32(additionalData.length() * 8);\n  // pad additional data to 128 bit (16 byte) block size\n  var overflow = additionalData.length() % this.blockSize;\n  if(overflow) {\n    additionalData.fillWithByte(0, this.blockSize - overflow);\n  }\n  this._s = [0, 0, 0, 0];\n  while(additionalData.length() > 0) {\n    this._s = this.ghash(this._hashSubkey, this._s, [\n      additionalData.getInt32(),\n      additionalData.getInt32(),\n      additionalData.getInt32(),\n      additionalData.getInt32()\n    ]);\n  }\n};\n\nmodes.gcm.prototype.encrypt = function(input, output, finish) {\n  // not enough input to encrypt\n  var inputLength = input.length();\n  if(inputLength === 0) {\n    return true;\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // handle full block\n  if(this._partialBytes === 0 && inputLength >= this.blockSize) {\n    // XOR input with output\n    for(var i = 0; i < this._ints; ++i) {\n      output.putInt32(this._outBlock[i] ^= input.getInt32());\n    }\n    this._cipherLength += this.blockSize;\n  } else {\n    // handle partial block\n    var partialBytes = (this.blockSize - inputLength) % this.blockSize;\n    if(partialBytes > 0) {\n      partialBytes = this.blockSize - partialBytes;\n    }\n\n    // XOR input with output\n    this._partialOutput.clear();\n    for(var i = 0; i < this._ints; ++i) {\n      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);\n    }\n\n    if(partialBytes <= 0 || finish) {\n      // handle overflow prior to hashing\n      if(finish) {\n        // get block overflow\n        var overflow = inputLength % this.blockSize;\n        this._cipherLength += overflow;\n        // truncate for hash function\n        this._partialOutput.truncate(this.blockSize - overflow);\n      } else {\n        this._cipherLength += this.blockSize;\n      }\n\n      // get output block for hashing\n      for(var i = 0; i < this._ints; ++i) {\n        this._outBlock[i] = this._partialOutput.getInt32();\n      }\n      this._partialOutput.read -= this.blockSize;\n    }\n\n    // skip any previous partial bytes\n    if(this._partialBytes > 0) {\n      this._partialOutput.getBytes(this._partialBytes);\n    }\n\n    if(partialBytes > 0 && !finish) {\n      // block still incomplete, restore input buffer, get partial output,\n      // and return early\n      input.read -= this.blockSize;\n      output.putBytes(this._partialOutput.getBytes(\n        partialBytes - this._partialBytes));\n      this._partialBytes = partialBytes;\n      return true;\n    }\n\n    output.putBytes(this._partialOutput.getBytes(\n      inputLength - this._partialBytes));\n    this._partialBytes = 0;\n  }\n\n  // update hash block S\n  this._s = this.ghash(this._hashSubkey, this._s, this._outBlock);\n\n  // increment counter (input block)\n  inc32(this._inBlock);\n};\n\nmodes.gcm.prototype.decrypt = function(input, output, finish) {\n  // not enough input to decrypt\n  var inputLength = input.length();\n  if(inputLength < this.blockSize && !(finish && inputLength > 0)) {\n    return true;\n  }\n\n  // encrypt block (GCM always uses encryption mode)\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // increment counter (input block)\n  inc32(this._inBlock);\n\n  // update hash block S\n  this._hashBlock[0] = input.getInt32();\n  this._hashBlock[1] = input.getInt32();\n  this._hashBlock[2] = input.getInt32();\n  this._hashBlock[3] = input.getInt32();\n  this._s = this.ghash(this._hashSubkey, this._s, this._hashBlock);\n\n  // XOR hash input with output\n  for(var i = 0; i < this._ints; ++i) {\n    output.putInt32(this._outBlock[i] ^ this._hashBlock[i]);\n  }\n\n  // increment cipher data length\n  if(inputLength < this.blockSize) {\n    this._cipherLength += inputLength % this.blockSize;\n  } else {\n    this._cipherLength += this.blockSize;\n  }\n};\n\nmodes.gcm.prototype.afterFinish = function(output, options) {\n  var rval = true;\n\n  // handle overflow\n  if(options.decrypt && options.overflow) {\n    output.truncate(this.blockSize - options.overflow);\n  }\n\n  // handle authentication tag\n  this.tag = forge.util.createBuffer();\n\n  // concatenate additional data length with cipher length\n  var lengths = this._aDataLength.concat(from64To32(this._cipherLength * 8));\n\n  // include lengths in hash\n  this._s = this.ghash(this._hashSubkey, this._s, lengths);\n\n  // do GCTR(J_0, S)\n  var tag = [];\n  this.cipher.encrypt(this._j0, tag);\n  for(var i = 0; i < this._ints; ++i) {\n    this.tag.putInt32(this._s[i] ^ tag[i]);\n  }\n\n  // trim tag to length\n  this.tag.truncate(this.tag.length() % (this._tagLength / 8));\n\n  // check authentication tag\n  if(options.decrypt && this.tag.bytes() !== this._tag) {\n    rval = false;\n  }\n\n  return rval;\n};\n\n/**\n * See NIST SP-800-38D 6.3 (Algorithm 1). This function performs Galois\n * field multiplication. The field, GF(2^128), is defined by the polynomial:\n *\n * x^128 + x^7 + x^2 + x + 1\n *\n * Which is represented in little-endian binary form as: 11100001 (0xe1). When\n * the value of a coefficient is 1, a bit is set. The value R, is the\n * concatenation of this value and 120 zero bits, yielding a 128-bit value\n * which matches the block size.\n *\n * This function will multiply two elements (vectors of bytes), X and Y, in\n * the field GF(2^128). The result is initialized to zero. For each bit of\n * X (out of 128), x_i, if x_i is set, then the result is multiplied (XOR'd)\n * by the current value of Y. For each bit, the value of Y will be raised by\n * a power of x (multiplied by the polynomial x). This can be achieved by\n * shifting Y once to the right. If the current value of Y, prior to being\n * multiplied by x, has 0 as its LSB, then it is a 127th degree polynomial.\n * Otherwise, we must divide by R after shifting to find the remainder.\n *\n * @param x the first block to multiply by the second.\n * @param y the second block to multiply by the first.\n *\n * @return the block result of the multiplication.\n */\nmodes.gcm.prototype.multiply = function(x, y) {\n  var z_i = [0, 0, 0, 0];\n  var v_i = y.slice(0);\n\n  // calculate Z_128 (block has 128 bits)\n  for(var i = 0; i < 128; ++i) {\n    // if x_i is 0, Z_{i+1} = Z_i (unchanged)\n    // else Z_{i+1} = Z_i ^ V_i\n    // get x_i by finding 32-bit int position, then left shift 1 by remainder\n    var x_i = x[(i / 32) | 0] & (1 << (31 - i % 32));\n    if(x_i) {\n      z_i[0] ^= v_i[0];\n      z_i[1] ^= v_i[1];\n      z_i[2] ^= v_i[2];\n      z_i[3] ^= v_i[3];\n    }\n\n    // if LSB(V_i) is 1, V_i = V_i >> 1\n    // else V_i = (V_i >> 1) ^ R\n    this.pow(v_i, v_i);\n  }\n\n  return z_i;\n};\n\nmodes.gcm.prototype.pow = function(x, out) {\n  // if LSB(x) is 1, x = x >>> 1\n  // else x = (x >>> 1) ^ R\n  var lsb = x[3] & 1;\n\n  // always do x >>> 1:\n  // starting with the rightmost integer, shift each integer to the right\n  // one bit, pulling in the bit from the integer to the left as its top\n  // most bit (do this for the last 3 integers)\n  for(var i = 3; i > 0; --i) {\n    out[i] = (x[i] >>> 1) | ((x[i - 1] & 1) << 31);\n  }\n  // shift the first integer normally\n  out[0] = x[0] >>> 1;\n\n  // if lsb was not set, then polynomial had a degree of 127 and doesn't\n  // need to divided; otherwise, XOR with R to find the remainder; we only\n  // need to XOR the first integer since R technically ends w/120 zero bits\n  if(lsb) {\n    out[0] ^= this._R;\n  }\n};\n\nmodes.gcm.prototype.tableMultiply = function(x) {\n  // assumes 4-bit tables are used\n  var z = [0, 0, 0, 0];\n  for(var i = 0; i < 32; ++i) {\n    var idx = (i / 8) | 0;\n    var x_i = (x[idx] >>> ((7 - (i % 8)) * 4)) & 0xF;\n    var ah = this._m[i][x_i];\n    z[0] ^= ah[0];\n    z[1] ^= ah[1];\n    z[2] ^= ah[2];\n    z[3] ^= ah[3];\n  }\n  return z;\n};\n\n/**\n * A continuing version of the GHASH algorithm that operates on a single\n * block. The hash block, last hash value (Ym) and the new block to hash\n * are given.\n *\n * @param h the hash block.\n * @param y the previous value for Ym, use [0, 0, 0, 0] for a new hash.\n * @param x the block to hash.\n *\n * @return the hashed value (Ym).\n */\nmodes.gcm.prototype.ghash = function(h, y, x) {\n  y[0] ^= x[0];\n  y[1] ^= x[1];\n  y[2] ^= x[2];\n  y[3] ^= x[3];\n  return this.tableMultiply(y);\n  //return this.multiply(y, h);\n};\n\n/**\n * Precomputes a table for multiplying against the hash subkey. This\n * mechanism provides a substantial speed increase over multiplication\n * performed without a table. The table-based multiplication this table is\n * for solves X * H by multiplying each component of X by H and then\n * composing the results together using XOR.\n *\n * This function can be used to generate tables with different bit sizes\n * for the components, however, this implementation assumes there are\n * 32 components of X (which is a 16 byte vector), therefore each component\n * takes 4-bits (so the table is constructed with bits=4).\n *\n * @param h the hash subkey.\n * @param bits the bit size for a component.\n */\nmodes.gcm.prototype.generateHashTable = function(h, bits) {\n  // TODO: There are further optimizations that would use only the\n  // first table M_0 (or some variant) along with a remainder table;\n  // this can be explored in the future\n  var multiplier = 8 / bits;\n  var perInt = 4 * multiplier;\n  var size = 16 * multiplier;\n  var m = new Array(size);\n  for(var i = 0; i < size; ++i) {\n    var tmp = [0, 0, 0, 0];\n    var idx = (i / perInt) | 0;\n    var shft = ((perInt - 1 - (i % perInt)) * bits);\n    tmp[idx] = (1 << (bits - 1)) << shft;\n    m[i] = this.generateSubHashTable(this.multiply(tmp, h), bits);\n  }\n  return m;\n};\n\n/**\n * Generates a table for multiplying against the hash subkey for one\n * particular component (out of all possible component values).\n *\n * @param mid the pre-multiplied value for the middle key of the table.\n * @param bits the bit size for a component.\n */\nmodes.gcm.prototype.generateSubHashTable = function(mid, bits) {\n  // compute the table quickly by minimizing the number of\n  // POW operations -- they only need to be performed for powers of 2,\n  // all other entries can be composed from those powers using XOR\n  var size = 1 << bits;\n  var half = size >>> 1;\n  var m = new Array(size);\n  m[half] = mid.slice(0);\n  var i = half >>> 1;\n  while(i > 0) {\n    // raise m0[2 * i] and store in m0[i]\n    this.pow(m[2 * i], m[i] = []);\n    i >>= 1;\n  }\n  i = 2;\n  while(i < half) {\n    for(var j = 1; j < i; ++j) {\n      var m_i = m[i];\n      var m_j = m[j];\n      m[i + j] = [\n        m_i[0] ^ m_j[0],\n        m_i[1] ^ m_j[1],\n        m_i[2] ^ m_j[2],\n        m_i[3] ^ m_j[3]\n      ];\n    }\n    i *= 2;\n  }\n  m[0] = [0, 0, 0, 0];\n  /* Note: We could avoid storing these by doing composition during multiply\n  calculate top half using composition by speed is preferred. */\n  for(i = half + 1; i < size; ++i) {\n    var c = m[i ^ half];\n    m[i] = [mid[0] ^ c[0], mid[1] ^ c[1], mid[2] ^ c[2], mid[3] ^ c[3]];\n  }\n  return m;\n};\n\n/** Utility functions */\n\nfunction transformIV(iv, blockSize) {\n  if(typeof iv === 'string') {\n    // convert iv string into byte buffer\n    iv = forge.util.createBuffer(iv);\n  }\n\n  if(forge.util.isArray(iv) && iv.length > 4) {\n    // convert iv byte array into byte buffer\n    var tmp = iv;\n    iv = forge.util.createBuffer();\n    for(var i = 0; i < tmp.length; ++i) {\n      iv.putByte(tmp[i]);\n    }\n  }\n\n  if(iv.length() < blockSize) {\n    throw new Error(\n      'Invalid IV length; got ' + iv.length() +\n      ' bytes and expected ' + blockSize + ' bytes.');\n  }\n\n  if(!forge.util.isArray(iv)) {\n    // convert iv byte buffer into 32-bit integer array\n    var ints = [];\n    var blocks = blockSize / 4;\n    for(var i = 0; i < blocks; ++i) {\n      ints.push(iv.getInt32());\n    }\n    iv = ints;\n  }\n\n  return iv;\n}\n\nfunction inc32(block) {\n  // increment last 32 bits of block only\n  block[block.length - 1] = (block[block.length - 1] + 1) & 0xFFFFFFFF;\n}\n\nfunction from64To32(num) {\n  // convert 64-bit number to two BE Int32s\n  return [(num / 0x100000000) | 0, num & 0xFFFFFFFF];\n}\n","/**\n * DES (Data Encryption Standard) implementation.\n *\n * This implementation supports DES as well as 3DES-EDE in ECB and CBC mode.\n * It is based on the BSD-licensed implementation by Paul Tero:\n *\n * Paul Tero, July 2001\n * http://www.tero.co.uk/des/\n *\n * Optimised for performance with large blocks by\n * Michael Hayworth, November 2001\n * http://www.netdealing.com\n *\n * THIS SOFTWARE IS PROVIDED \"AS IS\" AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n * @author Stefan Siegl\n * @author Dave Longley\n *\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n * Copyright (c) 2012-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./cipher');\nrequire('./cipherModes');\nrequire('./util');\n\n/* DES API */\nmodule.exports = forge.des = forge.des || {};\n\n/**\n * Deprecated. Instead, use:\n *\n * var cipher = forge.cipher.createCipher('DES-<mode>', key);\n * cipher.start({iv: iv});\n *\n * Creates an DES cipher object to encrypt data using the given symmetric key.\n * The output will be stored in the 'output' member of the returned cipher.\n *\n * The key and iv may be given as binary-encoded strings of bytes or\n * byte buffers.\n *\n * @param key the symmetric key to use (64 or 192 bits).\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n * @param mode the cipher mode to use (default: 'CBC' if IV is\n *          given, 'ECB' if null).\n *\n * @return the cipher.\n */\nforge.des.startEncrypting = function(key, iv, output, mode) {\n  var cipher = _createCipher({\n    key: key,\n    output: output,\n    decrypt: false,\n    mode: mode || (iv === null ? 'ECB' : 'CBC')\n  });\n  cipher.start(iv);\n  return cipher;\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var cipher = forge.cipher.createCipher('DES-<mode>', key);\n *\n * Creates an DES cipher object to encrypt data using the given symmetric key.\n *\n * The key may be given as a binary-encoded string of bytes or a byte buffer.\n *\n * @param key the symmetric key to use (64 or 192 bits).\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.des.createEncryptionCipher = function(key, mode) {\n  return _createCipher({\n    key: key,\n    output: null,\n    decrypt: false,\n    mode: mode\n  });\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var decipher = forge.cipher.createDecipher('DES-<mode>', key);\n * decipher.start({iv: iv});\n *\n * Creates an DES cipher object to decrypt data using the given symmetric key.\n * The output will be stored in the 'output' member of the returned cipher.\n *\n * The key and iv may be given as binary-encoded strings of bytes or\n * byte buffers.\n *\n * @param key the symmetric key to use (64 or 192 bits).\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n * @param mode the cipher mode to use (default: 'CBC' if IV is\n *          given, 'ECB' if null).\n *\n * @return the cipher.\n */\nforge.des.startDecrypting = function(key, iv, output, mode) {\n  var cipher = _createCipher({\n    key: key,\n    output: output,\n    decrypt: true,\n    mode: mode || (iv === null ? 'ECB' : 'CBC')\n  });\n  cipher.start(iv);\n  return cipher;\n};\n\n/**\n * Deprecated. Instead, use:\n *\n * var decipher = forge.cipher.createDecipher('DES-<mode>', key);\n *\n * Creates an DES cipher object to decrypt data using the given symmetric key.\n *\n * The key may be given as a binary-encoded string of bytes or a byte buffer.\n *\n * @param key the symmetric key to use (64 or 192 bits).\n * @param mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nforge.des.createDecryptionCipher = function(key, mode) {\n  return _createCipher({\n    key: key,\n    output: null,\n    decrypt: true,\n    mode: mode\n  });\n};\n\n/**\n * Creates a new DES cipher algorithm object.\n *\n * @param name the name of the algorithm.\n * @param mode the mode factory function.\n *\n * @return the DES algorithm object.\n */\nforge.des.Algorithm = function(name, mode) {\n  var self = this;\n  self.name = name;\n  self.mode = new mode({\n    blockSize: 8,\n    cipher: {\n      encrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._keys, inBlock, outBlock, false);\n      },\n      decrypt: function(inBlock, outBlock) {\n        return _updateBlock(self._keys, inBlock, outBlock, true);\n      }\n    }\n  });\n  self._init = false;\n};\n\n/**\n * Initializes this DES algorithm by expanding its key.\n *\n * @param options the options to use.\n *          key the key to use with this algorithm.\n *          decrypt true if the algorithm should be initialized for decryption,\n *            false for encryption.\n */\nforge.des.Algorithm.prototype.initialize = function(options) {\n  if(this._init) {\n    return;\n  }\n\n  var key = forge.util.createBuffer(options.key);\n  if(this.name.indexOf('3DES') === 0) {\n    if(key.length() !== 24) {\n      throw new Error('Invalid Triple-DES key size: ' + key.length() * 8);\n    }\n  }\n\n  // do key expansion to 16 or 48 subkeys (single or triple DES)\n  this._keys = _createKeys(key);\n  this._init = true;\n};\n\n/** Register DES algorithms **/\n\nregisterAlgorithm('DES-ECB', forge.cipher.modes.ecb);\nregisterAlgorithm('DES-CBC', forge.cipher.modes.cbc);\nregisterAlgorithm('DES-CFB', forge.cipher.modes.cfb);\nregisterAlgorithm('DES-OFB', forge.cipher.modes.ofb);\nregisterAlgorithm('DES-CTR', forge.cipher.modes.ctr);\n\nregisterAlgorithm('3DES-ECB', forge.cipher.modes.ecb);\nregisterAlgorithm('3DES-CBC', forge.cipher.modes.cbc);\nregisterAlgorithm('3DES-CFB', forge.cipher.modes.cfb);\nregisterAlgorithm('3DES-OFB', forge.cipher.modes.ofb);\nregisterAlgorithm('3DES-CTR', forge.cipher.modes.ctr);\n\nfunction registerAlgorithm(name, mode) {\n  var factory = function() {\n    return new forge.des.Algorithm(name, mode);\n  };\n  forge.cipher.registerAlgorithm(name, factory);\n}\n\n/** DES implementation **/\n\nvar spfunction1 = [0x1010400,0,0x10000,0x1010404,0x1010004,0x10404,0x4,0x10000,0x400,0x1010400,0x1010404,0x400,0x1000404,0x1010004,0x1000000,0x4,0x404,0x1000400,0x1000400,0x10400,0x10400,0x1010000,0x1010000,0x1000404,0x10004,0x1000004,0x1000004,0x10004,0,0x404,0x10404,0x1000000,0x10000,0x1010404,0x4,0x1010000,0x1010400,0x1000000,0x1000000,0x400,0x1010004,0x10000,0x10400,0x1000004,0x400,0x4,0x1000404,0x10404,0x1010404,0x10004,0x1010000,0x1000404,0x1000004,0x404,0x10404,0x1010400,0x404,0x1000400,0x1000400,0,0x10004,0x10400,0,0x1010004];\nvar spfunction2 = [-0x7fef7fe0,-0x7fff8000,0x8000,0x108020,0x100000,0x20,-0x7fefffe0,-0x7fff7fe0,-0x7fffffe0,-0x7fef7fe0,-0x7fef8000,-0x80000000,-0x7fff8000,0x100000,0x20,-0x7fefffe0,0x108000,0x100020,-0x7fff7fe0,0,-0x80000000,0x8000,0x108020,-0x7ff00000,0x100020,-0x7fffffe0,0,0x108000,0x8020,-0x7fef8000,-0x7ff00000,0x8020,0,0x108020,-0x7fefffe0,0x100000,-0x7fff7fe0,-0x7ff00000,-0x7fef8000,0x8000,-0x7ff00000,-0x7fff8000,0x20,-0x7fef7fe0,0x108020,0x20,0x8000,-0x80000000,0x8020,-0x7fef8000,0x100000,-0x7fffffe0,0x100020,-0x7fff7fe0,-0x7fffffe0,0x100020,0x108000,0,-0x7fff8000,0x8020,-0x80000000,-0x7fefffe0,-0x7fef7fe0,0x108000];\nvar spfunction3 = [0x208,0x8020200,0,0x8020008,0x8000200,0,0x20208,0x8000200,0x20008,0x8000008,0x8000008,0x20000,0x8020208,0x20008,0x8020000,0x208,0x8000000,0x8,0x8020200,0x200,0x20200,0x8020000,0x8020008,0x20208,0x8000208,0x20200,0x20000,0x8000208,0x8,0x8020208,0x200,0x8000000,0x8020200,0x8000000,0x20008,0x208,0x20000,0x8020200,0x8000200,0,0x200,0x20008,0x8020208,0x8000200,0x8000008,0x200,0,0x8020008,0x8000208,0x20000,0x8000000,0x8020208,0x8,0x20208,0x20200,0x8000008,0x8020000,0x8000208,0x208,0x8020000,0x20208,0x8,0x8020008,0x20200];\nvar spfunction4 = [0x802001,0x2081,0x2081,0x80,0x802080,0x800081,0x800001,0x2001,0,0x802000,0x802000,0x802081,0x81,0,0x800080,0x800001,0x1,0x2000,0x800000,0x802001,0x80,0x800000,0x2001,0x2080,0x800081,0x1,0x2080,0x800080,0x2000,0x802080,0x802081,0x81,0x800080,0x800001,0x802000,0x802081,0x81,0,0,0x802000,0x2080,0x800080,0x800081,0x1,0x802001,0x2081,0x2081,0x80,0x802081,0x81,0x1,0x2000,0x800001,0x2001,0x802080,0x800081,0x2001,0x2080,0x800000,0x802001,0x80,0x800000,0x2000,0x802080];\nvar spfunction5 = [0x100,0x2080100,0x2080000,0x42000100,0x80000,0x100,0x40000000,0x2080000,0x40080100,0x80000,0x2000100,0x40080100,0x42000100,0x42080000,0x80100,0x40000000,0x2000000,0x40080000,0x40080000,0,0x40000100,0x42080100,0x42080100,0x2000100,0x42080000,0x40000100,0,0x42000000,0x2080100,0x2000000,0x42000000,0x80100,0x80000,0x42000100,0x100,0x2000000,0x40000000,0x2080000,0x42000100,0x40080100,0x2000100,0x40000000,0x42080000,0x2080100,0x40080100,0x100,0x2000000,0x42080000,0x42080100,0x80100,0x42000000,0x42080100,0x2080000,0,0x40080000,0x42000000,0x80100,0x2000100,0x40000100,0x80000,0,0x40080000,0x2080100,0x40000100];\nvar spfunction6 = [0x20000010,0x20400000,0x4000,0x20404010,0x20400000,0x10,0x20404010,0x400000,0x20004000,0x404010,0x400000,0x20000010,0x400010,0x20004000,0x20000000,0x4010,0,0x400010,0x20004010,0x4000,0x404000,0x20004010,0x10,0x20400010,0x20400010,0,0x404010,0x20404000,0x4010,0x404000,0x20404000,0x20000000,0x20004000,0x10,0x20400010,0x404000,0x20404010,0x400000,0x4010,0x20000010,0x400000,0x20004000,0x20000000,0x4010,0x20000010,0x20404010,0x404000,0x20400000,0x404010,0x20404000,0,0x20400010,0x10,0x4000,0x20400000,0x404010,0x4000,0x400010,0x20004010,0,0x20404000,0x20000000,0x400010,0x20004010];\nvar spfunction7 = [0x200000,0x4200002,0x4000802,0,0x800,0x4000802,0x200802,0x4200800,0x4200802,0x200000,0,0x4000002,0x2,0x4000000,0x4200002,0x802,0x4000800,0x200802,0x200002,0x4000800,0x4000002,0x4200000,0x4200800,0x200002,0x4200000,0x800,0x802,0x4200802,0x200800,0x2,0x4000000,0x200800,0x4000000,0x200800,0x200000,0x4000802,0x4000802,0x4200002,0x4200002,0x2,0x200002,0x4000000,0x4000800,0x200000,0x4200800,0x802,0x200802,0x4200800,0x802,0x4000002,0x4200802,0x4200000,0x200800,0,0x2,0x4200802,0,0x200802,0x4200000,0x800,0x4000002,0x4000800,0x800,0x200002];\nvar spfunction8 = [0x10001040,0x1000,0x40000,0x10041040,0x10000000,0x10001040,0x40,0x10000000,0x40040,0x10040000,0x10041040,0x41000,0x10041000,0x41040,0x1000,0x40,0x10040000,0x10000040,0x10001000,0x1040,0x41000,0x40040,0x10040040,0x10041000,0x1040,0,0,0x10040040,0x10000040,0x10001000,0x41040,0x40000,0x41040,0x40000,0x10041000,0x1000,0x40,0x10040040,0x1000,0x41040,0x10001000,0x40,0x10000040,0x10040000,0x10040040,0x10000000,0x40000,0x10001040,0,0x10041040,0x40040,0x10000040,0x10040000,0x10001000,0x10001040,0,0x10041040,0x41000,0x41000,0x1040,0x1040,0x40040,0x10000000,0x10041000];\n\n/**\n * Create necessary sub keys.\n *\n * @param key the 64-bit or 192-bit key.\n *\n * @return the expanded keys.\n */\nfunction _createKeys(key) {\n  var pc2bytes0  = [0,0x4,0x20000000,0x20000004,0x10000,0x10004,0x20010000,0x20010004,0x200,0x204,0x20000200,0x20000204,0x10200,0x10204,0x20010200,0x20010204],\n      pc2bytes1  = [0,0x1,0x100000,0x100001,0x4000000,0x4000001,0x4100000,0x4100001,0x100,0x101,0x100100,0x100101,0x4000100,0x4000101,0x4100100,0x4100101],\n      pc2bytes2  = [0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808,0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808],\n      pc2bytes3  = [0,0x200000,0x8000000,0x8200000,0x2000,0x202000,0x8002000,0x8202000,0x20000,0x220000,0x8020000,0x8220000,0x22000,0x222000,0x8022000,0x8222000],\n      pc2bytes4  = [0,0x40000,0x10,0x40010,0,0x40000,0x10,0x40010,0x1000,0x41000,0x1010,0x41010,0x1000,0x41000,0x1010,0x41010],\n      pc2bytes5  = [0,0x400,0x20,0x420,0,0x400,0x20,0x420,0x2000000,0x2000400,0x2000020,0x2000420,0x2000000,0x2000400,0x2000020,0x2000420],\n      pc2bytes6  = [0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002,0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002],\n      pc2bytes7  = [0,0x10000,0x800,0x10800,0x20000000,0x20010000,0x20000800,0x20010800,0x20000,0x30000,0x20800,0x30800,0x20020000,0x20030000,0x20020800,0x20030800],\n      pc2bytes8  = [0,0x40000,0,0x40000,0x2,0x40002,0x2,0x40002,0x2000000,0x2040000,0x2000000,0x2040000,0x2000002,0x2040002,0x2000002,0x2040002],\n      pc2bytes9  = [0,0x10000000,0x8,0x10000008,0,0x10000000,0x8,0x10000008,0x400,0x10000400,0x408,0x10000408,0x400,0x10000400,0x408,0x10000408],\n      pc2bytes10 = [0,0x20,0,0x20,0x100000,0x100020,0x100000,0x100020,0x2000,0x2020,0x2000,0x2020,0x102000,0x102020,0x102000,0x102020],\n      pc2bytes11 = [0,0x1000000,0x200,0x1000200,0x200000,0x1200000,0x200200,0x1200200,0x4000000,0x5000000,0x4000200,0x5000200,0x4200000,0x5200000,0x4200200,0x5200200],\n      pc2bytes12 = [0,0x1000,0x8000000,0x8001000,0x80000,0x81000,0x8080000,0x8081000,0x10,0x1010,0x8000010,0x8001010,0x80010,0x81010,0x8080010,0x8081010],\n      pc2bytes13 = [0,0x4,0x100,0x104,0,0x4,0x100,0x104,0x1,0x5,0x101,0x105,0x1,0x5,0x101,0x105];\n\n  // how many iterations (1 for des, 3 for triple des)\n  // changed by Paul 16/6/2007 to use Triple DES for 9+ byte keys\n  var iterations = key.length() > 8 ? 3 : 1;\n\n  // stores the return keys\n  var keys = [];\n\n  // now define the left shifts which need to be done\n  var shifts = [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0];\n\n  var n = 0, tmp;\n  for(var j = 0; j < iterations; j++) {\n    var left = key.getInt32();\n    var right = key.getInt32();\n\n    tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;\n    right ^= tmp;\n    left ^= (tmp << 4);\n\n    tmp = ((right >>> -16) ^ left) & 0x0000ffff;\n    left ^= tmp;\n    right ^= (tmp << -16);\n\n    tmp = ((left >>> 2) ^ right) & 0x33333333;\n    right ^= tmp;\n    left ^= (tmp << 2);\n\n    tmp = ((right >>> -16) ^ left) & 0x0000ffff;\n    left ^= tmp;\n    right ^= (tmp << -16);\n\n    tmp = ((left >>> 1) ^ right) & 0x55555555;\n    right ^= tmp;\n    left ^= (tmp << 1);\n\n    tmp = ((right >>> 8) ^ left) & 0x00ff00ff;\n    left ^= tmp;\n    right ^= (tmp << 8);\n\n    tmp = ((left >>> 1) ^ right) & 0x55555555;\n    right ^= tmp;\n    left ^= (tmp << 1);\n\n    // right needs to be shifted and OR'd with last four bits of left\n    tmp = (left << 8) | ((right >>> 20) & 0x000000f0);\n\n    // left needs to be put upside down\n    left = ((right << 24) | ((right << 8) & 0xff0000) |\n      ((right >>> 8) & 0xff00) | ((right >>> 24) & 0xf0));\n    right = tmp;\n\n    // now go through and perform these shifts on the left and right keys\n    for(var i = 0; i < shifts.length; ++i) {\n      //shift the keys either one or two bits to the left\n      if(shifts[i]) {\n        left = (left << 2) | (left >>> 26);\n        right = (right << 2) | (right >>> 26);\n      } else {\n        left = (left << 1) | (left >>> 27);\n        right = (right << 1) | (right >>> 27);\n      }\n      left &= -0xf;\n      right &= -0xf;\n\n      // now apply PC-2, in such a way that E is easier when encrypting or\n      // decrypting this conversion will look like PC-2 except only the last 6\n      // bits of each byte are used rather than 48 consecutive bits and the\n      // order of lines will be according to how the S selection functions will\n      // be applied: S2, S4, S6, S8, S1, S3, S5, S7\n      var lefttmp = (\n        pc2bytes0[left >>> 28] | pc2bytes1[(left >>> 24) & 0xf] |\n        pc2bytes2[(left >>> 20) & 0xf] | pc2bytes3[(left >>> 16) & 0xf] |\n        pc2bytes4[(left >>> 12) & 0xf] | pc2bytes5[(left >>> 8) & 0xf] |\n        pc2bytes6[(left >>> 4) & 0xf]);\n      var righttmp = (\n        pc2bytes7[right >>> 28] | pc2bytes8[(right >>> 24) & 0xf] |\n        pc2bytes9[(right >>> 20) & 0xf] | pc2bytes10[(right >>> 16) & 0xf] |\n        pc2bytes11[(right >>> 12) & 0xf] | pc2bytes12[(right >>> 8) & 0xf] |\n        pc2bytes13[(right >>> 4) & 0xf]);\n      tmp = ((righttmp >>> 16) ^ lefttmp) & 0x0000ffff;\n      keys[n++] = lefttmp ^ tmp;\n      keys[n++] = righttmp ^ (tmp << 16);\n    }\n  }\n\n  return keys;\n}\n\n/**\n * Updates a single block (1 byte) using DES. The update will either\n * encrypt or decrypt the block.\n *\n * @param keys the expanded keys.\n * @param input the input block (an array of 32-bit words).\n * @param output the updated output block.\n * @param decrypt true to decrypt the block, false to encrypt it.\n */\nfunction _updateBlock(keys, input, output, decrypt) {\n  // set up loops for single or triple DES\n  var iterations = keys.length === 32 ? 3 : 9;\n  var looping;\n  if(iterations === 3) {\n    looping = decrypt ? [30, -2, -2] : [0, 32, 2];\n  } else {\n    looping = (decrypt ?\n      [94, 62, -2, 32, 64, 2, 30, -2, -2] :\n      [0, 32, 2, 62, 30, -2, 64, 96, 2]);\n  }\n\n  var tmp;\n\n  var left = input[0];\n  var right = input[1];\n\n  // first each 64 bit chunk of the message must be permuted according to IP\n  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;\n  right ^= tmp;\n  left ^= (tmp << 4);\n\n  tmp = ((left >>> 16) ^ right) & 0x0000ffff;\n  right ^= tmp;\n  left ^= (tmp << 16);\n\n  tmp = ((right >>> 2) ^ left) & 0x33333333;\n  left ^= tmp;\n  right ^= (tmp << 2);\n\n  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;\n  left ^= tmp;\n  right ^= (tmp << 8);\n\n  tmp = ((left >>> 1) ^ right) & 0x55555555;\n  right ^= tmp;\n  left ^= (tmp << 1);\n\n  // rotate left 1 bit\n  left = ((left << 1) | (left >>> 31));\n  right = ((right << 1) | (right >>> 31));\n\n  for(var j = 0; j < iterations; j += 3) {\n    var endloop = looping[j + 1];\n    var loopinc = looping[j + 2];\n\n    // now go through and perform the encryption or decryption\n    for(var i = looping[j]; i != endloop; i += loopinc) {\n      var right1 = right ^ keys[i];\n      var right2 = ((right >>> 4) | (right << 28)) ^ keys[i + 1];\n\n      // passing these bytes through the S selection functions\n      tmp = left;\n      left = right;\n      right = tmp ^ (\n        spfunction2[(right1 >>> 24) & 0x3f] |\n        spfunction4[(right1 >>> 16) & 0x3f] |\n        spfunction6[(right1 >>>  8) & 0x3f] |\n        spfunction8[right1 & 0x3f] |\n        spfunction1[(right2 >>> 24) & 0x3f] |\n        spfunction3[(right2 >>> 16) & 0x3f] |\n        spfunction5[(right2 >>>  8) & 0x3f] |\n        spfunction7[right2 & 0x3f]);\n    }\n    // unreverse left and right\n    tmp = left;\n    left = right;\n    right = tmp;\n  }\n\n  // rotate right 1 bit\n  left = ((left >>> 1) | (left << 31));\n  right = ((right >>> 1) | (right << 31));\n\n  // now perform IP-1, which is IP in the opposite direction\n  tmp = ((left >>> 1) ^ right) & 0x55555555;\n  right ^= tmp;\n  left ^= (tmp << 1);\n\n  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;\n  left ^= tmp;\n  right ^= (tmp << 8);\n\n  tmp = ((right >>> 2) ^ left) & 0x33333333;\n  left ^= tmp;\n  right ^= (tmp << 2);\n\n  tmp = ((left >>> 16) ^ right) & 0x0000ffff;\n  right ^= tmp;\n  left ^= (tmp << 16);\n\n  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;\n  right ^= tmp;\n  left ^= (tmp << 4);\n\n  output[0] = left;\n  output[1] = right;\n}\n\n/**\n * Deprecated. Instead, use:\n *\n * forge.cipher.createCipher('DES-<mode>', key);\n * forge.cipher.createDecipher('DES-<mode>', key);\n *\n * Creates a deprecated DES cipher object. This object's mode will default to\n * CBC (cipher-block-chaining).\n *\n * The key may be given as a binary-encoded string of bytes or a byte buffer.\n *\n * @param options the options to use.\n *          key the symmetric key to use (64 or 192 bits).\n *          output the buffer to write to.\n *          decrypt true for decryption, false for encryption.\n *          mode the cipher mode to use (default: 'CBC').\n *\n * @return the cipher.\n */\nfunction _createCipher(options) {\n  options = options || {};\n  var mode = (options.mode || 'CBC').toUpperCase();\n  var algorithm = 'DES-' + mode;\n\n  var cipher;\n  if(options.decrypt) {\n    cipher = forge.cipher.createDecipher(algorithm, options.key);\n  } else {\n    cipher = forge.cipher.createCipher(algorithm, options.key);\n  }\n\n  // backwards compatible start API\n  var start = cipher.start;\n  cipher.start = function(iv, options) {\n    // backwards compatibility: support second arg as output buffer\n    var output = null;\n    if(options instanceof forge.util.ByteBuffer) {\n      output = options;\n      options = {};\n    }\n    options = options || {};\n    options.output = output;\n    options.iv = iv;\n    start.call(cipher, options);\n  };\n\n  return cipher;\n}\n","/**\n * Node.js module for Forge.\n *\n * @author Dave Longley\n *\n * Copyright 2011-2016 Digital Bazaar, Inc.\n */\nmodule.exports = {\n  // default options\n  options: {\n    usePureJavaScript: false\n  }\n};\n","/**\n * Hash-based Message Authentication Code implementation. Requires a message\n * digest object that can be obtained, for example, from forge.md.sha1 or\n * forge.md.md5.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2012 Digital Bazaar, Inc. All rights reserved.\n */\nvar forge = require('./forge');\nrequire('./md');\nrequire('./util');\n\n/* HMAC API */\nvar hmac = module.exports = forge.hmac = forge.hmac || {};\n\n/**\n * Creates an HMAC object that uses the given message digest object.\n *\n * @return an HMAC object.\n */\nhmac.create = function() {\n  // the hmac key to use\n  var _key = null;\n\n  // the message digest to use\n  var _md = null;\n\n  // the inner padding\n  var _ipadding = null;\n\n  // the outer padding\n  var _opadding = null;\n\n  // hmac context\n  var ctx = {};\n\n  /**\n   * Starts or restarts the HMAC with the given key and message digest.\n   *\n   * @param md the message digest to use, null to reuse the previous one,\n   *           a string to use builtin 'sha1', 'md5', 'sha256'.\n   * @param key the key to use as a string, array of bytes, byte buffer,\n   *           or null to reuse the previous key.\n   */\n  ctx.start = function(md, key) {\n    if(md !== null) {\n      if(typeof md === 'string') {\n        // create builtin message digest\n        md = md.toLowerCase();\n        if(md in forge.md.algorithms) {\n          _md = forge.md.algorithms[md].create();\n        } else {\n          throw new Error('Unknown hash algorithm \"' + md + '\"');\n        }\n      } else {\n        // store message digest\n        _md = md;\n      }\n    }\n\n    if(key === null) {\n      // reuse previous key\n      key = _key;\n    } else {\n      if(typeof key === 'string') {\n        // convert string into byte buffer\n        key = forge.util.createBuffer(key);\n      } else if(forge.util.isArray(key)) {\n        // convert byte array into byte buffer\n        var tmp = key;\n        key = forge.util.createBuffer();\n        for(var i = 0; i < tmp.length; ++i) {\n          key.putByte(tmp[i]);\n        }\n      }\n\n      // if key is longer than blocksize, hash it\n      var keylen = key.length();\n      if(keylen > _md.blockLength) {\n        _md.start();\n        _md.update(key.bytes());\n        key = _md.digest();\n      }\n\n      // mix key into inner and outer padding\n      // ipadding = [0x36 * blocksize] ^ key\n      // opadding = [0x5C * blocksize] ^ key\n      _ipadding = forge.util.createBuffer();\n      _opadding = forge.util.createBuffer();\n      keylen = key.length();\n      for(var i = 0; i < keylen; ++i) {\n        var tmp = key.at(i);\n        _ipadding.putByte(0x36 ^ tmp);\n        _opadding.putByte(0x5C ^ tmp);\n      }\n\n      // if key is shorter than blocksize, add additional padding\n      if(keylen < _md.blockLength) {\n        var tmp = _md.blockLength - keylen;\n        for(var i = 0; i < tmp; ++i) {\n          _ipadding.putByte(0x36);\n          _opadding.putByte(0x5C);\n        }\n      }\n      _key = key;\n      _ipadding = _ipadding.bytes();\n      _opadding = _opadding.bytes();\n    }\n\n    // digest is done like so: hash(opadding | hash(ipadding | message))\n\n    // prepare to do inner hash\n    // hash(ipadding | message)\n    _md.start();\n    _md.update(_ipadding);\n  };\n\n  /**\n   * Updates the HMAC with the given message bytes.\n   *\n   * @param bytes the bytes to update with.\n   */\n  ctx.update = function(bytes) {\n    _md.update(bytes);\n  };\n\n  /**\n   * Produces the Message Authentication Code (MAC).\n   *\n   * @return a byte buffer containing the digest value.\n   */\n  ctx.getMac = function() {\n    // digest is done like so: hash(opadding | hash(ipadding | message))\n    // here we do the outer hashing\n    var inner = _md.digest().bytes();\n    _md.start();\n    _md.update(_opadding);\n    _md.update(inner);\n    return _md.digest();\n  };\n  // alias for getMac\n  ctx.digest = ctx.getMac;\n\n  return ctx;\n};\n","// Copyright (c) 2005  Tom Wu\n// All Rights Reserved.\n// See \"LICENSE\" for details.\n\n// Basic JavaScript BN library - subset useful for RSA encryption.\n\n/*\nLicensing (LICENSE)\n-------------------\n\nThis software is covered under the following copyright:\n*/\n/*\n * Copyright (c) 2003-2005  Tom Wu\n * All Rights Reserved.\n *\n * Permission is hereby granted, free of charge, to any person obtaining\n * a copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sublicense, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be\n * included in all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS-IS\" AND WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY\n * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\n *\n * IN NO EVENT SHALL TOM WU BE LIABLE FOR ANY SPECIAL, INCIDENTAL,\n * INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND, OR ANY DAMAGES WHATSOEVER\n * RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER OR NOT ADVISED OF\n * THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF LIABILITY, ARISING OUT\n * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n *\n * In addition, the following condition applies:\n *\n * All redistributions must retain an intact copy of this copyright notice\n * and disclaimer.\n */\n/*\nAddress all questions regarding this license to:\n\n  Tom Wu\n  tjw@cs.Stanford.EDU\n*/\nvar forge = require('./forge');\n\nmodule.exports = forge.jsbn = forge.jsbn || {};\n\n// Bits per digit\nvar dbits;\n\n// JavaScript engine analysis\nvar canary = 0xdeadbeefcafe;\nvar j_lm = ((canary&0xffffff)==0xefcafe);\n\n// (public) Constructor\nfunction BigInteger(a,b,c) {\n  this.data = [];\n  if(a != null)\n    if(\"number\" == typeof a) this.fromNumber(a,b,c);\n    else if(b == null && \"string\" != typeof a) this.fromString(a,256);\n    else this.fromString(a,b);\n}\nforge.jsbn.BigInteger = BigInteger;\n\n// return new, unset BigInteger\nfunction nbi() { return new BigInteger(null); }\n\n// am: Compute w_j += (x*this_i), propagate carries,\n// c is initial carry, returns final carry.\n// c < 3*dvalue, x < 2*dvalue, this_i < dvalue\n// We need to select the fastest one that works in this environment.\n\n// am1: use a single mult and divide to get the high bits,\n// max digit bits should be 26 because\n// max internal value = 2*dvalue^2-2*dvalue (< 2^53)\nfunction am1(i,x,w,j,c,n) {\n  while(--n >= 0) {\n    var v = x*this.data[i++]+w.data[j]+c;\n    c = Math.floor(v/0x4000000);\n    w.data[j++] = v&0x3ffffff;\n  }\n  return c;\n}\n// am2 avoids a big mult-and-extract completely.\n// Max digit bits should be <= 30 because we do bitwise ops\n// on values up to 2*hdvalue^2-hdvalue-1 (< 2^31)\nfunction am2(i,x,w,j,c,n) {\n  var xl = x&0x7fff, xh = x>>15;\n  while(--n >= 0) {\n    var l = this.data[i]&0x7fff;\n    var h = this.data[i++]>>15;\n    var m = xh*l+h*xl;\n    l = xl*l+((m&0x7fff)<<15)+w.data[j]+(c&0x3fffffff);\n    c = (l>>>30)+(m>>>15)+xh*h+(c>>>30);\n    w.data[j++] = l&0x3fffffff;\n  }\n  return c;\n}\n// Alternately, set max digit bits to 28 since some\n// browsers slow down when dealing with 32-bit numbers.\nfunction am3(i,x,w,j,c,n) {\n  var xl = x&0x3fff, xh = x>>14;\n  while(--n >= 0) {\n    var l = this.data[i]&0x3fff;\n    var h = this.data[i++]>>14;\n    var m = xh*l+h*xl;\n    l = xl*l+((m&0x3fff)<<14)+w.data[j]+c;\n    c = (l>>28)+(m>>14)+xh*h;\n    w.data[j++] = l&0xfffffff;\n  }\n  return c;\n}\n\n// node.js (no browser)\nif(typeof(navigator) === 'undefined')\n{\n   BigInteger.prototype.am = am3;\n   dbits = 28;\n} else if(j_lm && (navigator.appName == \"Microsoft Internet Explorer\")) {\n  BigInteger.prototype.am = am2;\n  dbits = 30;\n} else if(j_lm && (navigator.appName != \"Netscape\")) {\n  BigInteger.prototype.am = am1;\n  dbits = 26;\n} else { // Mozilla/Netscape seems to prefer am3\n  BigInteger.prototype.am = am3;\n  dbits = 28;\n}\n\nBigInteger.prototype.DB = dbits;\nBigInteger.prototype.DM = ((1<<dbits)-1);\nBigInteger.prototype.DV = (1<<dbits);\n\nvar BI_FP = 52;\nBigInteger.prototype.FV = Math.pow(2,BI_FP);\nBigInteger.prototype.F1 = BI_FP-dbits;\nBigInteger.prototype.F2 = 2*dbits-BI_FP;\n\n// Digit conversions\nvar BI_RM = \"0123456789abcdefghijklmnopqrstuvwxyz\";\nvar BI_RC = new Array();\nvar rr,vv;\nrr = \"0\".charCodeAt(0);\nfor(vv = 0; vv <= 9; ++vv) BI_RC[rr++] = vv;\nrr = \"a\".charCodeAt(0);\nfor(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;\nrr = \"A\".charCodeAt(0);\nfor(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;\n\nfunction int2char(n) { return BI_RM.charAt(n); }\nfunction intAt(s,i) {\n  var c = BI_RC[s.charCodeAt(i)];\n  return (c==null)?-1:c;\n}\n\n// (protected) copy this to r\nfunction bnpCopyTo(r) {\n  for(var i = this.t-1; i >= 0; --i) r.data[i] = this.data[i];\n  r.t = this.t;\n  r.s = this.s;\n}\n\n// (protected) set from integer value x, -DV <= x < DV\nfunction bnpFromInt(x) {\n  this.t = 1;\n  this.s = (x<0)?-1:0;\n  if(x > 0) this.data[0] = x;\n  else if(x < -1) this.data[0] = x+this.DV;\n  else this.t = 0;\n}\n\n// return bigint initialized to value\nfunction nbv(i) { var r = nbi(); r.fromInt(i); return r; }\n\n// (protected) set from string and radix\nfunction bnpFromString(s,b) {\n  var k;\n  if(b == 16) k = 4;\n  else if(b == 8) k = 3;\n  else if(b == 256) k = 8; // byte array\n  else if(b == 2) k = 1;\n  else if(b == 32) k = 5;\n  else if(b == 4) k = 2;\n  else { this.fromRadix(s,b); return; }\n  this.t = 0;\n  this.s = 0;\n  var i = s.length, mi = false, sh = 0;\n  while(--i >= 0) {\n    var x = (k==8)?s[i]&0xff:intAt(s,i);\n    if(x < 0) {\n      if(s.charAt(i) == \"-\") mi = true;\n      continue;\n    }\n    mi = false;\n    if(sh == 0)\n      this.data[this.t++] = x;\n    else if(sh+k > this.DB) {\n      this.data[this.t-1] |= (x&((1<<(this.DB-sh))-1))<<sh;\n      this.data[this.t++] = (x>>(this.DB-sh));\n    } else\n      this.data[this.t-1] |= x<<sh;\n    sh += k;\n    if(sh >= this.DB) sh -= this.DB;\n  }\n  if(k == 8 && (s[0]&0x80) != 0) {\n    this.s = -1;\n    if(sh > 0) this.data[this.t-1] |= ((1<<(this.DB-sh))-1)<<sh;\n  }\n  this.clamp();\n  if(mi) BigInteger.ZERO.subTo(this,this);\n}\n\n// (protected) clamp off excess high words\nfunction bnpClamp() {\n  var c = this.s&this.DM;\n  while(this.t > 0 && this.data[this.t-1] == c) --this.t;\n}\n\n// (public) return string representation in given radix\nfunction bnToString(b) {\n  if(this.s < 0) return \"-\"+this.negate().toString(b);\n  var k;\n  if(b == 16) k = 4;\n  else if(b == 8) k = 3;\n  else if(b == 2) k = 1;\n  else if(b == 32) k = 5;\n  else if(b == 4) k = 2;\n  else return this.toRadix(b);\n  var km = (1<<k)-1, d, m = false, r = \"\", i = this.t;\n  var p = this.DB-(i*this.DB)%k;\n  if(i-- > 0) {\n    if(p < this.DB && (d = this.data[i]>>p) > 0) { m = true; r = int2char(d); }\n    while(i >= 0) {\n      if(p < k) {\n        d = (this.data[i]&((1<<p)-1))<<(k-p);\n        d |= this.data[--i]>>(p+=this.DB-k);\n      } else {\n        d = (this.data[i]>>(p-=k))&km;\n        if(p <= 0) { p += this.DB; --i; }\n      }\n      if(d > 0) m = true;\n      if(m) r += int2char(d);\n    }\n  }\n  return m?r:\"0\";\n}\n\n// (public) -this\nfunction bnNegate() { var r = nbi(); BigInteger.ZERO.subTo(this,r); return r; }\n\n// (public) |this|\nfunction bnAbs() { return (this.s<0)?this.negate():this; }\n\n// (public) return + if this > a, - if this < a, 0 if equal\nfunction bnCompareTo(a) {\n  var r = this.s-a.s;\n  if(r != 0) return r;\n  var i = this.t;\n  r = i-a.t;\n  if(r != 0) return (this.s<0)?-r:r;\n  while(--i >= 0) if((r=this.data[i]-a.data[i]) != 0) return r;\n  return 0;\n}\n\n// returns bit length of the integer x\nfunction nbits(x) {\n  var r = 1, t;\n  if((t=x>>>16) != 0) { x = t; r += 16; }\n  if((t=x>>8) != 0) { x = t; r += 8; }\n  if((t=x>>4) != 0) { x = t; r += 4; }\n  if((t=x>>2) != 0) { x = t; r += 2; }\n  if((t=x>>1) != 0) { x = t; r += 1; }\n  return r;\n}\n\n// (public) return the number of bits in \"this\"\nfunction bnBitLength() {\n  if(this.t <= 0) return 0;\n  return this.DB*(this.t-1)+nbits(this.data[this.t-1]^(this.s&this.DM));\n}\n\n// (protected) r = this << n*DB\nfunction bnpDLShiftTo(n,r) {\n  var i;\n  for(i = this.t-1; i >= 0; --i) r.data[i+n] = this.data[i];\n  for(i = n-1; i >= 0; --i) r.data[i] = 0;\n  r.t = this.t+n;\n  r.s = this.s;\n}\n\n// (protected) r = this >> n*DB\nfunction bnpDRShiftTo(n,r) {\n  for(var i = n; i < this.t; ++i) r.data[i-n] = this.data[i];\n  r.t = Math.max(this.t-n,0);\n  r.s = this.s;\n}\n\n// (protected) r = this << n\nfunction bnpLShiftTo(n,r) {\n  var bs = n%this.DB;\n  var cbs = this.DB-bs;\n  var bm = (1<<cbs)-1;\n  var ds = Math.floor(n/this.DB), c = (this.s<<bs)&this.DM, i;\n  for(i = this.t-1; i >= 0; --i) {\n    r.data[i+ds+1] = (this.data[i]>>cbs)|c;\n    c = (this.data[i]&bm)<<bs;\n  }\n  for(i = ds-1; i >= 0; --i) r.data[i] = 0;\n  r.data[ds] = c;\n  r.t = this.t+ds+1;\n  r.s = this.s;\n  r.clamp();\n}\n\n// (protected) r = this >> n\nfunction bnpRShiftTo(n,r) {\n  r.s = this.s;\n  var ds = Math.floor(n/this.DB);\n  if(ds >= this.t) { r.t = 0; return; }\n  var bs = n%this.DB;\n  var cbs = this.DB-bs;\n  var bm = (1<<bs)-1;\n  r.data[0] = this.data[ds]>>bs;\n  for(var i = ds+1; i < this.t; ++i) {\n    r.data[i-ds-1] |= (this.data[i]&bm)<<cbs;\n    r.data[i-ds] = this.data[i]>>bs;\n  }\n  if(bs > 0) r.data[this.t-ds-1] |= (this.s&bm)<<cbs;\n  r.t = this.t-ds;\n  r.clamp();\n}\n\n// (protected) r = this - a\nfunction bnpSubTo(a,r) {\n  var i = 0, c = 0, m = Math.min(a.t,this.t);\n  while(i < m) {\n    c += this.data[i]-a.data[i];\n    r.data[i++] = c&this.DM;\n    c >>= this.DB;\n  }\n  if(a.t < this.t) {\n    c -= a.s;\n    while(i < this.t) {\n      c += this.data[i];\n      r.data[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c += this.s;\n  } else {\n    c += this.s;\n    while(i < a.t) {\n      c -= a.data[i];\n      r.data[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c -= a.s;\n  }\n  r.s = (c<0)?-1:0;\n  if(c < -1) r.data[i++] = this.DV+c;\n  else if(c > 0) r.data[i++] = c;\n  r.t = i;\n  r.clamp();\n}\n\n// (protected) r = this * a, r != this,a (HAC 14.12)\n// \"this\" should be the larger one if appropriate.\nfunction bnpMultiplyTo(a,r) {\n  var x = this.abs(), y = a.abs();\n  var i = x.t;\n  r.t = i+y.t;\n  while(--i >= 0) r.data[i] = 0;\n  for(i = 0; i < y.t; ++i) r.data[i+x.t] = x.am(0,y.data[i],r,i,0,x.t);\n  r.s = 0;\n  r.clamp();\n  if(this.s != a.s) BigInteger.ZERO.subTo(r,r);\n}\n\n// (protected) r = this^2, r != this (HAC 14.16)\nfunction bnpSquareTo(r) {\n  var x = this.abs();\n  var i = r.t = 2*x.t;\n  while(--i >= 0) r.data[i] = 0;\n  for(i = 0; i < x.t-1; ++i) {\n    var c = x.am(i,x.data[i],r,2*i,0,1);\n    if((r.data[i+x.t]+=x.am(i+1,2*x.data[i],r,2*i+1,c,x.t-i-1)) >= x.DV) {\n      r.data[i+x.t] -= x.DV;\n      r.data[i+x.t+1] = 1;\n    }\n  }\n  if(r.t > 0) r.data[r.t-1] += x.am(i,x.data[i],r,2*i,0,1);\n  r.s = 0;\n  r.clamp();\n}\n\n// (protected) divide this by m, quotient and remainder to q, r (HAC 14.20)\n// r != q, this != m.  q or r may be null.\nfunction bnpDivRemTo(m,q,r) {\n  var pm = m.abs();\n  if(pm.t <= 0) return;\n  var pt = this.abs();\n  if(pt.t < pm.t) {\n    if(q != null) q.fromInt(0);\n    if(r != null) this.copyTo(r);\n    return;\n  }\n  if(r == null) r = nbi();\n  var y = nbi(), ts = this.s, ms = m.s;\n  var nsh = this.DB-nbits(pm.data[pm.t-1]);\t// normalize modulus\n  if(nsh > 0) { pm.lShiftTo(nsh,y); pt.lShiftTo(nsh,r); } else { pm.copyTo(y); pt.copyTo(r); }\n  var ys = y.t;\n  var y0 = y.data[ys-1];\n  if(y0 == 0) return;\n  var yt = y0*(1<<this.F1)+((ys>1)?y.data[ys-2]>>this.F2:0);\n  var d1 = this.FV/yt, d2 = (1<<this.F1)/yt, e = 1<<this.F2;\n  var i = r.t, j = i-ys, t = (q==null)?nbi():q;\n  y.dlShiftTo(j,t);\n  if(r.compareTo(t) >= 0) {\n    r.data[r.t++] = 1;\n    r.subTo(t,r);\n  }\n  BigInteger.ONE.dlShiftTo(ys,t);\n  t.subTo(y,y);\t// \"negative\" y so we can replace sub with am later\n  while(y.t < ys) y.data[y.t++] = 0;\n  while(--j >= 0) {\n    // Estimate quotient digit\n    var qd = (r.data[--i]==y0)?this.DM:Math.floor(r.data[i]*d1+(r.data[i-1]+e)*d2);\n    if((r.data[i]+=y.am(0,qd,r,j,0,ys)) < qd) {\t// Try it out\n      y.dlShiftTo(j,t);\n      r.subTo(t,r);\n      while(r.data[i] < --qd) r.subTo(t,r);\n    }\n  }\n  if(q != null) {\n    r.drShiftTo(ys,q);\n    if(ts != ms) BigInteger.ZERO.subTo(q,q);\n  }\n  r.t = ys;\n  r.clamp();\n  if(nsh > 0) r.rShiftTo(nsh,r);\t// Denormalize remainder\n  if(ts < 0) BigInteger.ZERO.subTo(r,r);\n}\n\n// (public) this mod a\nfunction bnMod(a) {\n  var r = nbi();\n  this.abs().divRemTo(a,null,r);\n  if(this.s < 0 && r.compareTo(BigInteger.ZERO) > 0) a.subTo(r,r);\n  return r;\n}\n\n// Modular reduction using \"classic\" algorithm\nfunction Classic(m) { this.m = m; }\nfunction cConvert(x) {\n  if(x.s < 0 || x.compareTo(this.m) >= 0) return x.mod(this.m);\n  else return x;\n}\nfunction cRevert(x) { return x; }\nfunction cReduce(x) { x.divRemTo(this.m,null,x); }\nfunction cMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\nfunction cSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\nClassic.prototype.convert = cConvert;\nClassic.prototype.revert = cRevert;\nClassic.prototype.reduce = cReduce;\nClassic.prototype.mulTo = cMulTo;\nClassic.prototype.sqrTo = cSqrTo;\n\n// (protected) return \"-1/this % 2^DB\"; useful for Mont. reduction\n// justification:\n//         xy == 1 (mod m)\n//         xy =  1+km\n//   xy(2-xy) = (1+km)(1-km)\n// x[y(2-xy)] = 1-k^2m^2\n// x[y(2-xy)] == 1 (mod m^2)\n// if y is 1/x mod m, then y(2-xy) is 1/x mod m^2\n// should reduce x and y(2-xy) by m^2 at each step to keep size bounded.\n// JS multiply \"overflows\" differently from C/C++, so care is needed here.\nfunction bnpInvDigit() {\n  if(this.t < 1) return 0;\n  var x = this.data[0];\n  if((x&1) == 0) return 0;\n  var y = x&3;\t\t// y == 1/x mod 2^2\n  y = (y*(2-(x&0xf)*y))&0xf;\t// y == 1/x mod 2^4\n  y = (y*(2-(x&0xff)*y))&0xff;\t// y == 1/x mod 2^8\n  y = (y*(2-(((x&0xffff)*y)&0xffff)))&0xffff;\t// y == 1/x mod 2^16\n  // last step - calculate inverse mod DV directly;\n  // assumes 16 < DB <= 32 and assumes ability to handle 48-bit ints\n  y = (y*(2-x*y%this.DV))%this.DV;\t\t// y == 1/x mod 2^dbits\n  // we really want the negative inverse, and -DV < y < DV\n  return (y>0)?this.DV-y:-y;\n}\n\n// Montgomery reduction\nfunction Montgomery(m) {\n  this.m = m;\n  this.mp = m.invDigit();\n  this.mpl = this.mp&0x7fff;\n  this.mph = this.mp>>15;\n  this.um = (1<<(m.DB-15))-1;\n  this.mt2 = 2*m.t;\n}\n\n// xR mod m\nfunction montConvert(x) {\n  var r = nbi();\n  x.abs().dlShiftTo(this.m.t,r);\n  r.divRemTo(this.m,null,r);\n  if(x.s < 0 && r.compareTo(BigInteger.ZERO) > 0) this.m.subTo(r,r);\n  return r;\n}\n\n// x/R mod m\nfunction montRevert(x) {\n  var r = nbi();\n  x.copyTo(r);\n  this.reduce(r);\n  return r;\n}\n\n// x = x/R mod m (HAC 14.32)\nfunction montReduce(x) {\n  while(x.t <= this.mt2)\t// pad x so am has enough room later\n    x.data[x.t++] = 0;\n  for(var i = 0; i < this.m.t; ++i) {\n    // faster way of calculating u0 = x.data[i]*mp mod DV\n    var j = x.data[i]&0x7fff;\n    var u0 = (j*this.mpl+(((j*this.mph+(x.data[i]>>15)*this.mpl)&this.um)<<15))&x.DM;\n    // use am to combine the multiply-shift-add into one call\n    j = i+this.m.t;\n    x.data[j] += this.m.am(0,u0,x,i,0,this.m.t);\n    // propagate carry\n    while(x.data[j] >= x.DV) { x.data[j] -= x.DV; x.data[++j]++; }\n  }\n  x.clamp();\n  x.drShiftTo(this.m.t,x);\n  if(x.compareTo(this.m) >= 0) x.subTo(this.m,x);\n}\n\n// r = \"x^2/R mod m\"; x != r\nfunction montSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\n// r = \"xy/R mod m\"; x,y != r\nfunction montMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\n\nMontgomery.prototype.convert = montConvert;\nMontgomery.prototype.revert = montRevert;\nMontgomery.prototype.reduce = montReduce;\nMontgomery.prototype.mulTo = montMulTo;\nMontgomery.prototype.sqrTo = montSqrTo;\n\n// (protected) true iff this is even\nfunction bnpIsEven() { return ((this.t>0)?(this.data[0]&1):this.s) == 0; }\n\n// (protected) this^e, e < 2^32, doing sqr and mul with \"r\" (HAC 14.79)\nfunction bnpExp(e,z) {\n  if(e > 0xffffffff || e < 1) return BigInteger.ONE;\n  var r = nbi(), r2 = nbi(), g = z.convert(this), i = nbits(e)-1;\n  g.copyTo(r);\n  while(--i >= 0) {\n    z.sqrTo(r,r2);\n    if((e&(1<<i)) > 0) z.mulTo(r2,g,r);\n    else { var t = r; r = r2; r2 = t; }\n  }\n  return z.revert(r);\n}\n\n// (public) this^e % m, 0 <= e < 2^32\nfunction bnModPowInt(e,m) {\n  var z;\n  if(e < 256 || m.isEven()) z = new Classic(m); else z = new Montgomery(m);\n  return this.exp(e,z);\n}\n\n// protected\nBigInteger.prototype.copyTo = bnpCopyTo;\nBigInteger.prototype.fromInt = bnpFromInt;\nBigInteger.prototype.fromString = bnpFromString;\nBigInteger.prototype.clamp = bnpClamp;\nBigInteger.prototype.dlShiftTo = bnpDLShiftTo;\nBigInteger.prototype.drShiftTo = bnpDRShiftTo;\nBigInteger.prototype.lShiftTo = bnpLShiftTo;\nBigInteger.prototype.rShiftTo = bnpRShiftTo;\nBigInteger.prototype.subTo = bnpSubTo;\nBigInteger.prototype.multiplyTo = bnpMultiplyTo;\nBigInteger.prototype.squareTo = bnpSquareTo;\nBigInteger.prototype.divRemTo = bnpDivRemTo;\nBigInteger.prototype.invDigit = bnpInvDigit;\nBigInteger.prototype.isEven = bnpIsEven;\nBigInteger.prototype.exp = bnpExp;\n\n// public\nBigInteger.prototype.toString = bnToString;\nBigInteger.prototype.negate = bnNegate;\nBigInteger.prototype.abs = bnAbs;\nBigInteger.prototype.compareTo = bnCompareTo;\nBigInteger.prototype.bitLength = bnBitLength;\nBigInteger.prototype.mod = bnMod;\nBigInteger.prototype.modPowInt = bnModPowInt;\n\n// \"constants\"\nBigInteger.ZERO = nbv(0);\nBigInteger.ONE = nbv(1);\n\n// jsbn2 lib\n\n//Copyright (c) 2005-2009  Tom Wu\n//All Rights Reserved.\n//See \"LICENSE\" for details (See jsbn.js for LICENSE).\n\n//Extended JavaScript BN functions, required for RSA private ops.\n\n//Version 1.1: new BigInteger(\"0\", 10) returns \"proper\" zero\n\n//(public)\nfunction bnClone() { var r = nbi(); this.copyTo(r); return r; }\n\n//(public) return value as integer\nfunction bnIntValue() {\nif(this.s < 0) {\n if(this.t == 1) return this.data[0]-this.DV;\n else if(this.t == 0) return -1;\n} else if(this.t == 1) return this.data[0];\nelse if(this.t == 0) return 0;\n// assumes 16 < DB < 32\nreturn ((this.data[1]&((1<<(32-this.DB))-1))<<this.DB)|this.data[0];\n}\n\n//(public) return value as byte\nfunction bnByteValue() { return (this.t==0)?this.s:(this.data[0]<<24)>>24; }\n\n//(public) return value as short (assumes DB>=16)\nfunction bnShortValue() { return (this.t==0)?this.s:(this.data[0]<<16)>>16; }\n\n//(protected) return x s.t. r^x < DV\nfunction bnpChunkSize(r) { return Math.floor(Math.LN2*this.DB/Math.log(r)); }\n\n//(public) 0 if this == 0, 1 if this > 0\nfunction bnSigNum() {\nif(this.s < 0) return -1;\nelse if(this.t <= 0 || (this.t == 1 && this.data[0] <= 0)) return 0;\nelse return 1;\n}\n\n//(protected) convert to radix string\nfunction bnpToRadix(b) {\nif(b == null) b = 10;\nif(this.signum() == 0 || b < 2 || b > 36) return \"0\";\nvar cs = this.chunkSize(b);\nvar a = Math.pow(b,cs);\nvar d = nbv(a), y = nbi(), z = nbi(), r = \"\";\nthis.divRemTo(d,y,z);\nwhile(y.signum() > 0) {\n r = (a+z.intValue()).toString(b).substr(1) + r;\n y.divRemTo(d,y,z);\n}\nreturn z.intValue().toString(b) + r;\n}\n\n//(protected) convert from radix string\nfunction bnpFromRadix(s,b) {\nthis.fromInt(0);\nif(b == null) b = 10;\nvar cs = this.chunkSize(b);\nvar d = Math.pow(b,cs), mi = false, j = 0, w = 0;\nfor(var i = 0; i < s.length; ++i) {\n var x = intAt(s,i);\n if(x < 0) {\n   if(s.charAt(i) == \"-\" && this.signum() == 0) mi = true;\n   continue;\n }\n w = b*w+x;\n if(++j >= cs) {\n   this.dMultiply(d);\n   this.dAddOffset(w,0);\n   j = 0;\n   w = 0;\n }\n}\nif(j > 0) {\n this.dMultiply(Math.pow(b,j));\n this.dAddOffset(w,0);\n}\nif(mi) BigInteger.ZERO.subTo(this,this);\n}\n\n//(protected) alternate constructor\nfunction bnpFromNumber(a,b,c) {\nif(\"number\" == typeof b) {\n // new BigInteger(int,int,RNG)\n if(a < 2) this.fromInt(1);\n else {\n   this.fromNumber(a,c);\n   if(!this.testBit(a-1))  // force MSB set\n     this.bitwiseTo(BigInteger.ONE.shiftLeft(a-1),op_or,this);\n   if(this.isEven()) this.dAddOffset(1,0); // force odd\n   while(!this.isProbablePrime(b)) {\n     this.dAddOffset(2,0);\n     if(this.bitLength() > a) this.subTo(BigInteger.ONE.shiftLeft(a-1),this);\n   }\n }\n} else {\n // new BigInteger(int,RNG)\n var x = new Array(), t = a&7;\n x.length = (a>>3)+1;\n b.nextBytes(x);\n if(t > 0) x[0] &= ((1<<t)-1); else x[0] = 0;\n this.fromString(x,256);\n}\n}\n\n//(public) convert to bigendian byte array\nfunction bnToByteArray() {\nvar i = this.t, r = new Array();\nr[0] = this.s;\nvar p = this.DB-(i*this.DB)%8, d, k = 0;\nif(i-- > 0) {\n if(p < this.DB && (d = this.data[i]>>p) != (this.s&this.DM)>>p)\n   r[k++] = d|(this.s<<(this.DB-p));\n while(i >= 0) {\n   if(p < 8) {\n     d = (this.data[i]&((1<<p)-1))<<(8-p);\n     d |= this.data[--i]>>(p+=this.DB-8);\n   } else {\n     d = (this.data[i]>>(p-=8))&0xff;\n     if(p <= 0) { p += this.DB; --i; }\n   }\n   if((d&0x80) != 0) d |= -256;\n   if(k == 0 && (this.s&0x80) != (d&0x80)) ++k;\n   if(k > 0 || d != this.s) r[k++] = d;\n }\n}\nreturn r;\n}\n\nfunction bnEquals(a) { return(this.compareTo(a)==0); }\nfunction bnMin(a) { return(this.compareTo(a)<0)?this:a; }\nfunction bnMax(a) { return(this.compareTo(a)>0)?this:a; }\n\n//(protected) r = this op a (bitwise)\nfunction bnpBitwiseTo(a,op,r) {\nvar i, f, m = Math.min(a.t,this.t);\nfor(i = 0; i < m; ++i) r.data[i] = op(this.data[i],a.data[i]);\nif(a.t < this.t) {\n f = a.s&this.DM;\n for(i = m; i < this.t; ++i) r.data[i] = op(this.data[i],f);\n r.t = this.t;\n} else {\n f = this.s&this.DM;\n for(i = m; i < a.t; ++i) r.data[i] = op(f,a.data[i]);\n r.t = a.t;\n}\nr.s = op(this.s,a.s);\nr.clamp();\n}\n\n//(public) this & a\nfunction op_and(x,y) { return x&y; }\nfunction bnAnd(a) { var r = nbi(); this.bitwiseTo(a,op_and,r); return r; }\n\n//(public) this | a\nfunction op_or(x,y) { return x|y; }\nfunction bnOr(a) { var r = nbi(); this.bitwiseTo(a,op_or,r); return r; }\n\n//(public) this ^ a\nfunction op_xor(x,y) { return x^y; }\nfunction bnXor(a) { var r = nbi(); this.bitwiseTo(a,op_xor,r); return r; }\n\n//(public) this & ~a\nfunction op_andnot(x,y) { return x&~y; }\nfunction bnAndNot(a) { var r = nbi(); this.bitwiseTo(a,op_andnot,r); return r; }\n\n//(public) ~this\nfunction bnNot() {\nvar r = nbi();\nfor(var i = 0; i < this.t; ++i) r.data[i] = this.DM&~this.data[i];\nr.t = this.t;\nr.s = ~this.s;\nreturn r;\n}\n\n//(public) this << n\nfunction bnShiftLeft(n) {\nvar r = nbi();\nif(n < 0) this.rShiftTo(-n,r); else this.lShiftTo(n,r);\nreturn r;\n}\n\n//(public) this >> n\nfunction bnShiftRight(n) {\nvar r = nbi();\nif(n < 0) this.lShiftTo(-n,r); else this.rShiftTo(n,r);\nreturn r;\n}\n\n//return index of lowest 1-bit in x, x < 2^31\nfunction lbit(x) {\nif(x == 0) return -1;\nvar r = 0;\nif((x&0xffff) == 0) { x >>= 16; r += 16; }\nif((x&0xff) == 0) { x >>= 8; r += 8; }\nif((x&0xf) == 0) { x >>= 4; r += 4; }\nif((x&3) == 0) { x >>= 2; r += 2; }\nif((x&1) == 0) ++r;\nreturn r;\n}\n\n//(public) returns index of lowest 1-bit (or -1 if none)\nfunction bnGetLowestSetBit() {\nfor(var i = 0; i < this.t; ++i)\n if(this.data[i] != 0) return i*this.DB+lbit(this.data[i]);\nif(this.s < 0) return this.t*this.DB;\nreturn -1;\n}\n\n//return number of 1 bits in x\nfunction cbit(x) {\nvar r = 0;\nwhile(x != 0) { x &= x-1; ++r; }\nreturn r;\n}\n\n//(public) return number of set bits\nfunction bnBitCount() {\nvar r = 0, x = this.s&this.DM;\nfor(var i = 0; i < this.t; ++i) r += cbit(this.data[i]^x);\nreturn r;\n}\n\n//(public) true iff nth bit is set\nfunction bnTestBit(n) {\nvar j = Math.floor(n/this.DB);\nif(j >= this.t) return(this.s!=0);\nreturn((this.data[j]&(1<<(n%this.DB)))!=0);\n}\n\n//(protected) this op (1<<n)\nfunction bnpChangeBit(n,op) {\nvar r = BigInteger.ONE.shiftLeft(n);\nthis.bitwiseTo(r,op,r);\nreturn r;\n}\n\n//(public) this | (1<<n)\nfunction bnSetBit(n) { return this.changeBit(n,op_or); }\n\n//(public) this & ~(1<<n)\nfunction bnClearBit(n) { return this.changeBit(n,op_andnot); }\n\n//(public) this ^ (1<<n)\nfunction bnFlipBit(n) { return this.changeBit(n,op_xor); }\n\n//(protected) r = this + a\nfunction bnpAddTo(a,r) {\nvar i = 0, c = 0, m = Math.min(a.t,this.t);\nwhile(i < m) {\n c += this.data[i]+a.data[i];\n r.data[i++] = c&this.DM;\n c >>= this.DB;\n}\nif(a.t < this.t) {\n c += a.s;\n while(i < this.t) {\n   c += this.data[i];\n   r.data[i++] = c&this.DM;\n   c >>= this.DB;\n }\n c += this.s;\n} else {\n c += this.s;\n while(i < a.t) {\n   c += a.data[i];\n   r.data[i++] = c&this.DM;\n   c >>= this.DB;\n }\n c += a.s;\n}\nr.s = (c<0)?-1:0;\nif(c > 0) r.data[i++] = c;\nelse if(c < -1) r.data[i++] = this.DV+c;\nr.t = i;\nr.clamp();\n}\n\n//(public) this + a\nfunction bnAdd(a) { var r = nbi(); this.addTo(a,r); return r; }\n\n//(public) this - a\nfunction bnSubtract(a) { var r = nbi(); this.subTo(a,r); return r; }\n\n//(public) this * a\nfunction bnMultiply(a) { var r = nbi(); this.multiplyTo(a,r); return r; }\n\n//(public) this / a\nfunction bnDivide(a) { var r = nbi(); this.divRemTo(a,r,null); return r; }\n\n//(public) this % a\nfunction bnRemainder(a) { var r = nbi(); this.divRemTo(a,null,r); return r; }\n\n//(public) [this/a,this%a]\nfunction bnDivideAndRemainder(a) {\nvar q = nbi(), r = nbi();\nthis.divRemTo(a,q,r);\nreturn new Array(q,r);\n}\n\n//(protected) this *= n, this >= 0, 1 < n < DV\nfunction bnpDMultiply(n) {\nthis.data[this.t] = this.am(0,n-1,this,0,0,this.t);\n++this.t;\nthis.clamp();\n}\n\n//(protected) this += n << w words, this >= 0\nfunction bnpDAddOffset(n,w) {\nif(n == 0) return;\nwhile(this.t <= w) this.data[this.t++] = 0;\nthis.data[w] += n;\nwhile(this.data[w] >= this.DV) {\n this.data[w] -= this.DV;\n if(++w >= this.t) this.data[this.t++] = 0;\n ++this.data[w];\n}\n}\n\n//A \"null\" reducer\nfunction NullExp() {}\nfunction nNop(x) { return x; }\nfunction nMulTo(x,y,r) { x.multiplyTo(y,r); }\nfunction nSqrTo(x,r) { x.squareTo(r); }\n\nNullExp.prototype.convert = nNop;\nNullExp.prototype.revert = nNop;\nNullExp.prototype.mulTo = nMulTo;\nNullExp.prototype.sqrTo = nSqrTo;\n\n//(public) this^e\nfunction bnPow(e) { return this.exp(e,new NullExp()); }\n\n//(protected) r = lower n words of \"this * a\", a.t <= n\n//\"this\" should be the larger one if appropriate.\nfunction bnpMultiplyLowerTo(a,n,r) {\nvar i = Math.min(this.t+a.t,n);\nr.s = 0; // assumes a,this >= 0\nr.t = i;\nwhile(i > 0) r.data[--i] = 0;\nvar j;\nfor(j = r.t-this.t; i < j; ++i) r.data[i+this.t] = this.am(0,a.data[i],r,i,0,this.t);\nfor(j = Math.min(a.t,n); i < j; ++i) this.am(0,a.data[i],r,i,0,n-i);\nr.clamp();\n}\n\n//(protected) r = \"this * a\" without lower n words, n > 0\n//\"this\" should be the larger one if appropriate.\nfunction bnpMultiplyUpperTo(a,n,r) {\n--n;\nvar i = r.t = this.t+a.t-n;\nr.s = 0; // assumes a,this >= 0\nwhile(--i >= 0) r.data[i] = 0;\nfor(i = Math.max(n-this.t,0); i < a.t; ++i)\n r.data[this.t+i-n] = this.am(n-i,a.data[i],r,0,0,this.t+i-n);\nr.clamp();\nr.drShiftTo(1,r);\n}\n\n//Barrett modular reduction\nfunction Barrett(m) {\n// setup Barrett\nthis.r2 = nbi();\nthis.q3 = nbi();\nBigInteger.ONE.dlShiftTo(2*m.t,this.r2);\nthis.mu = this.r2.divide(m);\nthis.m = m;\n}\n\nfunction barrettConvert(x) {\nif(x.s < 0 || x.t > 2*this.m.t) return x.mod(this.m);\nelse if(x.compareTo(this.m) < 0) return x;\nelse { var r = nbi(); x.copyTo(r); this.reduce(r); return r; }\n}\n\nfunction barrettRevert(x) { return x; }\n\n//x = x mod m (HAC 14.42)\nfunction barrettReduce(x) {\nx.drShiftTo(this.m.t-1,this.r2);\nif(x.t > this.m.t+1) { x.t = this.m.t+1; x.clamp(); }\nthis.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);\nthis.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);\nwhile(x.compareTo(this.r2) < 0) x.dAddOffset(1,this.m.t+1);\nx.subTo(this.r2,x);\nwhile(x.compareTo(this.m) >= 0) x.subTo(this.m,x);\n}\n\n//r = x^2 mod m; x != r\nfunction barrettSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\n//r = x*y mod m; x,y != r\nfunction barrettMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\n\nBarrett.prototype.convert = barrettConvert;\nBarrett.prototype.revert = barrettRevert;\nBarrett.prototype.reduce = barrettReduce;\nBarrett.prototype.mulTo = barrettMulTo;\nBarrett.prototype.sqrTo = barrettSqrTo;\n\n//(public) this^e % m (HAC 14.85)\nfunction bnModPow(e,m) {\nvar i = e.bitLength(), k, r = nbv(1), z;\nif(i <= 0) return r;\nelse if(i < 18) k = 1;\nelse if(i < 48) k = 3;\nelse if(i < 144) k = 4;\nelse if(i < 768) k = 5;\nelse k = 6;\nif(i < 8)\n z = new Classic(m);\nelse if(m.isEven())\n z = new Barrett(m);\nelse\n z = new Montgomery(m);\n\n// precomputation\nvar g = new Array(), n = 3, k1 = k-1, km = (1<<k)-1;\ng[1] = z.convert(this);\nif(k > 1) {\n var g2 = nbi();\n z.sqrTo(g[1],g2);\n while(n <= km) {\n   g[n] = nbi();\n   z.mulTo(g2,g[n-2],g[n]);\n   n += 2;\n }\n}\n\nvar j = e.t-1, w, is1 = true, r2 = nbi(), t;\ni = nbits(e.data[j])-1;\nwhile(j >= 0) {\n if(i >= k1) w = (e.data[j]>>(i-k1))&km;\n else {\n   w = (e.data[j]&((1<<(i+1))-1))<<(k1-i);\n   if(j > 0) w |= e.data[j-1]>>(this.DB+i-k1);\n }\n\n n = k;\n while((w&1) == 0) { w >>= 1; --n; }\n if((i -= n) < 0) { i += this.DB; --j; }\n if(is1) {  // ret == 1, don't bother squaring or multiplying it\n   g[w].copyTo(r);\n   is1 = false;\n } else {\n   while(n > 1) { z.sqrTo(r,r2); z.sqrTo(r2,r); n -= 2; }\n   if(n > 0) z.sqrTo(r,r2); else { t = r; r = r2; r2 = t; }\n   z.mulTo(r2,g[w],r);\n }\n\n while(j >= 0 && (e.data[j]&(1<<i)) == 0) {\n   z.sqrTo(r,r2); t = r; r = r2; r2 = t;\n   if(--i < 0) { i = this.DB-1; --j; }\n }\n}\nreturn z.revert(r);\n}\n\n//(public) gcd(this,a) (HAC 14.54)\nfunction bnGCD(a) {\nvar x = (this.s<0)?this.negate():this.clone();\nvar y = (a.s<0)?a.negate():a.clone();\nif(x.compareTo(y) < 0) { var t = x; x = y; y = t; }\nvar i = x.getLowestSetBit(), g = y.getLowestSetBit();\nif(g < 0) return x;\nif(i < g) g = i;\nif(g > 0) {\n x.rShiftTo(g,x);\n y.rShiftTo(g,y);\n}\nwhile(x.signum() > 0) {\n if((i = x.getLowestSetBit()) > 0) x.rShiftTo(i,x);\n if((i = y.getLowestSetBit()) > 0) y.rShiftTo(i,y);\n if(x.compareTo(y) >= 0) {\n   x.subTo(y,x);\n   x.rShiftTo(1,x);\n } else {\n   y.subTo(x,y);\n   y.rShiftTo(1,y);\n }\n}\nif(g > 0) y.lShiftTo(g,y);\nreturn y;\n}\n\n//(protected) this % n, n < 2^26\nfunction bnpModInt(n) {\nif(n <= 0) return 0;\nvar d = this.DV%n, r = (this.s<0)?n-1:0;\nif(this.t > 0)\n if(d == 0) r = this.data[0]%n;\n else for(var i = this.t-1; i >= 0; --i) r = (d*r+this.data[i])%n;\nreturn r;\n}\n\n//(public) 1/this % m (HAC 14.61)\nfunction bnModInverse(m) {\nvar ac = m.isEven();\nif((this.isEven() && ac) || m.signum() == 0) return BigInteger.ZERO;\nvar u = m.clone(), v = this.clone();\nvar a = nbv(1), b = nbv(0), c = nbv(0), d = nbv(1);\nwhile(u.signum() != 0) {\n while(u.isEven()) {\n   u.rShiftTo(1,u);\n   if(ac) {\n     if(!a.isEven() || !b.isEven()) { a.addTo(this,a); b.subTo(m,b); }\n     a.rShiftTo(1,a);\n   } else if(!b.isEven()) b.subTo(m,b);\n   b.rShiftTo(1,b);\n }\n while(v.isEven()) {\n   v.rShiftTo(1,v);\n   if(ac) {\n     if(!c.isEven() || !d.isEven()) { c.addTo(this,c); d.subTo(m,d); }\n     c.rShiftTo(1,c);\n   } else if(!d.isEven()) d.subTo(m,d);\n   d.rShiftTo(1,d);\n }\n if(u.compareTo(v) >= 0) {\n   u.subTo(v,u);\n   if(ac) a.subTo(c,a);\n   b.subTo(d,b);\n } else {\n   v.subTo(u,v);\n   if(ac) c.subTo(a,c);\n   d.subTo(b,d);\n }\n}\nif(v.compareTo(BigInteger.ONE) != 0) return BigInteger.ZERO;\nif(d.compareTo(m) >= 0) return d.subtract(m);\nif(d.signum() < 0) d.addTo(m,d); else return d;\nif(d.signum() < 0) return d.add(m); else return d;\n}\n\nvar lowprimes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509];\nvar lplim = (1<<26)/lowprimes[lowprimes.length-1];\n\n//(public) test primality with certainty >= 1-.5^t\nfunction bnIsProbablePrime(t) {\nvar i, x = this.abs();\nif(x.t == 1 && x.data[0] <= lowprimes[lowprimes.length-1]) {\n for(i = 0; i < lowprimes.length; ++i)\n   if(x.data[0] == lowprimes[i]) return true;\n return false;\n}\nif(x.isEven()) return false;\ni = 1;\nwhile(i < lowprimes.length) {\n var m = lowprimes[i], j = i+1;\n while(j < lowprimes.length && m < lplim) m *= lowprimes[j++];\n m = x.modInt(m);\n while(i < j) if(m%lowprimes[i++] == 0) return false;\n}\nreturn x.millerRabin(t);\n}\n\n//(protected) true if probably prime (HAC 4.24, Miller-Rabin)\nfunction bnpMillerRabin(t) {\nvar n1 = this.subtract(BigInteger.ONE);\nvar k = n1.getLowestSetBit();\nif(k <= 0) return false;\nvar r = n1.shiftRight(k);\nvar prng = bnGetPrng();\nvar a;\nfor(var i = 0; i < t; ++i) {\n // select witness 'a' at random from between 1 and n1\n do {\n   a = new BigInteger(this.bitLength(), prng);\n }\n while(a.compareTo(BigInteger.ONE) <= 0 || a.compareTo(n1) >= 0);\n var y = a.modPow(r,this);\n if(y.compareTo(BigInteger.ONE) != 0 && y.compareTo(n1) != 0) {\n   var j = 1;\n   while(j++ < k && y.compareTo(n1) != 0) {\n     y = y.modPowInt(2,this);\n     if(y.compareTo(BigInteger.ONE) == 0) return false;\n   }\n   if(y.compareTo(n1) != 0) return false;\n }\n}\nreturn true;\n}\n\n// get pseudo random number generator\nfunction bnGetPrng() {\n  // create prng with api that matches BigInteger secure random\n  return {\n    // x is an array to fill with bytes\n    nextBytes: function(x) {\n      for(var i = 0; i < x.length; ++i) {\n        x[i] = Math.floor(Math.random() * 0x0100);\n      }\n    }\n  };\n}\n\n//protected\nBigInteger.prototype.chunkSize = bnpChunkSize;\nBigInteger.prototype.toRadix = bnpToRadix;\nBigInteger.prototype.fromRadix = bnpFromRadix;\nBigInteger.prototype.fromNumber = bnpFromNumber;\nBigInteger.prototype.bitwiseTo = bnpBitwiseTo;\nBigInteger.prototype.changeBit = bnpChangeBit;\nBigInteger.prototype.addTo = bnpAddTo;\nBigInteger.prototype.dMultiply = bnpDMultiply;\nBigInteger.prototype.dAddOffset = bnpDAddOffset;\nBigInteger.prototype.multiplyLowerTo = bnpMultiplyLowerTo;\nBigInteger.prototype.multiplyUpperTo = bnpMultiplyUpperTo;\nBigInteger.prototype.modInt = bnpModInt;\nBigInteger.prototype.millerRabin = bnpMillerRabin;\n\n//public\nBigInteger.prototype.clone = bnClone;\nBigInteger.prototype.intValue = bnIntValue;\nBigInteger.prototype.byteValue = bnByteValue;\nBigInteger.prototype.shortValue = bnShortValue;\nBigInteger.prototype.signum = bnSigNum;\nBigInteger.prototype.toByteArray = bnToByteArray;\nBigInteger.prototype.equals = bnEquals;\nBigInteger.prototype.min = bnMin;\nBigInteger.prototype.max = bnMax;\nBigInteger.prototype.and = bnAnd;\nBigInteger.prototype.or = bnOr;\nBigInteger.prototype.xor = bnXor;\nBigInteger.prototype.andNot = bnAndNot;\nBigInteger.prototype.not = bnNot;\nBigInteger.prototype.shiftLeft = bnShiftLeft;\nBigInteger.prototype.shiftRight = bnShiftRight;\nBigInteger.prototype.getLowestSetBit = bnGetLowestSetBit;\nBigInteger.prototype.bitCount = bnBitCount;\nBigInteger.prototype.testBit = bnTestBit;\nBigInteger.prototype.setBit = bnSetBit;\nBigInteger.prototype.clearBit = bnClearBit;\nBigInteger.prototype.flipBit = bnFlipBit;\nBigInteger.prototype.add = bnAdd;\nBigInteger.prototype.subtract = bnSubtract;\nBigInteger.prototype.multiply = bnMultiply;\nBigInteger.prototype.divide = bnDivide;\nBigInteger.prototype.remainder = bnRemainder;\nBigInteger.prototype.divideAndRemainder = bnDivideAndRemainder;\nBigInteger.prototype.modPow = bnModPow;\nBigInteger.prototype.modInverse = bnModInverse;\nBigInteger.prototype.pow = bnPow;\nBigInteger.prototype.gcd = bnGCD;\nBigInteger.prototype.isProbablePrime = bnIsProbablePrime;\n\n//BigInteger interfaces not implemented in jsbn:\n\n//BigInteger(int signum, byte[] magnitude)\n//double doubleValue()\n//float floatValue()\n//int hashCode()\n//long longValue()\n//static BigInteger valueOf(long val)\n","/**\n * Node.js module for Forge message digests.\n *\n * @author Dave Longley\n *\n * Copyright 2011-2017 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\n\nmodule.exports = forge.md = forge.md || {};\nforge.md.algorithms = forge.md.algorithms || {};\n","/**\n * Node.js module for Forge mask generation functions.\n *\n * @author Stefan Siegl\n *\n * Copyright 2012 Stefan Siegl <stesie@brokenpipe.de>\n */\nvar forge = require('./forge');\nrequire('./mgf1');\n\nmodule.exports = forge.mgf = forge.mgf || {};\nforge.mgf.mgf1 = forge.mgf1;\n","/**\n * Javascript implementation of mask generation function MGF1.\n *\n * @author Stefan Siegl\n * @author Dave Longley\n *\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n * Copyright (c) 2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\n\nforge.mgf = forge.mgf || {};\nvar mgf1 = module.exports = forge.mgf.mgf1 = forge.mgf1 = forge.mgf1 || {};\n\n/**\n * Creates a MGF1 mask generation function object.\n *\n * @param md the message digest API to use (eg: forge.md.sha1.create()).\n *\n * @return a mask generation function object.\n */\nmgf1.create = function(md) {\n  var mgf = {\n    /**\n     * Generate mask of specified length.\n     *\n     * @param {String} seed The seed for mask generation.\n     * @param maskLen Number of bytes to generate.\n     * @return {String} The generated mask.\n     */\n    generate: function(seed, maskLen) {\n      /* 2. Let T be the empty octet string. */\n      var t = new forge.util.ByteBuffer();\n\n      /* 3. For counter from 0 to ceil(maskLen / hLen), do the following: */\n      var len = Math.ceil(maskLen / md.digestLength);\n      for(var i = 0; i < len; i++) {\n        /* a. Convert counter to an octet string C of length 4 octets */\n        var c = new forge.util.ByteBuffer();\n        c.putInt32(i);\n\n        /* b. Concatenate the hash of the seed mgfSeed and C to the octet\n         * string T: */\n        md.start();\n        md.update(seed + c.getBytes());\n        t.putBuffer(md.digest());\n      }\n\n      /* Output the leading maskLen octets of T as the octet string mask. */\n      t.truncate(t.length() - maskLen);\n      return t.getBytes();\n    }\n  };\n\n  return mgf;\n};\n","/**\n * Object IDs for ASN.1.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2013 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\n\nforge.pki = forge.pki || {};\nvar oids = module.exports = forge.pki.oids = forge.oids = forge.oids || {};\n\n// set id to name mapping and name to id mapping\nfunction _IN(id, name) {\n  oids[id] = name;\n  oids[name] = id;\n}\n// set id to name mapping only\nfunction _I_(id, name) {\n  oids[id] = name;\n}\n\n// algorithm OIDs\n_IN('1.2.840.113549.1.1.1', 'rsaEncryption');\n// Note: md2 & md4 not implemented\n//_IN('1.2.840.113549.1.1.2', 'md2WithRSAEncryption');\n//_IN('1.2.840.113549.1.1.3', 'md4WithRSAEncryption');\n_IN('1.2.840.113549.1.1.4', 'md5WithRSAEncryption');\n_IN('1.2.840.113549.1.1.5', 'sha1WithRSAEncryption');\n_IN('1.2.840.113549.1.1.7', 'RSAES-OAEP');\n_IN('1.2.840.113549.1.1.8', 'mgf1');\n_IN('1.2.840.113549.1.1.9', 'pSpecified');\n_IN('1.2.840.113549.1.1.10', 'RSASSA-PSS');\n_IN('1.2.840.113549.1.1.11', 'sha256WithRSAEncryption');\n_IN('1.2.840.113549.1.1.12', 'sha384WithRSAEncryption');\n_IN('1.2.840.113549.1.1.13', 'sha512WithRSAEncryption');\n// Edwards-curve Digital Signature Algorithm (EdDSA) Ed25519\n_IN('1.3.101.112', 'EdDSA25519');\n\n_IN('1.2.840.10040.4.3', 'dsa-with-sha1');\n\n_IN('1.3.14.3.2.7', 'desCBC');\n\n_IN('1.3.14.3.2.26', 'sha1');\n// Deprecated equivalent of sha1WithRSAEncryption\n_IN('1.3.14.3.2.29', 'sha1WithRSASignature');\n_IN('2.16.840.1.101.3.4.2.1', 'sha256');\n_IN('2.16.840.1.101.3.4.2.2', 'sha384');\n_IN('2.16.840.1.101.3.4.2.3', 'sha512');\n_IN('2.16.840.1.101.3.4.2.4', 'sha224');\n_IN('2.16.840.1.101.3.4.2.5', 'sha512-224');\n_IN('2.16.840.1.101.3.4.2.6', 'sha512-256');\n_IN('1.2.840.113549.2.2', 'md2');\n_IN('1.2.840.113549.2.5', 'md5');\n\n// pkcs#7 content types\n_IN('1.2.840.113549.1.7.1', 'data');\n_IN('1.2.840.113549.1.7.2', 'signedData');\n_IN('1.2.840.113549.1.7.3', 'envelopedData');\n_IN('1.2.840.113549.1.7.4', 'signedAndEnvelopedData');\n_IN('1.2.840.113549.1.7.5', 'digestedData');\n_IN('1.2.840.113549.1.7.6', 'encryptedData');\n\n// pkcs#9 oids\n_IN('1.2.840.113549.1.9.1', 'emailAddress');\n_IN('1.2.840.113549.1.9.2', 'unstructuredName');\n_IN('1.2.840.113549.1.9.3', 'contentType');\n_IN('1.2.840.113549.1.9.4', 'messageDigest');\n_IN('1.2.840.113549.1.9.5', 'signingTime');\n_IN('1.2.840.113549.1.9.6', 'counterSignature');\n_IN('1.2.840.113549.1.9.7', 'challengePassword');\n_IN('1.2.840.113549.1.9.8', 'unstructuredAddress');\n_IN('1.2.840.113549.1.9.14', 'extensionRequest');\n\n_IN('1.2.840.113549.1.9.20', 'friendlyName');\n_IN('1.2.840.113549.1.9.21', 'localKeyId');\n_IN('1.2.840.113549.1.9.22.1', 'x509Certificate');\n\n// pkcs#12 safe bags\n_IN('1.2.840.113549.1.12.10.1.1', 'keyBag');\n_IN('1.2.840.113549.1.12.10.1.2', 'pkcs8ShroudedKeyBag');\n_IN('1.2.840.113549.1.12.10.1.3', 'certBag');\n_IN('1.2.840.113549.1.12.10.1.4', 'crlBag');\n_IN('1.2.840.113549.1.12.10.1.5', 'secretBag');\n_IN('1.2.840.113549.1.12.10.1.6', 'safeContentsBag');\n\n// password-based-encryption for pkcs#12\n_IN('1.2.840.113549.1.5.13', 'pkcs5PBES2');\n_IN('1.2.840.113549.1.5.12', 'pkcs5PBKDF2');\n\n_IN('1.2.840.113549.1.12.1.1', 'pbeWithSHAAnd128BitRC4');\n_IN('1.2.840.113549.1.12.1.2', 'pbeWithSHAAnd40BitRC4');\n_IN('1.2.840.113549.1.12.1.3', 'pbeWithSHAAnd3-KeyTripleDES-CBC');\n_IN('1.2.840.113549.1.12.1.4', 'pbeWithSHAAnd2-KeyTripleDES-CBC');\n_IN('1.2.840.113549.1.12.1.5', 'pbeWithSHAAnd128BitRC2-CBC');\n_IN('1.2.840.113549.1.12.1.6', 'pbewithSHAAnd40BitRC2-CBC');\n\n// hmac OIDs\n_IN('1.2.840.113549.2.7', 'hmacWithSHA1');\n_IN('1.2.840.113549.2.8', 'hmacWithSHA224');\n_IN('1.2.840.113549.2.9', 'hmacWithSHA256');\n_IN('1.2.840.113549.2.10', 'hmacWithSHA384');\n_IN('1.2.840.113549.2.11', 'hmacWithSHA512');\n\n// symmetric key algorithm oids\n_IN('1.2.840.113549.3.7', 'des-EDE3-CBC');\n_IN('2.16.840.1.101.3.4.1.2', 'aes128-CBC');\n_IN('2.16.840.1.101.3.4.1.22', 'aes192-CBC');\n_IN('2.16.840.1.101.3.4.1.42', 'aes256-CBC');\n\n// certificate issuer/subject OIDs\n_IN('2.5.4.3', 'commonName');\n_IN('2.5.4.4', 'surname');\n_IN('2.5.4.5', 'serialNumber');\n_IN('2.5.4.6', 'countryName');\n_IN('2.5.4.7', 'localityName');\n_IN('2.5.4.8', 'stateOrProvinceName');\n_IN('2.5.4.9', 'streetAddress');\n_IN('2.5.4.10', 'organizationName');\n_IN('2.5.4.11', 'organizationalUnitName');\n_IN('2.5.4.12', 'title');\n_IN('2.5.4.13', 'description');\n_IN('2.5.4.15', 'businessCategory');\n_IN('2.5.4.17', 'postalCode');\n_IN('2.5.4.42', 'givenName');\n_IN('1.3.6.1.4.1.311.60.2.1.2', 'jurisdictionOfIncorporationStateOrProvinceName');\n_IN('1.3.6.1.4.1.311.60.2.1.3', 'jurisdictionOfIncorporationCountryName');\n\n// X.509 extension OIDs\n_IN('2.16.840.1.113730.1.1', 'nsCertType');\n_IN('2.16.840.1.113730.1.13', 'nsComment'); // deprecated in theory; still widely used\n_I_('2.5.29.1', 'authorityKeyIdentifier'); // deprecated, use .35\n_I_('2.5.29.2', 'keyAttributes'); // obsolete use .37 or .15\n_I_('2.5.29.3', 'certificatePolicies'); // deprecated, use .32\n_I_('2.5.29.4', 'keyUsageRestriction'); // obsolete use .37 or .15\n_I_('2.5.29.5', 'policyMapping'); // deprecated use .33\n_I_('2.5.29.6', 'subtreesConstraint'); // obsolete use .30\n_I_('2.5.29.7', 'subjectAltName'); // deprecated use .17\n_I_('2.5.29.8', 'issuerAltName'); // deprecated use .18\n_I_('2.5.29.9', 'subjectDirectoryAttributes');\n_I_('2.5.29.10', 'basicConstraints'); // deprecated use .19\n_I_('2.5.29.11', 'nameConstraints'); // deprecated use .30\n_I_('2.5.29.12', 'policyConstraints'); // deprecated use .36\n_I_('2.5.29.13', 'basicConstraints'); // deprecated use .19\n_IN('2.5.29.14', 'subjectKeyIdentifier');\n_IN('2.5.29.15', 'keyUsage');\n_I_('2.5.29.16', 'privateKeyUsagePeriod');\n_IN('2.5.29.17', 'subjectAltName');\n_IN('2.5.29.18', 'issuerAltName');\n_IN('2.5.29.19', 'basicConstraints');\n_I_('2.5.29.20', 'cRLNumber');\n_I_('2.5.29.21', 'cRLReason');\n_I_('2.5.29.22', 'expirationDate');\n_I_('2.5.29.23', 'instructionCode');\n_I_('2.5.29.24', 'invalidityDate');\n_I_('2.5.29.25', 'cRLDistributionPoints'); // deprecated use .31\n_I_('2.5.29.26', 'issuingDistributionPoint'); // deprecated use .28\n_I_('2.5.29.27', 'deltaCRLIndicator');\n_I_('2.5.29.28', 'issuingDistributionPoint');\n_I_('2.5.29.29', 'certificateIssuer');\n_I_('2.5.29.30', 'nameConstraints');\n_IN('2.5.29.31', 'cRLDistributionPoints');\n_IN('2.5.29.32', 'certificatePolicies');\n_I_('2.5.29.33', 'policyMappings');\n_I_('2.5.29.34', 'policyConstraints'); // deprecated use .36\n_IN('2.5.29.35', 'authorityKeyIdentifier');\n_I_('2.5.29.36', 'policyConstraints');\n_IN('2.5.29.37', 'extKeyUsage');\n_I_('2.5.29.46', 'freshestCRL');\n_I_('2.5.29.54', 'inhibitAnyPolicy');\n\n// extKeyUsage purposes\n_IN('1.3.6.1.4.1.11129.2.4.2', 'timestampList');\n_IN('1.3.6.1.5.5.7.1.1', 'authorityInfoAccess');\n_IN('1.3.6.1.5.5.7.3.1', 'serverAuth');\n_IN('1.3.6.1.5.5.7.3.2', 'clientAuth');\n_IN('1.3.6.1.5.5.7.3.3', 'codeSigning');\n_IN('1.3.6.1.5.5.7.3.4', 'emailProtection');\n_IN('1.3.6.1.5.5.7.3.8', 'timeStamping');\n","/**\n * Password-based encryption functions.\n *\n * @author Dave Longley\n * @author Stefan Siegl <stesie@brokenpipe.de>\n *\n * Copyright (c) 2010-2013 Digital Bazaar, Inc.\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n *\n * An EncryptedPrivateKeyInfo:\n *\n * EncryptedPrivateKeyInfo ::= SEQUENCE {\n *   encryptionAlgorithm  EncryptionAlgorithmIdentifier,\n *   encryptedData        EncryptedData }\n *\n * EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier\n *\n * EncryptedData ::= OCTET STRING\n */\nvar forge = require('./forge');\nrequire('./aes');\nrequire('./asn1');\nrequire('./des');\nrequire('./md');\nrequire('./oids');\nrequire('./pbkdf2');\nrequire('./pem');\nrequire('./random');\nrequire('./rc2');\nrequire('./rsa');\nrequire('./util');\n\nif(typeof BigInteger === 'undefined') {\n  var BigInteger = forge.jsbn.BigInteger;\n}\n\n// shortcut for asn.1 API\nvar asn1 = forge.asn1;\n\n/* Password-based encryption implementation. */\nvar pki = forge.pki = forge.pki || {};\nmodule.exports = pki.pbe = forge.pbe = forge.pbe || {};\nvar oids = pki.oids;\n\n// validator for an EncryptedPrivateKeyInfo structure\n// Note: Currently only works w/algorithm params\nvar encryptedPrivateKeyValidator = {\n  name: 'EncryptedPrivateKeyInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'EncryptedPrivateKeyInfo.encryptionAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'AlgorithmIdentifier.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'encryptionOid'\n    }, {\n      name: 'AlgorithmIdentifier.parameters',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: 'encryptionParams'\n    }]\n  }, {\n    // encryptedData\n    name: 'EncryptedPrivateKeyInfo.encryptedData',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'encryptedData'\n  }]\n};\n\n// validator for a PBES2Algorithms structure\n// Note: Currently only works w/PBKDF2 + AES encryption schemes\nvar PBES2AlgorithmsValidator = {\n  name: 'PBES2Algorithms',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'PBES2Algorithms.keyDerivationFunc',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'PBES2Algorithms.keyDerivationFunc.oid',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'kdfOid'\n    }, {\n      name: 'PBES2Algorithms.params',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [{\n        name: 'PBES2Algorithms.params.salt',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OCTETSTRING,\n        constructed: false,\n        capture: 'kdfSalt'\n      }, {\n        name: 'PBES2Algorithms.params.iterationCount',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.INTEGER,\n        constructed: false,\n        capture: 'kdfIterationCount'\n      }, {\n        name: 'PBES2Algorithms.params.keyLength',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.INTEGER,\n        constructed: false,\n        optional: true,\n        capture: 'keyLength'\n      }, {\n        // prf\n        name: 'PBES2Algorithms.params.prf',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.SEQUENCE,\n        constructed: true,\n        optional: true,\n        value: [{\n          name: 'PBES2Algorithms.params.prf.algorithm',\n          tagClass: asn1.Class.UNIVERSAL,\n          type: asn1.Type.OID,\n          constructed: false,\n          capture: 'prfOid'\n        }]\n      }]\n    }]\n  }, {\n    name: 'PBES2Algorithms.encryptionScheme',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'PBES2Algorithms.encryptionScheme.oid',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'encOid'\n    }, {\n      name: 'PBES2Algorithms.encryptionScheme.iv',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OCTETSTRING,\n      constructed: false,\n      capture: 'encIv'\n    }]\n  }]\n};\n\nvar pkcs12PbeParamsValidator = {\n  name: 'pkcs-12PbeParams',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'pkcs-12PbeParams.salt',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'salt'\n  }, {\n    name: 'pkcs-12PbeParams.iterations',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'iterations'\n  }]\n};\n\n/**\n * Encrypts a ASN.1 PrivateKeyInfo object, producing an EncryptedPrivateKeyInfo.\n *\n * PBES2Algorithms ALGORITHM-IDENTIFIER ::=\n *   { {PBES2-params IDENTIFIED BY id-PBES2}, ...}\n *\n * id-PBES2 OBJECT IDENTIFIER ::= {pkcs-5 13}\n *\n * PBES2-params ::= SEQUENCE {\n *   keyDerivationFunc AlgorithmIdentifier {{PBES2-KDFs}},\n *   encryptionScheme AlgorithmIdentifier {{PBES2-Encs}}\n * }\n *\n * PBES2-KDFs ALGORITHM-IDENTIFIER ::=\n *   { {PBKDF2-params IDENTIFIED BY id-PBKDF2}, ... }\n *\n * PBES2-Encs ALGORITHM-IDENTIFIER ::= { ... }\n *\n * PBKDF2-params ::= SEQUENCE {\n *   salt CHOICE {\n *     specified OCTET STRING,\n *     otherSource AlgorithmIdentifier {{PBKDF2-SaltSources}}\n *   },\n *   iterationCount INTEGER (1..MAX),\n *   keyLength INTEGER (1..MAX) OPTIONAL,\n *   prf AlgorithmIdentifier {{PBKDF2-PRFs}} DEFAULT algid-hmacWithSHA1\n * }\n *\n * @param obj the ASN.1 PrivateKeyInfo object.\n * @param password the password to encrypt with.\n * @param options:\n *          algorithm the encryption algorithm to use\n *            ('aes128', 'aes192', 'aes256', '3des'), defaults to 'aes128'.\n *          count the iteration count to use.\n *          saltSize the salt size to use.\n *          prfAlgorithm the PRF message digest algorithm to use\n *            ('sha1', 'sha224', 'sha256', 'sha384', 'sha512')\n *\n * @return the ASN.1 EncryptedPrivateKeyInfo.\n */\npki.encryptPrivateKeyInfo = function(obj, password, options) {\n  // set default options\n  options = options || {};\n  options.saltSize = options.saltSize || 8;\n  options.count = options.count || 2048;\n  options.algorithm = options.algorithm || 'aes128';\n  options.prfAlgorithm = options.prfAlgorithm || 'sha1';\n\n  // generate PBE params\n  var salt = forge.random.getBytesSync(options.saltSize);\n  var count = options.count;\n  var countBytes = asn1.integerToDer(count);\n  var dkLen;\n  var encryptionAlgorithm;\n  var encryptedData;\n  if(options.algorithm.indexOf('aes') === 0 || options.algorithm === 'des') {\n    // do PBES2\n    var ivLen, encOid, cipherFn;\n    switch(options.algorithm) {\n    case 'aes128':\n      dkLen = 16;\n      ivLen = 16;\n      encOid = oids['aes128-CBC'];\n      cipherFn = forge.aes.createEncryptionCipher;\n      break;\n    case 'aes192':\n      dkLen = 24;\n      ivLen = 16;\n      encOid = oids['aes192-CBC'];\n      cipherFn = forge.aes.createEncryptionCipher;\n      break;\n    case 'aes256':\n      dkLen = 32;\n      ivLen = 16;\n      encOid = oids['aes256-CBC'];\n      cipherFn = forge.aes.createEncryptionCipher;\n      break;\n    case 'des':\n      dkLen = 8;\n      ivLen = 8;\n      encOid = oids['desCBC'];\n      cipherFn = forge.des.createEncryptionCipher;\n      break;\n    default:\n      var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');\n      error.algorithm = options.algorithm;\n      throw error;\n    }\n\n    // get PRF message digest\n    var prfAlgorithm = 'hmacWith' + options.prfAlgorithm.toUpperCase();\n    var md = prfAlgorithmToMessageDigest(prfAlgorithm);\n\n    // encrypt private key using pbe SHA-1 and AES/DES\n    var dk = forge.pkcs5.pbkdf2(password, salt, count, dkLen, md);\n    var iv = forge.random.getBytesSync(ivLen);\n    var cipher = cipherFn(dk);\n    cipher.start(iv);\n    cipher.update(asn1.toDer(obj));\n    cipher.finish();\n    encryptedData = cipher.output.getBytes();\n\n    // get PBKDF2-params\n    var params = createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm);\n\n    encryptionAlgorithm = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(oids['pkcs5PBES2']).getBytes()),\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // keyDerivationFunc\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n            asn1.oidToDer(oids['pkcs5PBKDF2']).getBytes()),\n          // PBKDF2-params\n          params\n        ]),\n        // encryptionScheme\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n            asn1.oidToDer(encOid).getBytes()),\n          // iv\n          asn1.create(\n            asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, iv)\n        ])\n      ])\n    ]);\n  } else if(options.algorithm === '3des') {\n    // Do PKCS12 PBE\n    dkLen = 24;\n\n    var saltBytes = new forge.util.ByteBuffer(salt);\n    var dk = pki.pbe.generatePkcs12Key(password, saltBytes, 1, count, dkLen);\n    var iv = pki.pbe.generatePkcs12Key(password, saltBytes, 2, count, dkLen);\n    var cipher = forge.des.createEncryptionCipher(dk);\n    cipher.start(iv);\n    cipher.update(asn1.toDer(obj));\n    cipher.finish();\n    encryptedData = cipher.output.getBytes();\n\n    encryptionAlgorithm = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(oids['pbeWithSHAAnd3-KeyTripleDES-CBC']).getBytes()),\n      // pkcs-12PbeParams\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // salt\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, salt),\n        // iteration count\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n          countBytes.getBytes())\n      ])\n    ]);\n  } else {\n    var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');\n    error.algorithm = options.algorithm;\n    throw error;\n  }\n\n  // EncryptedPrivateKeyInfo\n  var rval = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // encryptionAlgorithm\n    encryptionAlgorithm,\n    // encryptedData\n    asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, encryptedData)\n  ]);\n  return rval;\n};\n\n/**\n * Decrypts a ASN.1 PrivateKeyInfo object.\n *\n * @param obj the ASN.1 EncryptedPrivateKeyInfo object.\n * @param password the password to decrypt with.\n *\n * @return the ASN.1 PrivateKeyInfo on success, null on failure.\n */\npki.decryptPrivateKeyInfo = function(obj, password) {\n  var rval = null;\n\n  // get PBE params\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, encryptedPrivateKeyValidator, capture, errors)) {\n    var error = new Error('Cannot read encrypted private key. ' +\n      'ASN.1 object is not a supported EncryptedPrivateKeyInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // get cipher\n  var oid = asn1.derToOid(capture.encryptionOid);\n  var cipher = pki.pbe.getCipher(oid, capture.encryptionParams, password);\n\n  // get encrypted data\n  var encrypted = forge.util.createBuffer(capture.encryptedData);\n\n  cipher.update(encrypted);\n  if(cipher.finish()) {\n    rval = asn1.fromDer(cipher.output);\n  }\n\n  return rval;\n};\n\n/**\n * Converts a EncryptedPrivateKeyInfo to PEM format.\n *\n * @param epki the EncryptedPrivateKeyInfo.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted encrypted private key.\n */\npki.encryptedPrivateKeyToPem = function(epki, maxline) {\n  // convert to DER, then PEM-encode\n  var msg = {\n    type: 'ENCRYPTED PRIVATE KEY',\n    body: asn1.toDer(epki).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Converts a PEM-encoded EncryptedPrivateKeyInfo to ASN.1 format. Decryption\n * is not performed.\n *\n * @param pem the EncryptedPrivateKeyInfo in PEM-format.\n *\n * @return the ASN.1 EncryptedPrivateKeyInfo.\n */\npki.encryptedPrivateKeyFromPem = function(pem) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'ENCRYPTED PRIVATE KEY') {\n    var error = new Error('Could not convert encrypted private key from PEM; ' +\n      'PEM header type is \"ENCRYPTED PRIVATE KEY\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert encrypted private key from PEM; ' +\n      'PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  return asn1.fromDer(msg.body);\n};\n\n/**\n * Encrypts an RSA private key. By default, the key will be wrapped in\n * a PrivateKeyInfo and encrypted to produce a PKCS#8 EncryptedPrivateKeyInfo.\n * This is the standard, preferred way to encrypt a private key.\n *\n * To produce a non-standard PEM-encrypted private key that uses encapsulated\n * headers to indicate the encryption algorithm (old-style non-PKCS#8 OpenSSL\n * private key encryption), set the 'legacy' option to true. Note: Using this\n * option will cause the iteration count to be forced to 1.\n *\n * Note: The 'des' algorithm is supported, but it is not considered to be\n * secure because it only uses a single 56-bit key. If possible, it is highly\n * recommended that a different algorithm be used.\n *\n * @param rsaKey the RSA key to encrypt.\n * @param password the password to use.\n * @param options:\n *          algorithm: the encryption algorithm to use\n *            ('aes128', 'aes192', 'aes256', '3des', 'des').\n *          count: the iteration count to use.\n *          saltSize: the salt size to use.\n *          legacy: output an old non-PKCS#8 PEM-encrypted+encapsulated\n *            headers (DEK-Info) private key.\n *\n * @return the PEM-encoded ASN.1 EncryptedPrivateKeyInfo.\n */\npki.encryptRsaPrivateKey = function(rsaKey, password, options) {\n  // standard PKCS#8\n  options = options || {};\n  if(!options.legacy) {\n    // encrypt PrivateKeyInfo\n    var rval = pki.wrapRsaPrivateKey(pki.privateKeyToAsn1(rsaKey));\n    rval = pki.encryptPrivateKeyInfo(rval, password, options);\n    return pki.encryptedPrivateKeyToPem(rval);\n  }\n\n  // legacy non-PKCS#8\n  var algorithm;\n  var iv;\n  var dkLen;\n  var cipherFn;\n  switch(options.algorithm) {\n  case 'aes128':\n    algorithm = 'AES-128-CBC';\n    dkLen = 16;\n    iv = forge.random.getBytesSync(16);\n    cipherFn = forge.aes.createEncryptionCipher;\n    break;\n  case 'aes192':\n    algorithm = 'AES-192-CBC';\n    dkLen = 24;\n    iv = forge.random.getBytesSync(16);\n    cipherFn = forge.aes.createEncryptionCipher;\n    break;\n  case 'aes256':\n    algorithm = 'AES-256-CBC';\n    dkLen = 32;\n    iv = forge.random.getBytesSync(16);\n    cipherFn = forge.aes.createEncryptionCipher;\n    break;\n  case '3des':\n    algorithm = 'DES-EDE3-CBC';\n    dkLen = 24;\n    iv = forge.random.getBytesSync(8);\n    cipherFn = forge.des.createEncryptionCipher;\n    break;\n  case 'des':\n    algorithm = 'DES-CBC';\n    dkLen = 8;\n    iv = forge.random.getBytesSync(8);\n    cipherFn = forge.des.createEncryptionCipher;\n    break;\n  default:\n    var error = new Error('Could not encrypt RSA private key; unsupported ' +\n      'encryption algorithm \"' + options.algorithm + '\".');\n    error.algorithm = options.algorithm;\n    throw error;\n  }\n\n  // encrypt private key using OpenSSL legacy key derivation\n  var dk = forge.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);\n  var cipher = cipherFn(dk);\n  cipher.start(iv);\n  cipher.update(asn1.toDer(pki.privateKeyToAsn1(rsaKey)));\n  cipher.finish();\n\n  var msg = {\n    type: 'RSA PRIVATE KEY',\n    procType: {\n      version: '4',\n      type: 'ENCRYPTED'\n    },\n    dekInfo: {\n      algorithm: algorithm,\n      parameters: forge.util.bytesToHex(iv).toUpperCase()\n    },\n    body: cipher.output.getBytes()\n  };\n  return forge.pem.encode(msg);\n};\n\n/**\n * Decrypts an RSA private key.\n *\n * @param pem the PEM-formatted EncryptedPrivateKeyInfo to decrypt.\n * @param password the password to use.\n *\n * @return the RSA key on success, null on failure.\n */\npki.decryptRsaPrivateKey = function(pem, password) {\n  var rval = null;\n\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'ENCRYPTED PRIVATE KEY' &&\n    msg.type !== 'PRIVATE KEY' &&\n    msg.type !== 'RSA PRIVATE KEY') {\n    var error = new Error('Could not convert private key from PEM; PEM header type ' +\n      'is not \"ENCRYPTED PRIVATE KEY\", \"PRIVATE KEY\", or \"RSA PRIVATE KEY\".');\n    error.headerType = error;\n    throw error;\n  }\n\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    var dkLen;\n    var cipherFn;\n    switch(msg.dekInfo.algorithm) {\n    case 'DES-CBC':\n      dkLen = 8;\n      cipherFn = forge.des.createDecryptionCipher;\n      break;\n    case 'DES-EDE3-CBC':\n      dkLen = 24;\n      cipherFn = forge.des.createDecryptionCipher;\n      break;\n    case 'AES-128-CBC':\n      dkLen = 16;\n      cipherFn = forge.aes.createDecryptionCipher;\n      break;\n    case 'AES-192-CBC':\n      dkLen = 24;\n      cipherFn = forge.aes.createDecryptionCipher;\n      break;\n    case 'AES-256-CBC':\n      dkLen = 32;\n      cipherFn = forge.aes.createDecryptionCipher;\n      break;\n    case 'RC2-40-CBC':\n      dkLen = 5;\n      cipherFn = function(key) {\n        return forge.rc2.createDecryptionCipher(key, 40);\n      };\n      break;\n    case 'RC2-64-CBC':\n      dkLen = 8;\n      cipherFn = function(key) {\n        return forge.rc2.createDecryptionCipher(key, 64);\n      };\n      break;\n    case 'RC2-128-CBC':\n      dkLen = 16;\n      cipherFn = function(key) {\n        return forge.rc2.createDecryptionCipher(key, 128);\n      };\n      break;\n    default:\n      var error = new Error('Could not decrypt private key; unsupported ' +\n        'encryption algorithm \"' + msg.dekInfo.algorithm + '\".');\n      error.algorithm = msg.dekInfo.algorithm;\n      throw error;\n    }\n\n    // use OpenSSL legacy key derivation\n    var iv = forge.util.hexToBytes(msg.dekInfo.parameters);\n    var dk = forge.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);\n    var cipher = cipherFn(dk);\n    cipher.start(iv);\n    cipher.update(forge.util.createBuffer(msg.body));\n    if(cipher.finish()) {\n      rval = cipher.output.getBytes();\n    } else {\n      return rval;\n    }\n  } else {\n    rval = msg.body;\n  }\n\n  if(msg.type === 'ENCRYPTED PRIVATE KEY') {\n    rval = pki.decryptPrivateKeyInfo(asn1.fromDer(rval), password);\n  } else {\n    // decryption already performed above\n    rval = asn1.fromDer(rval);\n  }\n\n  if(rval !== null) {\n    rval = pki.privateKeyFromAsn1(rval);\n  }\n\n  return rval;\n};\n\n/**\n * Derives a PKCS#12 key.\n *\n * @param password the password to derive the key material from, null or\n *          undefined for none.\n * @param salt the salt, as a ByteBuffer, to use.\n * @param id the PKCS#12 ID byte (1 = key material, 2 = IV, 3 = MAC).\n * @param iter the iteration count.\n * @param n the number of bytes to derive from the password.\n * @param md the message digest to use, defaults to SHA-1.\n *\n * @return a ByteBuffer with the bytes derived from the password.\n */\npki.pbe.generatePkcs12Key = function(password, salt, id, iter, n, md) {\n  var j, l;\n\n  if(typeof md === 'undefined' || md === null) {\n    if(!('sha1' in forge.md)) {\n      throw new Error('\"sha1\" hash algorithm unavailable.');\n    }\n    md = forge.md.sha1.create();\n  }\n\n  var u = md.digestLength;\n  var v = md.blockLength;\n  var result = new forge.util.ByteBuffer();\n\n  /* Convert password to Unicode byte buffer + trailing 0-byte. */\n  var passBuf = new forge.util.ByteBuffer();\n  if(password !== null && password !== undefined) {\n    for(l = 0; l < password.length; l++) {\n      passBuf.putInt16(password.charCodeAt(l));\n    }\n    passBuf.putInt16(0);\n  }\n\n  /* Length of salt and password in BYTES. */\n  var p = passBuf.length();\n  var s = salt.length();\n\n  /* 1. Construct a string, D (the \"diversifier\"), by concatenating\n        v copies of ID. */\n  var D = new forge.util.ByteBuffer();\n  D.fillWithByte(id, v);\n\n  /* 2. Concatenate copies of the salt together to create a string S of length\n        v * ceil(s / v) bytes (the final copy of the salt may be trunacted\n        to create S).\n        Note that if the salt is the empty string, then so is S. */\n  var Slen = v * Math.ceil(s / v);\n  var S = new forge.util.ByteBuffer();\n  for(l = 0; l < Slen; l++) {\n    S.putByte(salt.at(l % s));\n  }\n\n  /* 3. Concatenate copies of the password together to create a string P of\n        length v * ceil(p / v) bytes (the final copy of the password may be\n        truncated to create P).\n        Note that if the password is the empty string, then so is P. */\n  var Plen = v * Math.ceil(p / v);\n  var P = new forge.util.ByteBuffer();\n  for(l = 0; l < Plen; l++) {\n    P.putByte(passBuf.at(l % p));\n  }\n\n  /* 4. Set I=S||P to be the concatenation of S and P. */\n  var I = S;\n  I.putBuffer(P);\n\n  /* 5. Set c=ceil(n / u). */\n  var c = Math.ceil(n / u);\n\n  /* 6. For i=1, 2, ..., c, do the following: */\n  for(var i = 1; i <= c; i++) {\n    /* a) Set Ai=H^r(D||I). (l.e. the rth hash of D||I, H(H(H(...H(D||I)))) */\n    var buf = new forge.util.ByteBuffer();\n    buf.putBytes(D.bytes());\n    buf.putBytes(I.bytes());\n    for(var round = 0; round < iter; round++) {\n      md.start();\n      md.update(buf.getBytes());\n      buf = md.digest();\n    }\n\n    /* b) Concatenate copies of Ai to create a string B of length v bytes (the\n          final copy of Ai may be truncated to create B). */\n    var B = new forge.util.ByteBuffer();\n    for(l = 0; l < v; l++) {\n      B.putByte(buf.at(l % u));\n    }\n\n    /* c) Treating I as a concatenation I0, I1, ..., Ik-1 of v-byte blocks,\n          where k=ceil(s / v) + ceil(p / v), modify I by setting\n          Ij=(Ij+B+1) mod 2v for each j.  */\n    var k = Math.ceil(s / v) + Math.ceil(p / v);\n    var Inew = new forge.util.ByteBuffer();\n    for(j = 0; j < k; j++) {\n      var chunk = new forge.util.ByteBuffer(I.getBytes(v));\n      var x = 0x1ff;\n      for(l = B.length() - 1; l >= 0; l--) {\n        x = x >> 8;\n        x += B.at(l) + chunk.at(l);\n        chunk.setAt(l, x & 0xff);\n      }\n      Inew.putBuffer(chunk);\n    }\n    I = Inew;\n\n    /* Add Ai to A. */\n    result.putBuffer(buf);\n  }\n\n  result.truncate(result.length() - n);\n  return result;\n};\n\n/**\n * Get new Forge cipher object instance.\n *\n * @param oid the OID (in string notation).\n * @param params the ASN.1 params object.\n * @param password the password to decrypt with.\n *\n * @return new cipher object instance.\n */\npki.pbe.getCipher = function(oid, params, password) {\n  switch(oid) {\n  case pki.oids['pkcs5PBES2']:\n    return pki.pbe.getCipherForPBES2(oid, params, password);\n\n  case pki.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:\n  case pki.oids['pbewithSHAAnd40BitRC2-CBC']:\n    return pki.pbe.getCipherForPKCS12PBE(oid, params, password);\n\n  default:\n    var error = new Error('Cannot read encrypted PBE data block. Unsupported OID.');\n    error.oid = oid;\n    error.supportedOids = [\n      'pkcs5PBES2',\n      'pbeWithSHAAnd3-KeyTripleDES-CBC',\n      'pbewithSHAAnd40BitRC2-CBC'\n    ];\n    throw error;\n  }\n};\n\n/**\n * Get new Forge cipher object instance according to PBES2 params block.\n *\n * The returned cipher instance is already started using the IV\n * from PBES2 parameter block.\n *\n * @param oid the PKCS#5 PBKDF2 OID (in string notation).\n * @param params the ASN.1 PBES2-params object.\n * @param password the password to decrypt with.\n *\n * @return new cipher object instance.\n */\npki.pbe.getCipherForPBES2 = function(oid, params, password) {\n  // get PBE params\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(params, PBES2AlgorithmsValidator, capture, errors)) {\n    var error = new Error('Cannot read password-based-encryption algorithm ' +\n      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // check oids\n  oid = asn1.derToOid(capture.kdfOid);\n  if(oid !== pki.oids['pkcs5PBKDF2']) {\n    var error = new Error('Cannot read encrypted private key. ' +\n      'Unsupported key derivation function OID.');\n    error.oid = oid;\n    error.supportedOids = ['pkcs5PBKDF2'];\n    throw error;\n  }\n  oid = asn1.derToOid(capture.encOid);\n  if(oid !== pki.oids['aes128-CBC'] &&\n    oid !== pki.oids['aes192-CBC'] &&\n    oid !== pki.oids['aes256-CBC'] &&\n    oid !== pki.oids['des-EDE3-CBC'] &&\n    oid !== pki.oids['desCBC']) {\n    var error = new Error('Cannot read encrypted private key. ' +\n      'Unsupported encryption scheme OID.');\n    error.oid = oid;\n    error.supportedOids = [\n      'aes128-CBC', 'aes192-CBC', 'aes256-CBC', 'des-EDE3-CBC', 'desCBC'];\n    throw error;\n  }\n\n  // set PBE params\n  var salt = capture.kdfSalt;\n  var count = forge.util.createBuffer(capture.kdfIterationCount);\n  count = count.getInt(count.length() << 3);\n  var dkLen;\n  var cipherFn;\n  switch(pki.oids[oid]) {\n  case 'aes128-CBC':\n    dkLen = 16;\n    cipherFn = forge.aes.createDecryptionCipher;\n    break;\n  case 'aes192-CBC':\n    dkLen = 24;\n    cipherFn = forge.aes.createDecryptionCipher;\n    break;\n  case 'aes256-CBC':\n    dkLen = 32;\n    cipherFn = forge.aes.createDecryptionCipher;\n    break;\n  case 'des-EDE3-CBC':\n    dkLen = 24;\n    cipherFn = forge.des.createDecryptionCipher;\n    break;\n  case 'desCBC':\n    dkLen = 8;\n    cipherFn = forge.des.createDecryptionCipher;\n    break;\n  }\n\n  // get PRF message digest\n  var md = prfOidToMessageDigest(capture.prfOid);\n\n  // decrypt private key using pbe with chosen PRF and AES/DES\n  var dk = forge.pkcs5.pbkdf2(password, salt, count, dkLen, md);\n  var iv = capture.encIv;\n  var cipher = cipherFn(dk);\n  cipher.start(iv);\n\n  return cipher;\n};\n\n/**\n * Get new Forge cipher object instance for PKCS#12 PBE.\n *\n * The returned cipher instance is already started using the key & IV\n * derived from the provided password and PKCS#12 PBE salt.\n *\n * @param oid The PKCS#12 PBE OID (in string notation).\n * @param params The ASN.1 PKCS#12 PBE-params object.\n * @param password The password to decrypt with.\n *\n * @return the new cipher object instance.\n */\npki.pbe.getCipherForPKCS12PBE = function(oid, params, password) {\n  // get PBE params\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(params, pkcs12PbeParamsValidator, capture, errors)) {\n    var error = new Error('Cannot read password-based-encryption algorithm ' +\n      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  var salt = forge.util.createBuffer(capture.salt);\n  var count = forge.util.createBuffer(capture.iterations);\n  count = count.getInt(count.length() << 3);\n\n  var dkLen, dIvLen, cipherFn;\n  switch(oid) {\n    case pki.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:\n      dkLen = 24;\n      dIvLen = 8;\n      cipherFn = forge.des.startDecrypting;\n      break;\n\n    case pki.oids['pbewithSHAAnd40BitRC2-CBC']:\n      dkLen = 5;\n      dIvLen = 8;\n      cipherFn = function(key, iv) {\n        var cipher = forge.rc2.createDecryptionCipher(key, 40);\n        cipher.start(iv, null);\n        return cipher;\n      };\n      break;\n\n    default:\n      var error = new Error('Cannot read PKCS #12 PBE data block. Unsupported OID.');\n      error.oid = oid;\n      throw error;\n  }\n\n  // get PRF message digest\n  var md = prfOidToMessageDigest(capture.prfOid);\n  var key = pki.pbe.generatePkcs12Key(password, salt, 1, count, dkLen, md);\n  md.start();\n  var iv = pki.pbe.generatePkcs12Key(password, salt, 2, count, dIvLen, md);\n\n  return cipherFn(key, iv);\n};\n\n/**\n * OpenSSL's legacy key derivation function.\n *\n * See: http://www.openssl.org/docs/crypto/EVP_BytesToKey.html\n *\n * @param password the password to derive the key from.\n * @param salt the salt to use, null for none.\n * @param dkLen the number of bytes needed for the derived key.\n * @param [options] the options to use:\n *          [md] an optional message digest object to use.\n */\npki.pbe.opensslDeriveBytes = function(password, salt, dkLen, md) {\n  if(typeof md === 'undefined' || md === null) {\n    if(!('md5' in forge.md)) {\n      throw new Error('\"md5\" hash algorithm unavailable.');\n    }\n    md = forge.md.md5.create();\n  }\n  if(salt === null) {\n    salt = '';\n  }\n  var digests = [hash(md, password + salt)];\n  for(var length = 16, i = 1; length < dkLen; ++i, length += 16) {\n    digests.push(hash(md, digests[i - 1] + password + salt));\n  }\n  return digests.join('').substr(0, dkLen);\n};\n\nfunction hash(md, bytes) {\n  return md.start().update(bytes).digest().getBytes();\n}\n\nfunction prfOidToMessageDigest(prfOid) {\n  // get PRF algorithm, default to SHA-1\n  var prfAlgorithm;\n  if(!prfOid) {\n    prfAlgorithm = 'hmacWithSHA1';\n  } else {\n    prfAlgorithm = pki.oids[asn1.derToOid(prfOid)];\n    if(!prfAlgorithm) {\n      var error = new Error('Unsupported PRF OID.');\n      error.oid = prfOid;\n      error.supported = [\n        'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',\n        'hmacWithSHA512'];\n      throw error;\n    }\n  }\n  return prfAlgorithmToMessageDigest(prfAlgorithm);\n}\n\nfunction prfAlgorithmToMessageDigest(prfAlgorithm) {\n  var factory = forge.md;\n  switch(prfAlgorithm) {\n  case 'hmacWithSHA224':\n    factory = forge.md.sha512;\n  case 'hmacWithSHA1':\n  case 'hmacWithSHA256':\n  case 'hmacWithSHA384':\n  case 'hmacWithSHA512':\n    prfAlgorithm = prfAlgorithm.substr(8).toLowerCase();\n    break;\n  default:\n    var error = new Error('Unsupported PRF algorithm.');\n    error.algorithm = prfAlgorithm;\n    error.supported = [\n      'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',\n      'hmacWithSHA512'];\n    throw error;\n  }\n  if(!factory || !(prfAlgorithm in factory)) {\n    throw new Error('Unknown hash algorithm: ' + prfAlgorithm);\n  }\n  return factory[prfAlgorithm].create();\n}\n\nfunction createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm) {\n  var params = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // salt\n    asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, salt),\n    // iteration count\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      countBytes.getBytes())\n  ]);\n  // when PRF algorithm is not SHA-1 default, add key length and PRF algorithm\n  if(prfAlgorithm !== 'hmacWithSHA1') {\n    params.value.push(\n      // key length\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        forge.util.hexToBytes(dkLen.toString(16))),\n      // AlgorithmIdentifier\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // algorithm\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids[prfAlgorithm]).getBytes()),\n        // parameters (null)\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n      ]));\n  }\n  return params;\n}\n","/**\n * Password-Based Key-Derivation Function #2 implementation.\n *\n * See RFC 2898 for details.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2013 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./hmac');\nrequire('./md');\nrequire('./util');\n\nvar pkcs5 = forge.pkcs5 = forge.pkcs5 || {};\n\nvar crypto;\nif(forge.util.isNodejs && !forge.options.usePureJavaScript) {\n  crypto = require('crypto');\n}\n\n/**\n * Derives a key from a password.\n *\n * @param p the password as a binary-encoded string of bytes.\n * @param s the salt as a binary-encoded string of bytes.\n * @param c the iteration count, a positive integer.\n * @param dkLen the intended length, in bytes, of the derived key,\n *          (max: 2^32 - 1) * hash length of the PRF.\n * @param [md] the message digest (or algorithm identifier as a string) to use\n *          in the PRF, defaults to SHA-1.\n * @param [callback(err, key)] presence triggers asynchronous version, called\n *          once the operation completes.\n *\n * @return the derived key, as a binary-encoded string of bytes, for the\n *           synchronous version (if no callback is specified).\n */\nmodule.exports = forge.pbkdf2 = pkcs5.pbkdf2 = function(\n  p, s, c, dkLen, md, callback) {\n  if(typeof md === 'function') {\n    callback = md;\n    md = null;\n  }\n\n  // use native implementation if possible and not disabled, note that\n  // some node versions only support SHA-1, others allow digest to be changed\n  if(forge.util.isNodejs && !forge.options.usePureJavaScript &&\n    crypto.pbkdf2 && (md === null || typeof md !== 'object') &&\n    (crypto.pbkdf2Sync.length > 4 || (!md || md === 'sha1'))) {\n    if(typeof md !== 'string') {\n      // default prf to SHA-1\n      md = 'sha1';\n    }\n    p = Buffer.from(p, 'binary');\n    s = Buffer.from(s, 'binary');\n    if(!callback) {\n      if(crypto.pbkdf2Sync.length === 4) {\n        return crypto.pbkdf2Sync(p, s, c, dkLen).toString('binary');\n      }\n      return crypto.pbkdf2Sync(p, s, c, dkLen, md).toString('binary');\n    }\n    if(crypto.pbkdf2Sync.length === 4) {\n      return crypto.pbkdf2(p, s, c, dkLen, function(err, key) {\n        if(err) {\n          return callback(err);\n        }\n        callback(null, key.toString('binary'));\n      });\n    }\n    return crypto.pbkdf2(p, s, c, dkLen, md, function(err, key) {\n      if(err) {\n        return callback(err);\n      }\n      callback(null, key.toString('binary'));\n    });\n  }\n\n  if(typeof md === 'undefined' || md === null) {\n    // default prf to SHA-1\n    md = 'sha1';\n  }\n  if(typeof md === 'string') {\n    if(!(md in forge.md.algorithms)) {\n      throw new Error('Unknown hash algorithm: ' + md);\n    }\n    md = forge.md[md].create();\n  }\n\n  var hLen = md.digestLength;\n\n  /* 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and\n    stop. */\n  if(dkLen > (0xFFFFFFFF * hLen)) {\n    var err = new Error('Derived key is too long.');\n    if(callback) {\n      return callback(err);\n    }\n    throw err;\n  }\n\n  /* 2. Let len be the number of hLen-octet blocks in the derived key,\n    rounding up, and let r be the number of octets in the last\n    block:\n\n    len = CEIL(dkLen / hLen),\n    r = dkLen - (len - 1) * hLen. */\n  var len = Math.ceil(dkLen / hLen);\n  var r = dkLen - (len - 1) * hLen;\n\n  /* 3. For each block of the derived key apply the function F defined\n    below to the password P, the salt S, the iteration count c, and\n    the block index to compute the block:\n\n    T_1 = F(P, S, c, 1),\n    T_2 = F(P, S, c, 2),\n    ...\n    T_len = F(P, S, c, len),\n\n    where the function F is defined as the exclusive-or sum of the\n    first c iterates of the underlying pseudorandom function PRF\n    applied to the password P and the concatenation of the salt S\n    and the block index i:\n\n    F(P, S, c, i) = u_1 XOR u_2 XOR ... XOR u_c\n\n    where\n\n    u_1 = PRF(P, S || INT(i)),\n    u_2 = PRF(P, u_1),\n    ...\n    u_c = PRF(P, u_{c-1}).\n\n    Here, INT(i) is a four-octet encoding of the integer i, most\n    significant octet first. */\n  var prf = forge.hmac.create();\n  prf.start(md, p);\n  var dk = '';\n  var xor, u_c, u_c1;\n\n  // sync version\n  if(!callback) {\n    for(var i = 1; i <= len; ++i) {\n      // PRF(P, S || INT(i)) (first iteration)\n      prf.start(null, null);\n      prf.update(s);\n      prf.update(forge.util.int32ToBytes(i));\n      xor = u_c1 = prf.digest().getBytes();\n\n      // PRF(P, u_{c-1}) (other iterations)\n      for(var j = 2; j <= c; ++j) {\n        prf.start(null, null);\n        prf.update(u_c1);\n        u_c = prf.digest().getBytes();\n        // F(p, s, c, i)\n        xor = forge.util.xorBytes(xor, u_c, hLen);\n        u_c1 = u_c;\n      }\n\n      /* 4. Concatenate the blocks and extract the first dkLen octets to\n        produce a derived key DK:\n\n        DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */\n      dk += (i < len) ? xor : xor.substr(0, r);\n    }\n    /* 5. Output the derived key DK. */\n    return dk;\n  }\n\n  // async version\n  var i = 1, j;\n  function outer() {\n    if(i > len) {\n      // done\n      return callback(null, dk);\n    }\n\n    // PRF(P, S || INT(i)) (first iteration)\n    prf.start(null, null);\n    prf.update(s);\n    prf.update(forge.util.int32ToBytes(i));\n    xor = u_c1 = prf.digest().getBytes();\n\n    // PRF(P, u_{c-1}) (other iterations)\n    j = 2;\n    inner();\n  }\n\n  function inner() {\n    if(j <= c) {\n      prf.start(null, null);\n      prf.update(u_c1);\n      u_c = prf.digest().getBytes();\n      // F(p, s, c, i)\n      xor = forge.util.xorBytes(xor, u_c, hLen);\n      u_c1 = u_c;\n      ++j;\n      return forge.util.setImmediate(inner);\n    }\n\n    /* 4. Concatenate the blocks and extract the first dkLen octets to\n      produce a derived key DK:\n\n      DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */\n    dk += (i < len) ? xor : xor.substr(0, r);\n\n    ++i;\n    outer();\n  }\n\n  outer();\n};\n","/**\n * Javascript implementation of basic PEM (Privacy Enhanced Mail) algorithms.\n *\n * See: RFC 1421.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2013-2014 Digital Bazaar, Inc.\n *\n * A Forge PEM object has the following fields:\n *\n * type: identifies the type of message (eg: \"RSA PRIVATE KEY\").\n *\n * procType: identifies the type of processing performed on the message,\n *   it has two subfields: version and type, eg: 4,ENCRYPTED.\n *\n * contentDomain: identifies the type of content in the message, typically\n *   only uses the value: \"RFC822\".\n *\n * dekInfo: identifies the message encryption algorithm and mode and includes\n *   any parameters for the algorithm, it has two subfields: algorithm and\n *   parameters, eg: DES-CBC,F8143EDE5960C597.\n *\n * headers: contains all other PEM encapsulated headers -- where order is\n *   significant (for pairing data like recipient ID + key info).\n *\n * body: the binary-encoded body.\n */\nvar forge = require('./forge');\nrequire('./util');\n\n// shortcut for pem API\nvar pem = module.exports = forge.pem = forge.pem || {};\n\n/**\n * Encodes (serializes) the given PEM object.\n *\n * @param msg the PEM message object to encode.\n * @param options the options to use:\n *          maxline the maximum characters per line for the body, (default: 64).\n *\n * @return the PEM-formatted string.\n */\npem.encode = function(msg, options) {\n  options = options || {};\n  var rval = '-----BEGIN ' + msg.type + '-----\\r\\n';\n\n  // encode special headers\n  var header;\n  if(msg.procType) {\n    header = {\n      name: 'Proc-Type',\n      values: [String(msg.procType.version), msg.procType.type]\n    };\n    rval += foldHeader(header);\n  }\n  if(msg.contentDomain) {\n    header = {name: 'Content-Domain', values: [msg.contentDomain]};\n    rval += foldHeader(header);\n  }\n  if(msg.dekInfo) {\n    header = {name: 'DEK-Info', values: [msg.dekInfo.algorithm]};\n    if(msg.dekInfo.parameters) {\n      header.values.push(msg.dekInfo.parameters);\n    }\n    rval += foldHeader(header);\n  }\n\n  if(msg.headers) {\n    // encode all other headers\n    for(var i = 0; i < msg.headers.length; ++i) {\n      rval += foldHeader(msg.headers[i]);\n    }\n  }\n\n  // terminate header\n  if(msg.procType) {\n    rval += '\\r\\n';\n  }\n\n  // add body\n  rval += forge.util.encode64(msg.body, options.maxline || 64) + '\\r\\n';\n\n  rval += '-----END ' + msg.type + '-----\\r\\n';\n  return rval;\n};\n\n/**\n * Decodes (deserializes) all PEM messages found in the given string.\n *\n * @param str the PEM-formatted string to decode.\n *\n * @return the PEM message objects in an array.\n */\npem.decode = function(str) {\n  var rval = [];\n\n  // split string into PEM messages (be lenient w/EOF on BEGIN line)\n  var rMessage = /\\s*-----BEGIN ([A-Z0-9- ]+)-----\\r?\\n?([\\x21-\\x7e\\s]+?(?:\\r?\\n\\r?\\n))?([:A-Za-z0-9+\\/=\\s]+?)-----END \\1-----/g;\n  var rHeader = /([\\x21-\\x7e]+):\\s*([\\x21-\\x7e\\s^:]+)/;\n  var rCRLF = /\\r?\\n/;\n  var match;\n  while(true) {\n    match = rMessage.exec(str);\n    if(!match) {\n      break;\n    }\n\n    // accept \"NEW CERTIFICATE REQUEST\" as \"CERTIFICATE REQUEST\"\n    // https://datatracker.ietf.org/doc/html/rfc7468#section-7\n    var type = match[1];\n    if(type === 'NEW CERTIFICATE REQUEST') {\n      type = 'CERTIFICATE REQUEST';\n    }\n\n    var msg = {\n      type: type,\n      procType: null,\n      contentDomain: null,\n      dekInfo: null,\n      headers: [],\n      body: forge.util.decode64(match[3])\n    };\n    rval.push(msg);\n\n    // no headers\n    if(!match[2]) {\n      continue;\n    }\n\n    // parse headers\n    var lines = match[2].split(rCRLF);\n    var li = 0;\n    while(match && li < lines.length) {\n      // get line, trim any rhs whitespace\n      var line = lines[li].replace(/\\s+$/, '');\n\n      // RFC2822 unfold any following folded lines\n      for(var nl = li + 1; nl < lines.length; ++nl) {\n        var next = lines[nl];\n        if(!/\\s/.test(next[0])) {\n          break;\n        }\n        line += next;\n        li = nl;\n      }\n\n      // parse header\n      match = line.match(rHeader);\n      if(match) {\n        var header = {name: match[1], values: []};\n        var values = match[2].split(',');\n        for(var vi = 0; vi < values.length; ++vi) {\n          header.values.push(ltrim(values[vi]));\n        }\n\n        // Proc-Type must be the first header\n        if(!msg.procType) {\n          if(header.name !== 'Proc-Type') {\n            throw new Error('Invalid PEM formatted message. The first ' +\n              'encapsulated header must be \"Proc-Type\".');\n          } else if(header.values.length !== 2) {\n            throw new Error('Invalid PEM formatted message. The \"Proc-Type\" ' +\n              'header must have two subfields.');\n          }\n          msg.procType = {version: values[0], type: values[1]};\n        } else if(!msg.contentDomain && header.name === 'Content-Domain') {\n          // special-case Content-Domain\n          msg.contentDomain = values[0] || '';\n        } else if(!msg.dekInfo && header.name === 'DEK-Info') {\n          // special-case DEK-Info\n          if(header.values.length === 0) {\n            throw new Error('Invalid PEM formatted message. The \"DEK-Info\" ' +\n              'header must have at least one subfield.');\n          }\n          msg.dekInfo = {algorithm: values[0], parameters: values[1] || null};\n        } else {\n          msg.headers.push(header);\n        }\n      }\n\n      ++li;\n    }\n\n    if(msg.procType === 'ENCRYPTED' && !msg.dekInfo) {\n      throw new Error('Invalid PEM formatted message. The \"DEK-Info\" ' +\n        'header must be present if \"Proc-Type\" is \"ENCRYPTED\".');\n    }\n  }\n\n  if(rval.length === 0) {\n    throw new Error('Invalid PEM formatted message.');\n  }\n\n  return rval;\n};\n\nfunction foldHeader(header) {\n  var rval = header.name + ': ';\n\n  // ensure values with CRLF are folded\n  var values = [];\n  var insertSpace = function(match, $1) {\n    return ' ' + $1;\n  };\n  for(var i = 0; i < header.values.length; ++i) {\n    values.push(header.values[i].replace(/^(\\S+\\r\\n)/, insertSpace));\n  }\n  rval += values.join(',') + '\\r\\n';\n\n  // do folding\n  var length = 0;\n  var candidate = -1;\n  for(var i = 0; i < rval.length; ++i, ++length) {\n    if(length > 65 && candidate !== -1) {\n      var insert = rval[candidate];\n      if(insert === ',') {\n        ++candidate;\n        rval = rval.substr(0, candidate) + '\\r\\n ' + rval.substr(candidate);\n      } else {\n        rval = rval.substr(0, candidate) +\n          '\\r\\n' + insert + rval.substr(candidate + 1);\n      }\n      length = (i - candidate - 1);\n      candidate = -1;\n      ++i;\n    } else if(rval[i] === ' ' || rval[i] === '\\t' || rval[i] === ',') {\n      candidate = i;\n    }\n  }\n\n  return rval;\n}\n\nfunction ltrim(str) {\n  return str.replace(/^\\s+/, '');\n}\n","/**\n * Partial implementation of PKCS#1 v2.2: RSA-OEAP\n *\n * Modified but based on the following MIT and BSD licensed code:\n *\n * https://github.com/kjur/jsjws/blob/master/rsa.js:\n *\n * The 'jsjws'(JSON Web Signature JavaScript Library) License\n *\n * Copyright (c) 2012 Kenji Urushima\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n *\n * http://webrsa.cvs.sourceforge.net/viewvc/webrsa/Client/RSAES-OAEP.js?content-type=text%2Fplain:\n *\n * RSAES-OAEP.js\n * $Id: RSAES-OAEP.js,v 1.1.1.1 2003/03/19 15:37:20 ellispritchard Exp $\n * JavaScript Implementation of PKCS #1 v2.1 RSA CRYPTOGRAPHY STANDARD (RSA Laboratories, June 14, 2002)\n * Copyright (C) Ellis Pritchard, Guardian Unlimited 2003.\n * Contact: ellis@nukinetics.com\n * Distributed under the BSD License.\n *\n * Official documentation: http://www.rsa.com/rsalabs/node.asp?id=2125\n *\n * @author Evan Jones (http://evanjones.ca/)\n * @author Dave Longley\n *\n * Copyright (c) 2013-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\nrequire('./random');\nrequire('./sha1');\n\n// shortcut for PKCS#1 API\nvar pkcs1 = module.exports = forge.pkcs1 = forge.pkcs1 || {};\n\n/**\n * Encode the given RSAES-OAEP message (M) using key, with optional label (L)\n * and seed.\n *\n * This method does not perform RSA encryption, it only encodes the message\n * using RSAES-OAEP.\n *\n * @param key the RSA key to use.\n * @param message the message to encode.\n * @param options the options to use:\n *          label an optional label to use.\n *          seed the seed to use.\n *          md the message digest object to use, undefined for SHA-1.\n *          mgf1 optional mgf1 parameters:\n *            md the message digest object to use for MGF1.\n *\n * @return the encoded message bytes.\n */\npkcs1.encode_rsa_oaep = function(key, message, options) {\n  // parse arguments\n  var label;\n  var seed;\n  var md;\n  var mgf1Md;\n  // legacy args (label, seed, md)\n  if(typeof options === 'string') {\n    label = options;\n    seed = arguments[3] || undefined;\n    md = arguments[4] || undefined;\n  } else if(options) {\n    label = options.label || undefined;\n    seed = options.seed || undefined;\n    md = options.md || undefined;\n    if(options.mgf1 && options.mgf1.md) {\n      mgf1Md = options.mgf1.md;\n    }\n  }\n\n  // default OAEP to SHA-1 message digest\n  if(!md) {\n    md = forge.md.sha1.create();\n  } else {\n    md.start();\n  }\n\n  // default MGF-1 to same as OAEP\n  if(!mgf1Md) {\n    mgf1Md = md;\n  }\n\n  // compute length in bytes and check output\n  var keyLength = Math.ceil(key.n.bitLength() / 8);\n  var maxLength = keyLength - 2 * md.digestLength - 2;\n  if(message.length > maxLength) {\n    var error = new Error('RSAES-OAEP input message length is too long.');\n    error.length = message.length;\n    error.maxLength = maxLength;\n    throw error;\n  }\n\n  if(!label) {\n    label = '';\n  }\n  md.update(label, 'raw');\n  var lHash = md.digest();\n\n  var PS = '';\n  var PS_length = maxLength - message.length;\n  for(var i = 0; i < PS_length; i++) {\n    PS += '\\x00';\n  }\n\n  var DB = lHash.getBytes() + PS + '\\x01' + message;\n\n  if(!seed) {\n    seed = forge.random.getBytes(md.digestLength);\n  } else if(seed.length !== md.digestLength) {\n    var error = new Error('Invalid RSAES-OAEP seed. The seed length must ' +\n      'match the digest length.');\n    error.seedLength = seed.length;\n    error.digestLength = md.digestLength;\n    throw error;\n  }\n\n  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);\n  var maskedDB = forge.util.xorBytes(DB, dbMask, DB.length);\n\n  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);\n  var maskedSeed = forge.util.xorBytes(seed, seedMask, seed.length);\n\n  // return encoded message\n  return '\\x00' + maskedSeed + maskedDB;\n};\n\n/**\n * Decode the given RSAES-OAEP encoded message (EM) using key, with optional\n * label (L).\n *\n * This method does not perform RSA decryption, it only decodes the message\n * using RSAES-OAEP.\n *\n * @param key the RSA key to use.\n * @param em the encoded message to decode.\n * @param options the options to use:\n *          label an optional label to use.\n *          md the message digest object to use for OAEP, undefined for SHA-1.\n *          mgf1 optional mgf1 parameters:\n *            md the message digest object to use for MGF1.\n *\n * @return the decoded message bytes.\n */\npkcs1.decode_rsa_oaep = function(key, em, options) {\n  // parse args\n  var label;\n  var md;\n  var mgf1Md;\n  // legacy args\n  if(typeof options === 'string') {\n    label = options;\n    md = arguments[3] || undefined;\n  } else if(options) {\n    label = options.label || undefined;\n    md = options.md || undefined;\n    if(options.mgf1 && options.mgf1.md) {\n      mgf1Md = options.mgf1.md;\n    }\n  }\n\n  // compute length in bytes\n  var keyLength = Math.ceil(key.n.bitLength() / 8);\n\n  if(em.length !== keyLength) {\n    var error = new Error('RSAES-OAEP encoded message length is invalid.');\n    error.length = em.length;\n    error.expectedLength = keyLength;\n    throw error;\n  }\n\n  // default OAEP to SHA-1 message digest\n  if(md === undefined) {\n    md = forge.md.sha1.create();\n  } else {\n    md.start();\n  }\n\n  // default MGF-1 to same as OAEP\n  if(!mgf1Md) {\n    mgf1Md = md;\n  }\n\n  if(keyLength < 2 * md.digestLength + 2) {\n    throw new Error('RSAES-OAEP key is too short for the hash function.');\n  }\n\n  if(!label) {\n    label = '';\n  }\n  md.update(label, 'raw');\n  var lHash = md.digest().getBytes();\n\n  // split the message into its parts\n  var y = em.charAt(0);\n  var maskedSeed = em.substring(1, md.digestLength + 1);\n  var maskedDB = em.substring(1 + md.digestLength);\n\n  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);\n  var seed = forge.util.xorBytes(maskedSeed, seedMask, maskedSeed.length);\n\n  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);\n  var db = forge.util.xorBytes(maskedDB, dbMask, maskedDB.length);\n\n  var lHashPrime = db.substring(0, md.digestLength);\n\n  // constant time check that all values match what is expected\n  var error = (y !== '\\x00');\n\n  // constant time check lHash vs lHashPrime\n  for(var i = 0; i < md.digestLength; ++i) {\n    error |= (lHash.charAt(i) !== lHashPrime.charAt(i));\n  }\n\n  // \"constant time\" find the 0x1 byte separating the padding (zeros) from the\n  // message\n  // TODO: It must be possible to do this in a better/smarter way?\n  var in_ps = 1;\n  var index = md.digestLength;\n  for(var j = md.digestLength; j < db.length; j++) {\n    var code = db.charCodeAt(j);\n\n    var is_0 = (code & 0x1) ^ 0x1;\n\n    // non-zero if not 0 or 1 in the ps section\n    var error_mask = in_ps ? 0xfffe : 0x0000;\n    error |= (code & error_mask);\n\n    // latch in_ps to zero after we find 0x1\n    in_ps = in_ps & is_0;\n    index += in_ps;\n  }\n\n  if(error || db.charCodeAt(index) !== 0x1) {\n    throw new Error('Invalid RSAES-OAEP padding.');\n  }\n\n  return db.substring(index + 1);\n};\n\nfunction rsa_mgf1(seed, maskLength, hash) {\n  // default to SHA-1 message digest\n  if(!hash) {\n    hash = forge.md.sha1.create();\n  }\n  var t = '';\n  var count = Math.ceil(maskLength / hash.digestLength);\n  for(var i = 0; i < count; ++i) {\n    var c = String.fromCharCode(\n      (i >> 24) & 0xFF, (i >> 16) & 0xFF, (i >> 8) & 0xFF, i & 0xFF);\n    hash.start();\n    hash.update(seed + c);\n    t += hash.digest().getBytes();\n  }\n  return t.substring(0, maskLength);\n}\n","/**\n * Javascript implementation of PKCS#12.\n *\n * @author Dave Longley\n * @author Stefan Siegl <stesie@brokenpipe.de>\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n *\n * The ASN.1 representation of PKCS#12 is as follows\n * (see ftp://ftp.rsasecurity.com/pub/pkcs/pkcs-12/pkcs-12-tc1.pdf for details)\n *\n * PFX ::= SEQUENCE {\n *   version  INTEGER {v3(3)}(v3,...),\n *   authSafe ContentInfo,\n *   macData  MacData OPTIONAL\n * }\n *\n * MacData ::= SEQUENCE {\n *   mac DigestInfo,\n *   macSalt OCTET STRING,\n *   iterations INTEGER DEFAULT 1\n * }\n * Note: The iterations default is for historical reasons and its use is\n * deprecated. A higher value, like 1024, is recommended.\n *\n * DigestInfo is defined in PKCS#7 as follows:\n *\n * DigestInfo ::= SEQUENCE {\n *   digestAlgorithm DigestAlgorithmIdentifier,\n *   digest Digest\n * }\n *\n * DigestAlgorithmIdentifier ::= AlgorithmIdentifier\n *\n * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters\n * for the algorithm, if any. In the case of SHA1 there is none.\n *\n * AlgorithmIdentifer ::= SEQUENCE {\n *    algorithm OBJECT IDENTIFIER,\n *    parameters ANY DEFINED BY algorithm OPTIONAL\n * }\n *\n * Digest ::= OCTET STRING\n *\n *\n * ContentInfo ::= SEQUENCE {\n *   contentType ContentType,\n *   content     [0] EXPLICIT ANY DEFINED BY contentType OPTIONAL\n * }\n *\n * ContentType ::= OBJECT IDENTIFIER\n *\n * AuthenticatedSafe ::= SEQUENCE OF ContentInfo\n * -- Data if unencrypted\n * -- EncryptedData if password-encrypted\n * -- EnvelopedData if public key-encrypted\n *\n *\n * SafeContents ::= SEQUENCE OF SafeBag\n *\n * SafeBag ::= SEQUENCE {\n *   bagId     BAG-TYPE.&id ({PKCS12BagSet})\n *   bagValue  [0] EXPLICIT BAG-TYPE.&Type({PKCS12BagSet}{@bagId}),\n *   bagAttributes SET OF PKCS12Attribute OPTIONAL\n * }\n *\n * PKCS12Attribute ::= SEQUENCE {\n *   attrId ATTRIBUTE.&id ({PKCS12AttrSet}),\n *   attrValues SET OF ATTRIBUTE.&Type ({PKCS12AttrSet}{@attrId})\n * } -- This type is compatible with the X.500 type 'Attribute'\n *\n * PKCS12AttrSet ATTRIBUTE ::= {\n *   friendlyName | -- from PKCS #9\n *   localKeyId, -- from PKCS #9\n *   ... -- Other attributes are allowed\n * }\n *\n * CertBag ::= SEQUENCE {\n *   certId    BAG-TYPE.&id   ({CertTypes}),\n *   certValue [0] EXPLICIT BAG-TYPE.&Type ({CertTypes}{@certId})\n * }\n *\n * x509Certificate BAG-TYPE ::= {OCTET STRING IDENTIFIED BY {certTypes 1}}\n *   -- DER-encoded X.509 certificate stored in OCTET STRING\n *\n * sdsiCertificate BAG-TYPE ::= {IA5String IDENTIFIED BY {certTypes 2}}\n * -- Base64-encoded SDSI certificate stored in IA5String\n *\n * CertTypes BAG-TYPE ::= {\n *   x509Certificate |\n *   sdsiCertificate,\n *   ... -- For future extensions\n * }\n */\nvar forge = require('./forge');\nrequire('./asn1');\nrequire('./hmac');\nrequire('./oids');\nrequire('./pkcs7asn1');\nrequire('./pbe');\nrequire('./random');\nrequire('./rsa');\nrequire('./sha1');\nrequire('./util');\nrequire('./x509');\n\n// shortcut for asn.1 & PKI API\nvar asn1 = forge.asn1;\nvar pki = forge.pki;\n\n// shortcut for PKCS#12 API\nvar p12 = module.exports = forge.pkcs12 = forge.pkcs12 || {};\n\nvar contentInfoValidator = {\n  name: 'ContentInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,  // a ContentInfo\n  constructed: true,\n  value: [{\n    name: 'ContentInfo.contentType',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'contentType'\n  }, {\n    name: 'ContentInfo.content',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    constructed: true,\n    captureAsn1: 'content'\n  }]\n};\n\nvar pfxValidator = {\n  name: 'PFX',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'PFX.version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'version'\n  },\n  contentInfoValidator, {\n    name: 'PFX.macData',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    optional: true,\n    captureAsn1: 'mac',\n    value: [{\n      name: 'PFX.macData.mac',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,  // DigestInfo\n      constructed: true,\n      value: [{\n        name: 'PFX.macData.mac.digestAlgorithm',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.SEQUENCE,  // DigestAlgorithmIdentifier\n        constructed: true,\n        value: [{\n          name: 'PFX.macData.mac.digestAlgorithm.algorithm',\n          tagClass: asn1.Class.UNIVERSAL,\n          type: asn1.Type.OID,\n          constructed: false,\n          capture: 'macAlgorithm'\n        }, {\n          name: 'PFX.macData.mac.digestAlgorithm.parameters',\n          tagClass: asn1.Class.UNIVERSAL,\n          captureAsn1: 'macAlgorithmParameters'\n        }]\n      }, {\n        name: 'PFX.macData.mac.digest',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OCTETSTRING,\n        constructed: false,\n        capture: 'macDigest'\n      }]\n    }, {\n      name: 'PFX.macData.macSalt',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OCTETSTRING,\n      constructed: false,\n      capture: 'macSalt'\n    }, {\n      name: 'PFX.macData.iterations',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.INTEGER,\n      constructed: false,\n      optional: true,\n      capture: 'macIterations'\n    }]\n  }]\n};\n\nvar safeBagValidator = {\n  name: 'SafeBag',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'SafeBag.bagId',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'bagId'\n  }, {\n    name: 'SafeBag.bagValue',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    constructed: true,\n    captureAsn1: 'bagValue'\n  }, {\n    name: 'SafeBag.bagAttributes',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SET,\n    constructed: true,\n    optional: true,\n    capture: 'bagAttributes'\n  }]\n};\n\nvar attributeValidator = {\n  name: 'Attribute',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'Attribute.attrId',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'oid'\n  }, {\n    name: 'Attribute.attrValues',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SET,\n    constructed: true,\n    capture: 'values'\n  }]\n};\n\nvar certBagValidator = {\n  name: 'CertBag',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'CertBag.certId',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'certId'\n  }, {\n    name: 'CertBag.certValue',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    constructed: true,\n    /* So far we only support X.509 certificates (which are wrapped in\n       an OCTET STRING, hence hard code that here). */\n    value: [{\n      name: 'CertBag.certValue[0]',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Class.OCTETSTRING,\n      constructed: false,\n      capture: 'cert'\n    }]\n  }]\n};\n\n/**\n * Search SafeContents structure for bags with matching attributes.\n *\n * The search can optionally be narrowed by a certain bag type.\n *\n * @param safeContents the SafeContents structure to search in.\n * @param attrName the name of the attribute to compare against.\n * @param attrValue the attribute value to search for.\n * @param [bagType] bag type to narrow search by.\n *\n * @return an array of matching bags.\n */\nfunction _getBagsByAttribute(safeContents, attrName, attrValue, bagType) {\n  var result = [];\n\n  for(var i = 0; i < safeContents.length; i++) {\n    for(var j = 0; j < safeContents[i].safeBags.length; j++) {\n      var bag = safeContents[i].safeBags[j];\n      if(bagType !== undefined && bag.type !== bagType) {\n        continue;\n      }\n      // only filter by bag type, no attribute specified\n      if(attrName === null) {\n        result.push(bag);\n        continue;\n      }\n      if(bag.attributes[attrName] !== undefined &&\n        bag.attributes[attrName].indexOf(attrValue) >= 0) {\n        result.push(bag);\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Converts a PKCS#12 PFX in ASN.1 notation into a PFX object.\n *\n * @param obj The PKCS#12 PFX in ASN.1 notation.\n * @param strict true to use strict DER decoding, false not to (default: true).\n * @param {String} password Password to decrypt with (optional).\n *\n * @return PKCS#12 PFX object.\n */\np12.pkcs12FromAsn1 = function(obj, strict, password) {\n  // handle args\n  if(typeof strict === 'string') {\n    password = strict;\n    strict = true;\n  } else if(strict === undefined) {\n    strict = true;\n  }\n\n  // validate PFX and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, pfxValidator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#12 PFX. ' +\n      'ASN.1 object is not an PKCS#12 PFX.');\n    error.errors = error;\n    throw error;\n  }\n\n  var pfx = {\n    version: capture.version.charCodeAt(0),\n    safeContents: [],\n\n    /**\n     * Gets bags with matching attributes.\n     *\n     * @param filter the attributes to filter by:\n     *          [localKeyId] the localKeyId to search for.\n     *          [localKeyIdHex] the localKeyId in hex to search for.\n     *          [friendlyName] the friendly name to search for.\n     *          [bagType] bag type to narrow each attribute search by.\n     *\n     * @return a map of attribute type to an array of matching bags or, if no\n     *           attribute was given but a bag type, the map key will be the\n     *           bag type.\n     */\n    getBags: function(filter) {\n      var rval = {};\n\n      var localKeyId;\n      if('localKeyId' in filter) {\n        localKeyId = filter.localKeyId;\n      } else if('localKeyIdHex' in filter) {\n        localKeyId = forge.util.hexToBytes(filter.localKeyIdHex);\n      }\n\n      // filter on bagType only\n      if(localKeyId === undefined && !('friendlyName' in filter) &&\n        'bagType' in filter) {\n        rval[filter.bagType] = _getBagsByAttribute(\n          pfx.safeContents, null, null, filter.bagType);\n      }\n\n      if(localKeyId !== undefined) {\n        rval.localKeyId = _getBagsByAttribute(\n          pfx.safeContents, 'localKeyId',\n          localKeyId, filter.bagType);\n      }\n      if('friendlyName' in filter) {\n        rval.friendlyName = _getBagsByAttribute(\n          pfx.safeContents, 'friendlyName',\n          filter.friendlyName, filter.bagType);\n      }\n\n      return rval;\n    },\n\n    /**\n     * DEPRECATED: use getBags() instead.\n     *\n     * Get bags with matching friendlyName attribute.\n     *\n     * @param friendlyName the friendly name to search for.\n     * @param [bagType] bag type to narrow search by.\n     *\n     * @return an array of bags with matching friendlyName attribute.\n     */\n    getBagsByFriendlyName: function(friendlyName, bagType) {\n      return _getBagsByAttribute(\n        pfx.safeContents, 'friendlyName', friendlyName, bagType);\n    },\n\n    /**\n     * DEPRECATED: use getBags() instead.\n     *\n     * Get bags with matching localKeyId attribute.\n     *\n     * @param localKeyId the localKeyId to search for.\n     * @param [bagType] bag type to narrow search by.\n     *\n     * @return an array of bags with matching localKeyId attribute.\n     */\n    getBagsByLocalKeyId: function(localKeyId, bagType) {\n      return _getBagsByAttribute(\n        pfx.safeContents, 'localKeyId', localKeyId, bagType);\n    }\n  };\n\n  if(capture.version.charCodeAt(0) !== 3) {\n    var error = new Error('PKCS#12 PFX of version other than 3 not supported.');\n    error.version = capture.version.charCodeAt(0);\n    throw error;\n  }\n\n  if(asn1.derToOid(capture.contentType) !== pki.oids.data) {\n    var error = new Error('Only PKCS#12 PFX in password integrity mode supported.');\n    error.oid = asn1.derToOid(capture.contentType);\n    throw error;\n  }\n\n  var data = capture.content.value[0];\n  if(data.tagClass !== asn1.Class.UNIVERSAL ||\n     data.type !== asn1.Type.OCTETSTRING) {\n    throw new Error('PKCS#12 authSafe content data is not an OCTET STRING.');\n  }\n  data = _decodePkcs7Data(data);\n\n  // check for MAC\n  if(capture.mac) {\n    var md = null;\n    var macKeyBytes = 0;\n    var macAlgorithm = asn1.derToOid(capture.macAlgorithm);\n    switch(macAlgorithm) {\n    case pki.oids.sha1:\n      md = forge.md.sha1.create();\n      macKeyBytes = 20;\n      break;\n    case pki.oids.sha256:\n      md = forge.md.sha256.create();\n      macKeyBytes = 32;\n      break;\n    case pki.oids.sha384:\n      md = forge.md.sha384.create();\n      macKeyBytes = 48;\n      break;\n    case pki.oids.sha512:\n      md = forge.md.sha512.create();\n      macKeyBytes = 64;\n      break;\n    case pki.oids.md5:\n      md = forge.md.md5.create();\n      macKeyBytes = 16;\n      break;\n    }\n    if(md === null) {\n      throw new Error('PKCS#12 uses unsupported MAC algorithm: ' + macAlgorithm);\n    }\n\n    // verify MAC (iterations default to 1)\n    var macSalt = new forge.util.ByteBuffer(capture.macSalt);\n    var macIterations = (('macIterations' in capture) ?\n      parseInt(forge.util.bytesToHex(capture.macIterations), 16) : 1);\n    var macKey = p12.generateKey(\n      password, macSalt, 3, macIterations, macKeyBytes, md);\n    var mac = forge.hmac.create();\n    mac.start(md, macKey);\n    mac.update(data.value);\n    var macValue = mac.getMac();\n    if(macValue.getBytes() !== capture.macDigest) {\n      throw new Error('PKCS#12 MAC could not be verified. Invalid password?');\n    }\n  }\n\n  _decodeAuthenticatedSafe(pfx, data.value, strict, password);\n  return pfx;\n};\n\n/**\n * Decodes PKCS#7 Data. PKCS#7 (RFC 2315) defines \"Data\" as an OCTET STRING,\n * but it is sometimes an OCTET STRING that is composed/constructed of chunks,\n * each its own OCTET STRING. This is BER-encoding vs. DER-encoding. This\n * function transforms this corner-case into the usual simple,\n * non-composed/constructed OCTET STRING.\n *\n * This function may be moved to ASN.1 at some point to better deal with\n * more BER-encoding issues, should they arise.\n *\n * @param data the ASN.1 Data object to transform.\n */\nfunction _decodePkcs7Data(data) {\n  // handle special case of \"chunked\" data content: an octet string composed\n  // of other octet strings\n  if(data.composed || data.constructed) {\n    var value = forge.util.createBuffer();\n    for(var i = 0; i < data.value.length; ++i) {\n      value.putBytes(data.value[i].value);\n    }\n    data.composed = data.constructed = false;\n    data.value = value.getBytes();\n  }\n  return data;\n}\n\n/**\n * Decode PKCS#12 AuthenticatedSafe (BER encoded) into PFX object.\n *\n * The AuthenticatedSafe is a BER-encoded SEQUENCE OF ContentInfo.\n *\n * @param pfx The PKCS#12 PFX object to fill.\n * @param {String} authSafe BER-encoded AuthenticatedSafe.\n * @param strict true to use strict DER decoding, false not to.\n * @param {String} password Password to decrypt with (optional).\n */\nfunction _decodeAuthenticatedSafe(pfx, authSafe, strict, password) {\n  authSafe = asn1.fromDer(authSafe, strict);  /* actually it's BER encoded */\n\n  if(authSafe.tagClass !== asn1.Class.UNIVERSAL ||\n     authSafe.type !== asn1.Type.SEQUENCE ||\n     authSafe.constructed !== true) {\n    throw new Error('PKCS#12 AuthenticatedSafe expected to be a ' +\n      'SEQUENCE OF ContentInfo');\n  }\n\n  for(var i = 0; i < authSafe.value.length; i++) {\n    var contentInfo = authSafe.value[i];\n\n    // validate contentInfo and capture data\n    var capture = {};\n    var errors = [];\n    if(!asn1.validate(contentInfo, contentInfoValidator, capture, errors)) {\n      var error = new Error('Cannot read ContentInfo.');\n      error.errors = errors;\n      throw error;\n    }\n\n    var obj = {\n      encrypted: false\n    };\n    var safeContents = null;\n    var data = capture.content.value[0];\n    switch(asn1.derToOid(capture.contentType)) {\n    case pki.oids.data:\n      if(data.tagClass !== asn1.Class.UNIVERSAL ||\n         data.type !== asn1.Type.OCTETSTRING) {\n        throw new Error('PKCS#12 SafeContents Data is not an OCTET STRING.');\n      }\n      safeContents = _decodePkcs7Data(data).value;\n      break;\n    case pki.oids.encryptedData:\n      safeContents = _decryptSafeContents(data, password);\n      obj.encrypted = true;\n      break;\n    default:\n      var error = new Error('Unsupported PKCS#12 contentType.');\n      error.contentType = asn1.derToOid(capture.contentType);\n      throw error;\n    }\n\n    obj.safeBags = _decodeSafeContents(safeContents, strict, password);\n    pfx.safeContents.push(obj);\n  }\n}\n\n/**\n * Decrypt PKCS#7 EncryptedData structure.\n *\n * @param data ASN.1 encoded EncryptedContentInfo object.\n * @param password The user-provided password.\n *\n * @return The decrypted SafeContents (ASN.1 object).\n */\nfunction _decryptSafeContents(data, password) {\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(\n    data, forge.pkcs7.asn1.encryptedDataValidator, capture, errors)) {\n    var error = new Error('Cannot read EncryptedContentInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  var oid = asn1.derToOid(capture.contentType);\n  if(oid !== pki.oids.data) {\n    var error = new Error(\n      'PKCS#12 EncryptedContentInfo ContentType is not Data.');\n    error.oid = oid;\n    throw error;\n  }\n\n  // get cipher\n  oid = asn1.derToOid(capture.encAlgorithm);\n  var cipher = pki.pbe.getCipher(oid, capture.encParameter, password);\n\n  // get encrypted data\n  var encryptedContentAsn1 = _decodePkcs7Data(capture.encryptedContentAsn1);\n  var encrypted = forge.util.createBuffer(encryptedContentAsn1.value);\n\n  cipher.update(encrypted);\n  if(!cipher.finish()) {\n    throw new Error('Failed to decrypt PKCS#12 SafeContents.');\n  }\n\n  return cipher.output.getBytes();\n}\n\n/**\n * Decode PKCS#12 SafeContents (BER-encoded) into array of Bag objects.\n *\n * The safeContents is a BER-encoded SEQUENCE OF SafeBag.\n *\n * @param {String} safeContents BER-encoded safeContents.\n * @param strict true to use strict DER decoding, false not to.\n * @param {String} password Password to decrypt with (optional).\n *\n * @return {Array} Array of Bag objects.\n */\nfunction _decodeSafeContents(safeContents, strict, password) {\n  // if strict and no safe contents, return empty safes\n  if(!strict && safeContents.length === 0) {\n    return [];\n  }\n\n  // actually it's BER-encoded\n  safeContents = asn1.fromDer(safeContents, strict);\n\n  if(safeContents.tagClass !== asn1.Class.UNIVERSAL ||\n    safeContents.type !== asn1.Type.SEQUENCE ||\n    safeContents.constructed !== true) {\n    throw new Error(\n      'PKCS#12 SafeContents expected to be a SEQUENCE OF SafeBag.');\n  }\n\n  var res = [];\n  for(var i = 0; i < safeContents.value.length; i++) {\n    var safeBag = safeContents.value[i];\n\n    // validate SafeBag and capture data\n    var capture = {};\n    var errors = [];\n    if(!asn1.validate(safeBag, safeBagValidator, capture, errors)) {\n      var error = new Error('Cannot read SafeBag.');\n      error.errors = errors;\n      throw error;\n    }\n\n    /* Create bag object and push to result array. */\n    var bag = {\n      type: asn1.derToOid(capture.bagId),\n      attributes: _decodeBagAttributes(capture.bagAttributes)\n    };\n    res.push(bag);\n\n    var validator, decoder;\n    var bagAsn1 = capture.bagValue.value[0];\n    switch(bag.type) {\n      case pki.oids.pkcs8ShroudedKeyBag:\n        /* bagAsn1 has a EncryptedPrivateKeyInfo, which we need to decrypt.\n           Afterwards we can handle it like a keyBag,\n           which is a PrivateKeyInfo. */\n        bagAsn1 = pki.decryptPrivateKeyInfo(bagAsn1, password);\n        if(bagAsn1 === null) {\n          throw new Error(\n            'Unable to decrypt PKCS#8 ShroudedKeyBag, wrong password?');\n        }\n\n        /* fall through */\n      case pki.oids.keyBag:\n        /* A PKCS#12 keyBag is a simple PrivateKeyInfo as understood by our\n           PKI module, hence we don't have to do validation/capturing here,\n           just pass what we already got. */\n        try {\n          bag.key = pki.privateKeyFromAsn1(bagAsn1);\n        } catch(e) {\n          // ignore unknown key type, pass asn1 value\n          bag.key = null;\n          bag.asn1 = bagAsn1;\n        }\n        continue;  /* Nothing more to do. */\n\n      case pki.oids.certBag:\n        /* A PKCS#12 certBag can wrap both X.509 and sdsi certificates.\n           Therefore put the SafeBag content through another validator to\n           capture the fields.  Afterwards check & store the results. */\n        validator = certBagValidator;\n        decoder = function() {\n          if(asn1.derToOid(capture.certId) !== pki.oids.x509Certificate) {\n            var error = new Error(\n              'Unsupported certificate type, only X.509 supported.');\n            error.oid = asn1.derToOid(capture.certId);\n            throw error;\n          }\n\n          // true=produce cert hash\n          var certAsn1 = asn1.fromDer(capture.cert, strict);\n          try {\n            bag.cert = pki.certificateFromAsn1(certAsn1, true);\n          } catch(e) {\n            // ignore unknown cert type, pass asn1 value\n            bag.cert = null;\n            bag.asn1 = certAsn1;\n          }\n        };\n        break;\n\n      default:\n        var error = new Error('Unsupported PKCS#12 SafeBag type.');\n        error.oid = bag.type;\n        throw error;\n    }\n\n    /* Validate SafeBag value (i.e. CertBag, etc.) and capture data if needed. */\n    if(validator !== undefined &&\n       !asn1.validate(bagAsn1, validator, capture, errors)) {\n      var error = new Error('Cannot read PKCS#12 ' + validator.name);\n      error.errors = errors;\n      throw error;\n    }\n\n    /* Call decoder function from above to store the results. */\n    decoder();\n  }\n\n  return res;\n}\n\n/**\n * Decode PKCS#12 SET OF PKCS12Attribute into JavaScript object.\n *\n * @param attributes SET OF PKCS12Attribute (ASN.1 object).\n *\n * @return the decoded attributes.\n */\nfunction _decodeBagAttributes(attributes) {\n  var decodedAttrs = {};\n\n  if(attributes !== undefined) {\n    for(var i = 0; i < attributes.length; ++i) {\n      var capture = {};\n      var errors = [];\n      if(!asn1.validate(attributes[i], attributeValidator, capture, errors)) {\n        var error = new Error('Cannot read PKCS#12 BagAttribute.');\n        error.errors = errors;\n        throw error;\n      }\n\n      var oid = asn1.derToOid(capture.oid);\n      if(pki.oids[oid] === undefined) {\n        // unsupported attribute type, ignore.\n        continue;\n      }\n\n      decodedAttrs[pki.oids[oid]] = [];\n      for(var j = 0; j < capture.values.length; ++j) {\n        decodedAttrs[pki.oids[oid]].push(capture.values[j].value);\n      }\n    }\n  }\n\n  return decodedAttrs;\n}\n\n/**\n * Wraps a private key and certificate in a PKCS#12 PFX wrapper. If a\n * password is provided then the private key will be encrypted.\n *\n * An entire certificate chain may also be included. To do this, pass\n * an array for the \"cert\" parameter where the first certificate is\n * the one that is paired with the private key and each subsequent one\n * verifies the previous one. The certificates may be in PEM format or\n * have been already parsed by Forge.\n *\n * @todo implement password-based-encryption for the whole package\n *\n * @param key the private key.\n * @param cert the certificate (may be an array of certificates in order\n *          to specify a certificate chain).\n * @param password the password to use, null for none.\n * @param options:\n *          algorithm the encryption algorithm to use\n *            ('aes128', 'aes192', 'aes256', '3des'), defaults to 'aes128'.\n *          count the iteration count to use.\n *          saltSize the salt size to use.\n *          useMac true to include a MAC, false not to, defaults to true.\n *          localKeyId the local key ID to use, in hex.\n *          friendlyName the friendly name to use.\n *          generateLocalKeyId true to generate a random local key ID,\n *            false not to, defaults to true.\n *\n * @return the PKCS#12 PFX ASN.1 object.\n */\np12.toPkcs12Asn1 = function(key, cert, password, options) {\n  // set default options\n  options = options || {};\n  options.saltSize = options.saltSize || 8;\n  options.count = options.count || 2048;\n  options.algorithm = options.algorithm || options.encAlgorithm || 'aes128';\n  if(!('useMac' in options)) {\n    options.useMac = true;\n  }\n  if(!('localKeyId' in options)) {\n    options.localKeyId = null;\n  }\n  if(!('generateLocalKeyId' in options)) {\n    options.generateLocalKeyId = true;\n  }\n\n  var localKeyId = options.localKeyId;\n  var bagAttrs;\n  if(localKeyId !== null) {\n    localKeyId = forge.util.hexToBytes(localKeyId);\n  } else if(options.generateLocalKeyId) {\n    // use SHA-1 of paired cert, if available\n    if(cert) {\n      var pairedCert = forge.util.isArray(cert) ? cert[0] : cert;\n      if(typeof pairedCert === 'string') {\n        pairedCert = pki.certificateFromPem(pairedCert);\n      }\n      var sha1 = forge.md.sha1.create();\n      sha1.update(asn1.toDer(pki.certificateToAsn1(pairedCert)).getBytes());\n      localKeyId = sha1.digest().getBytes();\n    } else {\n      // FIXME: consider using SHA-1 of public key (which can be generated\n      // from private key components), see: cert.generateSubjectKeyIdentifier\n      // generate random bytes\n      localKeyId = forge.random.getBytes(20);\n    }\n  }\n\n  var attrs = [];\n  if(localKeyId !== null) {\n    attrs.push(\n      // localKeyID\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // attrId\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids.localKeyId).getBytes()),\n        // attrValues\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n            localKeyId)\n        ])\n      ]));\n  }\n  if('friendlyName' in options) {\n    attrs.push(\n      // friendlyName\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // attrId\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids.friendlyName).getBytes()),\n        // attrValues\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BMPSTRING, false,\n            options.friendlyName)\n        ])\n      ]));\n  }\n\n  if(attrs.length > 0) {\n    bagAttrs = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, attrs);\n  }\n\n  // collect contents for AuthenticatedSafe\n  var contents = [];\n\n  // create safe bag(s) for certificate chain\n  var chain = [];\n  if(cert !== null) {\n    if(forge.util.isArray(cert)) {\n      chain = cert;\n    } else {\n      chain = [cert];\n    }\n  }\n\n  var certSafeBags = [];\n  for(var i = 0; i < chain.length; ++i) {\n    // convert cert from PEM as necessary\n    cert = chain[i];\n    if(typeof cert === 'string') {\n      cert = pki.certificateFromPem(cert);\n    }\n\n    // SafeBag\n    var certBagAttrs = (i === 0) ? bagAttrs : undefined;\n    var certAsn1 = pki.certificateToAsn1(cert);\n    var certSafeBag =\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // bagId\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids.certBag).getBytes()),\n        // bagValue\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          // CertBag\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n            // certId\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n              asn1.oidToDer(pki.oids.x509Certificate).getBytes()),\n            // certValue (x509Certificate)\n            asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n              asn1.create(\n                asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n                asn1.toDer(certAsn1).getBytes())\n            ])])]),\n        // bagAttributes (OPTIONAL)\n        certBagAttrs\n      ]);\n    certSafeBags.push(certSafeBag);\n  }\n\n  if(certSafeBags.length > 0) {\n    // SafeContents\n    var certSafeContents = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, certSafeBags);\n\n    // ContentInfo\n    var certCI =\n      // PKCS#7 ContentInfo\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // contentType\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          // OID for the content type is 'data'\n          asn1.oidToDer(pki.oids.data).getBytes()),\n        // content\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          asn1.create(\n            asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n            asn1.toDer(certSafeContents).getBytes())\n        ])\n      ]);\n    contents.push(certCI);\n  }\n\n  // create safe contents for private key\n  var keyBag = null;\n  if(key !== null) {\n    // SafeBag\n    var pkAsn1 = pki.wrapRsaPrivateKey(pki.privateKeyToAsn1(key));\n    if(password === null) {\n      // no encryption\n      keyBag = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // bagId\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids.keyBag).getBytes()),\n        // bagValue\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          // PrivateKeyInfo\n          pkAsn1\n        ]),\n        // bagAttributes (OPTIONAL)\n        bagAttrs\n      ]);\n    } else {\n      // encrypted PrivateKeyInfo\n      keyBag = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // bagId\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(pki.oids.pkcs8ShroudedKeyBag).getBytes()),\n        // bagValue\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          // EncryptedPrivateKeyInfo\n          pki.encryptPrivateKeyInfo(pkAsn1, password, options)\n        ]),\n        // bagAttributes (OPTIONAL)\n        bagAttrs\n      ]);\n    }\n\n    // SafeContents\n    var keySafeContents =\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [keyBag]);\n\n    // ContentInfo\n    var keyCI =\n      // PKCS#7 ContentInfo\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // contentType\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          // OID for the content type is 'data'\n          asn1.oidToDer(pki.oids.data).getBytes()),\n        // content\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          asn1.create(\n            asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n            asn1.toDer(keySafeContents).getBytes())\n        ])\n      ]);\n    contents.push(keyCI);\n  }\n\n  // create AuthenticatedSafe by stringing together the contents\n  var safe = asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, contents);\n\n  var macData;\n  if(options.useMac) {\n    // MacData\n    var sha1 = forge.md.sha1.create();\n    var macSalt = new forge.util.ByteBuffer(\n      forge.random.getBytes(options.saltSize));\n    var count = options.count;\n    // 160-bit key\n    var key = p12.generateKey(password, macSalt, 3, count, 20);\n    var mac = forge.hmac.create();\n    mac.start(sha1, key);\n    mac.update(asn1.toDer(safe).getBytes());\n    var macValue = mac.getMac();\n    macData = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // mac DigestInfo\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // digestAlgorithm\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          // algorithm = SHA-1\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n            asn1.oidToDer(pki.oids.sha1).getBytes()),\n          // parameters = Null\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n        ]),\n        // digest\n        asn1.create(\n          asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING,\n          false, macValue.getBytes())\n      ]),\n      // macSalt OCTET STRING\n      asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, macSalt.getBytes()),\n      // iterations INTEGER (XXX: Only support count < 65536)\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        asn1.integerToDer(count).getBytes()\n      )\n    ]);\n  }\n\n  // PFX\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version (3)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(3).getBytes()),\n    // PKCS#7 ContentInfo\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // contentType\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        // OID for the content type is 'data'\n        asn1.oidToDer(pki.oids.data).getBytes()),\n      // content\n      asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n        asn1.create(\n          asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n          asn1.toDer(safe).getBytes())\n      ])\n    ]),\n    macData\n  ]);\n};\n\n/**\n * Derives a PKCS#12 key.\n *\n * @param password the password to derive the key material from, null or\n *          undefined for none.\n * @param salt the salt, as a ByteBuffer, to use.\n * @param id the PKCS#12 ID byte (1 = key material, 2 = IV, 3 = MAC).\n * @param iter the iteration count.\n * @param n the number of bytes to derive from the password.\n * @param md the message digest to use, defaults to SHA-1.\n *\n * @return a ByteBuffer with the bytes derived from the password.\n */\np12.generateKey = forge.pbe.generatePkcs12Key;\n","/**\n * Javascript implementation of PKCS#7 v1.5.\n *\n * @author Stefan Siegl\n * @author Dave Longley\n *\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n * Copyright (c) 2012-2015 Digital Bazaar, Inc.\n *\n * Currently this implementation only supports ContentType of EnvelopedData,\n * EncryptedData, or SignedData at the root level. The top level elements may\n * contain only a ContentInfo of ContentType Data, i.e. plain data. Further\n * nesting is not (yet) supported.\n *\n * The Forge validators for PKCS #7's ASN.1 structures are available from\n * a separate file pkcs7asn1.js, since those are referenced from other\n * PKCS standards like PKCS #12.\n */\nvar forge = require('./forge');\nrequire('./aes');\nrequire('./asn1');\nrequire('./des');\nrequire('./oids');\nrequire('./pem');\nrequire('./pkcs7asn1');\nrequire('./random');\nrequire('./util');\nrequire('./x509');\n\n// shortcut for ASN.1 API\nvar asn1 = forge.asn1;\n\n// shortcut for PKCS#7 API\nvar p7 = module.exports = forge.pkcs7 = forge.pkcs7 || {};\n\n/**\n * Converts a PKCS#7 message from PEM format.\n *\n * @param pem the PEM-formatted PKCS#7 message.\n *\n * @return the PKCS#7 message.\n */\np7.messageFromPem = function(pem) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'PKCS7') {\n    var error = new Error('Could not convert PKCS#7 message from PEM; PEM ' +\n      'header type is not \"PKCS#7\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert PKCS#7 message from PEM; PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  var obj = asn1.fromDer(msg.body);\n\n  return p7.messageFromAsn1(obj);\n};\n\n/**\n * Converts a PKCS#7 message to PEM format.\n *\n * @param msg The PKCS#7 message object\n * @param maxline The maximum characters per line, defaults to 64.\n *\n * @return The PEM-formatted PKCS#7 message.\n */\np7.messageToPem = function(msg, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var pemObj = {\n    type: 'PKCS7',\n    body: asn1.toDer(msg.toAsn1()).getBytes()\n  };\n  return forge.pem.encode(pemObj, {maxline: maxline});\n};\n\n/**\n * Converts a PKCS#7 message from an ASN.1 object.\n *\n * @param obj the ASN.1 representation of a ContentInfo.\n *\n * @return the PKCS#7 message.\n */\np7.messageFromAsn1 = function(obj) {\n  // validate root level ContentInfo and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, p7.asn1.contentInfoValidator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#7 message. ' +\n      'ASN.1 object is not an PKCS#7 ContentInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  var contentType = asn1.derToOid(capture.contentType);\n  var msg;\n\n  switch(contentType) {\n    case forge.pki.oids.envelopedData:\n      msg = p7.createEnvelopedData();\n      break;\n\n    case forge.pki.oids.encryptedData:\n      msg = p7.createEncryptedData();\n      break;\n\n    case forge.pki.oids.signedData:\n      msg = p7.createSignedData();\n      break;\n\n    default:\n      throw new Error('Cannot read PKCS#7 message. ContentType with OID ' +\n        contentType + ' is not (yet) supported.');\n  }\n\n  msg.fromAsn1(capture.content.value[0]);\n  return msg;\n};\n\np7.createSignedData = function() {\n  var msg = null;\n  msg = {\n    type: forge.pki.oids.signedData,\n    version: 1,\n    certificates: [],\n    crls: [],\n    // TODO: add json-formatted signer stuff here?\n    signers: [],\n    // populated during sign()\n    digestAlgorithmIdentifiers: [],\n    contentInfo: null,\n    signerInfos: [],\n\n    fromAsn1: function(obj) {\n      // validate SignedData content block and capture data.\n      _fromAsn1(msg, obj, p7.asn1.signedDataValidator);\n      msg.certificates = [];\n      msg.crls = [];\n      msg.digestAlgorithmIdentifiers = [];\n      msg.contentInfo = null;\n      msg.signerInfos = [];\n\n      if(msg.rawCapture.certificates) {\n        var certs = msg.rawCapture.certificates.value;\n        for(var i = 0; i < certs.length; ++i) {\n          msg.certificates.push(forge.pki.certificateFromAsn1(certs[i]));\n        }\n      }\n\n      // TODO: parse crls\n    },\n\n    toAsn1: function() {\n      // degenerate case with no content\n      if(!msg.contentInfo) {\n        msg.sign();\n      }\n\n      var certs = [];\n      for(var i = 0; i < msg.certificates.length; ++i) {\n        certs.push(forge.pki.certificateToAsn1(msg.certificates[i]));\n      }\n\n      var crls = [];\n      // TODO: implement CRLs\n\n      // [0] SignedData\n      var signedData = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          // Version\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n            asn1.integerToDer(msg.version).getBytes()),\n          // DigestAlgorithmIdentifiers\n          asn1.create(\n            asn1.Class.UNIVERSAL, asn1.Type.SET, true,\n            msg.digestAlgorithmIdentifiers),\n          // ContentInfo\n          msg.contentInfo\n        ])\n      ]);\n      if(certs.length > 0) {\n        // [0] IMPLICIT ExtendedCertificatesAndCertificates OPTIONAL\n        signedData.value[0].value.push(\n          asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, certs));\n      }\n      if(crls.length > 0) {\n        // [1] IMPLICIT CertificateRevocationLists OPTIONAL\n        signedData.value[0].value.push(\n          asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, crls));\n      }\n      // SignerInfos\n      signedData.value[0].value.push(\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true,\n          msg.signerInfos));\n\n      // ContentInfo\n      return asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          // ContentType\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n            asn1.oidToDer(msg.type).getBytes()),\n          // [0] SignedData\n          signedData\n        ]);\n    },\n\n    /**\n     * Add (another) entity to list of signers.\n     *\n     * Note: If authenticatedAttributes are provided, then, per RFC 2315,\n     * they must include at least two attributes: content type and\n     * message digest. The message digest attribute value will be\n     * auto-calculated during signing and will be ignored if provided.\n     *\n     * Here's an example of providing these two attributes:\n     *\n     * forge.pkcs7.createSignedData();\n     * p7.addSigner({\n     *   issuer: cert.issuer.attributes,\n     *   serialNumber: cert.serialNumber,\n     *   key: privateKey,\n     *   digestAlgorithm: forge.pki.oids.sha1,\n     *   authenticatedAttributes: [{\n     *     type: forge.pki.oids.contentType,\n     *     value: forge.pki.oids.data\n     *   }, {\n     *     type: forge.pki.oids.messageDigest\n     *   }]\n     * });\n     *\n     * TODO: Support [subjectKeyIdentifier] as signer's ID.\n     *\n     * @param signer the signer information:\n     *          key the signer's private key.\n     *          [certificate] a certificate containing the public key\n     *            associated with the signer's private key; use this option as\n     *            an alternative to specifying signer.issuer and\n     *            signer.serialNumber.\n     *          [issuer] the issuer attributes (eg: cert.issuer.attributes).\n     *          [serialNumber] the signer's certificate's serial number in\n     *           hexadecimal (eg: cert.serialNumber).\n     *          [digestAlgorithm] the message digest OID, as a string, to use\n     *            (eg: forge.pki.oids.sha1).\n     *          [authenticatedAttributes] an optional array of attributes\n     *            to also sign along with the content.\n     */\n    addSigner: function(signer) {\n      var issuer = signer.issuer;\n      var serialNumber = signer.serialNumber;\n      if(signer.certificate) {\n        var cert = signer.certificate;\n        if(typeof cert === 'string') {\n          cert = forge.pki.certificateFromPem(cert);\n        }\n        issuer = cert.issuer.attributes;\n        serialNumber = cert.serialNumber;\n      }\n      var key = signer.key;\n      if(!key) {\n        throw new Error(\n          'Could not add PKCS#7 signer; no private key specified.');\n      }\n      if(typeof key === 'string') {\n        key = forge.pki.privateKeyFromPem(key);\n      }\n\n      // ensure OID known for digest algorithm\n      var digestAlgorithm = signer.digestAlgorithm || forge.pki.oids.sha1;\n      switch(digestAlgorithm) {\n      case forge.pki.oids.sha1:\n      case forge.pki.oids.sha256:\n      case forge.pki.oids.sha384:\n      case forge.pki.oids.sha512:\n      case forge.pki.oids.md5:\n        break;\n      default:\n        throw new Error(\n          'Could not add PKCS#7 signer; unknown message digest algorithm: ' +\n          digestAlgorithm);\n      }\n\n      // if authenticatedAttributes is present, then the attributes\n      // must contain at least PKCS #9 content-type and message-digest\n      var authenticatedAttributes = signer.authenticatedAttributes || [];\n      if(authenticatedAttributes.length > 0) {\n        var contentType = false;\n        var messageDigest = false;\n        for(var i = 0; i < authenticatedAttributes.length; ++i) {\n          var attr = authenticatedAttributes[i];\n          if(!contentType && attr.type === forge.pki.oids.contentType) {\n            contentType = true;\n            if(messageDigest) {\n              break;\n            }\n            continue;\n          }\n          if(!messageDigest && attr.type === forge.pki.oids.messageDigest) {\n            messageDigest = true;\n            if(contentType) {\n              break;\n            }\n            continue;\n          }\n        }\n\n        if(!contentType || !messageDigest) {\n          throw new Error('Invalid signer.authenticatedAttributes. If ' +\n            'signer.authenticatedAttributes is specified, then it must ' +\n            'contain at least two attributes, PKCS #9 content-type and ' +\n            'PKCS #9 message-digest.');\n        }\n      }\n\n      msg.signers.push({\n        key: key,\n        version: 1,\n        issuer: issuer,\n        serialNumber: serialNumber,\n        digestAlgorithm: digestAlgorithm,\n        signatureAlgorithm: forge.pki.oids.rsaEncryption,\n        signature: null,\n        authenticatedAttributes: authenticatedAttributes,\n        unauthenticatedAttributes: []\n      });\n    },\n\n    /**\n     * Signs the content.\n     * @param options Options to apply when signing:\n     *    [detached] boolean. If signing should be done in detached mode. Defaults to false.\n     */\n    sign: function(options) {\n      options = options || {};\n      // auto-generate content info\n      if(typeof msg.content !== 'object' || msg.contentInfo === null) {\n        // use Data ContentInfo\n        msg.contentInfo = asn1.create(\n          asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n            // ContentType\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n              asn1.oidToDer(forge.pki.oids.data).getBytes())\n          ]);\n\n        // add actual content, if present\n        if('content' in msg) {\n          var content;\n          if(msg.content instanceof forge.util.ByteBuffer) {\n            content = msg.content.bytes();\n          } else if(typeof msg.content === 'string') {\n            content = forge.util.encodeUtf8(msg.content);\n          }\n\n          if (options.detached) {\n            msg.detachedContent = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, content);\n          } else {\n            msg.contentInfo.value.push(\n              // [0] EXPLICIT content\n              asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n                asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n                  content)\n              ]));\n          }\n        }\n      }\n\n      // no signers, return early (degenerate case for certificate container)\n      if(msg.signers.length === 0) {\n        return;\n      }\n\n      // generate digest algorithm identifiers\n      var mds = addDigestAlgorithmIds();\n\n      // generate signerInfos\n      addSignerInfos(mds);\n    },\n\n    verify: function() {\n      throw new Error('PKCS#7 signature verification not yet implemented.');\n    },\n\n    /**\n     * Add a certificate.\n     *\n     * @param cert the certificate to add.\n     */\n    addCertificate: function(cert) {\n      // convert from PEM\n      if(typeof cert === 'string') {\n        cert = forge.pki.certificateFromPem(cert);\n      }\n      msg.certificates.push(cert);\n    },\n\n    /**\n     * Add a certificate revokation list.\n     *\n     * @param crl the certificate revokation list to add.\n     */\n    addCertificateRevokationList: function(crl) {\n      throw new Error('PKCS#7 CRL support not yet implemented.');\n    }\n  };\n  return msg;\n\n  function addDigestAlgorithmIds() {\n    var mds = {};\n\n    for(var i = 0; i < msg.signers.length; ++i) {\n      var signer = msg.signers[i];\n      var oid = signer.digestAlgorithm;\n      if(!(oid in mds)) {\n        // content digest\n        mds[oid] = forge.md[forge.pki.oids[oid]].create();\n      }\n      if(signer.authenticatedAttributes.length === 0) {\n        // no custom attributes to digest; use content message digest\n        signer.md = mds[oid];\n      } else {\n        // custom attributes to be digested; use own message digest\n        // TODO: optimize to just copy message digest state if that\n        // feature is ever supported with message digests\n        signer.md = forge.md[forge.pki.oids[oid]].create();\n      }\n    }\n\n    // add unique digest algorithm identifiers\n    msg.digestAlgorithmIdentifiers = [];\n    for(var oid in mds) {\n      msg.digestAlgorithmIdentifiers.push(\n        // AlgorithmIdentifier\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n          // algorithm\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n            asn1.oidToDer(oid).getBytes()),\n          // parameters (null)\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n        ]));\n    }\n\n    return mds;\n  }\n\n  function addSignerInfos(mds) {\n    var content;\n\n    if (msg.detachedContent) {\n      // Signature has been made in detached mode.\n      content = msg.detachedContent;\n    } else {\n      // Note: ContentInfo is a SEQUENCE with 2 values, second value is\n      // the content field and is optional for a ContentInfo but required here\n      // since signers are present\n      // get ContentInfo content\n      content = msg.contentInfo.value[1];\n      // skip [0] EXPLICIT content wrapper\n      content = content.value[0];\n    }\n\n    if(!content) {\n      throw new Error(\n        'Could not sign PKCS#7 message; there is no content to sign.');\n    }\n\n    // get ContentInfo content type\n    var contentType = asn1.derToOid(msg.contentInfo.value[0].value);\n\n    // serialize content\n    var bytes = asn1.toDer(content);\n\n    // skip identifier and length per RFC 2315 9.3\n    // skip identifier (1 byte)\n    bytes.getByte();\n    // read and discard length bytes\n    asn1.getBerValueLength(bytes);\n    bytes = bytes.getBytes();\n\n    // digest content DER value bytes\n    for(var oid in mds) {\n      mds[oid].start().update(bytes);\n    }\n\n    // sign content\n    var signingTime = new Date();\n    for(var i = 0; i < msg.signers.length; ++i) {\n      var signer = msg.signers[i];\n\n      if(signer.authenticatedAttributes.length === 0) {\n        // if ContentInfo content type is not \"Data\", then\n        // authenticatedAttributes must be present per RFC 2315\n        if(contentType !== forge.pki.oids.data) {\n          throw new Error(\n            'Invalid signer; authenticatedAttributes must be present ' +\n            'when the ContentInfo content type is not PKCS#7 Data.');\n        }\n      } else {\n        // process authenticated attributes\n        // [0] IMPLICIT\n        signer.authenticatedAttributesAsn1 = asn1.create(\n          asn1.Class.CONTEXT_SPECIFIC, 0, true, []);\n\n        // per RFC 2315, attributes are to be digested using a SET container\n        // not the above [0] IMPLICIT container\n        var attrsAsn1 = asn1.create(\n          asn1.Class.UNIVERSAL, asn1.Type.SET, true, []);\n\n        for(var ai = 0; ai < signer.authenticatedAttributes.length; ++ai) {\n          var attr = signer.authenticatedAttributes[ai];\n          if(attr.type === forge.pki.oids.messageDigest) {\n            // use content message digest as value\n            attr.value = mds[signer.digestAlgorithm].digest();\n          } else if(attr.type === forge.pki.oids.signingTime) {\n            // auto-populate signing time if not already set\n            if(!attr.value) {\n              attr.value = signingTime;\n            }\n          }\n\n          // convert to ASN.1 and push onto Attributes SET (for signing) and\n          // onto authenticatedAttributesAsn1 to complete SignedData ASN.1\n          // TODO: optimize away duplication\n          attrsAsn1.value.push(_attributeToAsn1(attr));\n          signer.authenticatedAttributesAsn1.value.push(_attributeToAsn1(attr));\n        }\n\n        // DER-serialize and digest SET OF attributes only\n        bytes = asn1.toDer(attrsAsn1).getBytes();\n        signer.md.start().update(bytes);\n      }\n\n      // sign digest\n      signer.signature = signer.key.sign(signer.md, 'RSASSA-PKCS1-V1_5');\n    }\n\n    // add signer info\n    msg.signerInfos = _signersToAsn1(msg.signers);\n  }\n};\n\n/**\n * Creates an empty PKCS#7 message of type EncryptedData.\n *\n * @return the message.\n */\np7.createEncryptedData = function() {\n  var msg = null;\n  msg = {\n    type: forge.pki.oids.encryptedData,\n    version: 0,\n    encryptedContent: {\n      algorithm: forge.pki.oids['aes256-CBC']\n    },\n\n    /**\n     * Reads an EncryptedData content block (in ASN.1 format)\n     *\n     * @param obj The ASN.1 representation of the EncryptedData content block\n     */\n    fromAsn1: function(obj) {\n      // Validate EncryptedData content block and capture data.\n      _fromAsn1(msg, obj, p7.asn1.encryptedDataValidator);\n    },\n\n    /**\n     * Decrypt encrypted content\n     *\n     * @param key The (symmetric) key as a byte buffer\n     */\n    decrypt: function(key) {\n      if(key !== undefined) {\n        msg.encryptedContent.key = key;\n      }\n      _decryptContent(msg);\n    }\n  };\n  return msg;\n};\n\n/**\n * Creates an empty PKCS#7 message of type EnvelopedData.\n *\n * @return the message.\n */\np7.createEnvelopedData = function() {\n  var msg = null;\n  msg = {\n    type: forge.pki.oids.envelopedData,\n    version: 0,\n    recipients: [],\n    encryptedContent: {\n      algorithm: forge.pki.oids['aes256-CBC']\n    },\n\n    /**\n     * Reads an EnvelopedData content block (in ASN.1 format)\n     *\n     * @param obj the ASN.1 representation of the EnvelopedData content block.\n     */\n    fromAsn1: function(obj) {\n      // validate EnvelopedData content block and capture data\n      var capture = _fromAsn1(msg, obj, p7.asn1.envelopedDataValidator);\n      msg.recipients = _recipientsFromAsn1(capture.recipientInfos.value);\n    },\n\n    toAsn1: function() {\n      // ContentInfo\n      return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // ContentType\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(msg.type).getBytes()),\n        // [0] EnvelopedData\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n            // Version\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n              asn1.integerToDer(msg.version).getBytes()),\n            // RecipientInfos\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true,\n              _recipientsToAsn1(msg.recipients)),\n            // EncryptedContentInfo\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true,\n              _encryptedContentToAsn1(msg.encryptedContent))\n          ])\n        ])\n      ]);\n    },\n\n    /**\n     * Find recipient by X.509 certificate's issuer.\n     *\n     * @param cert the certificate with the issuer to look for.\n     *\n     * @return the recipient object.\n     */\n    findRecipient: function(cert) {\n      var sAttr = cert.issuer.attributes;\n\n      for(var i = 0; i < msg.recipients.length; ++i) {\n        var r = msg.recipients[i];\n        var rAttr = r.issuer;\n\n        if(r.serialNumber !== cert.serialNumber) {\n          continue;\n        }\n\n        if(rAttr.length !== sAttr.length) {\n          continue;\n        }\n\n        var match = true;\n        for(var j = 0; j < sAttr.length; ++j) {\n          if(rAttr[j].type !== sAttr[j].type ||\n            rAttr[j].value !== sAttr[j].value) {\n            match = false;\n            break;\n          }\n        }\n\n        if(match) {\n          return r;\n        }\n      }\n\n      return null;\n    },\n\n    /**\n     * Decrypt enveloped content\n     *\n     * @param recipient The recipient object related to the private key\n     * @param privKey The (RSA) private key object\n     */\n    decrypt: function(recipient, privKey) {\n      if(msg.encryptedContent.key === undefined && recipient !== undefined &&\n        privKey !== undefined) {\n        switch(recipient.encryptedContent.algorithm) {\n          case forge.pki.oids.rsaEncryption:\n          case forge.pki.oids.desCBC:\n            var key = privKey.decrypt(recipient.encryptedContent.content);\n            msg.encryptedContent.key = forge.util.createBuffer(key);\n            break;\n\n          default:\n            throw new Error('Unsupported asymmetric cipher, ' +\n              'OID ' + recipient.encryptedContent.algorithm);\n        }\n      }\n\n      _decryptContent(msg);\n    },\n\n    /**\n     * Add (another) entity to list of recipients.\n     *\n     * @param cert The certificate of the entity to add.\n     */\n    addRecipient: function(cert) {\n      msg.recipients.push({\n        version: 0,\n        issuer: cert.issuer.attributes,\n        serialNumber: cert.serialNumber,\n        encryptedContent: {\n          // We simply assume rsaEncryption here, since forge.pki only\n          // supports RSA so far.  If the PKI module supports other\n          // ciphers one day, we need to modify this one as well.\n          algorithm: forge.pki.oids.rsaEncryption,\n          key: cert.publicKey\n        }\n      });\n    },\n\n    /**\n     * Encrypt enveloped content.\n     *\n     * This function supports two optional arguments, cipher and key, which\n     * can be used to influence symmetric encryption.  Unless cipher is\n     * provided, the cipher specified in encryptedContent.algorithm is used\n     * (defaults to AES-256-CBC).  If no key is provided, encryptedContent.key\n     * is (re-)used.  If that one's not set, a random key will be generated\n     * automatically.\n     *\n     * @param [key] The key to be used for symmetric encryption.\n     * @param [cipher] The OID of the symmetric cipher to use.\n     */\n    encrypt: function(key, cipher) {\n      // Part 1: Symmetric encryption\n      if(msg.encryptedContent.content === undefined) {\n        cipher = cipher || msg.encryptedContent.algorithm;\n        key = key || msg.encryptedContent.key;\n\n        var keyLen, ivLen, ciphFn;\n        switch(cipher) {\n          case forge.pki.oids['aes128-CBC']:\n            keyLen = 16;\n            ivLen = 16;\n            ciphFn = forge.aes.createEncryptionCipher;\n            break;\n\n          case forge.pki.oids['aes192-CBC']:\n            keyLen = 24;\n            ivLen = 16;\n            ciphFn = forge.aes.createEncryptionCipher;\n            break;\n\n          case forge.pki.oids['aes256-CBC']:\n            keyLen = 32;\n            ivLen = 16;\n            ciphFn = forge.aes.createEncryptionCipher;\n            break;\n\n          case forge.pki.oids['des-EDE3-CBC']:\n            keyLen = 24;\n            ivLen = 8;\n            ciphFn = forge.des.createEncryptionCipher;\n            break;\n\n          default:\n            throw new Error('Unsupported symmetric cipher, OID ' + cipher);\n        }\n\n        if(key === undefined) {\n          key = forge.util.createBuffer(forge.random.getBytes(keyLen));\n        } else if(key.length() != keyLen) {\n          throw new Error('Symmetric key has wrong length; ' +\n            'got ' + key.length() + ' bytes, expected ' + keyLen + '.');\n        }\n\n        // Keep a copy of the key & IV in the object, so the caller can\n        // use it for whatever reason.\n        msg.encryptedContent.algorithm = cipher;\n        msg.encryptedContent.key = key;\n        msg.encryptedContent.parameter = forge.util.createBuffer(\n          forge.random.getBytes(ivLen));\n\n        var ciph = ciphFn(key);\n        ciph.start(msg.encryptedContent.parameter.copy());\n        ciph.update(msg.content);\n\n        // The finish function does PKCS#7 padding by default, therefore\n        // no action required by us.\n        if(!ciph.finish()) {\n          throw new Error('Symmetric encryption failed.');\n        }\n\n        msg.encryptedContent.content = ciph.output;\n      }\n\n      // Part 2: asymmetric encryption for each recipient\n      for(var i = 0; i < msg.recipients.length; ++i) {\n        var recipient = msg.recipients[i];\n\n        // Nothing to do, encryption already done.\n        if(recipient.encryptedContent.content !== undefined) {\n          continue;\n        }\n\n        switch(recipient.encryptedContent.algorithm) {\n          case forge.pki.oids.rsaEncryption:\n            recipient.encryptedContent.content =\n              recipient.encryptedContent.key.encrypt(\n                msg.encryptedContent.key.data);\n            break;\n\n          default:\n            throw new Error('Unsupported asymmetric cipher, OID ' +\n              recipient.encryptedContent.algorithm);\n        }\n      }\n    }\n  };\n  return msg;\n};\n\n/**\n * Converts a single recipient from an ASN.1 object.\n *\n * @param obj the ASN.1 RecipientInfo.\n *\n * @return the recipient object.\n */\nfunction _recipientFromAsn1(obj) {\n  // validate EnvelopedData content block and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, p7.asn1.recipientInfoValidator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#7 RecipientInfo. ' +\n      'ASN.1 object is not an PKCS#7 RecipientInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  return {\n    version: capture.version.charCodeAt(0),\n    issuer: forge.pki.RDNAttributesAsArray(capture.issuer),\n    serialNumber: forge.util.createBuffer(capture.serial).toHex(),\n    encryptedContent: {\n      algorithm: asn1.derToOid(capture.encAlgorithm),\n      parameter: capture.encParameter ? capture.encParameter.value : undefined,\n      content: capture.encKey\n    }\n  };\n}\n\n/**\n * Converts a single recipient object to an ASN.1 object.\n *\n * @param obj the recipient object.\n *\n * @return the ASN.1 RecipientInfo.\n */\nfunction _recipientToAsn1(obj) {\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // Version\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(obj.version).getBytes()),\n    // IssuerAndSerialNumber\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // Name\n      forge.pki.distinguishedNameToAsn1({attributes: obj.issuer}),\n      // Serial\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        forge.util.hexToBytes(obj.serialNumber))\n    ]),\n    // KeyEncryptionAlgorithmIdentifier\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // Algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(obj.encryptedContent.algorithm).getBytes()),\n      // Parameter, force NULL, only RSA supported for now.\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n    ]),\n    // EncryptedKey\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n      obj.encryptedContent.content)\n  ]);\n}\n\n/**\n * Map a set of RecipientInfo ASN.1 objects to recipient objects.\n *\n * @param infos an array of ASN.1 representations RecipientInfo (i.e. SET OF).\n *\n * @return an array of recipient objects.\n */\nfunction _recipientsFromAsn1(infos) {\n  var ret = [];\n  for(var i = 0; i < infos.length; ++i) {\n    ret.push(_recipientFromAsn1(infos[i]));\n  }\n  return ret;\n}\n\n/**\n * Map an array of recipient objects to ASN.1 RecipientInfo objects.\n *\n * @param recipients an array of recipientInfo objects.\n *\n * @return an array of ASN.1 RecipientInfos.\n */\nfunction _recipientsToAsn1(recipients) {\n  var ret = [];\n  for(var i = 0; i < recipients.length; ++i) {\n    ret.push(_recipientToAsn1(recipients[i]));\n  }\n  return ret;\n}\n\n/**\n * Converts a single signer from an ASN.1 object.\n *\n * @param obj the ASN.1 representation of a SignerInfo.\n *\n * @return the signer object.\n */\nfunction _signerFromAsn1(obj) {\n  // validate EnvelopedData content block and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, p7.asn1.signerInfoValidator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#7 SignerInfo. ' +\n      'ASN.1 object is not an PKCS#7 SignerInfo.');\n    error.errors = errors;\n    throw error;\n  }\n\n  var rval = {\n    version: capture.version.charCodeAt(0),\n    issuer: forge.pki.RDNAttributesAsArray(capture.issuer),\n    serialNumber: forge.util.createBuffer(capture.serial).toHex(),\n    digestAlgorithm: asn1.derToOid(capture.digestAlgorithm),\n    signatureAlgorithm: asn1.derToOid(capture.signatureAlgorithm),\n    signature: capture.signature,\n    authenticatedAttributes: [],\n    unauthenticatedAttributes: []\n  };\n\n  // TODO: convert attributes\n  var authenticatedAttributes = capture.authenticatedAttributes || [];\n  var unauthenticatedAttributes = capture.unauthenticatedAttributes || [];\n\n  return rval;\n}\n\n/**\n * Converts a single signerInfo object to an ASN.1 object.\n *\n * @param obj the signerInfo object.\n *\n * @return the ASN.1 representation of a SignerInfo.\n */\nfunction _signerToAsn1(obj) {\n  // SignerInfo\n  var rval = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(obj.version).getBytes()),\n    // issuerAndSerialNumber\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // name\n      forge.pki.distinguishedNameToAsn1({attributes: obj.issuer}),\n      // serial\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        forge.util.hexToBytes(obj.serialNumber))\n    ]),\n    // digestAlgorithm\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(obj.digestAlgorithm).getBytes()),\n      // parameters (null)\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n    ])\n  ]);\n\n  // authenticatedAttributes (OPTIONAL)\n  if(obj.authenticatedAttributesAsn1) {\n    // add ASN.1 previously generated during signing\n    rval.value.push(obj.authenticatedAttributesAsn1);\n  }\n\n  // digestEncryptionAlgorithm\n  rval.value.push(asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // algorithm\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n      asn1.oidToDer(obj.signatureAlgorithm).getBytes()),\n    // parameters (null)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n  ]));\n\n  // encryptedDigest\n  rval.value.push(asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, obj.signature));\n\n  // unauthenticatedAttributes (OPTIONAL)\n  if(obj.unauthenticatedAttributes.length > 0) {\n    // [1] IMPLICIT\n    var attrsAsn1 = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, []);\n    for(var i = 0; i < obj.unauthenticatedAttributes.length; ++i) {\n      var attr = obj.unauthenticatedAttributes[i];\n      attrsAsn1.values.push(_attributeToAsn1(attr));\n    }\n    rval.value.push(attrsAsn1);\n  }\n\n  return rval;\n}\n\n/**\n * Map a set of SignerInfo ASN.1 objects to an array of signer objects.\n *\n * @param signerInfoAsn1s an array of ASN.1 SignerInfos (i.e. SET OF).\n *\n * @return an array of signers objects.\n */\nfunction _signersFromAsn1(signerInfoAsn1s) {\n  var ret = [];\n  for(var i = 0; i < signerInfoAsn1s.length; ++i) {\n    ret.push(_signerFromAsn1(signerInfoAsn1s[i]));\n  }\n  return ret;\n}\n\n/**\n * Map an array of signer objects to ASN.1 objects.\n *\n * @param signers an array of signer objects.\n *\n * @return an array of ASN.1 SignerInfos.\n */\nfunction _signersToAsn1(signers) {\n  var ret = [];\n  for(var i = 0; i < signers.length; ++i) {\n    ret.push(_signerToAsn1(signers[i]));\n  }\n  return ret;\n}\n\n/**\n * Convert an attribute object to an ASN.1 Attribute.\n *\n * @param attr the attribute object.\n *\n * @return the ASN.1 Attribute.\n */\nfunction _attributeToAsn1(attr) {\n  var value;\n\n  // TODO: generalize to support more attributes\n  if(attr.type === forge.pki.oids.contentType) {\n    value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n      asn1.oidToDer(attr.value).getBytes());\n  } else if(attr.type === forge.pki.oids.messageDigest) {\n    value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n      attr.value.bytes());\n  } else if(attr.type === forge.pki.oids.signingTime) {\n    /* Note per RFC 2985: Dates between 1 January 1950 and 31 December 2049\n      (inclusive) MUST be encoded as UTCTime. Any dates with year values\n      before 1950 or after 2049 MUST be encoded as GeneralizedTime. [Further,]\n      UTCTime values MUST be expressed in Greenwich Mean Time (Zulu) and MUST\n      include seconds (i.e., times are YYMMDDHHMMSSZ), even where the\n      number of seconds is zero.  Midnight (GMT) must be represented as\n      \"YYMMDD000000Z\". */\n    // TODO: make these module-level constants\n    var jan_1_1950 = new Date('1950-01-01T00:00:00Z');\n    var jan_1_2050 = new Date('2050-01-01T00:00:00Z');\n    var date = attr.value;\n    if(typeof date === 'string') {\n      // try to parse date\n      var timestamp = Date.parse(date);\n      if(!isNaN(timestamp)) {\n        date = new Date(timestamp);\n      } else if(date.length === 13) {\n        // YYMMDDHHMMSSZ (13 chars for UTCTime)\n        date = asn1.utcTimeToDate(date);\n      } else {\n        // assume generalized time\n        date = asn1.generalizedTimeToDate(date);\n      }\n    }\n\n    if(date >= jan_1_1950 && date < jan_1_2050) {\n      value = asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.UTCTIME, false,\n        asn1.dateToUtcTime(date));\n    } else {\n      value = asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.GENERALIZEDTIME, false,\n        asn1.dateToGeneralizedTime(date));\n    }\n  }\n\n  // TODO: expose as common API call\n  // create a RelativeDistinguishedName set\n  // each value in the set is an AttributeTypeAndValue first\n  // containing the type (an OID) and second the value\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // AttributeType\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n      asn1.oidToDer(attr.type).getBytes()),\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [\n      // AttributeValue\n      value\n    ])\n  ]);\n}\n\n/**\n * Map messages encrypted content to ASN.1 objects.\n *\n * @param ec The encryptedContent object of the message.\n *\n * @return ASN.1 representation of the encryptedContent object (SEQUENCE).\n */\nfunction _encryptedContentToAsn1(ec) {\n  return [\n    // ContentType, always Data for the moment\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n      asn1.oidToDer(forge.pki.oids.data).getBytes()),\n    // ContentEncryptionAlgorithmIdentifier\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // Algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(ec.algorithm).getBytes()),\n      // Parameters (IV)\n      !ec.parameter ?\n        undefined :\n        asn1.create(\n          asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n          ec.parameter.getBytes())\n    ]),\n    // [0] EncryptedContent\n    asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n        ec.content.getBytes())\n    ])\n  ];\n}\n\n/**\n * Reads the \"common part\" of an PKCS#7 content block (in ASN.1 format)\n *\n * This function reads the \"common part\" of the PKCS#7 content blocks\n * EncryptedData and EnvelopedData, i.e. version number and symmetrically\n * encrypted content block.\n *\n * The result of the ASN.1 validate and capture process is returned\n * to allow the caller to extract further data, e.g. the list of recipients\n * in case of a EnvelopedData object.\n *\n * @param msg the PKCS#7 object to read the data to.\n * @param obj the ASN.1 representation of the content block.\n * @param validator the ASN.1 structure validator object to use.\n *\n * @return the value map captured by validator object.\n */\nfunction _fromAsn1(msg, obj, validator) {\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, validator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#7 message. ' +\n      'ASN.1 object is not a supported PKCS#7 message.');\n    error.errors = error;\n    throw error;\n  }\n\n  // Check contentType, so far we only support (raw) Data.\n  var contentType = asn1.derToOid(capture.contentType);\n  if(contentType !== forge.pki.oids.data) {\n    throw new Error('Unsupported PKCS#7 message. ' +\n      'Only wrapped ContentType Data supported.');\n  }\n\n  if(capture.encryptedContent) {\n    var content = '';\n    if(forge.util.isArray(capture.encryptedContent)) {\n      for(var i = 0; i < capture.encryptedContent.length; ++i) {\n        if(capture.encryptedContent[i].type !== asn1.Type.OCTETSTRING) {\n          throw new Error('Malformed PKCS#7 message, expecting encrypted ' +\n            'content constructed of only OCTET STRING objects.');\n        }\n        content += capture.encryptedContent[i].value;\n      }\n    } else {\n      content = capture.encryptedContent;\n    }\n    msg.encryptedContent = {\n      algorithm: asn1.derToOid(capture.encAlgorithm),\n      parameter: forge.util.createBuffer(capture.encParameter.value),\n      content: forge.util.createBuffer(content)\n    };\n  }\n\n  if(capture.content) {\n    var content = '';\n    if(forge.util.isArray(capture.content)) {\n      for(var i = 0; i < capture.content.length; ++i) {\n        if(capture.content[i].type !== asn1.Type.OCTETSTRING) {\n          throw new Error('Malformed PKCS#7 message, expecting ' +\n            'content constructed of only OCTET STRING objects.');\n        }\n        content += capture.content[i].value;\n      }\n    } else {\n      content = capture.content;\n    }\n    msg.content = forge.util.createBuffer(content);\n  }\n\n  msg.version = capture.version.charCodeAt(0);\n  msg.rawCapture = capture;\n\n  return capture;\n}\n\n/**\n * Decrypt the symmetrically encrypted content block of the PKCS#7 message.\n *\n * Decryption is skipped in case the PKCS#7 message object already has a\n * (decrypted) content attribute.  The algorithm, key and cipher parameters\n * (probably the iv) are taken from the encryptedContent attribute of the\n * message object.\n *\n * @param The PKCS#7 message object.\n */\nfunction _decryptContent(msg) {\n  if(msg.encryptedContent.key === undefined) {\n    throw new Error('Symmetric key not available.');\n  }\n\n  if(msg.content === undefined) {\n    var ciph;\n\n    switch(msg.encryptedContent.algorithm) {\n      case forge.pki.oids['aes128-CBC']:\n      case forge.pki.oids['aes192-CBC']:\n      case forge.pki.oids['aes256-CBC']:\n        ciph = forge.aes.createDecryptionCipher(msg.encryptedContent.key);\n        break;\n\n      case forge.pki.oids['desCBC']:\n      case forge.pki.oids['des-EDE3-CBC']:\n        ciph = forge.des.createDecryptionCipher(msg.encryptedContent.key);\n        break;\n\n      default:\n        throw new Error('Unsupported symmetric cipher, OID ' +\n          msg.encryptedContent.algorithm);\n    }\n    ciph.start(msg.encryptedContent.parameter);\n    ciph.update(msg.encryptedContent.content);\n\n    if(!ciph.finish()) {\n      throw new Error('Symmetric decryption failed.');\n    }\n\n    msg.content = ciph.output;\n  }\n}\n","/**\n * Javascript implementation of ASN.1 validators for PKCS#7 v1.5.\n *\n * @author Dave Longley\n * @author Stefan Siegl\n *\n * Copyright (c) 2012-2015 Digital Bazaar, Inc.\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n *\n * The ASN.1 representation of PKCS#7 is as follows\n * (see RFC #2315 for details, http://www.ietf.org/rfc/rfc2315.txt):\n *\n * A PKCS#7 message consists of a ContentInfo on root level, which may\n * contain any number of further ContentInfo nested into it.\n *\n * ContentInfo ::= SEQUENCE {\n *   contentType                ContentType,\n *   content               [0]  EXPLICIT ANY DEFINED BY contentType OPTIONAL\n * }\n *\n * ContentType ::= OBJECT IDENTIFIER\n *\n * EnvelopedData ::= SEQUENCE {\n *   version                    Version,\n *   recipientInfos             RecipientInfos,\n *   encryptedContentInfo       EncryptedContentInfo\n * }\n *\n * EncryptedData ::= SEQUENCE {\n *   version                    Version,\n *   encryptedContentInfo       EncryptedContentInfo\n * }\n *\n * id-signedData OBJECT IDENTIFIER ::= { iso(1) member-body(2)\n *   us(840) rsadsi(113549) pkcs(1) pkcs7(7) 2 }\n *\n * SignedData ::= SEQUENCE {\n *   version           INTEGER,\n *   digestAlgorithms  DigestAlgorithmIdentifiers,\n *   contentInfo       ContentInfo,\n *   certificates      [0] IMPLICIT Certificates OPTIONAL,\n *   crls              [1] IMPLICIT CertificateRevocationLists OPTIONAL,\n *   signerInfos       SignerInfos\n * }\n *\n * SignerInfos ::= SET OF SignerInfo\n *\n * SignerInfo ::= SEQUENCE {\n *   version                    Version,\n *   issuerAndSerialNumber      IssuerAndSerialNumber,\n *   digestAlgorithm            DigestAlgorithmIdentifier,\n *   authenticatedAttributes    [0] IMPLICIT Attributes OPTIONAL,\n *   digestEncryptionAlgorithm  DigestEncryptionAlgorithmIdentifier,\n *   encryptedDigest            EncryptedDigest,\n *   unauthenticatedAttributes  [1] IMPLICIT Attributes OPTIONAL\n * }\n *\n * EncryptedDigest ::= OCTET STRING\n *\n * Attributes ::= SET OF Attribute\n *\n * Attribute ::= SEQUENCE {\n *   attrType    OBJECT IDENTIFIER,\n *   attrValues  SET OF AttributeValue\n * }\n *\n * AttributeValue ::= ANY\n *\n * Version ::= INTEGER\n *\n * RecipientInfos ::= SET OF RecipientInfo\n *\n * EncryptedContentInfo ::= SEQUENCE {\n *   contentType                 ContentType,\n *   contentEncryptionAlgorithm  ContentEncryptionAlgorithmIdentifier,\n *   encryptedContent       [0]  IMPLICIT EncryptedContent OPTIONAL\n * }\n *\n * ContentEncryptionAlgorithmIdentifier ::= AlgorithmIdentifier\n *\n * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters\n * for the algorithm, if any. In the case of AES and DES3, there is only one,\n * the IV.\n *\n * AlgorithmIdentifer ::= SEQUENCE {\n *    algorithm OBJECT IDENTIFIER,\n *    parameters ANY DEFINED BY algorithm OPTIONAL\n * }\n *\n * EncryptedContent ::= OCTET STRING\n *\n * RecipientInfo ::= SEQUENCE {\n *   version                     Version,\n *   issuerAndSerialNumber       IssuerAndSerialNumber,\n *   keyEncryptionAlgorithm      KeyEncryptionAlgorithmIdentifier,\n *   encryptedKey                EncryptedKey\n * }\n *\n * IssuerAndSerialNumber ::= SEQUENCE {\n *   issuer                      Name,\n *   serialNumber                CertificateSerialNumber\n * }\n *\n * CertificateSerialNumber ::= INTEGER\n *\n * KeyEncryptionAlgorithmIdentifier ::= AlgorithmIdentifier\n *\n * EncryptedKey ::= OCTET STRING\n */\nvar forge = require('./forge');\nrequire('./asn1');\nrequire('./util');\n\n// shortcut for ASN.1 API\nvar asn1 = forge.asn1;\n\n// shortcut for PKCS#7 API\nvar p7v = module.exports = forge.pkcs7asn1 = forge.pkcs7asn1 || {};\nforge.pkcs7 = forge.pkcs7 || {};\nforge.pkcs7.asn1 = p7v;\n\nvar contentInfoValidator = {\n  name: 'ContentInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'ContentInfo.ContentType',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'contentType'\n  }, {\n    name: 'ContentInfo.content',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    constructed: true,\n    optional: true,\n    captureAsn1: 'content'\n  }]\n};\np7v.contentInfoValidator = contentInfoValidator;\n\nvar encryptedContentInfoValidator = {\n  name: 'EncryptedContentInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'EncryptedContentInfo.contentType',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OID,\n    constructed: false,\n    capture: 'contentType'\n  }, {\n    name: 'EncryptedContentInfo.contentEncryptionAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'EncryptedContentInfo.contentEncryptionAlgorithm.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'encAlgorithm'\n    }, {\n      name: 'EncryptedContentInfo.contentEncryptionAlgorithm.parameter',\n      tagClass: asn1.Class.UNIVERSAL,\n      captureAsn1: 'encParameter'\n    }]\n  }, {\n    name: 'EncryptedContentInfo.encryptedContent',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    /* The PKCS#7 structure output by OpenSSL somewhat differs from what\n     * other implementations do generate.\n     *\n     * OpenSSL generates a structure like this:\n     * SEQUENCE {\n     *    ...\n     *    [0]\n     *       26 DA 67 D2 17 9C 45 3C B1 2A A8 59 2F 29 33 38\n     *       C3 C3 DF 86 71 74 7A 19 9F 40 D0 29 BE 85 90 45\n     *       ...\n     * }\n     *\n     * Whereas other implementations (and this PKCS#7 module) generate:\n     * SEQUENCE {\n     *    ...\n     *    [0] {\n     *       OCTET STRING\n     *          26 DA 67 D2 17 9C 45 3C B1 2A A8 59 2F 29 33 38\n     *          C3 C3 DF 86 71 74 7A 19 9F 40 D0 29 BE 85 90 45\n     *          ...\n     *    }\n     * }\n     *\n     * In order to support both, we just capture the context specific\n     * field here.  The OCTET STRING bit is removed below.\n     */\n    capture: 'encryptedContent',\n    captureAsn1: 'encryptedContentAsn1'\n  }]\n};\n\np7v.envelopedDataValidator = {\n  name: 'EnvelopedData',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'EnvelopedData.Version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'version'\n  }, {\n    name: 'EnvelopedData.RecipientInfos',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SET,\n    constructed: true,\n    captureAsn1: 'recipientInfos'\n  }].concat(encryptedContentInfoValidator)\n};\n\np7v.encryptedDataValidator = {\n  name: 'EncryptedData',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'EncryptedData.Version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'version'\n  }].concat(encryptedContentInfoValidator)\n};\n\nvar signerValidator = {\n  name: 'SignerInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'SignerInfo.version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false\n  }, {\n    name: 'SignerInfo.issuerAndSerialNumber',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'SignerInfo.issuerAndSerialNumber.issuer',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: 'issuer'\n    }, {\n      name: 'SignerInfo.issuerAndSerialNumber.serialNumber',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.INTEGER,\n      constructed: false,\n      capture: 'serial'\n    }]\n  }, {\n    name: 'SignerInfo.digestAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'SignerInfo.digestAlgorithm.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'digestAlgorithm'\n    }, {\n      name: 'SignerInfo.digestAlgorithm.parameter',\n      tagClass: asn1.Class.UNIVERSAL,\n      constructed: false,\n      captureAsn1: 'digestParameter',\n      optional: true\n    }]\n  }, {\n    name: 'SignerInfo.authenticatedAttributes',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    constructed: true,\n    optional: true,\n    capture: 'authenticatedAttributes'\n  }, {\n    name: 'SignerInfo.digestEncryptionAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    capture: 'signatureAlgorithm'\n  }, {\n    name: 'SignerInfo.encryptedDigest',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'signature'\n  }, {\n    name: 'SignerInfo.unauthenticatedAttributes',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 1,\n    constructed: true,\n    optional: true,\n    capture: 'unauthenticatedAttributes'\n  }]\n};\n\np7v.signedDataValidator = {\n  name: 'SignedData',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'SignedData.Version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'version'\n  }, {\n    name: 'SignedData.DigestAlgorithms',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SET,\n    constructed: true,\n    captureAsn1: 'digestAlgorithms'\n  },\n  contentInfoValidator,\n  {\n    name: 'SignedData.Certificates',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    optional: true,\n    captureAsn1: 'certificates'\n  }, {\n    name: 'SignedData.CertificateRevocationLists',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 1,\n    optional: true,\n    captureAsn1: 'crls'\n  }, {\n    name: 'SignedData.SignerInfos',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SET,\n    capture: 'signerInfos',\n    optional: true,\n    value: [signerValidator]\n  }]\n};\n\np7v.recipientInfoValidator = {\n  name: 'RecipientInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'RecipientInfo.version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'version'\n  }, {\n    name: 'RecipientInfo.issuerAndSerial',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'RecipientInfo.issuerAndSerial.issuer',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: 'issuer'\n    }, {\n      name: 'RecipientInfo.issuerAndSerial.serialNumber',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.INTEGER,\n      constructed: false,\n      capture: 'serial'\n    }]\n  }, {\n    name: 'RecipientInfo.keyEncryptionAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'RecipientInfo.keyEncryptionAlgorithm.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'encAlgorithm'\n    }, {\n      name: 'RecipientInfo.keyEncryptionAlgorithm.parameter',\n      tagClass: asn1.Class.UNIVERSAL,\n      constructed: false,\n      captureAsn1: 'encParameter',\n      optional: true\n    }]\n  }, {\n    name: 'RecipientInfo.encryptedKey',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'encKey'\n  }]\n};\n","/**\n * Javascript implementation of a basic Public Key Infrastructure, including\n * support for RSA public and private keys.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2013 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./asn1');\nrequire('./oids');\nrequire('./pbe');\nrequire('./pem');\nrequire('./pbkdf2');\nrequire('./pkcs12');\nrequire('./pss');\nrequire('./rsa');\nrequire('./util');\nrequire('./x509');\n\n// shortcut for asn.1 API\nvar asn1 = forge.asn1;\n\n/* Public Key Infrastructure (PKI) implementation. */\nvar pki = module.exports = forge.pki = forge.pki || {};\n\n/**\n * NOTE: THIS METHOD IS DEPRECATED. Use pem.decode() instead.\n *\n * Converts PEM-formatted data to DER.\n *\n * @param pem the PEM-formatted data.\n *\n * @return the DER-formatted data.\n */\npki.pemToDer = function(pem) {\n  var msg = forge.pem.decode(pem)[0];\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert PEM to DER; PEM is encrypted.');\n  }\n  return forge.util.createBuffer(msg.body);\n};\n\n/**\n * Converts an RSA private key from PEM format.\n *\n * @param pem the PEM-formatted private key.\n *\n * @return the private key.\n */\npki.privateKeyFromPem = function(pem) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'PRIVATE KEY' && msg.type !== 'RSA PRIVATE KEY') {\n    var error = new Error('Could not convert private key from PEM; PEM ' +\n      'header type is not \"PRIVATE KEY\" or \"RSA PRIVATE KEY\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert private key from PEM; PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  var obj = asn1.fromDer(msg.body);\n\n  return pki.privateKeyFromAsn1(obj);\n};\n\n/**\n * Converts an RSA private key to PEM format.\n *\n * @param key the private key.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted private key.\n */\npki.privateKeyToPem = function(key, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var msg = {\n    type: 'RSA PRIVATE KEY',\n    body: asn1.toDer(pki.privateKeyToAsn1(key)).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Converts a PrivateKeyInfo to PEM format.\n *\n * @param pki the PrivateKeyInfo.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted private key.\n */\npki.privateKeyInfoToPem = function(pki, maxline) {\n  // convert to DER, then PEM-encode\n  var msg = {\n    type: 'PRIVATE KEY',\n    body: asn1.toDer(pki).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n","/**\n * Prime number generation API.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\nrequire('./jsbn');\nrequire('./random');\n\n(function() {\n\n// forge.prime already defined\nif(forge.prime) {\n  module.exports = forge.prime;\n  return;\n}\n\n/* PRIME API */\nvar prime = module.exports = forge.prime = forge.prime || {};\n\nvar BigInteger = forge.jsbn.BigInteger;\n\n// primes are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29\nvar GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];\nvar THIRTY = new BigInteger(null);\nTHIRTY.fromInt(30);\nvar op_or = function(x, y) {return x|y;};\n\n/**\n * Generates a random probable prime with the given number of bits.\n *\n * Alternative algorithms can be specified by name as a string or as an\n * object with custom options like so:\n *\n * {\n *   name: 'PRIMEINC',\n *   options: {\n *     maxBlockTime: <the maximum amount of time to block the main\n *       thread before allowing I/O other JS to run>,\n *     millerRabinTests: <the number of miller-rabin tests to run>,\n *     workerScript: <the worker script URL>,\n *     workers: <the number of web workers (if supported) to use,\n *       -1 to use estimated cores minus one>.\n *     workLoad: the size of the work load, ie: number of possible prime\n *       numbers for each web worker to check per work assignment,\n *       (default: 100).\n *   }\n * }\n *\n * @param bits the number of bits for the prime number.\n * @param options the options to use.\n *          [algorithm] the algorithm to use (default: 'PRIMEINC').\n *          [prng] a custom crypto-secure pseudo-random number generator to use,\n *            that must define \"getBytesSync\".\n *\n * @return callback(err, num) called once the operation completes.\n */\nprime.generateProbablePrime = function(bits, options, callback) {\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // default to PRIMEINC algorithm\n  var algorithm = options.algorithm || 'PRIMEINC';\n  if(typeof algorithm === 'string') {\n    algorithm = {name: algorithm};\n  }\n  algorithm.options = algorithm.options || {};\n\n  // create prng with api that matches BigInteger secure random\n  var prng = options.prng || forge.random;\n  var rng = {\n    // x is an array to fill with bytes\n    nextBytes: function(x) {\n      var b = prng.getBytesSync(x.length);\n      for(var i = 0; i < x.length; ++i) {\n        x[i] = b.charCodeAt(i);\n      }\n    }\n  };\n\n  if(algorithm.name === 'PRIMEINC') {\n    return primeincFindPrime(bits, rng, algorithm.options, callback);\n  }\n\n  throw new Error('Invalid prime generation algorithm: ' + algorithm.name);\n};\n\nfunction primeincFindPrime(bits, rng, options, callback) {\n  if('workers' in options) {\n    return primeincFindPrimeWithWorkers(bits, rng, options, callback);\n  }\n  return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);\n}\n\nfunction primeincFindPrimeWithoutWorkers(bits, rng, options, callback) {\n  // initialize random number\n  var num = generateRandom(bits, rng);\n\n  /* Note: All primes are of the form 30k+i for i < 30 and gcd(30, i)=1. The\n  number we are given is always aligned at 30k + 1. Each time the number is\n  determined not to be prime we add to get to the next 'i', eg: if the number\n  was at 30k + 1 we add 6. */\n  var deltaIdx = 0;\n\n  // get required number of MR tests\n  var mrTests = getMillerRabinTests(num.bitLength());\n  if('millerRabinTests' in options) {\n    mrTests = options.millerRabinTests;\n  }\n\n  // find prime nearest to 'num' for maxBlockTime ms\n  // 10 ms gives 5ms of leeway for other calculations before dropping\n  // below 60fps (1000/60 == 16.67), but in reality, the number will\n  // likely be higher due to an 'atomic' big int modPow\n  var maxBlockTime = 10;\n  if('maxBlockTime' in options) {\n    maxBlockTime = options.maxBlockTime;\n  }\n\n  _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);\n}\n\nfunction _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback) {\n  var start = +new Date();\n  do {\n    // overflow, regenerate random number\n    if(num.bitLength() > bits) {\n      num = generateRandom(bits, rng);\n    }\n    // do primality test\n    if(num.isProbablePrime(mrTests)) {\n      return callback(null, num);\n    }\n    // get next potential prime\n    num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);\n  } while(maxBlockTime < 0 || (+new Date() - start < maxBlockTime));\n\n  // keep trying later\n  forge.util.setImmediate(function() {\n    _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);\n  });\n}\n\n// NOTE: This algorithm is indeterminate in nature because workers\n// run in parallel looking at different segments of numbers. Even if this\n// algorithm is run twice with the same input from a predictable RNG, it\n// may produce different outputs.\nfunction primeincFindPrimeWithWorkers(bits, rng, options, callback) {\n  // web workers unavailable\n  if(typeof Worker === 'undefined') {\n    return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);\n  }\n\n  // initialize random number\n  var num = generateRandom(bits, rng);\n\n  // use web workers to generate keys\n  var numWorkers = options.workers;\n  var workLoad = options.workLoad || 100;\n  var range = workLoad * 30 / 8;\n  var workerScript = options.workerScript || 'forge/prime.worker.js';\n  if(numWorkers === -1) {\n    return forge.util.estimateCores(function(err, cores) {\n      if(err) {\n        // default to 2\n        cores = 2;\n      }\n      numWorkers = cores - 1;\n      generate();\n    });\n  }\n  generate();\n\n  function generate() {\n    // require at least 1 worker\n    numWorkers = Math.max(1, numWorkers);\n\n    // TODO: consider optimizing by starting workers outside getPrime() ...\n    // note that in order to clean up they will have to be made internally\n    // asynchronous which may actually be slower\n\n    // start workers immediately\n    var workers = [];\n    for(var i = 0; i < numWorkers; ++i) {\n      // FIXME: fix path or use blob URLs\n      workers[i] = new Worker(workerScript);\n    }\n    var running = numWorkers;\n\n    // listen for requests from workers and assign ranges to find prime\n    for(var i = 0; i < numWorkers; ++i) {\n      workers[i].addEventListener('message', workerMessage);\n    }\n\n    /* Note: The distribution of random numbers is unknown. Therefore, each\n    web worker is continuously allocated a range of numbers to check for a\n    random number until one is found.\n\n    Every 30 numbers will be checked just 8 times, because prime numbers\n    have the form:\n\n    30k+i, for i < 30 and gcd(30, i)=1 (there are 8 values of i for this)\n\n    Therefore, if we want a web worker to run N checks before asking for\n    a new range of numbers, each range must contain N*30/8 numbers.\n\n    For 100 checks (workLoad), this is a range of 375. */\n\n    var found = false;\n    function workerMessage(e) {\n      // ignore message, prime already found\n      if(found) {\n        return;\n      }\n\n      --running;\n      var data = e.data;\n      if(data.found) {\n        // terminate all workers\n        for(var i = 0; i < workers.length; ++i) {\n          workers[i].terminate();\n        }\n        found = true;\n        return callback(null, new BigInteger(data.prime, 16));\n      }\n\n      // overflow, regenerate random number\n      if(num.bitLength() > bits) {\n        num = generateRandom(bits, rng);\n      }\n\n      // assign new range to check\n      var hex = num.toString(16);\n\n      // start prime search\n      e.target.postMessage({\n        hex: hex,\n        workLoad: workLoad\n      });\n\n      num.dAddOffset(range, 0);\n    }\n  }\n}\n\n/**\n * Generates a random number using the given number of bits and RNG.\n *\n * @param bits the number of bits for the number.\n * @param rng the random number generator to use.\n *\n * @return the random number.\n */\nfunction generateRandom(bits, rng) {\n  var num = new BigInteger(bits, rng);\n  // force MSB set\n  var bits1 = bits - 1;\n  if(!num.testBit(bits1)) {\n    num.bitwiseTo(BigInteger.ONE.shiftLeft(bits1), op_or, num);\n  }\n  // align number on 30k+1 boundary\n  num.dAddOffset(31 - num.mod(THIRTY).byteValue(), 0);\n  return num;\n}\n\n/**\n * Returns the required number of Miller-Rabin tests to generate a\n * prime with an error probability of (1/2)^80.\n *\n * See Handbook of Applied Cryptography Chapter 4, Table 4.4.\n *\n * @param bits the bit size.\n *\n * @return the required number of iterations.\n */\nfunction getMillerRabinTests(bits) {\n  if(bits <= 100) return 27;\n  if(bits <= 150) return 18;\n  if(bits <= 200) return 15;\n  if(bits <= 250) return 12;\n  if(bits <= 300) return 9;\n  if(bits <= 350) return 8;\n  if(bits <= 400) return 7;\n  if(bits <= 500) return 6;\n  if(bits <= 600) return 5;\n  if(bits <= 800) return 4;\n  if(bits <= 1250) return 3;\n  return 2;\n}\n\n})();\n","/**\n * A javascript implementation of a cryptographically-secure\n * Pseudo Random Number Generator (PRNG). The Fortuna algorithm is followed\n * here though the use of SHA-256 is not enforced; when generating an\n * a PRNG context, the hashing algorithm and block cipher used for\n * the generator are specified via a plugin.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./util');\n\nvar _crypto = null;\nif(forge.util.isNodejs && !forge.options.usePureJavaScript &&\n  !process.versions['node-webkit']) {\n  _crypto = require('crypto');\n}\n\n/* PRNG API */\nvar prng = module.exports = forge.prng = forge.prng || {};\n\n/**\n * Creates a new PRNG context.\n *\n * A PRNG plugin must be passed in that will provide:\n *\n * 1. A function that initializes the key and seed of a PRNG context. It\n *   will be given a 16 byte key and a 16 byte seed. Any key expansion\n *   or transformation of the seed from a byte string into an array of\n *   integers (or similar) should be performed.\n * 2. The cryptographic function used by the generator. It takes a key and\n *   a seed.\n * 3. A seed increment function. It takes the seed and returns seed + 1.\n * 4. An api to create a message digest.\n *\n * For an example, see random.js.\n *\n * @param plugin the PRNG plugin to use.\n */\nprng.create = function(plugin) {\n  var ctx = {\n    plugin: plugin,\n    key: null,\n    seed: null,\n    time: null,\n    // number of reseeds so far\n    reseeds: 0,\n    // amount of data generated so far\n    generated: 0,\n    // no initial key bytes\n    keyBytes: ''\n  };\n\n  // create 32 entropy pools (each is a message digest)\n  var md = plugin.md;\n  var pools = new Array(32);\n  for(var i = 0; i < 32; ++i) {\n    pools[i] = md.create();\n  }\n  ctx.pools = pools;\n\n  // entropy pools are written to cyclically, starting at index 0\n  ctx.pool = 0;\n\n  /**\n   * Generates random bytes. The bytes may be generated synchronously or\n   * asynchronously. Web workers must use the asynchronous interface or\n   * else the behavior is undefined.\n   *\n   * @param count the number of random bytes to generate.\n   * @param [callback(err, bytes)] called once the operation completes.\n   *\n   * @return count random bytes as a string.\n   */\n  ctx.generate = function(count, callback) {\n    // do synchronously\n    if(!callback) {\n      return ctx.generateSync(count);\n    }\n\n    // simple generator using counter-based CBC\n    var cipher = ctx.plugin.cipher;\n    var increment = ctx.plugin.increment;\n    var formatKey = ctx.plugin.formatKey;\n    var formatSeed = ctx.plugin.formatSeed;\n    var b = forge.util.createBuffer();\n\n    // paranoid deviation from Fortuna:\n    // reset key for every request to protect previously\n    // generated random bytes should the key be discovered;\n    // there is no 100ms based reseeding because of this\n    // forced reseed for every `generate` call\n    ctx.key = null;\n\n    generate();\n\n    function generate(err) {\n      if(err) {\n        return callback(err);\n      }\n\n      // sufficient bytes generated\n      if(b.length() >= count) {\n        return callback(null, b.getBytes(count));\n      }\n\n      // if amount of data generated is greater than 1 MiB, trigger reseed\n      if(ctx.generated > 0xfffff) {\n        ctx.key = null;\n      }\n\n      if(ctx.key === null) {\n        // prevent stack overflow\n        return forge.util.nextTick(function() {\n          _reseed(generate);\n        });\n      }\n\n      // generate the random bytes\n      var bytes = cipher(ctx.key, ctx.seed);\n      ctx.generated += bytes.length;\n      b.putBytes(bytes);\n\n      // generate bytes for a new key and seed\n      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));\n      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));\n\n      forge.util.setImmediate(generate);\n    }\n  };\n\n  /**\n   * Generates random bytes synchronously.\n   *\n   * @param count the number of random bytes to generate.\n   *\n   * @return count random bytes as a string.\n   */\n  ctx.generateSync = function(count) {\n    // simple generator using counter-based CBC\n    var cipher = ctx.plugin.cipher;\n    var increment = ctx.plugin.increment;\n    var formatKey = ctx.plugin.formatKey;\n    var formatSeed = ctx.plugin.formatSeed;\n\n    // paranoid deviation from Fortuna:\n    // reset key for every request to protect previously\n    // generated random bytes should the key be discovered;\n    // there is no 100ms based reseeding because of this\n    // forced reseed for every `generateSync` call\n    ctx.key = null;\n\n    var b = forge.util.createBuffer();\n    while(b.length() < count) {\n      // if amount of data generated is greater than 1 MiB, trigger reseed\n      if(ctx.generated > 0xfffff) {\n        ctx.key = null;\n      }\n\n      if(ctx.key === null) {\n        _reseedSync();\n      }\n\n      // generate the random bytes\n      var bytes = cipher(ctx.key, ctx.seed);\n      ctx.generated += bytes.length;\n      b.putBytes(bytes);\n\n      // generate bytes for a new key and seed\n      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));\n      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));\n    }\n\n    return b.getBytes(count);\n  };\n\n  /**\n   * Private function that asynchronously reseeds a generator.\n   *\n   * @param callback(err) called once the operation completes.\n   */\n  function _reseed(callback) {\n    if(ctx.pools[0].messageLength >= 32) {\n      _seed();\n      return callback();\n    }\n    // not enough seed data...\n    var needed = (32 - ctx.pools[0].messageLength) << 5;\n    ctx.seedFile(needed, function(err, bytes) {\n      if(err) {\n        return callback(err);\n      }\n      ctx.collect(bytes);\n      _seed();\n      callback();\n    });\n  }\n\n  /**\n   * Private function that synchronously reseeds a generator.\n   */\n  function _reseedSync() {\n    if(ctx.pools[0].messageLength >= 32) {\n      return _seed();\n    }\n    // not enough seed data...\n    var needed = (32 - ctx.pools[0].messageLength) << 5;\n    ctx.collect(ctx.seedFileSync(needed));\n    _seed();\n  }\n\n  /**\n   * Private function that seeds a generator once enough bytes are available.\n   */\n  function _seed() {\n    // update reseed count\n    ctx.reseeds = (ctx.reseeds === 0xffffffff) ? 0 : ctx.reseeds + 1;\n\n    // goal is to update `key` via:\n    // key = hash(key + s)\n    //   where 's' is all collected entropy from selected pools, then...\n\n    // create a plugin-based message digest\n    var md = ctx.plugin.md.create();\n\n    // consume current key bytes\n    md.update(ctx.keyBytes);\n\n    // digest the entropy of pools whose index k meet the\n    // condition 'n mod 2^k == 0' where n is the number of reseeds\n    var _2powK = 1;\n    for(var k = 0; k < 32; ++k) {\n      if(ctx.reseeds % _2powK === 0) {\n        md.update(ctx.pools[k].digest().getBytes());\n        ctx.pools[k].start();\n      }\n      _2powK = _2powK << 1;\n    }\n\n    // get digest for key bytes\n    ctx.keyBytes = md.digest().getBytes();\n\n    // paranoid deviation from Fortuna:\n    // update `seed` via `seed = hash(key)`\n    // instead of initializing to zero once and only\n    // ever incrementing it\n    md.start();\n    md.update(ctx.keyBytes);\n    var seedBytes = md.digest().getBytes();\n\n    // update state\n    ctx.key = ctx.plugin.formatKey(ctx.keyBytes);\n    ctx.seed = ctx.plugin.formatSeed(seedBytes);\n    ctx.generated = 0;\n  }\n\n  /**\n   * The built-in default seedFile. This seedFile is used when entropy\n   * is needed immediately.\n   *\n   * @param needed the number of bytes that are needed.\n   *\n   * @return the random bytes.\n   */\n  function defaultSeedFile(needed) {\n    // use window.crypto.getRandomValues strong source of entropy if available\n    var getRandomValues = null;\n    var globalScope = forge.util.globalScope;\n    var _crypto = globalScope.crypto || globalScope.msCrypto;\n    if(_crypto && _crypto.getRandomValues) {\n      getRandomValues = function(arr) {\n        return _crypto.getRandomValues(arr);\n      };\n    }\n\n    var b = forge.util.createBuffer();\n    if(getRandomValues) {\n      while(b.length() < needed) {\n        // max byte length is 65536 before QuotaExceededError is thrown\n        // http://www.w3.org/TR/WebCryptoAPI/#RandomSource-method-getRandomValues\n        var count = Math.max(1, Math.min(needed - b.length(), 65536) / 4);\n        var entropy = new Uint32Array(Math.floor(count));\n        try {\n          getRandomValues(entropy);\n          for(var i = 0; i < entropy.length; ++i) {\n            b.putInt32(entropy[i]);\n          }\n        } catch(e) {\n          /* only ignore QuotaExceededError */\n          if(!(typeof QuotaExceededError !== 'undefined' &&\n            e instanceof QuotaExceededError)) {\n            throw e;\n          }\n        }\n      }\n    }\n\n    // be sad and add some weak random data\n    if(b.length() < needed) {\n      /* Draws from Park-Miller \"minimal standard\" 31 bit PRNG,\n      implemented with David G. Carta's optimization: with 32 bit math\n      and without division (Public Domain). */\n      var hi, lo, next;\n      var seed = Math.floor(Math.random() * 0x010000);\n      while(b.length() < needed) {\n        lo = 16807 * (seed & 0xFFFF);\n        hi = 16807 * (seed >> 16);\n        lo += (hi & 0x7FFF) << 16;\n        lo += hi >> 15;\n        lo = (lo & 0x7FFFFFFF) + (lo >> 31);\n        seed = lo & 0xFFFFFFFF;\n\n        // consume lower 3 bytes of seed\n        for(var i = 0; i < 3; ++i) {\n          // throw in more pseudo random\n          next = seed >>> (i << 3);\n          next ^= Math.floor(Math.random() * 0x0100);\n          b.putByte(next & 0xFF);\n        }\n      }\n    }\n\n    return b.getBytes(needed);\n  }\n  // initialize seed file APIs\n  if(_crypto) {\n    // use nodejs async API\n    ctx.seedFile = function(needed, callback) {\n      _crypto.randomBytes(needed, function(err, bytes) {\n        if(err) {\n          return callback(err);\n        }\n        callback(null, bytes.toString());\n      });\n    };\n    // use nodejs sync API\n    ctx.seedFileSync = function(needed) {\n      return _crypto.randomBytes(needed).toString();\n    };\n  } else {\n    ctx.seedFile = function(needed, callback) {\n      try {\n        callback(null, defaultSeedFile(needed));\n      } catch(e) {\n        callback(e);\n      }\n    };\n    ctx.seedFileSync = defaultSeedFile;\n  }\n\n  /**\n   * Adds entropy to a prng ctx's accumulator.\n   *\n   * @param bytes the bytes of entropy as a string.\n   */\n  ctx.collect = function(bytes) {\n    // iterate over pools distributing entropy cyclically\n    var count = bytes.length;\n    for(var i = 0; i < count; ++i) {\n      ctx.pools[ctx.pool].update(bytes.substr(i, 1));\n      ctx.pool = (ctx.pool === 31) ? 0 : ctx.pool + 1;\n    }\n  };\n\n  /**\n   * Collects an integer of n bits.\n   *\n   * @param i the integer entropy.\n   * @param n the number of bits in the integer.\n   */\n  ctx.collectInt = function(i, n) {\n    var bytes = '';\n    for(var x = 0; x < n; x += 8) {\n      bytes += String.fromCharCode((i >> x) & 0xFF);\n    }\n    ctx.collect(bytes);\n  };\n\n  /**\n   * Registers a Web Worker to receive immediate entropy from the main thread.\n   * This method is required until Web Workers can access the native crypto\n   * API. This method should be called twice for each created worker, once in\n   * the main thread, and once in the worker itself.\n   *\n   * @param worker the worker to register.\n   */\n  ctx.registerWorker = function(worker) {\n    // worker receives random bytes\n    if(worker === self) {\n      ctx.seedFile = function(needed, callback) {\n        function listener(e) {\n          var data = e.data;\n          if(data.forge && data.forge.prng) {\n            self.removeEventListener('message', listener);\n            callback(data.forge.prng.err, data.forge.prng.bytes);\n          }\n        }\n        self.addEventListener('message', listener);\n        self.postMessage({forge: {prng: {needed: needed}}});\n      };\n    } else {\n      // main thread sends random bytes upon request\n      var listener = function(e) {\n        var data = e.data;\n        if(data.forge && data.forge.prng) {\n          ctx.seedFile(data.forge.prng.needed, function(err, bytes) {\n            worker.postMessage({forge: {prng: {err: err, bytes: bytes}}});\n          });\n        }\n      };\n      // TODO: do we need to remove the event listener when the worker dies?\n      worker.addEventListener('message', listener);\n    }\n  };\n\n  return ctx;\n};\n","/**\n * Javascript implementation of PKCS#1 PSS signature padding.\n *\n * @author Stefan Siegl\n *\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n */\nvar forge = require('./forge');\nrequire('./random');\nrequire('./util');\n\n// shortcut for PSS API\nvar pss = module.exports = forge.pss = forge.pss || {};\n\n/**\n * Creates a PSS signature scheme object.\n *\n * There are several ways to provide a salt for encoding:\n *\n * 1. Specify the saltLength only and the built-in PRNG will generate it.\n * 2. Specify the saltLength and a custom PRNG with 'getBytesSync' defined that\n *   will be used.\n * 3. Specify the salt itself as a forge.util.ByteBuffer.\n *\n * @param options the options to use:\n *          md the message digest object to use, a forge md instance.\n *          mgf the mask generation function to use, a forge mgf instance.\n *          [saltLength] the length of the salt in octets.\n *          [prng] the pseudo-random number generator to use to produce a salt.\n *          [salt] the salt to use when encoding.\n *\n * @return a signature scheme object.\n */\npss.create = function(options) {\n  // backwards compatibility w/legacy args: hash, mgf, sLen\n  if(arguments.length === 3) {\n    options = {\n      md: arguments[0],\n      mgf: arguments[1],\n      saltLength: arguments[2]\n    };\n  }\n\n  var hash = options.md;\n  var mgf = options.mgf;\n  var hLen = hash.digestLength;\n\n  var salt_ = options.salt || null;\n  if(typeof salt_ === 'string') {\n    // assume binary-encoded string\n    salt_ = forge.util.createBuffer(salt_);\n  }\n\n  var sLen;\n  if('saltLength' in options) {\n    sLen = options.saltLength;\n  } else if(salt_ !== null) {\n    sLen = salt_.length();\n  } else {\n    throw new Error('Salt length not specified or specific salt not given.');\n  }\n\n  if(salt_ !== null && salt_.length() !== sLen) {\n    throw new Error('Given salt length does not match length of given salt.');\n  }\n\n  var prng = options.prng || forge.random;\n\n  var pssobj = {};\n\n  /**\n   * Encodes a PSS signature.\n   *\n   * This function implements EMSA-PSS-ENCODE as per RFC 3447, section 9.1.1.\n   *\n   * @param md the message digest object with the hash to sign.\n   * @param modsBits the length of the RSA modulus in bits.\n   *\n   * @return the encoded message as a binary-encoded string of length\n   *           ceil((modBits - 1) / 8).\n   */\n  pssobj.encode = function(md, modBits) {\n    var i;\n    var emBits = modBits - 1;\n    var emLen = Math.ceil(emBits / 8);\n\n    /* 2. Let mHash = Hash(M), an octet string of length hLen. */\n    var mHash = md.digest().getBytes();\n\n    /* 3. If emLen < hLen + sLen + 2, output \"encoding error\" and stop. */\n    if(emLen < hLen + sLen + 2) {\n      throw new Error('Message is too long to encrypt.');\n    }\n\n    /* 4. Generate a random octet string salt of length sLen; if sLen = 0,\n     *    then salt is the empty string. */\n    var salt;\n    if(salt_ === null) {\n      salt = prng.getBytesSync(sLen);\n    } else {\n      salt = salt_.bytes();\n    }\n\n    /* 5. Let M' = (0x)00 00 00 00 00 00 00 00 || mHash || salt; */\n    var m_ = new forge.util.ByteBuffer();\n    m_.fillWithByte(0, 8);\n    m_.putBytes(mHash);\n    m_.putBytes(salt);\n\n    /* 6. Let H = Hash(M'), an octet string of length hLen. */\n    hash.start();\n    hash.update(m_.getBytes());\n    var h = hash.digest().getBytes();\n\n    /* 7. Generate an octet string PS consisting of emLen - sLen - hLen - 2\n     *    zero octets.  The length of PS may be 0. */\n    var ps = new forge.util.ByteBuffer();\n    ps.fillWithByte(0, emLen - sLen - hLen - 2);\n\n    /* 8. Let DB = PS || 0x01 || salt; DB is an octet string of length\n     *    emLen - hLen - 1. */\n    ps.putByte(0x01);\n    ps.putBytes(salt);\n    var db = ps.getBytes();\n\n    /* 9. Let dbMask = MGF(H, emLen - hLen - 1). */\n    var maskLen = emLen - hLen - 1;\n    var dbMask = mgf.generate(h, maskLen);\n\n    /* 10. Let maskedDB = DB \\xor dbMask. */\n    var maskedDB = '';\n    for(i = 0; i < maskLen; i++) {\n      maskedDB += String.fromCharCode(db.charCodeAt(i) ^ dbMask.charCodeAt(i));\n    }\n\n    /* 11. Set the leftmost 8emLen - emBits bits of the leftmost octet in\n     *     maskedDB to zero. */\n    var mask = (0xFF00 >> (8 * emLen - emBits)) & 0xFF;\n    maskedDB = String.fromCharCode(maskedDB.charCodeAt(0) & ~mask) +\n      maskedDB.substr(1);\n\n    /* 12. Let EM = maskedDB || H || 0xbc.\n     * 13. Output EM. */\n    return maskedDB + h + String.fromCharCode(0xbc);\n  };\n\n  /**\n   * Verifies a PSS signature.\n   *\n   * This function implements EMSA-PSS-VERIFY as per RFC 3447, section 9.1.2.\n   *\n   * @param mHash the message digest hash, as a binary-encoded string, to\n   *         compare against the signature.\n   * @param em the encoded message, as a binary-encoded string\n   *          (RSA decryption result).\n   * @param modsBits the length of the RSA modulus in bits.\n   *\n   * @return true if the signature was verified, false if not.\n   */\n  pssobj.verify = function(mHash, em, modBits) {\n    var i;\n    var emBits = modBits - 1;\n    var emLen = Math.ceil(emBits / 8);\n\n    /* c. Convert the message representative m to an encoded message EM\n     *    of length emLen = ceil((modBits - 1) / 8) octets, where modBits\n     *    is the length in bits of the RSA modulus n */\n    em = em.substr(-emLen);\n\n    /* 3. If emLen < hLen + sLen + 2, output \"inconsistent\" and stop. */\n    if(emLen < hLen + sLen + 2) {\n      throw new Error('Inconsistent parameters to PSS signature verification.');\n    }\n\n    /* 4. If the rightmost octet of EM does not have hexadecimal value\n     *    0xbc, output \"inconsistent\" and stop. */\n    if(em.charCodeAt(emLen - 1) !== 0xbc) {\n      throw new Error('Encoded message does not end in 0xBC.');\n    }\n\n    /* 5. Let maskedDB be the leftmost emLen - hLen - 1 octets of EM, and\n     *    let H be the next hLen octets. */\n    var maskLen = emLen - hLen - 1;\n    var maskedDB = em.substr(0, maskLen);\n    var h = em.substr(maskLen, hLen);\n\n    /* 6. If the leftmost 8emLen - emBits bits of the leftmost octet in\n     *    maskedDB are not all equal to zero, output \"inconsistent\" and stop. */\n    var mask = (0xFF00 >> (8 * emLen - emBits)) & 0xFF;\n    if((maskedDB.charCodeAt(0) & mask) !== 0) {\n      throw new Error('Bits beyond keysize not zero as expected.');\n    }\n\n    /* 7. Let dbMask = MGF(H, emLen - hLen - 1). */\n    var dbMask = mgf.generate(h, maskLen);\n\n    /* 8. Let DB = maskedDB \\xor dbMask. */\n    var db = '';\n    for(i = 0; i < maskLen; i++) {\n      db += String.fromCharCode(maskedDB.charCodeAt(i) ^ dbMask.charCodeAt(i));\n    }\n\n    /* 9. Set the leftmost 8emLen - emBits bits of the leftmost octet\n     * in DB to zero. */\n    db = String.fromCharCode(db.charCodeAt(0) & ~mask) + db.substr(1);\n\n    /* 10. If the emLen - hLen - sLen - 2 leftmost octets of DB are not zero\n     * or if the octet at position emLen - hLen - sLen - 1 (the leftmost\n     * position is \"position 1\") does not have hexadecimal value 0x01,\n     * output \"inconsistent\" and stop. */\n    var checkLen = emLen - hLen - sLen - 2;\n    for(i = 0; i < checkLen; i++) {\n      if(db.charCodeAt(i) !== 0x00) {\n        throw new Error('Leftmost octets not zero as expected');\n      }\n    }\n\n    if(db.charCodeAt(checkLen) !== 0x01) {\n      throw new Error('Inconsistent PSS signature, 0x01 marker not found');\n    }\n\n    /* 11. Let salt be the last sLen octets of DB. */\n    var salt = db.substr(-sLen);\n\n    /* 12.  Let M' = (0x)00 00 00 00 00 00 00 00 || mHash || salt */\n    var m_ = new forge.util.ByteBuffer();\n    m_.fillWithByte(0, 8);\n    m_.putBytes(mHash);\n    m_.putBytes(salt);\n\n    /* 13. Let H' = Hash(M'), an octet string of length hLen. */\n    hash.start();\n    hash.update(m_.getBytes());\n    var h_ = hash.digest().getBytes();\n\n    /* 14. If H = H', output \"consistent.\" Otherwise, output \"inconsistent.\" */\n    return h === h_;\n  };\n\n  return pssobj;\n};\n","/**\n * An API for getting cryptographically-secure random bytes. The bytes are\n * generated using the Fortuna algorithm devised by Bruce Schneier and\n * Niels Ferguson.\n *\n * Getting strong random bytes is not yet easy to do in javascript. The only\n * truish random entropy that can be collected is from the mouse, keyboard, or\n * from timing with respect to page loads, etc. This generator makes a poor\n * attempt at providing random bytes when those sources haven't yet provided\n * enough entropy to initially seed or to reseed the PRNG.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2009-2014 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./aes');\nrequire('./sha256');\nrequire('./prng');\nrequire('./util');\n\n(function() {\n\n// forge.random already defined\nif(forge.random && forge.random.getBytes) {\n  module.exports = forge.random;\n  return;\n}\n\n(function(jQuery) {\n\n// the default prng plugin, uses AES-128\nvar prng_aes = {};\nvar _prng_aes_output = new Array(4);\nvar _prng_aes_buffer = forge.util.createBuffer();\nprng_aes.formatKey = function(key) {\n  // convert the key into 32-bit integers\n  var tmp = forge.util.createBuffer(key);\n  key = new Array(4);\n  key[0] = tmp.getInt32();\n  key[1] = tmp.getInt32();\n  key[2] = tmp.getInt32();\n  key[3] = tmp.getInt32();\n\n  // return the expanded key\n  return forge.aes._expandKey(key, false);\n};\nprng_aes.formatSeed = function(seed) {\n  // convert seed into 32-bit integers\n  var tmp = forge.util.createBuffer(seed);\n  seed = new Array(4);\n  seed[0] = tmp.getInt32();\n  seed[1] = tmp.getInt32();\n  seed[2] = tmp.getInt32();\n  seed[3] = tmp.getInt32();\n  return seed;\n};\nprng_aes.cipher = function(key, seed) {\n  forge.aes._updateBlock(key, seed, _prng_aes_output, false);\n  _prng_aes_buffer.putInt32(_prng_aes_output[0]);\n  _prng_aes_buffer.putInt32(_prng_aes_output[1]);\n  _prng_aes_buffer.putInt32(_prng_aes_output[2]);\n  _prng_aes_buffer.putInt32(_prng_aes_output[3]);\n  return _prng_aes_buffer.getBytes();\n};\nprng_aes.increment = function(seed) {\n  // FIXME: do we care about carry or signed issues?\n  ++seed[3];\n  return seed;\n};\nprng_aes.md = forge.md.sha256;\n\n/**\n * Creates a new PRNG.\n */\nfunction spawnPrng() {\n  var ctx = forge.prng.create(prng_aes);\n\n  /**\n   * Gets random bytes. If a native secure crypto API is unavailable, this\n   * method tries to make the bytes more unpredictable by drawing from data that\n   * can be collected from the user of the browser, eg: mouse movement.\n   *\n   * If a callback is given, this method will be called asynchronously.\n   *\n   * @param count the number of random bytes to get.\n   * @param [callback(err, bytes)] called once the operation completes.\n   *\n   * @return the random bytes in a string.\n   */\n  ctx.getBytes = function(count, callback) {\n    return ctx.generate(count, callback);\n  };\n\n  /**\n   * Gets random bytes asynchronously. If a native secure crypto API is\n   * unavailable, this method tries to make the bytes more unpredictable by\n   * drawing from data that can be collected from the user of the browser,\n   * eg: mouse movement.\n   *\n   * @param count the number of random bytes to get.\n   *\n   * @return the random bytes in a string.\n   */\n  ctx.getBytesSync = function(count) {\n    return ctx.generate(count);\n  };\n\n  return ctx;\n}\n\n// create default prng context\nvar _ctx = spawnPrng();\n\n// add other sources of entropy only if window.crypto.getRandomValues is not\n// available -- otherwise this source will be automatically used by the prng\nvar getRandomValues = null;\nvar globalScope = forge.util.globalScope;\nvar _crypto = globalScope.crypto || globalScope.msCrypto;\nif(_crypto && _crypto.getRandomValues) {\n  getRandomValues = function(arr) {\n    return _crypto.getRandomValues(arr);\n  };\n}\n\nif(forge.options.usePureJavaScript ||\n  (!forge.util.isNodejs && !getRandomValues)) {\n  // if this is a web worker, do not use weak entropy, instead register to\n  // receive strong entropy asynchronously from the main thread\n  if(typeof window === 'undefined' || window.document === undefined) {\n    // FIXME:\n  }\n\n  // get load time entropy\n  _ctx.collectInt(+new Date(), 32);\n\n  // add some entropy from navigator object\n  if(typeof(navigator) !== 'undefined') {\n    var _navBytes = '';\n    for(var key in navigator) {\n      try {\n        if(typeof(navigator[key]) == 'string') {\n          _navBytes += navigator[key];\n        }\n      } catch(e) {\n        /* Some navigator keys might not be accessible, e.g. the geolocation\n          attribute throws an exception if touched in Mozilla chrome://\n          context.\n\n          Silently ignore this and just don't use this as a source of\n          entropy. */\n      }\n    }\n    _ctx.collect(_navBytes);\n    _navBytes = null;\n  }\n\n  // add mouse and keyboard collectors if jquery is available\n  if(jQuery) {\n    // set up mouse entropy capture\n    jQuery().mousemove(function(e) {\n      // add mouse coords\n      _ctx.collectInt(e.clientX, 16);\n      _ctx.collectInt(e.clientY, 16);\n    });\n\n    // set up keyboard entropy capture\n    jQuery().keypress(function(e) {\n      _ctx.collectInt(e.charCode, 8);\n    });\n  }\n}\n\n/* Random API */\nif(!forge.random) {\n  forge.random = _ctx;\n} else {\n  // extend forge.random with _ctx\n  for(var key in _ctx) {\n    forge.random[key] = _ctx[key];\n  }\n}\n\n// expose spawn PRNG\nforge.random.createInstance = spawnPrng;\n\nmodule.exports = forge.random;\n\n})(typeof(jQuery) !== 'undefined' ? jQuery : null);\n\n})();\n","/**\n * RC2 implementation.\n *\n * @author Stefan Siegl\n *\n * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>\n *\n * Information on the RC2 cipher is available from RFC #2268,\n * http://www.ietf.org/rfc/rfc2268.txt\n */\nvar forge = require('./forge');\nrequire('./util');\n\nvar piTable = [\n  0xd9, 0x78, 0xf9, 0xc4, 0x19, 0xdd, 0xb5, 0xed, 0x28, 0xe9, 0xfd, 0x79, 0x4a, 0xa0, 0xd8, 0x9d,\n  0xc6, 0x7e, 0x37, 0x83, 0x2b, 0x76, 0x53, 0x8e, 0x62, 0x4c, 0x64, 0x88, 0x44, 0x8b, 0xfb, 0xa2,\n  0x17, 0x9a, 0x59, 0xf5, 0x87, 0xb3, 0x4f, 0x13, 0x61, 0x45, 0x6d, 0x8d, 0x09, 0x81, 0x7d, 0x32,\n  0xbd, 0x8f, 0x40, 0xeb, 0x86, 0xb7, 0x7b, 0x0b, 0xf0, 0x95, 0x21, 0x22, 0x5c, 0x6b, 0x4e, 0x82,\n  0x54, 0xd6, 0x65, 0x93, 0xce, 0x60, 0xb2, 0x1c, 0x73, 0x56, 0xc0, 0x14, 0xa7, 0x8c, 0xf1, 0xdc,\n  0x12, 0x75, 0xca, 0x1f, 0x3b, 0xbe, 0xe4, 0xd1, 0x42, 0x3d, 0xd4, 0x30, 0xa3, 0x3c, 0xb6, 0x26,\n  0x6f, 0xbf, 0x0e, 0xda, 0x46, 0x69, 0x07, 0x57, 0x27, 0xf2, 0x1d, 0x9b, 0xbc, 0x94, 0x43, 0x03,\n  0xf8, 0x11, 0xc7, 0xf6, 0x90, 0xef, 0x3e, 0xe7, 0x06, 0xc3, 0xd5, 0x2f, 0xc8, 0x66, 0x1e, 0xd7,\n  0x08, 0xe8, 0xea, 0xde, 0x80, 0x52, 0xee, 0xf7, 0x84, 0xaa, 0x72, 0xac, 0x35, 0x4d, 0x6a, 0x2a,\n  0x96, 0x1a, 0xd2, 0x71, 0x5a, 0x15, 0x49, 0x74, 0x4b, 0x9f, 0xd0, 0x5e, 0x04, 0x18, 0xa4, 0xec,\n  0xc2, 0xe0, 0x41, 0x6e, 0x0f, 0x51, 0xcb, 0xcc, 0x24, 0x91, 0xaf, 0x50, 0xa1, 0xf4, 0x70, 0x39,\n  0x99, 0x7c, 0x3a, 0x85, 0x23, 0xb8, 0xb4, 0x7a, 0xfc, 0x02, 0x36, 0x5b, 0x25, 0x55, 0x97, 0x31,\n  0x2d, 0x5d, 0xfa, 0x98, 0xe3, 0x8a, 0x92, 0xae, 0x05, 0xdf, 0x29, 0x10, 0x67, 0x6c, 0xba, 0xc9,\n  0xd3, 0x00, 0xe6, 0xcf, 0xe1, 0x9e, 0xa8, 0x2c, 0x63, 0x16, 0x01, 0x3f, 0x58, 0xe2, 0x89, 0xa9,\n  0x0d, 0x38, 0x34, 0x1b, 0xab, 0x33, 0xff, 0xb0, 0xbb, 0x48, 0x0c, 0x5f, 0xb9, 0xb1, 0xcd, 0x2e,\n  0xc5, 0xf3, 0xdb, 0x47, 0xe5, 0xa5, 0x9c, 0x77, 0x0a, 0xa6, 0x20, 0x68, 0xfe, 0x7f, 0xc1, 0xad\n];\n\nvar s = [1, 2, 3, 5];\n\n/**\n * Rotate a word left by given number of bits.\n *\n * Bits that are shifted out on the left are put back in on the right\n * hand side.\n *\n * @param word The word to shift left.\n * @param bits The number of bits to shift by.\n * @return The rotated word.\n */\nvar rol = function(word, bits) {\n  return ((word << bits) & 0xffff) | ((word & 0xffff) >> (16 - bits));\n};\n\n/**\n * Rotate a word right by given number of bits.\n *\n * Bits that are shifted out on the right are put back in on the left\n * hand side.\n *\n * @param word The word to shift right.\n * @param bits The number of bits to shift by.\n * @return The rotated word.\n */\nvar ror = function(word, bits) {\n  return ((word & 0xffff) >> bits) | ((word << (16 - bits)) & 0xffff);\n};\n\n/* RC2 API */\nmodule.exports = forge.rc2 = forge.rc2 || {};\n\n/**\n * Perform RC2 key expansion as per RFC #2268, section 2.\n *\n * @param key variable-length user key (between 1 and 128 bytes)\n * @param effKeyBits number of effective key bits (default: 128)\n * @return the expanded RC2 key (ByteBuffer of 128 bytes)\n */\nforge.rc2.expandKey = function(key, effKeyBits) {\n  if(typeof key === 'string') {\n    key = forge.util.createBuffer(key);\n  }\n  effKeyBits = effKeyBits || 128;\n\n  /* introduce variables that match the names used in RFC #2268 */\n  var L = key;\n  var T = key.length();\n  var T1 = effKeyBits;\n  var T8 = Math.ceil(T1 / 8);\n  var TM = 0xff >> (T1 & 0x07);\n  var i;\n\n  for(i = T; i < 128; i++) {\n    L.putByte(piTable[(L.at(i - 1) + L.at(i - T)) & 0xff]);\n  }\n\n  L.setAt(128 - T8, piTable[L.at(128 - T8) & TM]);\n\n  for(i = 127 - T8; i >= 0; i--) {\n    L.setAt(i, piTable[L.at(i + 1) ^ L.at(i + T8)]);\n  }\n\n  return L;\n};\n\n/**\n * Creates a RC2 cipher object.\n *\n * @param key the symmetric key to use (as base for key generation).\n * @param bits the number of effective key bits.\n * @param encrypt false for decryption, true for encryption.\n *\n * @return the cipher.\n */\nvar createCipher = function(key, bits, encrypt) {\n  var _finish = false, _input = null, _output = null, _iv = null;\n  var mixRound, mashRound;\n  var i, j, K = [];\n\n  /* Expand key and fill into K[] Array */\n  key = forge.rc2.expandKey(key, bits);\n  for(i = 0; i < 64; i++) {\n    K.push(key.getInt16Le());\n  }\n\n  if(encrypt) {\n    /**\n     * Perform one mixing round \"in place\".\n     *\n     * @param R Array of four words to perform mixing on.\n     */\n    mixRound = function(R) {\n      for(i = 0; i < 4; i++) {\n        R[i] += K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +\n          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);\n        R[i] = rol(R[i], s[i]);\n        j++;\n      }\n    };\n\n    /**\n     * Perform one mashing round \"in place\".\n     *\n     * @param R Array of four words to perform mashing on.\n     */\n    mashRound = function(R) {\n      for(i = 0; i < 4; i++) {\n        R[i] += K[R[(i + 3) % 4] & 63];\n      }\n    };\n  } else {\n    /**\n     * Perform one r-mixing round \"in place\".\n     *\n     * @param R Array of four words to perform mixing on.\n     */\n    mixRound = function(R) {\n      for(i = 3; i >= 0; i--) {\n        R[i] = ror(R[i], s[i]);\n        R[i] -= K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +\n          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);\n        j--;\n      }\n    };\n\n    /**\n     * Perform one r-mashing round \"in place\".\n     *\n     * @param R Array of four words to perform mashing on.\n     */\n    mashRound = function(R) {\n      for(i = 3; i >= 0; i--) {\n        R[i] -= K[R[(i + 3) % 4] & 63];\n      }\n    };\n  }\n\n  /**\n   * Run the specified cipher execution plan.\n   *\n   * This function takes four words from the input buffer, applies the IV on\n   * it (if requested) and runs the provided execution plan.\n   *\n   * The plan must be put together in form of a array of arrays.  Where the\n   * outer one is simply a list of steps to perform and the inner one needs\n   * to have two elements: the first one telling how many rounds to perform,\n   * the second one telling what to do (i.e. the function to call).\n   *\n   * @param {Array} plan The plan to execute.\n   */\n  var runPlan = function(plan) {\n    var R = [];\n\n    /* Get data from input buffer and fill the four words into R */\n    for(i = 0; i < 4; i++) {\n      var val = _input.getInt16Le();\n\n      if(_iv !== null) {\n        if(encrypt) {\n          /* We're encrypting, apply the IV first. */\n          val ^= _iv.getInt16Le();\n        } else {\n          /* We're decryption, keep cipher text for next block. */\n          _iv.putInt16Le(val);\n        }\n      }\n\n      R.push(val & 0xffff);\n    }\n\n    /* Reset global \"j\" variable as per spec. */\n    j = encrypt ? 0 : 63;\n\n    /* Run execution plan. */\n    for(var ptr = 0; ptr < plan.length; ptr++) {\n      for(var ctr = 0; ctr < plan[ptr][0]; ctr++) {\n        plan[ptr][1](R);\n      }\n    }\n\n    /* Write back result to output buffer. */\n    for(i = 0; i < 4; i++) {\n      if(_iv !== null) {\n        if(encrypt) {\n          /* We're encrypting in CBC-mode, feed back encrypted bytes into\n             IV buffer to carry it forward to next block. */\n          _iv.putInt16Le(R[i]);\n        } else {\n          R[i] ^= _iv.getInt16Le();\n        }\n      }\n\n      _output.putInt16Le(R[i]);\n    }\n  };\n\n  /* Create cipher object */\n  var cipher = null;\n  cipher = {\n    /**\n     * Starts or restarts the encryption or decryption process, whichever\n     * was previously configured.\n     *\n     * To use the cipher in CBC mode, iv may be given either as a string\n     * of bytes, or as a byte buffer.  For ECB mode, give null as iv.\n     *\n     * @param iv the initialization vector to use, null for ECB mode.\n     * @param output the output the buffer to write to, null to create one.\n     */\n    start: function(iv, output) {\n      if(iv) {\n        /* CBC mode */\n        if(typeof iv === 'string') {\n          iv = forge.util.createBuffer(iv);\n        }\n      }\n\n      _finish = false;\n      _input = forge.util.createBuffer();\n      _output = output || new forge.util.createBuffer();\n      _iv = iv;\n\n      cipher.output = _output;\n    },\n\n    /**\n     * Updates the next block.\n     *\n     * @param input the buffer to read from.\n     */\n    update: function(input) {\n      if(!_finish) {\n        // not finishing, so fill the input buffer with more input\n        _input.putBuffer(input);\n      }\n\n      while(_input.length() >= 8) {\n        runPlan([\n            [ 5, mixRound ],\n            [ 1, mashRound ],\n            [ 6, mixRound ],\n            [ 1, mashRound ],\n            [ 5, mixRound ]\n          ]);\n      }\n    },\n\n    /**\n     * Finishes encrypting or decrypting.\n     *\n     * @param pad a padding function to use, null for PKCS#7 padding,\n     *           signature(blockSize, buffer, decrypt).\n     *\n     * @return true if successful, false on error.\n     */\n    finish: function(pad) {\n      var rval = true;\n\n      if(encrypt) {\n        if(pad) {\n          rval = pad(8, _input, !encrypt);\n        } else {\n          // add PKCS#7 padding to block (each pad byte is the\n          // value of the number of pad bytes)\n          var padding = (_input.length() === 8) ? 8 : (8 - _input.length());\n          _input.fillWithByte(padding, padding);\n        }\n      }\n\n      if(rval) {\n        // do final update\n        _finish = true;\n        cipher.update();\n      }\n\n      if(!encrypt) {\n        // check for error: input data not a multiple of block size\n        rval = (_input.length() === 0);\n        if(rval) {\n          if(pad) {\n            rval = pad(8, _output, !encrypt);\n          } else {\n            // ensure padding byte count is valid\n            var len = _output.length();\n            var count = _output.at(len - 1);\n\n            if(count > len) {\n              rval = false;\n            } else {\n              // trim off padding bytes\n              _output.truncate(count);\n            }\n          }\n        }\n      }\n\n      return rval;\n    }\n  };\n\n  return cipher;\n};\n\n/**\n * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the\n * given symmetric key. The output will be stored in the 'output' member\n * of the returned cipher.\n *\n * The key and iv may be given as a string of bytes or a byte buffer.\n * The cipher is initialized to use 128 effective key bits.\n *\n * @param key the symmetric key to use.\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n *\n * @return the cipher.\n */\nforge.rc2.startEncrypting = function(key, iv, output) {\n  var cipher = forge.rc2.createEncryptionCipher(key, 128);\n  cipher.start(iv, output);\n  return cipher;\n};\n\n/**\n * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the\n * given symmetric key.\n *\n * The key may be given as a string of bytes or a byte buffer.\n *\n * To start encrypting call start() on the cipher with an iv and optional\n * output buffer.\n *\n * @param key the symmetric key to use.\n *\n * @return the cipher.\n */\nforge.rc2.createEncryptionCipher = function(key, bits) {\n  return createCipher(key, bits, true);\n};\n\n/**\n * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the\n * given symmetric key. The output will be stored in the 'output' member\n * of the returned cipher.\n *\n * The key and iv may be given as a string of bytes or a byte buffer.\n * The cipher is initialized to use 128 effective key bits.\n *\n * @param key the symmetric key to use.\n * @param iv the initialization vector to use.\n * @param output the buffer to write to, null to create one.\n *\n * @return the cipher.\n */\nforge.rc2.startDecrypting = function(key, iv, output) {\n  var cipher = forge.rc2.createDecryptionCipher(key, 128);\n  cipher.start(iv, output);\n  return cipher;\n};\n\n/**\n * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the\n * given symmetric key.\n *\n * The key may be given as a string of bytes or a byte buffer.\n *\n * To start decrypting call start() on the cipher with an iv and optional\n * output buffer.\n *\n * @param key the symmetric key to use.\n *\n * @return the cipher.\n */\nforge.rc2.createDecryptionCipher = function(key, bits) {\n  return createCipher(key, bits, false);\n};\n","/**\n * Javascript implementation of basic RSA algorithms.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n *\n * The only algorithm currently supported for PKI is RSA.\n *\n * An RSA key is often stored in ASN.1 DER format. The SubjectPublicKeyInfo\n * ASN.1 structure is composed of an algorithm of type AlgorithmIdentifier\n * and a subjectPublicKey of type bit string.\n *\n * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters\n * for the algorithm, if any. In the case of RSA, there aren't any.\n *\n * SubjectPublicKeyInfo ::= SEQUENCE {\n *   algorithm AlgorithmIdentifier,\n *   subjectPublicKey BIT STRING\n * }\n *\n * AlgorithmIdentifer ::= SEQUENCE {\n *   algorithm OBJECT IDENTIFIER,\n *   parameters ANY DEFINED BY algorithm OPTIONAL\n * }\n *\n * For an RSA public key, the subjectPublicKey is:\n *\n * RSAPublicKey ::= SEQUENCE {\n *   modulus            INTEGER,    -- n\n *   publicExponent     INTEGER     -- e\n * }\n *\n * PrivateKeyInfo ::= SEQUENCE {\n *   version                   Version,\n *   privateKeyAlgorithm       PrivateKeyAlgorithmIdentifier,\n *   privateKey                PrivateKey,\n *   attributes           [0]  IMPLICIT Attributes OPTIONAL\n * }\n *\n * Version ::= INTEGER\n * PrivateKeyAlgorithmIdentifier ::= AlgorithmIdentifier\n * PrivateKey ::= OCTET STRING\n * Attributes ::= SET OF Attribute\n *\n * An RSA private key as the following structure:\n *\n * RSAPrivateKey ::= SEQUENCE {\n *   version Version,\n *   modulus INTEGER, -- n\n *   publicExponent INTEGER, -- e\n *   privateExponent INTEGER, -- d\n *   prime1 INTEGER, -- p\n *   prime2 INTEGER, -- q\n *   exponent1 INTEGER, -- d mod (p-1)\n *   exponent2 INTEGER, -- d mod (q-1)\n *   coefficient INTEGER -- (inverse of q) mod p\n * }\n *\n * Version ::= INTEGER\n *\n * The OID for the RSA key algorithm is: 1.2.840.113549.1.1.1\n */\nvar forge = require('./forge');\nrequire('./asn1');\nrequire('./jsbn');\nrequire('./oids');\nrequire('./pkcs1');\nrequire('./prime');\nrequire('./random');\nrequire('./util');\n\nif(typeof BigInteger === 'undefined') {\n  var BigInteger = forge.jsbn.BigInteger;\n}\n\nvar _crypto = forge.util.isNodejs ? require('crypto') : null;\n\n// shortcut for asn.1 API\nvar asn1 = forge.asn1;\n\n// shortcut for util API\nvar util = forge.util;\n\n/*\n * RSA encryption and decryption, see RFC 2313.\n */\nforge.pki = forge.pki || {};\nmodule.exports = forge.pki.rsa = forge.rsa = forge.rsa || {};\nvar pki = forge.pki;\n\n// for finding primes, which are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29\nvar GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];\n\n// validator for a PrivateKeyInfo structure\nvar privateKeyValidator = {\n  // PrivateKeyInfo\n  name: 'PrivateKeyInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    // Version (INTEGER)\n    name: 'PrivateKeyInfo.version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyVersion'\n  }, {\n    // privateKeyAlgorithm\n    name: 'PrivateKeyInfo.privateKeyAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'AlgorithmIdentifier.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'privateKeyOid'\n    }]\n  }, {\n    // PrivateKey\n    name: 'PrivateKeyInfo',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'privateKey'\n  }]\n};\n\n// validator for an RSA private key\nvar rsaPrivateKeyValidator = {\n  // RSAPrivateKey\n  name: 'RSAPrivateKey',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    // Version (INTEGER)\n    name: 'RSAPrivateKey.version',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyVersion'\n  }, {\n    // modulus (n)\n    name: 'RSAPrivateKey.modulus',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyModulus'\n  }, {\n    // publicExponent (e)\n    name: 'RSAPrivateKey.publicExponent',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyPublicExponent'\n  }, {\n    // privateExponent (d)\n    name: 'RSAPrivateKey.privateExponent',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyPrivateExponent'\n  }, {\n    // prime1 (p)\n    name: 'RSAPrivateKey.prime1',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyPrime1'\n  }, {\n    // prime2 (q)\n    name: 'RSAPrivateKey.prime2',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyPrime2'\n  }, {\n    // exponent1 (d mod (p-1))\n    name: 'RSAPrivateKey.exponent1',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyExponent1'\n  }, {\n    // exponent2 (d mod (q-1))\n    name: 'RSAPrivateKey.exponent2',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyExponent2'\n  }, {\n    // coefficient ((inverse of q) mod p)\n    name: 'RSAPrivateKey.coefficient',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'privateKeyCoefficient'\n  }]\n};\n\n// validator for an RSA public key\nvar rsaPublicKeyValidator = {\n  // RSAPublicKey\n  name: 'RSAPublicKey',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    // modulus (n)\n    name: 'RSAPublicKey.modulus',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'publicKeyModulus'\n  }, {\n    // publicExponent (e)\n    name: 'RSAPublicKey.exponent',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'publicKeyExponent'\n  }]\n};\n\n// validator for an SubjectPublicKeyInfo structure\n// Note: Currently only works with an RSA public key\nvar publicKeyValidator = forge.pki.rsa.publicKeyValidator = {\n  name: 'SubjectPublicKeyInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  captureAsn1: 'subjectPublicKeyInfo',\n  value: [{\n    name: 'SubjectPublicKeyInfo.AlgorithmIdentifier',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'AlgorithmIdentifier.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'publicKeyOid'\n    }]\n  }, {\n    // subjectPublicKey\n    name: 'SubjectPublicKeyInfo.subjectPublicKey',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.BITSTRING,\n    constructed: false,\n    value: [{\n      // RSAPublicKey\n      name: 'SubjectPublicKeyInfo.subjectPublicKey.RSAPublicKey',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      optional: true,\n      captureAsn1: 'rsaPublicKey'\n    }]\n  }]\n};\n\n// validator for a DigestInfo structure\nvar digestInfoValidator = {\n  name: 'DigestInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'DigestInfo.DigestAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      name: 'DigestInfo.DigestAlgorithm.algorithmIdentifier',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'algorithmIdentifier'\n    }, {\n      // NULL paramters\n      name: 'DigestInfo.DigestAlgorithm.parameters',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.NULL,\n      // captured only to check existence for md2 and md5\n      capture: 'parameters',\n      optional: true,\n      constructed: false\n    }]\n  }, {\n    // digest\n    name: 'DigestInfo.digest',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.OCTETSTRING,\n    constructed: false,\n    capture: 'digest'\n  }]\n};\n\n/**\n * Wrap digest in DigestInfo object.\n *\n * This function implements EMSA-PKCS1-v1_5-ENCODE as per RFC 3447.\n *\n * DigestInfo ::= SEQUENCE {\n *   digestAlgorithm DigestAlgorithmIdentifier,\n *   digest Digest\n * }\n *\n * DigestAlgorithmIdentifier ::= AlgorithmIdentifier\n * Digest ::= OCTET STRING\n *\n * @param md the message digest object with the hash to sign.\n *\n * @return the encoded message (ready for RSA encrytion)\n */\nvar emsaPkcs1v15encode = function(md) {\n  // get the oid for the algorithm\n  var oid;\n  if(md.algorithm in pki.oids) {\n    oid = pki.oids[md.algorithm];\n  } else {\n    var error = new Error('Unknown message digest algorithm.');\n    error.algorithm = md.algorithm;\n    throw error;\n  }\n  var oidBytes = asn1.oidToDer(oid).getBytes();\n\n  // create the digest info\n  var digestInfo = asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n  var digestAlgorithm = asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n  digestAlgorithm.value.push(asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.OID, false, oidBytes));\n  digestAlgorithm.value.push(asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.NULL, false, ''));\n  var digest = asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING,\n    false, md.digest().getBytes());\n  digestInfo.value.push(digestAlgorithm);\n  digestInfo.value.push(digest);\n\n  // encode digest info\n  return asn1.toDer(digestInfo).getBytes();\n};\n\n/**\n * Performs x^c mod n (RSA encryption or decryption operation).\n *\n * @param x the number to raise and mod.\n * @param key the key to use.\n * @param pub true if the key is public, false if private.\n *\n * @return the result of x^c mod n.\n */\nvar _modPow = function(x, key, pub) {\n  if(pub) {\n    return x.modPow(key.e, key.n);\n  }\n\n  if(!key.p || !key.q) {\n    // allow calculation without CRT params (slow)\n    return x.modPow(key.d, key.n);\n  }\n\n  // pre-compute dP, dQ, and qInv if necessary\n  if(!key.dP) {\n    key.dP = key.d.mod(key.p.subtract(BigInteger.ONE));\n  }\n  if(!key.dQ) {\n    key.dQ = key.d.mod(key.q.subtract(BigInteger.ONE));\n  }\n  if(!key.qInv) {\n    key.qInv = key.q.modInverse(key.p);\n  }\n\n  /* Chinese remainder theorem (CRT) states:\n\n    Suppose n1, n2, ..., nk are positive integers which are pairwise\n    coprime (n1 and n2 have no common factors other than 1). For any\n    integers x1, x2, ..., xk there exists an integer x solving the\n    system of simultaneous congruences (where ~= means modularly\n    congruent so a ~= b mod n means a mod n = b mod n):\n\n    x ~= x1 mod n1\n    x ~= x2 mod n2\n    ...\n    x ~= xk mod nk\n\n    This system of congruences has a single simultaneous solution x\n    between 0 and n - 1. Furthermore, each xk solution and x itself\n    is congruent modulo the product n = n1*n2*...*nk.\n    So x1 mod n = x2 mod n = xk mod n = x mod n.\n\n    The single simultaneous solution x can be solved with the following\n    equation:\n\n    x = sum(xi*ri*si) mod n where ri = n/ni and si = ri^-1 mod ni.\n\n    Where x is less than n, xi = x mod ni.\n\n    For RSA we are only concerned with k = 2. The modulus n = pq, where\n    p and q are coprime. The RSA decryption algorithm is:\n\n    y = x^d mod n\n\n    Given the above:\n\n    x1 = x^d mod p\n    r1 = n/p = q\n    s1 = q^-1 mod p\n    x2 = x^d mod q\n    r2 = n/q = p\n    s2 = p^-1 mod q\n\n    So y = (x1r1s1 + x2r2s2) mod n\n         = ((x^d mod p)q(q^-1 mod p) + (x^d mod q)p(p^-1 mod q)) mod n\n\n    According to Fermat's Little Theorem, if the modulus P is prime,\n    for any integer A not evenly divisible by P, A^(P-1) ~= 1 mod P.\n    Since A is not divisible by P it follows that if:\n    N ~= M mod (P - 1), then A^N mod P = A^M mod P. Therefore:\n\n    A^N mod P = A^(M mod (P - 1)) mod P. (The latter takes less effort\n    to calculate). In order to calculate x^d mod p more quickly the\n    exponent d mod (p - 1) is stored in the RSA private key (the same\n    is done for x^d mod q). These values are referred to as dP and dQ\n    respectively. Therefore we now have:\n\n    y = ((x^dP mod p)q(q^-1 mod p) + (x^dQ mod q)p(p^-1 mod q)) mod n\n\n    Since we'll be reducing x^dP by modulo p (same for q) we can also\n    reduce x by p (and q respectively) before hand. Therefore, let\n\n    xp = ((x mod p)^dP mod p), and\n    xq = ((x mod q)^dQ mod q), yielding:\n\n    y = (xp*q*(q^-1 mod p) + xq*p*(p^-1 mod q)) mod n\n\n    This can be further reduced to a simple algorithm that only\n    requires 1 inverse (the q inverse is used) to be used and stored.\n    The algorithm is called Garner's algorithm. If qInv is the\n    inverse of q, we simply calculate:\n\n    y = (qInv*(xp - xq) mod p) * q + xq\n\n    However, there are two further complications. First, we need to\n    ensure that xp > xq to prevent signed BigIntegers from being used\n    so we add p until this is true (since we will be mod'ing with\n    p anyway). Then, there is a known timing attack on algorithms\n    using the CRT. To mitigate this risk, \"cryptographic blinding\"\n    should be used. This requires simply generating a random number r\n    between 0 and n-1 and its inverse and multiplying x by r^e before\n    calculating y and then multiplying y by r^-1 afterwards. Note that\n    r must be coprime with n (gcd(r, n) === 1) in order to have an\n    inverse.\n  */\n\n  // cryptographic blinding\n  var r;\n  do {\n    r = new BigInteger(\n      forge.util.bytesToHex(forge.random.getBytes(key.n.bitLength() / 8)),\n      16);\n  } while(r.compareTo(key.n) >= 0 || !r.gcd(key.n).equals(BigInteger.ONE));\n  x = x.multiply(r.modPow(key.e, key.n)).mod(key.n);\n\n  // calculate xp and xq\n  var xp = x.mod(key.p).modPow(key.dP, key.p);\n  var xq = x.mod(key.q).modPow(key.dQ, key.q);\n\n  // xp must be larger than xq to avoid signed bit usage\n  while(xp.compareTo(xq) < 0) {\n    xp = xp.add(key.p);\n  }\n\n  // do last step\n  var y = xp.subtract(xq)\n    .multiply(key.qInv).mod(key.p)\n    .multiply(key.q).add(xq);\n\n  // remove effect of random for cryptographic blinding\n  y = y.multiply(r.modInverse(key.n)).mod(key.n);\n\n  return y;\n};\n\n/**\n * NOTE: THIS METHOD IS DEPRECATED, use 'sign' on a private key object or\n * 'encrypt' on a public key object instead.\n *\n * Performs RSA encryption.\n *\n * The parameter bt controls whether to put padding bytes before the\n * message passed in. Set bt to either true or false to disable padding\n * completely (in order to handle e.g. EMSA-PSS encoding seperately before),\n * signaling whether the encryption operation is a public key operation\n * (i.e. encrypting data) or not, i.e. private key operation (data signing).\n *\n * For PKCS#1 v1.5 padding pass in the block type to use, i.e. either 0x01\n * (for signing) or 0x02 (for encryption). The key operation mode (private\n * or public) is derived from this flag in that case).\n *\n * @param m the message to encrypt as a byte string.\n * @param key the RSA key to use.\n * @param bt for PKCS#1 v1.5 padding, the block type to use\n *   (0x01 for private key, 0x02 for public),\n *   to disable padding: true = public key, false = private key.\n *\n * @return the encrypted bytes as a string.\n */\npki.rsa.encrypt = function(m, key, bt) {\n  var pub = bt;\n  var eb;\n\n  // get the length of the modulus in bytes\n  var k = Math.ceil(key.n.bitLength() / 8);\n\n  if(bt !== false && bt !== true) {\n    // legacy, default to PKCS#1 v1.5 padding\n    pub = (bt === 0x02);\n    eb = _encodePkcs1_v1_5(m, key, bt);\n  } else {\n    eb = forge.util.createBuffer();\n    eb.putBytes(m);\n  }\n\n  // load encryption block as big integer 'x'\n  // FIXME: hex conversion inefficient, get BigInteger w/byte strings\n  var x = new BigInteger(eb.toHex(), 16);\n\n  // do RSA encryption\n  var y = _modPow(x, key, pub);\n\n  // convert y into the encrypted data byte string, if y is shorter in\n  // bytes than k, then prepend zero bytes to fill up ed\n  // FIXME: hex conversion inefficient, get BigInteger w/byte strings\n  var yhex = y.toString(16);\n  var ed = forge.util.createBuffer();\n  var zeros = k - Math.ceil(yhex.length / 2);\n  while(zeros > 0) {\n    ed.putByte(0x00);\n    --zeros;\n  }\n  ed.putBytes(forge.util.hexToBytes(yhex));\n  return ed.getBytes();\n};\n\n/**\n * NOTE: THIS METHOD IS DEPRECATED, use 'decrypt' on a private key object or\n * 'verify' on a public key object instead.\n *\n * Performs RSA decryption.\n *\n * The parameter ml controls whether to apply PKCS#1 v1.5 padding\n * or not.  Set ml = false to disable padding removal completely\n * (in order to handle e.g. EMSA-PSS later on) and simply pass back\n * the RSA encryption block.\n *\n * @param ed the encrypted data to decrypt in as a byte string.\n * @param key the RSA key to use.\n * @param pub true for a public key operation, false for private.\n * @param ml the message length, if known, false to disable padding.\n *\n * @return the decrypted message as a byte string.\n */\npki.rsa.decrypt = function(ed, key, pub, ml) {\n  // get the length of the modulus in bytes\n  var k = Math.ceil(key.n.bitLength() / 8);\n\n  // error if the length of the encrypted data ED is not k\n  if(ed.length !== k) {\n    var error = new Error('Encrypted message length is invalid.');\n    error.length = ed.length;\n    error.expected = k;\n    throw error;\n  }\n\n  // convert encrypted data into a big integer\n  // FIXME: hex conversion inefficient, get BigInteger w/byte strings\n  var y = new BigInteger(forge.util.createBuffer(ed).toHex(), 16);\n\n  // y must be less than the modulus or it wasn't the result of\n  // a previous mod operation (encryption) using that modulus\n  if(y.compareTo(key.n) >= 0) {\n    throw new Error('Encrypted message is invalid.');\n  }\n\n  // do RSA decryption\n  var x = _modPow(y, key, pub);\n\n  // create the encryption block, if x is shorter in bytes than k, then\n  // prepend zero bytes to fill up eb\n  // FIXME: hex conversion inefficient, get BigInteger w/byte strings\n  var xhex = x.toString(16);\n  var eb = forge.util.createBuffer();\n  var zeros = k - Math.ceil(xhex.length / 2);\n  while(zeros > 0) {\n    eb.putByte(0x00);\n    --zeros;\n  }\n  eb.putBytes(forge.util.hexToBytes(xhex));\n\n  if(ml !== false) {\n    // legacy, default to PKCS#1 v1.5 padding\n    return _decodePkcs1_v1_5(eb.getBytes(), key, pub);\n  }\n\n  // return message\n  return eb.getBytes();\n};\n\n/**\n * Creates an RSA key-pair generation state object. It is used to allow\n * key-generation to be performed in steps. It also allows for a UI to\n * display progress updates.\n *\n * @param bits the size for the private key in bits, defaults to 2048.\n * @param e the public exponent to use, defaults to 65537 (0x10001).\n * @param [options] the options to use.\n *          prng a custom crypto-secure pseudo-random number generator to use,\n *            that must define \"getBytesSync\".\n *          algorithm the algorithm to use (default: 'PRIMEINC').\n *\n * @return the state object to use to generate the key-pair.\n */\npki.rsa.createKeyPairGenerationState = function(bits, e, options) {\n  // TODO: migrate step-based prime generation code to forge.prime\n\n  // set default bits\n  if(typeof(bits) === 'string') {\n    bits = parseInt(bits, 10);\n  }\n  bits = bits || 2048;\n\n  // create prng with api that matches BigInteger secure random\n  options = options || {};\n  var prng = options.prng || forge.random;\n  var rng = {\n    // x is an array to fill with bytes\n    nextBytes: function(x) {\n      var b = prng.getBytesSync(x.length);\n      for(var i = 0; i < x.length; ++i) {\n        x[i] = b.charCodeAt(i);\n      }\n    }\n  };\n\n  var algorithm = options.algorithm || 'PRIMEINC';\n\n  // create PRIMEINC algorithm state\n  var rval;\n  if(algorithm === 'PRIMEINC') {\n    rval = {\n      algorithm: algorithm,\n      state: 0,\n      bits: bits,\n      rng: rng,\n      eInt: e || 65537,\n      e: new BigInteger(null),\n      p: null,\n      q: null,\n      qBits: bits >> 1,\n      pBits: bits - (bits >> 1),\n      pqState: 0,\n      num: null,\n      keys: null\n    };\n    rval.e.fromInt(rval.eInt);\n  } else {\n    throw new Error('Invalid key generation algorithm: ' + algorithm);\n  }\n\n  return rval;\n};\n\n/**\n * Attempts to runs the key-generation algorithm for at most n seconds\n * (approximately) using the given state. When key-generation has completed,\n * the keys will be stored in state.keys.\n *\n * To use this function to update a UI while generating a key or to prevent\n * causing browser lockups/warnings, set \"n\" to a value other than 0. A\n * simple pattern for generating a key and showing a progress indicator is:\n *\n * var state = pki.rsa.createKeyPairGenerationState(2048);\n * var step = function() {\n *   // step key-generation, run algorithm for 100 ms, repeat\n *   if(!forge.pki.rsa.stepKeyPairGenerationState(state, 100)) {\n *     setTimeout(step, 1);\n *   } else {\n *     // key-generation complete\n *     // TODO: turn off progress indicator here\n *     // TODO: use the generated key-pair in \"state.keys\"\n *   }\n * };\n * // TODO: turn on progress indicator here\n * setTimeout(step, 0);\n *\n * @param state the state to use.\n * @param n the maximum number of milliseconds to run the algorithm for, 0\n *          to run the algorithm to completion.\n *\n * @return true if the key-generation completed, false if not.\n */\npki.rsa.stepKeyPairGenerationState = function(state, n) {\n  // set default algorithm if not set\n  if(!('algorithm' in state)) {\n    state.algorithm = 'PRIMEINC';\n  }\n\n  // TODO: migrate step-based prime generation code to forge.prime\n  // TODO: abstract as PRIMEINC algorithm\n\n  // do key generation (based on Tom Wu's rsa.js, see jsbn.js license)\n  // with some minor optimizations and designed to run in steps\n\n  // local state vars\n  var THIRTY = new BigInteger(null);\n  THIRTY.fromInt(30);\n  var deltaIdx = 0;\n  var op_or = function(x, y) {return x | y;};\n\n  // keep stepping until time limit is reached or done\n  var t1 = +new Date();\n  var t2;\n  var total = 0;\n  while(state.keys === null && (n <= 0 || total < n)) {\n    // generate p or q\n    if(state.state === 0) {\n      /* Note: All primes are of the form:\n\n        30k+i, for i < 30 and gcd(30, i)=1, where there are 8 values for i\n\n        When we generate a random number, we always align it at 30k + 1. Each\n        time the number is determined not to be prime we add to get to the\n        next 'i', eg: if the number was at 30k + 1 we add 6. */\n      var bits = (state.p === null) ? state.pBits : state.qBits;\n      var bits1 = bits - 1;\n\n      // get a random number\n      if(state.pqState === 0) {\n        state.num = new BigInteger(bits, state.rng);\n        // force MSB set\n        if(!state.num.testBit(bits1)) {\n          state.num.bitwiseTo(\n            BigInteger.ONE.shiftLeft(bits1), op_or, state.num);\n        }\n        // align number on 30k+1 boundary\n        state.num.dAddOffset(31 - state.num.mod(THIRTY).byteValue(), 0);\n        deltaIdx = 0;\n\n        ++state.pqState;\n      } else if(state.pqState === 1) {\n        // try to make the number a prime\n        if(state.num.bitLength() > bits) {\n          // overflow, try again\n          state.pqState = 0;\n          // do primality test\n        } else if(state.num.isProbablePrime(\n          _getMillerRabinTests(state.num.bitLength()))) {\n          ++state.pqState;\n        } else {\n          // get next potential prime\n          state.num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);\n        }\n      } else if(state.pqState === 2) {\n        // ensure number is coprime with e\n        state.pqState =\n          (state.num.subtract(BigInteger.ONE).gcd(state.e)\n            .compareTo(BigInteger.ONE) === 0) ? 3 : 0;\n      } else if(state.pqState === 3) {\n        // store p or q\n        state.pqState = 0;\n        if(state.p === null) {\n          state.p = state.num;\n        } else {\n          state.q = state.num;\n        }\n\n        // advance state if both p and q are ready\n        if(state.p !== null && state.q !== null) {\n          ++state.state;\n        }\n        state.num = null;\n      }\n    } else if(state.state === 1) {\n      // ensure p is larger than q (swap them if not)\n      if(state.p.compareTo(state.q) < 0) {\n        state.num = state.p;\n        state.p = state.q;\n        state.q = state.num;\n      }\n      ++state.state;\n    } else if(state.state === 2) {\n      // compute phi: (p - 1)(q - 1) (Euler's totient function)\n      state.p1 = state.p.subtract(BigInteger.ONE);\n      state.q1 = state.q.subtract(BigInteger.ONE);\n      state.phi = state.p1.multiply(state.q1);\n      ++state.state;\n    } else if(state.state === 3) {\n      // ensure e and phi are coprime\n      if(state.phi.gcd(state.e).compareTo(BigInteger.ONE) === 0) {\n        // phi and e are coprime, advance\n        ++state.state;\n      } else {\n        // phi and e aren't coprime, so generate a new p and q\n        state.p = null;\n        state.q = null;\n        state.state = 0;\n      }\n    } else if(state.state === 4) {\n      // create n, ensure n is has the right number of bits\n      state.n = state.p.multiply(state.q);\n\n      // ensure n is right number of bits\n      if(state.n.bitLength() === state.bits) {\n        // success, advance\n        ++state.state;\n      } else {\n        // failed, get new q\n        state.q = null;\n        state.state = 0;\n      }\n    } else if(state.state === 5) {\n      // set keys\n      var d = state.e.modInverse(state.phi);\n      state.keys = {\n        privateKey: pki.rsa.setPrivateKey(\n          state.n, state.e, d, state.p, state.q,\n          d.mod(state.p1), d.mod(state.q1),\n          state.q.modInverse(state.p)),\n        publicKey: pki.rsa.setPublicKey(state.n, state.e)\n      };\n    }\n\n    // update timing\n    t2 = +new Date();\n    total += t2 - t1;\n    t1 = t2;\n  }\n\n  return state.keys !== null;\n};\n\n/**\n * Generates an RSA public-private key pair in a single call.\n *\n * To generate a key-pair in steps (to allow for progress updates and to\n * prevent blocking or warnings in slow browsers) then use the key-pair\n * generation state functions.\n *\n * To generate a key-pair asynchronously (either through web-workers, if\n * available, or by breaking up the work on the main thread), pass a\n * callback function.\n *\n * @param [bits] the size for the private key in bits, defaults to 2048.\n * @param [e] the public exponent to use, defaults to 65537.\n * @param [options] options for key-pair generation, if given then 'bits'\n *            and 'e' must *not* be given:\n *          bits the size for the private key in bits, (default: 2048).\n *          e the public exponent to use, (default: 65537 (0x10001)).\n *          workerScript the worker script URL.\n *          workers the number of web workers (if supported) to use,\n *            (default: 2).\n *          workLoad the size of the work load, ie: number of possible prime\n *            numbers for each web worker to check per work assignment,\n *            (default: 100).\n *          prng a custom crypto-secure pseudo-random number generator to use,\n *            that must define \"getBytesSync\". Disables use of native APIs.\n *          algorithm the algorithm to use (default: 'PRIMEINC').\n * @param [callback(err, keypair)] called once the operation completes.\n *\n * @return an object with privateKey and publicKey properties.\n */\npki.rsa.generateKeyPair = function(bits, e, options, callback) {\n  // (bits), (options), (callback)\n  if(arguments.length === 1) {\n    if(typeof bits === 'object') {\n      options = bits;\n      bits = undefined;\n    } else if(typeof bits === 'function') {\n      callback = bits;\n      bits = undefined;\n    }\n  } else if(arguments.length === 2) {\n    // (bits, e), (bits, options), (bits, callback), (options, callback)\n    if(typeof bits === 'number') {\n      if(typeof e === 'function') {\n        callback = e;\n        e = undefined;\n      } else if(typeof e !== 'number') {\n        options = e;\n        e = undefined;\n      }\n    } else {\n      options = bits;\n      callback = e;\n      bits = undefined;\n      e = undefined;\n    }\n  } else if(arguments.length === 3) {\n    // (bits, e, options), (bits, e, callback), (bits, options, callback)\n    if(typeof e === 'number') {\n      if(typeof options === 'function') {\n        callback = options;\n        options = undefined;\n      }\n    } else {\n      callback = options;\n      options = e;\n      e = undefined;\n    }\n  }\n  options = options || {};\n  if(bits === undefined) {\n    bits = options.bits || 2048;\n  }\n  if(e === undefined) {\n    e = options.e || 0x10001;\n  }\n\n  // use native code if permitted, available, and parameters are acceptable\n  if(!forge.options.usePureJavaScript && !options.prng &&\n    bits >= 256 && bits <= 16384 && (e === 0x10001 || e === 3)) {\n    if(callback) {\n      // try native async\n      if(_detectNodeCrypto('generateKeyPair')) {\n        return _crypto.generateKeyPair('rsa', {\n          modulusLength: bits,\n          publicExponent: e,\n          publicKeyEncoding: {\n            type: 'spki',\n            format: 'pem'\n          },\n          privateKeyEncoding: {\n            type: 'pkcs8',\n            format: 'pem'\n          }\n        }, function(err, pub, priv) {\n          if(err) {\n            return callback(err);\n          }\n          callback(null, {\n            privateKey: pki.privateKeyFromPem(priv),\n            publicKey: pki.publicKeyFromPem(pub)\n          });\n        });\n      }\n      if(_detectSubtleCrypto('generateKey') &&\n        _detectSubtleCrypto('exportKey')) {\n        // use standard native generateKey\n        return util.globalScope.crypto.subtle.generateKey({\n          name: 'RSASSA-PKCS1-v1_5',\n          modulusLength: bits,\n          publicExponent: _intToUint8Array(e),\n          hash: {name: 'SHA-256'}\n        }, true /* key can be exported*/, ['sign', 'verify'])\n        .then(function(pair) {\n          return util.globalScope.crypto.subtle.exportKey(\n            'pkcs8', pair.privateKey);\n        // avoiding catch(function(err) {...}) to support IE <= 8\n        }).then(undefined, function(err) {\n          callback(err);\n        }).then(function(pkcs8) {\n          if(pkcs8) {\n            var privateKey = pki.privateKeyFromAsn1(\n              asn1.fromDer(forge.util.createBuffer(pkcs8)));\n            callback(null, {\n              privateKey: privateKey,\n              publicKey: pki.setRsaPublicKey(privateKey.n, privateKey.e)\n            });\n          }\n        });\n      }\n      if(_detectSubtleMsCrypto('generateKey') &&\n        _detectSubtleMsCrypto('exportKey')) {\n        var genOp = util.globalScope.msCrypto.subtle.generateKey({\n          name: 'RSASSA-PKCS1-v1_5',\n          modulusLength: bits,\n          publicExponent: _intToUint8Array(e),\n          hash: {name: 'SHA-256'}\n        }, true /* key can be exported*/, ['sign', 'verify']);\n        genOp.oncomplete = function(e) {\n          var pair = e.target.result;\n          var exportOp = util.globalScope.msCrypto.subtle.exportKey(\n            'pkcs8', pair.privateKey);\n          exportOp.oncomplete = function(e) {\n            var pkcs8 = e.target.result;\n            var privateKey = pki.privateKeyFromAsn1(\n              asn1.fromDer(forge.util.createBuffer(pkcs8)));\n            callback(null, {\n              privateKey: privateKey,\n              publicKey: pki.setRsaPublicKey(privateKey.n, privateKey.e)\n            });\n          };\n          exportOp.onerror = function(err) {\n            callback(err);\n          };\n        };\n        genOp.onerror = function(err) {\n          callback(err);\n        };\n        return;\n      }\n    } else {\n      // try native sync\n      if(_detectNodeCrypto('generateKeyPairSync')) {\n        var keypair = _crypto.generateKeyPairSync('rsa', {\n          modulusLength: bits,\n          publicExponent: e,\n          publicKeyEncoding: {\n            type: 'spki',\n            format: 'pem'\n          },\n          privateKeyEncoding: {\n            type: 'pkcs8',\n            format: 'pem'\n          }\n        });\n        return {\n          privateKey: pki.privateKeyFromPem(keypair.privateKey),\n          publicKey: pki.publicKeyFromPem(keypair.publicKey)\n        };\n      }\n    }\n  }\n\n  // use JavaScript implementation\n  var state = pki.rsa.createKeyPairGenerationState(bits, e, options);\n  if(!callback) {\n    pki.rsa.stepKeyPairGenerationState(state, 0);\n    return state.keys;\n  }\n  _generateKeyPair(state, options, callback);\n};\n\n/**\n * Sets an RSA public key from BigIntegers modulus and exponent.\n *\n * @param n the modulus.\n * @param e the exponent.\n *\n * @return the public key.\n */\npki.setRsaPublicKey = pki.rsa.setPublicKey = function(n, e) {\n  var key = {\n    n: n,\n    e: e\n  };\n\n  /**\n   * Encrypts the given data with this public key. Newer applications\n   * should use the 'RSA-OAEP' decryption scheme, 'RSAES-PKCS1-V1_5' is for\n   * legacy applications.\n   *\n   * @param data the byte string to encrypt.\n   * @param scheme the encryption scheme to use:\n   *          'RSAES-PKCS1-V1_5' (default),\n   *          'RSA-OAEP',\n   *          'RAW', 'NONE', or null to perform raw RSA encryption,\n   *          an object with an 'encode' property set to a function\n   *          with the signature 'function(data, key)' that returns\n   *          a binary-encoded string representing the encoded data.\n   * @param schemeOptions any scheme-specific options.\n   *\n   * @return the encrypted byte string.\n   */\n  key.encrypt = function(data, scheme, schemeOptions) {\n    if(typeof scheme === 'string') {\n      scheme = scheme.toUpperCase();\n    } else if(scheme === undefined) {\n      scheme = 'RSAES-PKCS1-V1_5';\n    }\n\n    if(scheme === 'RSAES-PKCS1-V1_5') {\n      scheme = {\n        encode: function(m, key, pub) {\n          return _encodePkcs1_v1_5(m, key, 0x02).getBytes();\n        }\n      };\n    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {\n      scheme = {\n        encode: function(m, key) {\n          return forge.pkcs1.encode_rsa_oaep(key, m, schemeOptions);\n        }\n      };\n    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {\n      scheme = {encode: function(e) {return e;}};\n    } else if(typeof scheme === 'string') {\n      throw new Error('Unsupported encryption scheme: \"' + scheme + '\".');\n    }\n\n    // do scheme-based encoding then rsa encryption\n    var e = scheme.encode(data, key, true);\n    return pki.rsa.encrypt(e, key, true);\n  };\n\n  /**\n   * Verifies the given signature against the given digest.\n   *\n   * PKCS#1 supports multiple (currently two) signature schemes:\n   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.\n   *\n   * By default this implementation uses the \"old scheme\", i.e.\n   * RSASSA-PKCS1-V1_5, in which case once RSA-decrypted, the\n   * signature is an OCTET STRING that holds a DigestInfo.\n   *\n   * DigestInfo ::= SEQUENCE {\n   *   digestAlgorithm DigestAlgorithmIdentifier,\n   *   digest Digest\n   * }\n   * DigestAlgorithmIdentifier ::= AlgorithmIdentifier\n   * Digest ::= OCTET STRING\n   *\n   * To perform PSS signature verification, provide an instance\n   * of Forge PSS object as the scheme parameter.\n   *\n   * @param digest the message digest hash to compare against the signature,\n   *          as a binary-encoded string.\n   * @param signature the signature to verify, as a binary-encoded string.\n   * @param scheme signature verification scheme to use:\n   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,\n   *          a Forge PSS object for RSASSA-PSS,\n   *          'NONE' or null for none, DigestInfo will not be expected, but\n   *            PKCS#1 v1.5 padding will still be used.\n   * @param options optional verify options\n   *          _parseAllDigestBytes testing flag to control parsing of all\n   *            digest bytes. Unsupported and not for general usage.\n   *            (default: true)\n   *\n   * @return true if the signature was verified, false if not.\n   */\n  key.verify = function(digest, signature, scheme, options) {\n    if(typeof scheme === 'string') {\n      scheme = scheme.toUpperCase();\n    } else if(scheme === undefined) {\n      scheme = 'RSASSA-PKCS1-V1_5';\n    }\n    if(options === undefined) {\n      options = {\n        _parseAllDigestBytes: true\n      };\n    }\n    if(!('_parseAllDigestBytes' in options)) {\n      options._parseAllDigestBytes = true;\n    }\n\n    if(scheme === 'RSASSA-PKCS1-V1_5') {\n      scheme = {\n        verify: function(digest, d) {\n          // remove padding\n          d = _decodePkcs1_v1_5(d, key, true);\n          // d is ASN.1 BER-encoded DigestInfo\n          var obj = asn1.fromDer(d, {\n            parseAllBytes: options._parseAllDigestBytes\n          });\n\n          // validate DigestInfo\n          var capture = {};\n          var errors = [];\n          if(!asn1.validate(obj, digestInfoValidator, capture, errors)) {\n            var error = new Error(\n              'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +\n              'DigestInfo value.');\n            error.errors = errors;\n            throw error;\n          }\n          // check hash algorithm identifier\n          // see PKCS1-v1-5DigestAlgorithms in RFC 8017\n          // FIXME: add support to vaidator for strict value choices\n          var oid = asn1.derToOid(capture.algorithmIdentifier);\n          if(!(oid === forge.oids.md2 ||\n            oid === forge.oids.md5 ||\n            oid === forge.oids.sha1 ||\n            oid === forge.oids.sha224 ||\n            oid === forge.oids.sha256 ||\n            oid === forge.oids.sha384 ||\n            oid === forge.oids.sha512 ||\n            oid === forge.oids['sha512-224'] ||\n            oid === forge.oids['sha512-256'])) {\n            var error = new Error(\n              'Unknown RSASSA-PKCS1-v1_5 DigestAlgorithm identifier.');\n            error.oid = oid;\n            throw error;\n          }\n\n          // special check for md2 and md5 that NULL parameters exist\n          if(oid === forge.oids.md2 || oid === forge.oids.md5) {\n            if(!('parameters' in capture)) {\n              throw new Error(\n                'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +\n                'DigestInfo value. ' +\n                'Missing algorithm identifer NULL parameters.');\n            }\n          }\n\n          // compare the given digest to the decrypted one\n          return digest === capture.digest;\n        }\n      };\n    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {\n      scheme = {\n        verify: function(digest, d) {\n          // remove padding\n          d = _decodePkcs1_v1_5(d, key, true);\n          return digest === d;\n        }\n      };\n    }\n\n    // do rsa decryption w/o any decoding, then verify -- which does decoding\n    var d = pki.rsa.decrypt(signature, key, true, false);\n    return scheme.verify(digest, d, key.n.bitLength());\n  };\n\n  return key;\n};\n\n/**\n * Sets an RSA private key from BigIntegers modulus, exponent, primes,\n * prime exponents, and modular multiplicative inverse.\n *\n * @param n the modulus.\n * @param e the public exponent.\n * @param d the private exponent ((inverse of e) mod n).\n * @param p the first prime.\n * @param q the second prime.\n * @param dP exponent1 (d mod (p-1)).\n * @param dQ exponent2 (d mod (q-1)).\n * @param qInv ((inverse of q) mod p)\n *\n * @return the private key.\n */\npki.setRsaPrivateKey = pki.rsa.setPrivateKey = function(\n  n, e, d, p, q, dP, dQ, qInv) {\n  var key = {\n    n: n,\n    e: e,\n    d: d,\n    p: p,\n    q: q,\n    dP: dP,\n    dQ: dQ,\n    qInv: qInv\n  };\n\n  /**\n   * Decrypts the given data with this private key. The decryption scheme\n   * must match the one used to encrypt the data.\n   *\n   * @param data the byte string to decrypt.\n   * @param scheme the decryption scheme to use:\n   *          'RSAES-PKCS1-V1_5' (default),\n   *          'RSA-OAEP',\n   *          'RAW', 'NONE', or null to perform raw RSA decryption.\n   * @param schemeOptions any scheme-specific options.\n   *\n   * @return the decrypted byte string.\n   */\n  key.decrypt = function(data, scheme, schemeOptions) {\n    if(typeof scheme === 'string') {\n      scheme = scheme.toUpperCase();\n    } else if(scheme === undefined) {\n      scheme = 'RSAES-PKCS1-V1_5';\n    }\n\n    // do rsa decryption w/o any decoding\n    var d = pki.rsa.decrypt(data, key, false, false);\n\n    if(scheme === 'RSAES-PKCS1-V1_5') {\n      scheme = {decode: _decodePkcs1_v1_5};\n    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {\n      scheme = {\n        decode: function(d, key) {\n          return forge.pkcs1.decode_rsa_oaep(key, d, schemeOptions);\n        }\n      };\n    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {\n      scheme = {decode: function(d) {return d;}};\n    } else {\n      throw new Error('Unsupported encryption scheme: \"' + scheme + '\".');\n    }\n\n    // decode according to scheme\n    return scheme.decode(d, key, false);\n  };\n\n  /**\n   * Signs the given digest, producing a signature.\n   *\n   * PKCS#1 supports multiple (currently two) signature schemes:\n   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.\n   *\n   * By default this implementation uses the \"old scheme\", i.e.\n   * RSASSA-PKCS1-V1_5. In order to generate a PSS signature, provide\n   * an instance of Forge PSS object as the scheme parameter.\n   *\n   * @param md the message digest object with the hash to sign.\n   * @param scheme the signature scheme to use:\n   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,\n   *          a Forge PSS object for RSASSA-PSS,\n   *          'NONE' or null for none, DigestInfo will not be used but\n   *            PKCS#1 v1.5 padding will still be used.\n   *\n   * @return the signature as a byte string.\n   */\n  key.sign = function(md, scheme) {\n    /* Note: The internal implementation of RSA operations is being\n      transitioned away from a PKCS#1 v1.5 hard-coded scheme. Some legacy\n      code like the use of an encoding block identifier 'bt' will eventually\n      be removed. */\n\n    // private key operation\n    var bt = false;\n\n    if(typeof scheme === 'string') {\n      scheme = scheme.toUpperCase();\n    }\n\n    if(scheme === undefined || scheme === 'RSASSA-PKCS1-V1_5') {\n      scheme = {encode: emsaPkcs1v15encode};\n      bt = 0x01;\n    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {\n      scheme = {encode: function() {return md;}};\n      bt = 0x01;\n    }\n\n    // encode and then encrypt\n    var d = scheme.encode(md, key.n.bitLength());\n    return pki.rsa.encrypt(d, key, bt);\n  };\n\n  return key;\n};\n\n/**\n * Wraps an RSAPrivateKey ASN.1 object in an ASN.1 PrivateKeyInfo object.\n *\n * @param rsaKey the ASN.1 RSAPrivateKey.\n *\n * @return the ASN.1 PrivateKeyInfo.\n */\npki.wrapRsaPrivateKey = function(rsaKey) {\n  // PrivateKeyInfo\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version (0)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(0).getBytes()),\n    // privateKeyAlgorithm\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(pki.oids.rsaEncryption).getBytes()),\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n    ]),\n    // PrivateKey\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,\n      asn1.toDer(rsaKey).getBytes())\n  ]);\n};\n\n/**\n * Converts a private key from an ASN.1 object.\n *\n * @param obj the ASN.1 representation of a PrivateKeyInfo containing an\n *          RSAPrivateKey or an RSAPrivateKey.\n *\n * @return the private key.\n */\npki.privateKeyFromAsn1 = function(obj) {\n  // get PrivateKeyInfo\n  var capture = {};\n  var errors = [];\n  if(asn1.validate(obj, privateKeyValidator, capture, errors)) {\n    obj = asn1.fromDer(forge.util.createBuffer(capture.privateKey));\n  }\n\n  // get RSAPrivateKey\n  capture = {};\n  errors = [];\n  if(!asn1.validate(obj, rsaPrivateKeyValidator, capture, errors)) {\n    var error = new Error('Cannot read private key. ' +\n      'ASN.1 object does not contain an RSAPrivateKey.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // Note: Version is currently ignored.\n  // capture.privateKeyVersion\n  // FIXME: inefficient, get a BigInteger that uses byte strings\n  var n, e, d, p, q, dP, dQ, qInv;\n  n = forge.util.createBuffer(capture.privateKeyModulus).toHex();\n  e = forge.util.createBuffer(capture.privateKeyPublicExponent).toHex();\n  d = forge.util.createBuffer(capture.privateKeyPrivateExponent).toHex();\n  p = forge.util.createBuffer(capture.privateKeyPrime1).toHex();\n  q = forge.util.createBuffer(capture.privateKeyPrime2).toHex();\n  dP = forge.util.createBuffer(capture.privateKeyExponent1).toHex();\n  dQ = forge.util.createBuffer(capture.privateKeyExponent2).toHex();\n  qInv = forge.util.createBuffer(capture.privateKeyCoefficient).toHex();\n\n  // set private key\n  return pki.setRsaPrivateKey(\n    new BigInteger(n, 16),\n    new BigInteger(e, 16),\n    new BigInteger(d, 16),\n    new BigInteger(p, 16),\n    new BigInteger(q, 16),\n    new BigInteger(dP, 16),\n    new BigInteger(dQ, 16),\n    new BigInteger(qInv, 16));\n};\n\n/**\n * Converts a private key to an ASN.1 RSAPrivateKey.\n *\n * @param key the private key.\n *\n * @return the ASN.1 representation of an RSAPrivateKey.\n */\npki.privateKeyToAsn1 = pki.privateKeyToRSAPrivateKey = function(key) {\n  // RSAPrivateKey\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version (0 = only 2 primes, 1 multiple primes)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(0).getBytes()),\n    // modulus (n)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.n)),\n    // publicExponent (e)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.e)),\n    // privateExponent (d)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.d)),\n    // privateKeyPrime1 (p)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.p)),\n    // privateKeyPrime2 (q)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.q)),\n    // privateKeyExponent1 (dP)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.dP)),\n    // privateKeyExponent2 (dQ)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.dQ)),\n    // coefficient (qInv)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.qInv))\n  ]);\n};\n\n/**\n * Converts a public key from an ASN.1 SubjectPublicKeyInfo or RSAPublicKey.\n *\n * @param obj the asn1 representation of a SubjectPublicKeyInfo or RSAPublicKey.\n *\n * @return the public key.\n */\npki.publicKeyFromAsn1 = function(obj) {\n  // get SubjectPublicKeyInfo\n  var capture = {};\n  var errors = [];\n  if(asn1.validate(obj, publicKeyValidator, capture, errors)) {\n    // get oid\n    var oid = asn1.derToOid(capture.publicKeyOid);\n    if(oid !== pki.oids.rsaEncryption) {\n      var error = new Error('Cannot read public key. Unknown OID.');\n      error.oid = oid;\n      throw error;\n    }\n    obj = capture.rsaPublicKey;\n  }\n\n  // get RSA params\n  errors = [];\n  if(!asn1.validate(obj, rsaPublicKeyValidator, capture, errors)) {\n    var error = new Error('Cannot read public key. ' +\n      'ASN.1 object does not contain an RSAPublicKey.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // FIXME: inefficient, get a BigInteger that uses byte strings\n  var n = forge.util.createBuffer(capture.publicKeyModulus).toHex();\n  var e = forge.util.createBuffer(capture.publicKeyExponent).toHex();\n\n  // set public key\n  return pki.setRsaPublicKey(\n    new BigInteger(n, 16),\n    new BigInteger(e, 16));\n};\n\n/**\n * Converts a public key to an ASN.1 SubjectPublicKeyInfo.\n *\n * @param key the public key.\n *\n * @return the asn1 representation of a SubjectPublicKeyInfo.\n */\npki.publicKeyToAsn1 = pki.publicKeyToSubjectPublicKeyInfo = function(key) {\n  // SubjectPublicKeyInfo\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // AlgorithmIdentifier\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(pki.oids.rsaEncryption).getBytes()),\n      // parameters (null)\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n    ]),\n    // subjectPublicKey\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false, [\n      pki.publicKeyToRSAPublicKey(key)\n    ])\n  ]);\n};\n\n/**\n * Converts a public key to an ASN.1 RSAPublicKey.\n *\n * @param key the public key.\n *\n * @return the asn1 representation of a RSAPublicKey.\n */\npki.publicKeyToRSAPublicKey = function(key) {\n  // RSAPublicKey\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // modulus (n)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.n)),\n    // publicExponent (e)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      _bnToBytes(key.e))\n  ]);\n};\n\n/**\n * Encodes a message using PKCS#1 v1.5 padding.\n *\n * @param m the message to encode.\n * @param key the RSA key to use.\n * @param bt the block type to use, i.e. either 0x01 (for signing) or 0x02\n *          (for encryption).\n *\n * @return the padded byte buffer.\n */\nfunction _encodePkcs1_v1_5(m, key, bt) {\n  var eb = forge.util.createBuffer();\n\n  // get the length of the modulus in bytes\n  var k = Math.ceil(key.n.bitLength() / 8);\n\n  /* use PKCS#1 v1.5 padding */\n  if(m.length > (k - 11)) {\n    var error = new Error('Message is too long for PKCS#1 v1.5 padding.');\n    error.length = m.length;\n    error.max = k - 11;\n    throw error;\n  }\n\n  /* A block type BT, a padding string PS, and the data D shall be\n    formatted into an octet string EB, the encryption block:\n\n    EB = 00 || BT || PS || 00 || D\n\n    The block type BT shall be a single octet indicating the structure of\n    the encryption block. For this version of the document it shall have\n    value 00, 01, or 02. For a private-key operation, the block type\n    shall be 00 or 01. For a public-key operation, it shall be 02.\n\n    The padding string PS shall consist of k-3-||D|| octets. For block\n    type 00, the octets shall have value 00; for block type 01, they\n    shall have value FF; and for block type 02, they shall be\n    pseudorandomly generated and nonzero. This makes the length of the\n    encryption block EB equal to k. */\n\n  // build the encryption block\n  eb.putByte(0x00);\n  eb.putByte(bt);\n\n  // create the padding\n  var padNum = k - 3 - m.length;\n  var padByte;\n  // private key op\n  if(bt === 0x00 || bt === 0x01) {\n    padByte = (bt === 0x00) ? 0x00 : 0xFF;\n    for(var i = 0; i < padNum; ++i) {\n      eb.putByte(padByte);\n    }\n  } else {\n    // public key op\n    // pad with random non-zero values\n    while(padNum > 0) {\n      var numZeros = 0;\n      var padBytes = forge.random.getBytes(padNum);\n      for(var i = 0; i < padNum; ++i) {\n        padByte = padBytes.charCodeAt(i);\n        if(padByte === 0) {\n          ++numZeros;\n        } else {\n          eb.putByte(padByte);\n        }\n      }\n      padNum = numZeros;\n    }\n  }\n\n  // zero followed by message\n  eb.putByte(0x00);\n  eb.putBytes(m);\n\n  return eb;\n}\n\n/**\n * Decodes a message using PKCS#1 v1.5 padding.\n *\n * @param em the message to decode.\n * @param key the RSA key to use.\n * @param pub true if the key is a public key, false if it is private.\n * @param ml the message length, if specified.\n *\n * @return the decoded bytes.\n */\nfunction _decodePkcs1_v1_5(em, key, pub, ml) {\n  // get the length of the modulus in bytes\n  var k = Math.ceil(key.n.bitLength() / 8);\n\n  /* It is an error if any of the following conditions occurs:\n\n    1. The encryption block EB cannot be parsed unambiguously.\n    2. The padding string PS consists of fewer than eight octets\n      or is inconsisent with the block type BT.\n    3. The decryption process is a public-key operation and the block\n      type BT is not 00 or 01, or the decryption process is a\n      private-key operation and the block type is not 02.\n   */\n\n  // parse the encryption block\n  var eb = forge.util.createBuffer(em);\n  var first = eb.getByte();\n  var bt = eb.getByte();\n  if(first !== 0x00 ||\n    (pub && bt !== 0x00 && bt !== 0x01) ||\n    (!pub && bt != 0x02) ||\n    (pub && bt === 0x00 && typeof(ml) === 'undefined')) {\n    throw new Error('Encryption block is invalid.');\n  }\n\n  var padNum = 0;\n  if(bt === 0x00) {\n    // check all padding bytes for 0x00\n    padNum = k - 3 - ml;\n    for(var i = 0; i < padNum; ++i) {\n      if(eb.getByte() !== 0x00) {\n        throw new Error('Encryption block is invalid.');\n      }\n    }\n  } else if(bt === 0x01) {\n    // find the first byte that isn't 0xFF, should be after all padding\n    padNum = 0;\n    while(eb.length() > 1) {\n      if(eb.getByte() !== 0xFF) {\n        --eb.read;\n        break;\n      }\n      ++padNum;\n    }\n  } else if(bt === 0x02) {\n    // look for 0x00 byte\n    padNum = 0;\n    while(eb.length() > 1) {\n      if(eb.getByte() === 0x00) {\n        --eb.read;\n        break;\n      }\n      ++padNum;\n    }\n  }\n\n  // zero must be 0x00 and padNum must be (k - 3 - message length)\n  var zero = eb.getByte();\n  if(zero !== 0x00 || padNum !== (k - 3 - eb.length())) {\n    throw new Error('Encryption block is invalid.');\n  }\n\n  return eb.getBytes();\n}\n\n/**\n * Runs the key-generation algorithm asynchronously, either in the background\n * via Web Workers, or using the main thread and setImmediate.\n *\n * @param state the key-pair generation state.\n * @param [options] options for key-pair generation:\n *          workerScript the worker script URL.\n *          workers the number of web workers (if supported) to use,\n *            (default: 2, -1 to use estimated cores minus one).\n *          workLoad the size of the work load, ie: number of possible prime\n *            numbers for each web worker to check per work assignment,\n *            (default: 100).\n * @param callback(err, keypair) called once the operation completes.\n */\nfunction _generateKeyPair(state, options, callback) {\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  var opts = {\n    algorithm: {\n      name: options.algorithm || 'PRIMEINC',\n      options: {\n        workers: options.workers || 2,\n        workLoad: options.workLoad || 100,\n        workerScript: options.workerScript\n      }\n    }\n  };\n  if('prng' in options) {\n    opts.prng = options.prng;\n  }\n\n  generate();\n\n  function generate() {\n    // find p and then q (done in series to simplify)\n    getPrime(state.pBits, function(err, num) {\n      if(err) {\n        return callback(err);\n      }\n      state.p = num;\n      if(state.q !== null) {\n        return finish(err, state.q);\n      }\n      getPrime(state.qBits, finish);\n    });\n  }\n\n  function getPrime(bits, callback) {\n    forge.prime.generateProbablePrime(bits, opts, callback);\n  }\n\n  function finish(err, num) {\n    if(err) {\n      return callback(err);\n    }\n\n    // set q\n    state.q = num;\n\n    // ensure p is larger than q (swap them if not)\n    if(state.p.compareTo(state.q) < 0) {\n      var tmp = state.p;\n      state.p = state.q;\n      state.q = tmp;\n    }\n\n    // ensure p is coprime with e\n    if(state.p.subtract(BigInteger.ONE).gcd(state.e)\n      .compareTo(BigInteger.ONE) !== 0) {\n      state.p = null;\n      generate();\n      return;\n    }\n\n    // ensure q is coprime with e\n    if(state.q.subtract(BigInteger.ONE).gcd(state.e)\n      .compareTo(BigInteger.ONE) !== 0) {\n      state.q = null;\n      getPrime(state.qBits, finish);\n      return;\n    }\n\n    // compute phi: (p - 1)(q - 1) (Euler's totient function)\n    state.p1 = state.p.subtract(BigInteger.ONE);\n    state.q1 = state.q.subtract(BigInteger.ONE);\n    state.phi = state.p1.multiply(state.q1);\n\n    // ensure e and phi are coprime\n    if(state.phi.gcd(state.e).compareTo(BigInteger.ONE) !== 0) {\n      // phi and e aren't coprime, so generate a new p and q\n      state.p = state.q = null;\n      generate();\n      return;\n    }\n\n    // create n, ensure n is has the right number of bits\n    state.n = state.p.multiply(state.q);\n    if(state.n.bitLength() !== state.bits) {\n      // failed, get new q\n      state.q = null;\n      getPrime(state.qBits, finish);\n      return;\n    }\n\n    // set keys\n    var d = state.e.modInverse(state.phi);\n    state.keys = {\n      privateKey: pki.rsa.setPrivateKey(\n        state.n, state.e, d, state.p, state.q,\n        d.mod(state.p1), d.mod(state.q1),\n        state.q.modInverse(state.p)),\n      publicKey: pki.rsa.setPublicKey(state.n, state.e)\n    };\n\n    callback(null, state.keys);\n  }\n}\n\n/**\n * Converts a positive BigInteger into 2's-complement big-endian bytes.\n *\n * @param b the big integer to convert.\n *\n * @return the bytes.\n */\nfunction _bnToBytes(b) {\n  // prepend 0x00 if first byte >= 0x80\n  var hex = b.toString(16);\n  if(hex[0] >= '8') {\n    hex = '00' + hex;\n  }\n  var bytes = forge.util.hexToBytes(hex);\n\n  // ensure integer is minimally-encoded\n  if(bytes.length > 1 &&\n    // leading 0x00 for positive integer\n    ((bytes.charCodeAt(0) === 0 &&\n    (bytes.charCodeAt(1) & 0x80) === 0) ||\n    // leading 0xFF for negative integer\n    (bytes.charCodeAt(0) === 0xFF &&\n    (bytes.charCodeAt(1) & 0x80) === 0x80))) {\n    return bytes.substr(1);\n  }\n  return bytes;\n}\n\n/**\n * Returns the required number of Miller-Rabin tests to generate a\n * prime with an error probability of (1/2)^80.\n *\n * See Handbook of Applied Cryptography Chapter 4, Table 4.4.\n *\n * @param bits the bit size.\n *\n * @return the required number of iterations.\n */\nfunction _getMillerRabinTests(bits) {\n  if(bits <= 100) return 27;\n  if(bits <= 150) return 18;\n  if(bits <= 200) return 15;\n  if(bits <= 250) return 12;\n  if(bits <= 300) return 9;\n  if(bits <= 350) return 8;\n  if(bits <= 400) return 7;\n  if(bits <= 500) return 6;\n  if(bits <= 600) return 5;\n  if(bits <= 800) return 4;\n  if(bits <= 1250) return 3;\n  return 2;\n}\n\n/**\n * Performs feature detection on the Node crypto interface.\n *\n * @param fn the feature (function) to detect.\n *\n * @return true if detected, false if not.\n */\nfunction _detectNodeCrypto(fn) {\n  return forge.util.isNodejs && typeof _crypto[fn] === 'function';\n}\n\n/**\n * Performs feature detection on the SubtleCrypto interface.\n *\n * @param fn the feature (function) to detect.\n *\n * @return true if detected, false if not.\n */\nfunction _detectSubtleCrypto(fn) {\n  return (typeof util.globalScope !== 'undefined' &&\n    typeof util.globalScope.crypto === 'object' &&\n    typeof util.globalScope.crypto.subtle === 'object' &&\n    typeof util.globalScope.crypto.subtle[fn] === 'function');\n}\n\n/**\n * Performs feature detection on the deprecated Microsoft Internet Explorer\n * outdated SubtleCrypto interface. This function should only be used after\n * checking for the modern, standard SubtleCrypto interface.\n *\n * @param fn the feature (function) to detect.\n *\n * @return true if detected, false if not.\n */\nfunction _detectSubtleMsCrypto(fn) {\n  return (typeof util.globalScope !== 'undefined' &&\n    typeof util.globalScope.msCrypto === 'object' &&\n    typeof util.globalScope.msCrypto.subtle === 'object' &&\n    typeof util.globalScope.msCrypto.subtle[fn] === 'function');\n}\n\nfunction _intToUint8Array(x) {\n  var bytes = forge.util.hexToBytes(x.toString(16));\n  var buffer = new Uint8Array(bytes.length);\n  for(var i = 0; i < bytes.length; ++i) {\n    buffer[i] = bytes.charCodeAt(i);\n  }\n  return buffer;\n}\n\nfunction _privateKeyFromJwk(jwk) {\n  if(jwk.kty !== 'RSA') {\n    throw new Error(\n      'Unsupported key algorithm \"' + jwk.kty + '\"; algorithm must be \"RSA\".');\n  }\n  return pki.setRsaPrivateKey(\n    _base64ToBigInt(jwk.n),\n    _base64ToBigInt(jwk.e),\n    _base64ToBigInt(jwk.d),\n    _base64ToBigInt(jwk.p),\n    _base64ToBigInt(jwk.q),\n    _base64ToBigInt(jwk.dp),\n    _base64ToBigInt(jwk.dq),\n    _base64ToBigInt(jwk.qi));\n}\n\nfunction _publicKeyFromJwk(jwk) {\n  if(jwk.kty !== 'RSA') {\n    throw new Error('Key algorithm must be \"RSA\".');\n  }\n  return pki.setRsaPublicKey(\n    _base64ToBigInt(jwk.n),\n    _base64ToBigInt(jwk.e));\n}\n\nfunction _base64ToBigInt(b64) {\n  return new BigInteger(forge.util.bytesToHex(forge.util.decode64(b64)), 16);\n}\n","/**\n * Secure Hash Algorithm with 160-bit digest (SHA-1) implementation.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2015 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./md');\nrequire('./util');\n\nvar sha1 = module.exports = forge.sha1 = forge.sha1 || {};\nforge.md.sha1 = forge.md.algorithms.sha1 = sha1;\n\n/**\n * Creates a SHA-1 message digest object.\n *\n * @return a message digest object.\n */\nsha1.create = function() {\n  // do initialization as necessary\n  if(!_initialized) {\n    _init();\n  }\n\n  // SHA-1 state contains five 32-bit integers\n  var _state = null;\n\n  // input buffer\n  var _input = forge.util.createBuffer();\n\n  // used for word storage\n  var _w = new Array(80);\n\n  // message digest object\n  var md = {\n    algorithm: 'sha1',\n    blockLength: 64,\n    digestLength: 20,\n    // 56-bit length of message so far (does not including padding)\n    messageLength: 0,\n    // true message length\n    fullMessageLength: null,\n    // size of message length in bytes\n    messageLengthSize: 8\n  };\n\n  /**\n   * Starts the digest.\n   *\n   * @return this digest object.\n   */\n  md.start = function() {\n    // up to 56-bit message length for convenience\n    md.messageLength = 0;\n\n    // full message length (set md.messageLength64 for backwards-compatibility)\n    md.fullMessageLength = md.messageLength64 = [];\n    var int32s = md.messageLengthSize / 4;\n    for(var i = 0; i < int32s; ++i) {\n      md.fullMessageLength.push(0);\n    }\n    _input = forge.util.createBuffer();\n    _state = {\n      h0: 0x67452301,\n      h1: 0xEFCDAB89,\n      h2: 0x98BADCFE,\n      h3: 0x10325476,\n      h4: 0xC3D2E1F0\n    };\n    return md;\n  };\n  // start digest automatically for first time\n  md.start();\n\n  /**\n   * Updates the digest with the given message input. The given input can\n   * treated as raw input (no encoding will be applied) or an encoding of\n   * 'utf8' maybe given to encode the input using UTF-8.\n   *\n   * @param msg the message input to update with.\n   * @param encoding the encoding to use (default: 'raw', other: 'utf8').\n   *\n   * @return this digest object.\n   */\n  md.update = function(msg, encoding) {\n    if(encoding === 'utf8') {\n      msg = forge.util.encodeUtf8(msg);\n    }\n\n    // update message length\n    var len = msg.length;\n    md.messageLength += len;\n    len = [(len / 0x100000000) >>> 0, len >>> 0];\n    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {\n      md.fullMessageLength[i] += len[1];\n      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);\n      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;\n      len[0] = ((len[1] / 0x100000000) >>> 0);\n    }\n\n    // add bytes to input buffer\n    _input.putBytes(msg);\n\n    // process bytes\n    _update(_state, _w, _input);\n\n    // compact input buffer every 2K or if empty\n    if(_input.read > 2048 || _input.length() === 0) {\n      _input.compact();\n    }\n\n    return md;\n  };\n\n  /**\n   * Produces the digest.\n   *\n   * @return a byte buffer containing the digest value.\n   */\n  md.digest = function() {\n    /* Note: Here we copy the remaining bytes in the input buffer and\n    add the appropriate SHA-1 padding. Then we do the final update\n    on a copy of the state so that if the user wants to get\n    intermediate digests they can do so. */\n\n    /* Determine the number of bytes that must be added to the message\n    to ensure its length is congruent to 448 mod 512. In other words,\n    the data to be digested must be a multiple of 512 bits (or 128 bytes).\n    This data includes the message, some padding, and the length of the\n    message. Since the length of the message will be encoded as 8 bytes (64\n    bits), that means that the last segment of the data must have 56 bytes\n    (448 bits) of message and padding. Therefore, the length of the message\n    plus the padding must be congruent to 448 mod 512 because\n    512 - 128 = 448.\n\n    In order to fill up the message length it must be filled with\n    padding that begins with 1 bit followed by all 0 bits. Padding\n    must *always* be present, so if the message length is already\n    congruent to 448 mod 512, then 512 padding bits must be added. */\n\n    var finalBlock = forge.util.createBuffer();\n    finalBlock.putBytes(_input.bytes());\n\n    // compute remaining size to be digested (include message length size)\n    var remaining = (\n      md.fullMessageLength[md.fullMessageLength.length - 1] +\n      md.messageLengthSize);\n\n    // add padding for overflow blockSize - overflow\n    // _padding starts with 1 byte with first bit is set (byte value 128), then\n    // there may be up to (blockSize - 1) other pad bytes\n    var overflow = remaining & (md.blockLength - 1);\n    finalBlock.putBytes(_padding.substr(0, md.blockLength - overflow));\n\n    // serialize message length in bits in big-endian order; since length\n    // is stored in bytes we multiply by 8 and add carry from next int\n    var next, carry;\n    var bits = md.fullMessageLength[0] * 8;\n    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {\n      next = md.fullMessageLength[i + 1] * 8;\n      carry = (next / 0x100000000) >>> 0;\n      bits += carry;\n      finalBlock.putInt32(bits >>> 0);\n      bits = next >>> 0;\n    }\n    finalBlock.putInt32(bits);\n\n    var s2 = {\n      h0: _state.h0,\n      h1: _state.h1,\n      h2: _state.h2,\n      h3: _state.h3,\n      h4: _state.h4\n    };\n    _update(s2, _w, finalBlock);\n    var rval = forge.util.createBuffer();\n    rval.putInt32(s2.h0);\n    rval.putInt32(s2.h1);\n    rval.putInt32(s2.h2);\n    rval.putInt32(s2.h3);\n    rval.putInt32(s2.h4);\n    return rval;\n  };\n\n  return md;\n};\n\n// sha-1 padding bytes not initialized yet\nvar _padding = null;\nvar _initialized = false;\n\n/**\n * Initializes the constant tables.\n */\nfunction _init() {\n  // create padding\n  _padding = String.fromCharCode(128);\n  _padding += forge.util.fillString(String.fromCharCode(0x00), 64);\n\n  // now initialized\n  _initialized = true;\n}\n\n/**\n * Updates a SHA-1 state with the given byte buffer.\n *\n * @param s the SHA-1 state to update.\n * @param w the array to use to store words.\n * @param bytes the byte buffer to update with.\n */\nfunction _update(s, w, bytes) {\n  // consume 512 bit (64 byte) chunks\n  var t, a, b, c, d, e, f, i;\n  var len = bytes.length();\n  while(len >= 64) {\n    // the w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 80 32-bit words according to SHA-1 algorithm\n    // and for 32-79 using Max Locktyukhin's optimization\n\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n\n    // round 1\n    for(i = 0; i < 16; ++i) {\n      t = bytes.getInt32();\n      w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n    for(; i < 20; ++i) {\n      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n    // round 2\n    for(; i < 32; ++i) {\n      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n    for(; i < 40; ++i) {\n      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n    // round 3\n    for(; i < 60; ++i) {\n      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      w[i] = t;\n      f = (b & c) | (d & (b ^ c));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x8F1BBCDC + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n    // round 4\n    for(; i < 80; ++i) {\n      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0xCA62C1D6 + t;\n      e = d;\n      d = c;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      c = ((b << 30) | (b >>> 2)) >>> 0;\n      b = a;\n      a = t;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n\n    len -= 64;\n  }\n}\n","/**\n * Secure Hash Algorithm with 256-bit digest (SHA-256) implementation.\n *\n * See FIPS 180-2 for details.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2015 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./md');\nrequire('./util');\n\nvar sha256 = module.exports = forge.sha256 = forge.sha256 || {};\nforge.md.sha256 = forge.md.algorithms.sha256 = sha256;\n\n/**\n * Creates a SHA-256 message digest object.\n *\n * @return a message digest object.\n */\nsha256.create = function() {\n  // do initialization as necessary\n  if(!_initialized) {\n    _init();\n  }\n\n  // SHA-256 state contains eight 32-bit integers\n  var _state = null;\n\n  // input buffer\n  var _input = forge.util.createBuffer();\n\n  // used for word storage\n  var _w = new Array(64);\n\n  // message digest object\n  var md = {\n    algorithm: 'sha256',\n    blockLength: 64,\n    digestLength: 32,\n    // 56-bit length of message so far (does not including padding)\n    messageLength: 0,\n    // true message length\n    fullMessageLength: null,\n    // size of message length in bytes\n    messageLengthSize: 8\n  };\n\n  /**\n   * Starts the digest.\n   *\n   * @return this digest object.\n   */\n  md.start = function() {\n    // up to 56-bit message length for convenience\n    md.messageLength = 0;\n\n    // full message length (set md.messageLength64 for backwards-compatibility)\n    md.fullMessageLength = md.messageLength64 = [];\n    var int32s = md.messageLengthSize / 4;\n    for(var i = 0; i < int32s; ++i) {\n      md.fullMessageLength.push(0);\n    }\n    _input = forge.util.createBuffer();\n    _state = {\n      h0: 0x6A09E667,\n      h1: 0xBB67AE85,\n      h2: 0x3C6EF372,\n      h3: 0xA54FF53A,\n      h4: 0x510E527F,\n      h5: 0x9B05688C,\n      h6: 0x1F83D9AB,\n      h7: 0x5BE0CD19\n    };\n    return md;\n  };\n  // start digest automatically for first time\n  md.start();\n\n  /**\n   * Updates the digest with the given message input. The given input can\n   * treated as raw input (no encoding will be applied) or an encoding of\n   * 'utf8' maybe given to encode the input using UTF-8.\n   *\n   * @param msg the message input to update with.\n   * @param encoding the encoding to use (default: 'raw', other: 'utf8').\n   *\n   * @return this digest object.\n   */\n  md.update = function(msg, encoding) {\n    if(encoding === 'utf8') {\n      msg = forge.util.encodeUtf8(msg);\n    }\n\n    // update message length\n    var len = msg.length;\n    md.messageLength += len;\n    len = [(len / 0x100000000) >>> 0, len >>> 0];\n    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {\n      md.fullMessageLength[i] += len[1];\n      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);\n      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;\n      len[0] = ((len[1] / 0x100000000) >>> 0);\n    }\n\n    // add bytes to input buffer\n    _input.putBytes(msg);\n\n    // process bytes\n    _update(_state, _w, _input);\n\n    // compact input buffer every 2K or if empty\n    if(_input.read > 2048 || _input.length() === 0) {\n      _input.compact();\n    }\n\n    return md;\n  };\n\n  /**\n   * Produces the digest.\n   *\n   * @return a byte buffer containing the digest value.\n   */\n  md.digest = function() {\n    /* Note: Here we copy the remaining bytes in the input buffer and\n    add the appropriate SHA-256 padding. Then we do the final update\n    on a copy of the state so that if the user wants to get\n    intermediate digests they can do so. */\n\n    /* Determine the number of bytes that must be added to the message\n    to ensure its length is congruent to 448 mod 512. In other words,\n    the data to be digested must be a multiple of 512 bits (or 128 bytes).\n    This data includes the message, some padding, and the length of the\n    message. Since the length of the message will be encoded as 8 bytes (64\n    bits), that means that the last segment of the data must have 56 bytes\n    (448 bits) of message and padding. Therefore, the length of the message\n    plus the padding must be congruent to 448 mod 512 because\n    512 - 128 = 448.\n\n    In order to fill up the message length it must be filled with\n    padding that begins with 1 bit followed by all 0 bits. Padding\n    must *always* be present, so if the message length is already\n    congruent to 448 mod 512, then 512 padding bits must be added. */\n\n    var finalBlock = forge.util.createBuffer();\n    finalBlock.putBytes(_input.bytes());\n\n    // compute remaining size to be digested (include message length size)\n    var remaining = (\n      md.fullMessageLength[md.fullMessageLength.length - 1] +\n      md.messageLengthSize);\n\n    // add padding for overflow blockSize - overflow\n    // _padding starts with 1 byte with first bit is set (byte value 128), then\n    // there may be up to (blockSize - 1) other pad bytes\n    var overflow = remaining & (md.blockLength - 1);\n    finalBlock.putBytes(_padding.substr(0, md.blockLength - overflow));\n\n    // serialize message length in bits in big-endian order; since length\n    // is stored in bytes we multiply by 8 and add carry from next int\n    var next, carry;\n    var bits = md.fullMessageLength[0] * 8;\n    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {\n      next = md.fullMessageLength[i + 1] * 8;\n      carry = (next / 0x100000000) >>> 0;\n      bits += carry;\n      finalBlock.putInt32(bits >>> 0);\n      bits = next >>> 0;\n    }\n    finalBlock.putInt32(bits);\n\n    var s2 = {\n      h0: _state.h0,\n      h1: _state.h1,\n      h2: _state.h2,\n      h3: _state.h3,\n      h4: _state.h4,\n      h5: _state.h5,\n      h6: _state.h6,\n      h7: _state.h7\n    };\n    _update(s2, _w, finalBlock);\n    var rval = forge.util.createBuffer();\n    rval.putInt32(s2.h0);\n    rval.putInt32(s2.h1);\n    rval.putInt32(s2.h2);\n    rval.putInt32(s2.h3);\n    rval.putInt32(s2.h4);\n    rval.putInt32(s2.h5);\n    rval.putInt32(s2.h6);\n    rval.putInt32(s2.h7);\n    return rval;\n  };\n\n  return md;\n};\n\n// sha-256 padding bytes not initialized yet\nvar _padding = null;\nvar _initialized = false;\n\n// table of constants\nvar _k = null;\n\n/**\n * Initializes the constant tables.\n */\nfunction _init() {\n  // create padding\n  _padding = String.fromCharCode(128);\n  _padding += forge.util.fillString(String.fromCharCode(0x00), 64);\n\n  // create K table for SHA-256\n  _k = [\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,\n    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,\n    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,\n    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,\n    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,\n    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,\n    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,\n    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,\n    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];\n\n  // now initialized\n  _initialized = true;\n}\n\n/**\n * Updates a SHA-256 state with the given byte buffer.\n *\n * @param s the SHA-256 state to update.\n * @param w the array to use to store words.\n * @param bytes the byte buffer to update with.\n */\nfunction _update(s, w, bytes) {\n  // consume 512 bit (64 byte) chunks\n  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;\n  var len = bytes.length();\n  while(len >= 64) {\n    // the w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 64 32-bit words according to SHA-256\n    for(i = 0; i < 16; ++i) {\n      w[i] = bytes.getInt32();\n    }\n    for(; i < 64; ++i) {\n      // XOR word 2 words ago rot right 17, rot right 19, shft right 10\n      t1 = w[i - 2];\n      t1 =\n        ((t1 >>> 17) | (t1 << 15)) ^\n        ((t1 >>> 19) | (t1 << 13)) ^\n        (t1 >>> 10);\n      // XOR word 15 words ago rot right 7, rot right 18, shft right 3\n      t2 = w[i - 15];\n      t2 =\n        ((t2 >>> 7) | (t2 << 25)) ^\n        ((t2 >>> 18) | (t2 << 14)) ^\n        (t2 >>> 3);\n      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32\n      w[i] = (t1 + w[i - 7] + t2 + w[i - 16]) | 0;\n    }\n\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n    f = s.h5;\n    g = s.h6;\n    h = s.h7;\n\n    // round function\n    for(i = 0; i < 64; ++i) {\n      // Sum1(e)\n      s1 =\n        ((e >>> 6) | (e << 26)) ^\n        ((e >>> 11) | (e << 21)) ^\n        ((e >>> 25) | (e << 7));\n      // Ch(e, f, g) (optimized the same way as SHA-1)\n      ch = g ^ (e & (f ^ g));\n      // Sum0(a)\n      s0 =\n        ((a >>> 2) | (a << 30)) ^\n        ((a >>> 13) | (a << 19)) ^\n        ((a >>> 22) | (a << 10));\n      // Maj(a, b, c) (optimized the same way as SHA-1)\n      maj = (a & b) | (c & (a ^ b));\n\n      // main algorithm\n      t1 = h + s1 + ch + _k[i] + w[i];\n      t2 = s0 + maj;\n      h = g;\n      g = f;\n      f = e;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      // can't truncate with `| 0`\n      e = (d + t1) >>> 0;\n      d = c;\n      c = b;\n      b = a;\n      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug\n      // can't truncate with `| 0`\n      a = (t1 + t2) >>> 0;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n    s.h5 = (s.h5 + f) | 0;\n    s.h6 = (s.h6 + g) | 0;\n    s.h7 = (s.h7 + h) | 0;\n    len -= 64;\n  }\n}\n","/**\n * Secure Hash Algorithm with a 1024-bit block size implementation.\n *\n * This includes: SHA-512, SHA-384, SHA-512/224, and SHA-512/256. For\n * SHA-256 (block size 512 bits), see sha256.js.\n *\n * See FIPS 180-4 for details.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2014-2015 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nrequire('./md');\nrequire('./util');\n\nvar sha512 = module.exports = forge.sha512 = forge.sha512 || {};\n\n// SHA-512\nforge.md.sha512 = forge.md.algorithms.sha512 = sha512;\n\n// SHA-384\nvar sha384 = forge.sha384 = forge.sha512.sha384 = forge.sha512.sha384 || {};\nsha384.create = function() {\n  return sha512.create('SHA-384');\n};\nforge.md.sha384 = forge.md.algorithms.sha384 = sha384;\n\n// SHA-512/256\nforge.sha512.sha256 = forge.sha512.sha256 || {\n  create: function() {\n    return sha512.create('SHA-512/256');\n  }\n};\nforge.md['sha512/256'] = forge.md.algorithms['sha512/256'] =\n  forge.sha512.sha256;\n\n// SHA-512/224\nforge.sha512.sha224 = forge.sha512.sha224 || {\n  create: function() {\n    return sha512.create('SHA-512/224');\n  }\n};\nforge.md['sha512/224'] = forge.md.algorithms['sha512/224'] =\n  forge.sha512.sha224;\n\n/**\n * Creates a SHA-2 message digest object.\n *\n * @param algorithm the algorithm to use (SHA-512, SHA-384, SHA-512/224,\n *          SHA-512/256).\n *\n * @return a message digest object.\n */\nsha512.create = function(algorithm) {\n  // do initialization as necessary\n  if(!_initialized) {\n    _init();\n  }\n\n  if(typeof algorithm === 'undefined') {\n    algorithm = 'SHA-512';\n  }\n\n  if(!(algorithm in _states)) {\n    throw new Error('Invalid SHA-512 algorithm: ' + algorithm);\n  }\n\n  // SHA-512 state contains eight 64-bit integers (each as two 32-bit ints)\n  var _state = _states[algorithm];\n  var _h = null;\n\n  // input buffer\n  var _input = forge.util.createBuffer();\n\n  // used for 64-bit word storage\n  var _w = new Array(80);\n  for(var wi = 0; wi < 80; ++wi) {\n    _w[wi] = new Array(2);\n  }\n\n  // determine digest length by algorithm name (default)\n  var digestLength = 64;\n  switch(algorithm) {\n    case 'SHA-384':\n      digestLength = 48;\n      break;\n    case 'SHA-512/256':\n      digestLength = 32;\n      break;\n    case 'SHA-512/224':\n      digestLength = 28;\n      break;\n  }\n\n  // message digest object\n  var md = {\n    // SHA-512 => sha512\n    algorithm: algorithm.replace('-', '').toLowerCase(),\n    blockLength: 128,\n    digestLength: digestLength,\n    // 56-bit length of message so far (does not including padding)\n    messageLength: 0,\n    // true message length\n    fullMessageLength: null,\n    // size of message length in bytes\n    messageLengthSize: 16\n  };\n\n  /**\n   * Starts the digest.\n   *\n   * @return this digest object.\n   */\n  md.start = function() {\n    // up to 56-bit message length for convenience\n    md.messageLength = 0;\n\n    // full message length (set md.messageLength128 for backwards-compatibility)\n    md.fullMessageLength = md.messageLength128 = [];\n    var int32s = md.messageLengthSize / 4;\n    for(var i = 0; i < int32s; ++i) {\n      md.fullMessageLength.push(0);\n    }\n    _input = forge.util.createBuffer();\n    _h = new Array(_state.length);\n    for(var i = 0; i < _state.length; ++i) {\n      _h[i] = _state[i].slice(0);\n    }\n    return md;\n  };\n  // start digest automatically for first time\n  md.start();\n\n  /**\n   * Updates the digest with the given message input. The given input can\n   * treated as raw input (no encoding will be applied) or an encoding of\n   * 'utf8' maybe given to encode the input using UTF-8.\n   *\n   * @param msg the message input to update with.\n   * @param encoding the encoding to use (default: 'raw', other: 'utf8').\n   *\n   * @return this digest object.\n   */\n  md.update = function(msg, encoding) {\n    if(encoding === 'utf8') {\n      msg = forge.util.encodeUtf8(msg);\n    }\n\n    // update message length\n    var len = msg.length;\n    md.messageLength += len;\n    len = [(len / 0x100000000) >>> 0, len >>> 0];\n    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {\n      md.fullMessageLength[i] += len[1];\n      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);\n      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;\n      len[0] = ((len[1] / 0x100000000) >>> 0);\n    }\n\n    // add bytes to input buffer\n    _input.putBytes(msg);\n\n    // process bytes\n    _update(_h, _w, _input);\n\n    // compact input buffer every 2K or if empty\n    if(_input.read > 2048 || _input.length() === 0) {\n      _input.compact();\n    }\n\n    return md;\n  };\n\n  /**\n   * Produces the digest.\n   *\n   * @return a byte buffer containing the digest value.\n   */\n  md.digest = function() {\n    /* Note: Here we copy the remaining bytes in the input buffer and\n    add the appropriate SHA-512 padding. Then we do the final update\n    on a copy of the state so that if the user wants to get\n    intermediate digests they can do so. */\n\n    /* Determine the number of bytes that must be added to the message\n    to ensure its length is congruent to 896 mod 1024. In other words,\n    the data to be digested must be a multiple of 1024 bits (or 128 bytes).\n    This data includes the message, some padding, and the length of the\n    message. Since the length of the message will be encoded as 16 bytes (128\n    bits), that means that the last segment of the data must have 112 bytes\n    (896 bits) of message and padding. Therefore, the length of the message\n    plus the padding must be congruent to 896 mod 1024 because\n    1024 - 128 = 896.\n\n    In order to fill up the message length it must be filled with\n    padding that begins with 1 bit followed by all 0 bits. Padding\n    must *always* be present, so if the message length is already\n    congruent to 896 mod 1024, then 1024 padding bits must be added. */\n\n    var finalBlock = forge.util.createBuffer();\n    finalBlock.putBytes(_input.bytes());\n\n    // compute remaining size to be digested (include message length size)\n    var remaining = (\n      md.fullMessageLength[md.fullMessageLength.length - 1] +\n      md.messageLengthSize);\n\n    // add padding for overflow blockSize - overflow\n    // _padding starts with 1 byte with first bit is set (byte value 128), then\n    // there may be up to (blockSize - 1) other pad bytes\n    var overflow = remaining & (md.blockLength - 1);\n    finalBlock.putBytes(_padding.substr(0, md.blockLength - overflow));\n\n    // serialize message length in bits in big-endian order; since length\n    // is stored in bytes we multiply by 8 and add carry from next int\n    var next, carry;\n    var bits = md.fullMessageLength[0] * 8;\n    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {\n      next = md.fullMessageLength[i + 1] * 8;\n      carry = (next / 0x100000000) >>> 0;\n      bits += carry;\n      finalBlock.putInt32(bits >>> 0);\n      bits = next >>> 0;\n    }\n    finalBlock.putInt32(bits);\n\n    var h = new Array(_h.length);\n    for(var i = 0; i < _h.length; ++i) {\n      h[i] = _h[i].slice(0);\n    }\n    _update(h, _w, finalBlock);\n    var rval = forge.util.createBuffer();\n    var hlen;\n    if(algorithm === 'SHA-512') {\n      hlen = h.length;\n    } else if(algorithm === 'SHA-384') {\n      hlen = h.length - 2;\n    } else {\n      hlen = h.length - 4;\n    }\n    for(var i = 0; i < hlen; ++i) {\n      rval.putInt32(h[i][0]);\n      if(i !== hlen - 1 || algorithm !== 'SHA-512/224') {\n        rval.putInt32(h[i][1]);\n      }\n    }\n    return rval;\n  };\n\n  return md;\n};\n\n// sha-512 padding bytes not initialized yet\nvar _padding = null;\nvar _initialized = false;\n\n// table of constants\nvar _k = null;\n\n// initial hash states\nvar _states = null;\n\n/**\n * Initializes the constant tables.\n */\nfunction _init() {\n  // create padding\n  _padding = String.fromCharCode(128);\n  _padding += forge.util.fillString(String.fromCharCode(0x00), 128);\n\n  // create K table for SHA-512\n  _k = [\n    [0x428a2f98, 0xd728ae22], [0x71374491, 0x23ef65cd],\n    [0xb5c0fbcf, 0xec4d3b2f], [0xe9b5dba5, 0x8189dbbc],\n    [0x3956c25b, 0xf348b538], [0x59f111f1, 0xb605d019],\n    [0x923f82a4, 0xaf194f9b], [0xab1c5ed5, 0xda6d8118],\n    [0xd807aa98, 0xa3030242], [0x12835b01, 0x45706fbe],\n    [0x243185be, 0x4ee4b28c], [0x550c7dc3, 0xd5ffb4e2],\n    [0x72be5d74, 0xf27b896f], [0x80deb1fe, 0x3b1696b1],\n    [0x9bdc06a7, 0x25c71235], [0xc19bf174, 0xcf692694],\n    [0xe49b69c1, 0x9ef14ad2], [0xefbe4786, 0x384f25e3],\n    [0x0fc19dc6, 0x8b8cd5b5], [0x240ca1cc, 0x77ac9c65],\n    [0x2de92c6f, 0x592b0275], [0x4a7484aa, 0x6ea6e483],\n    [0x5cb0a9dc, 0xbd41fbd4], [0x76f988da, 0x831153b5],\n    [0x983e5152, 0xee66dfab], [0xa831c66d, 0x2db43210],\n    [0xb00327c8, 0x98fb213f], [0xbf597fc7, 0xbeef0ee4],\n    [0xc6e00bf3, 0x3da88fc2], [0xd5a79147, 0x930aa725],\n    [0x06ca6351, 0xe003826f], [0x14292967, 0x0a0e6e70],\n    [0x27b70a85, 0x46d22ffc], [0x2e1b2138, 0x5c26c926],\n    [0x4d2c6dfc, 0x5ac42aed], [0x53380d13, 0x9d95b3df],\n    [0x650a7354, 0x8baf63de], [0x766a0abb, 0x3c77b2a8],\n    [0x81c2c92e, 0x47edaee6], [0x92722c85, 0x1482353b],\n    [0xa2bfe8a1, 0x4cf10364], [0xa81a664b, 0xbc423001],\n    [0xc24b8b70, 0xd0f89791], [0xc76c51a3, 0x0654be30],\n    [0xd192e819, 0xd6ef5218], [0xd6990624, 0x5565a910],\n    [0xf40e3585, 0x5771202a], [0x106aa070, 0x32bbd1b8],\n    [0x19a4c116, 0xb8d2d0c8], [0x1e376c08, 0x5141ab53],\n    [0x2748774c, 0xdf8eeb99], [0x34b0bcb5, 0xe19b48a8],\n    [0x391c0cb3, 0xc5c95a63], [0x4ed8aa4a, 0xe3418acb],\n    [0x5b9cca4f, 0x7763e373], [0x682e6ff3, 0xd6b2b8a3],\n    [0x748f82ee, 0x5defb2fc], [0x78a5636f, 0x43172f60],\n    [0x84c87814, 0xa1f0ab72], [0x8cc70208, 0x1a6439ec],\n    [0x90befffa, 0x23631e28], [0xa4506ceb, 0xde82bde9],\n    [0xbef9a3f7, 0xb2c67915], [0xc67178f2, 0xe372532b],\n    [0xca273ece, 0xea26619c], [0xd186b8c7, 0x21c0c207],\n    [0xeada7dd6, 0xcde0eb1e], [0xf57d4f7f, 0xee6ed178],\n    [0x06f067aa, 0x72176fba], [0x0a637dc5, 0xa2c898a6],\n    [0x113f9804, 0xbef90dae], [0x1b710b35, 0x131c471b],\n    [0x28db77f5, 0x23047d84], [0x32caab7b, 0x40c72493],\n    [0x3c9ebe0a, 0x15c9bebc], [0x431d67c4, 0x9c100d4c],\n    [0x4cc5d4be, 0xcb3e42b6], [0x597f299c, 0xfc657e2a],\n    [0x5fcb6fab, 0x3ad6faec], [0x6c44198c, 0x4a475817]\n  ];\n\n  // initial hash states\n  _states = {};\n  _states['SHA-512'] = [\n    [0x6a09e667, 0xf3bcc908],\n    [0xbb67ae85, 0x84caa73b],\n    [0x3c6ef372, 0xfe94f82b],\n    [0xa54ff53a, 0x5f1d36f1],\n    [0x510e527f, 0xade682d1],\n    [0x9b05688c, 0x2b3e6c1f],\n    [0x1f83d9ab, 0xfb41bd6b],\n    [0x5be0cd19, 0x137e2179]\n  ];\n  _states['SHA-384'] = [\n    [0xcbbb9d5d, 0xc1059ed8],\n    [0x629a292a, 0x367cd507],\n    [0x9159015a, 0x3070dd17],\n    [0x152fecd8, 0xf70e5939],\n    [0x67332667, 0xffc00b31],\n    [0x8eb44a87, 0x68581511],\n    [0xdb0c2e0d, 0x64f98fa7],\n    [0x47b5481d, 0xbefa4fa4]\n  ];\n  _states['SHA-512/256'] = [\n    [0x22312194, 0xFC2BF72C],\n    [0x9F555FA3, 0xC84C64C2],\n    [0x2393B86B, 0x6F53B151],\n    [0x96387719, 0x5940EABD],\n    [0x96283EE2, 0xA88EFFE3],\n    [0xBE5E1E25, 0x53863992],\n    [0x2B0199FC, 0x2C85B8AA],\n    [0x0EB72DDC, 0x81C52CA2]\n  ];\n  _states['SHA-512/224'] = [\n    [0x8C3D37C8, 0x19544DA2],\n    [0x73E19966, 0x89DCD4D6],\n    [0x1DFAB7AE, 0x32FF9C82],\n    [0x679DD514, 0x582F9FCF],\n    [0x0F6D2B69, 0x7BD44DA8],\n    [0x77E36F73, 0x04C48942],\n    [0x3F9D85A8, 0x6A1D36C8],\n    [0x1112E6AD, 0x91D692A1]\n  ];\n\n  // now initialized\n  _initialized = true;\n}\n\n/**\n * Updates a SHA-512 state with the given byte buffer.\n *\n * @param s the SHA-512 state to update.\n * @param w the array to use to store words.\n * @param bytes the byte buffer to update with.\n */\nfunction _update(s, w, bytes) {\n  // consume 512 bit (128 byte) chunks\n  var t1_hi, t1_lo;\n  var t2_hi, t2_lo;\n  var s0_hi, s0_lo;\n  var s1_hi, s1_lo;\n  var ch_hi, ch_lo;\n  var maj_hi, maj_lo;\n  var a_hi, a_lo;\n  var b_hi, b_lo;\n  var c_hi, c_lo;\n  var d_hi, d_lo;\n  var e_hi, e_lo;\n  var f_hi, f_lo;\n  var g_hi, g_lo;\n  var h_hi, h_lo;\n  var i, hi, lo, w2, w7, w15, w16;\n  var len = bytes.length();\n  while(len >= 128) {\n    // the w array will be populated with sixteen 64-bit big-endian words\n    // and then extended into 64 64-bit words according to SHA-512\n    for(i = 0; i < 16; ++i) {\n      w[i][0] = bytes.getInt32() >>> 0;\n      w[i][1] = bytes.getInt32() >>> 0;\n    }\n    for(; i < 80; ++i) {\n      // for word 2 words ago: ROTR 19(x) ^ ROTR 61(x) ^ SHR 6(x)\n      w2 = w[i - 2];\n      hi = w2[0];\n      lo = w2[1];\n\n      // high bits\n      t1_hi = (\n        ((hi >>> 19) | (lo << 13)) ^ // ROTR 19\n        ((lo >>> 29) | (hi << 3)) ^ // ROTR 61/(swap + ROTR 29)\n        (hi >>> 6)) >>> 0; // SHR 6\n      // low bits\n      t1_lo = (\n        ((hi << 13) | (lo >>> 19)) ^ // ROTR 19\n        ((lo << 3) | (hi >>> 29)) ^ // ROTR 61/(swap + ROTR 29)\n        ((hi << 26) | (lo >>> 6))) >>> 0; // SHR 6\n\n      // for word 15 words ago: ROTR 1(x) ^ ROTR 8(x) ^ SHR 7(x)\n      w15 = w[i - 15];\n      hi = w15[0];\n      lo = w15[1];\n\n      // high bits\n      t2_hi = (\n        ((hi >>> 1) | (lo << 31)) ^ // ROTR 1\n        ((hi >>> 8) | (lo << 24)) ^ // ROTR 8\n        (hi >>> 7)) >>> 0; // SHR 7\n      // low bits\n      t2_lo = (\n        ((hi << 31) | (lo >>> 1)) ^ // ROTR 1\n        ((hi << 24) | (lo >>> 8)) ^ // ROTR 8\n        ((hi << 25) | (lo >>> 7))) >>> 0; // SHR 7\n\n      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^64 (carry lo overflow)\n      w7 = w[i - 7];\n      w16 = w[i - 16];\n      lo = (t1_lo + w7[1] + t2_lo + w16[1]);\n      w[i][0] = (t1_hi + w7[0] + t2_hi + w16[0] +\n        ((lo / 0x100000000) >>> 0)) >>> 0;\n      w[i][1] = lo >>> 0;\n    }\n\n    // initialize hash value for this chunk\n    a_hi = s[0][0];\n    a_lo = s[0][1];\n    b_hi = s[1][0];\n    b_lo = s[1][1];\n    c_hi = s[2][0];\n    c_lo = s[2][1];\n    d_hi = s[3][0];\n    d_lo = s[3][1];\n    e_hi = s[4][0];\n    e_lo = s[4][1];\n    f_hi = s[5][0];\n    f_lo = s[5][1];\n    g_hi = s[6][0];\n    g_lo = s[6][1];\n    h_hi = s[7][0];\n    h_lo = s[7][1];\n\n    // round function\n    for(i = 0; i < 80; ++i) {\n      // Sum1(e) = ROTR 14(e) ^ ROTR 18(e) ^ ROTR 41(e)\n      s1_hi = (\n        ((e_hi >>> 14) | (e_lo << 18)) ^ // ROTR 14\n        ((e_hi >>> 18) | (e_lo << 14)) ^ // ROTR 18\n        ((e_lo >>> 9) | (e_hi << 23))) >>> 0; // ROTR 41/(swap + ROTR 9)\n      s1_lo = (\n        ((e_hi << 18) | (e_lo >>> 14)) ^ // ROTR 14\n        ((e_hi << 14) | (e_lo >>> 18)) ^ // ROTR 18\n        ((e_lo << 23) | (e_hi >>> 9))) >>> 0; // ROTR 41/(swap + ROTR 9)\n\n      // Ch(e, f, g) (optimized the same way as SHA-1)\n      ch_hi = (g_hi ^ (e_hi & (f_hi ^ g_hi))) >>> 0;\n      ch_lo = (g_lo ^ (e_lo & (f_lo ^ g_lo))) >>> 0;\n\n      // Sum0(a) = ROTR 28(a) ^ ROTR 34(a) ^ ROTR 39(a)\n      s0_hi = (\n        ((a_hi >>> 28) | (a_lo << 4)) ^ // ROTR 28\n        ((a_lo >>> 2) | (a_hi << 30)) ^ // ROTR 34/(swap + ROTR 2)\n        ((a_lo >>> 7) | (a_hi << 25))) >>> 0; // ROTR 39/(swap + ROTR 7)\n      s0_lo = (\n        ((a_hi << 4) | (a_lo >>> 28)) ^ // ROTR 28\n        ((a_lo << 30) | (a_hi >>> 2)) ^ // ROTR 34/(swap + ROTR 2)\n        ((a_lo << 25) | (a_hi >>> 7))) >>> 0; // ROTR 39/(swap + ROTR 7)\n\n      // Maj(a, b, c) (optimized the same way as SHA-1)\n      maj_hi = ((a_hi & b_hi) | (c_hi & (a_hi ^ b_hi))) >>> 0;\n      maj_lo = ((a_lo & b_lo) | (c_lo & (a_lo ^ b_lo))) >>> 0;\n\n      // main algorithm\n      // t1 = (h + s1 + ch + _k[i] + _w[i]) modulo 2^64 (carry lo overflow)\n      lo = (h_lo + s1_lo + ch_lo + _k[i][1] + w[i][1]);\n      t1_hi = (h_hi + s1_hi + ch_hi + _k[i][0] + w[i][0] +\n        ((lo / 0x100000000) >>> 0)) >>> 0;\n      t1_lo = lo >>> 0;\n\n      // t2 = s0 + maj modulo 2^64 (carry lo overflow)\n      lo = s0_lo + maj_lo;\n      t2_hi = (s0_hi + maj_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n      t2_lo = lo >>> 0;\n\n      h_hi = g_hi;\n      h_lo = g_lo;\n\n      g_hi = f_hi;\n      g_lo = f_lo;\n\n      f_hi = e_hi;\n      f_lo = e_lo;\n\n      // e = (d + t1) modulo 2^64 (carry lo overflow)\n      lo = d_lo + t1_lo;\n      e_hi = (d_hi + t1_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n      e_lo = lo >>> 0;\n\n      d_hi = c_hi;\n      d_lo = c_lo;\n\n      c_hi = b_hi;\n      c_lo = b_lo;\n\n      b_hi = a_hi;\n      b_lo = a_lo;\n\n      // a = (t1 + t2) modulo 2^64 (carry lo overflow)\n      lo = t1_lo + t2_lo;\n      a_hi = (t1_hi + t2_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n      a_lo = lo >>> 0;\n    }\n\n    // update hash state (additional modulo 2^64)\n    lo = s[0][1] + a_lo;\n    s[0][0] = (s[0][0] + a_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[0][1] = lo >>> 0;\n\n    lo = s[1][1] + b_lo;\n    s[1][0] = (s[1][0] + b_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[1][1] = lo >>> 0;\n\n    lo = s[2][1] + c_lo;\n    s[2][0] = (s[2][0] + c_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[2][1] = lo >>> 0;\n\n    lo = s[3][1] + d_lo;\n    s[3][0] = (s[3][0] + d_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[3][1] = lo >>> 0;\n\n    lo = s[4][1] + e_lo;\n    s[4][0] = (s[4][0] + e_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[4][1] = lo >>> 0;\n\n    lo = s[5][1] + f_lo;\n    s[5][0] = (s[5][0] + f_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[5][1] = lo >>> 0;\n\n    lo = s[6][1] + g_lo;\n    s[6][0] = (s[6][0] + g_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[6][1] = lo >>> 0;\n\n    lo = s[7][1] + h_lo;\n    s[7][0] = (s[7][0] + h_hi + ((lo / 0x100000000) >>> 0)) >>> 0;\n    s[7][1] = lo >>> 0;\n\n    len -= 128;\n  }\n}\n","/**\n * Utility functions for web applications.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2018 Digital Bazaar, Inc.\n */\nvar forge = require('./forge');\nvar baseN = require('./baseN');\n\n/* Utilities API */\nvar util = module.exports = forge.util = forge.util || {};\n\n// define setImmediate and nextTick\n(function() {\n  // use native nextTick (unless we're in webpack)\n  // webpack (or better node-libs-browser polyfill) sets process.browser.\n  // this way we can detect webpack properly\n  if(typeof process !== 'undefined' && process.nextTick && !process.browser) {\n    util.nextTick = process.nextTick;\n    if(typeof setImmediate === 'function') {\n      util.setImmediate = setImmediate;\n    } else {\n      // polyfill setImmediate with nextTick, older versions of node\n      // (those w/o setImmediate) won't totally starve IO\n      util.setImmediate = util.nextTick;\n    }\n    return;\n  }\n\n  // polyfill nextTick with native setImmediate\n  if(typeof setImmediate === 'function') {\n    util.setImmediate = function() { return setImmediate.apply(undefined, arguments); };\n    util.nextTick = function(callback) {\n      return setImmediate(callback);\n    };\n    return;\n  }\n\n  /* Note: A polyfill upgrade pattern is used here to allow combining\n  polyfills. For example, MutationObserver is fast, but blocks UI updates,\n  so it needs to allow UI updates periodically, so it falls back on\n  postMessage or setTimeout. */\n\n  // polyfill with setTimeout\n  util.setImmediate = function(callback) {\n    setTimeout(callback, 0);\n  };\n\n  // upgrade polyfill to use postMessage\n  if(typeof window !== 'undefined' &&\n    typeof window.postMessage === 'function') {\n    var msg = 'forge.setImmediate';\n    var callbacks = [];\n    util.setImmediate = function(callback) {\n      callbacks.push(callback);\n      // only send message when one hasn't been sent in\n      // the current turn of the event loop\n      if(callbacks.length === 1) {\n        window.postMessage(msg, '*');\n      }\n    };\n    function handler(event) {\n      if(event.source === window && event.data === msg) {\n        event.stopPropagation();\n        var copy = callbacks.slice();\n        callbacks.length = 0;\n        copy.forEach(function(callback) {\n          callback();\n        });\n      }\n    }\n    window.addEventListener('message', handler, true);\n  }\n\n  // upgrade polyfill to use MutationObserver\n  if(typeof MutationObserver !== 'undefined') {\n    // polyfill with MutationObserver\n    var now = Date.now();\n    var attr = true;\n    var div = document.createElement('div');\n    var callbacks = [];\n    new MutationObserver(function() {\n      var copy = callbacks.slice();\n      callbacks.length = 0;\n      copy.forEach(function(callback) {\n        callback();\n      });\n    }).observe(div, {attributes: true});\n    var oldSetImmediate = util.setImmediate;\n    util.setImmediate = function(callback) {\n      if(Date.now() - now > 15) {\n        now = Date.now();\n        oldSetImmediate(callback);\n      } else {\n        callbacks.push(callback);\n        // only trigger observer when it hasn't been triggered in\n        // the current turn of the event loop\n        if(callbacks.length === 1) {\n          div.setAttribute('a', attr = !attr);\n        }\n      }\n    };\n  }\n\n  util.nextTick = util.setImmediate;\n})();\n\n// check if running under Node.js\nutil.isNodejs =\n  typeof process !== 'undefined' && process.versions && process.versions.node;\n\n\n// 'self' will also work in Web Workers (instance of WorkerGlobalScope) while\n// it will point to `window` in the main thread.\n// To remain compatible with older browsers, we fall back to 'window' if 'self'\n// is not available.\nutil.globalScope = (function() {\n  if(util.isNodejs) {\n    return global;\n  }\n\n  return typeof self === 'undefined' ? window : self;\n})();\n\n// define isArray\nutil.isArray = Array.isArray || function(x) {\n  return Object.prototype.toString.call(x) === '[object Array]';\n};\n\n// define isArrayBuffer\nutil.isArrayBuffer = function(x) {\n  return typeof ArrayBuffer !== 'undefined' && x instanceof ArrayBuffer;\n};\n\n// define isArrayBufferView\nutil.isArrayBufferView = function(x) {\n  return x && util.isArrayBuffer(x.buffer) && x.byteLength !== undefined;\n};\n\n/**\n * Ensure a bits param is 8, 16, 24, or 32. Used to validate input for\n * algorithms where bit manipulation, JavaScript limitations, and/or algorithm\n * design only allow for byte operations of a limited size.\n *\n * @param n number of bits.\n *\n * Throw Error if n invalid.\n */\nfunction _checkBitsParam(n) {\n  if(!(n === 8 || n === 16 || n === 24 || n === 32)) {\n    throw new Error('Only 8, 16, 24, or 32 bits supported: ' + n);\n  }\n}\n\n// TODO: set ByteBuffer to best available backing\nutil.ByteBuffer = ByteStringBuffer;\n\n/** Buffer w/BinaryString backing */\n\n/**\n * Constructor for a binary string backed byte buffer.\n *\n * @param [b] the bytes to wrap (either encoded as string, one byte per\n *          character, or as an ArrayBuffer or Typed Array).\n */\nfunction ByteStringBuffer(b) {\n  // TODO: update to match DataBuffer API\n\n  // the data in this buffer\n  this.data = '';\n  // the pointer for reading from this buffer\n  this.read = 0;\n\n  if(typeof b === 'string') {\n    this.data = b;\n  } else if(util.isArrayBuffer(b) || util.isArrayBufferView(b)) {\n    if(typeof Buffer !== 'undefined' && b instanceof Buffer) {\n      this.data = b.toString('binary');\n    } else {\n      // convert native buffer to forge buffer\n      // FIXME: support native buffers internally instead\n      var arr = new Uint8Array(b);\n      try {\n        this.data = String.fromCharCode.apply(null, arr);\n      } catch(e) {\n        for(var i = 0; i < arr.length; ++i) {\n          this.putByte(arr[i]);\n        }\n      }\n    }\n  } else if(b instanceof ByteStringBuffer ||\n    (typeof b === 'object' && typeof b.data === 'string' &&\n    typeof b.read === 'number')) {\n    // copy existing buffer\n    this.data = b.data;\n    this.read = b.read;\n  }\n\n  // used for v8 optimization\n  this._constructedStringLength = 0;\n}\nutil.ByteStringBuffer = ByteStringBuffer;\n\n/* Note: This is an optimization for V8-based browsers. When V8 concatenates\n  a string, the strings are only joined logically using a \"cons string\" or\n  \"constructed/concatenated string\". These containers keep references to one\n  another and can result in very large memory usage. For example, if a 2MB\n  string is constructed by concatenating 4 bytes together at a time, the\n  memory usage will be ~44MB; so ~22x increase. The strings are only joined\n  together when an operation requiring their joining takes place, such as\n  substr(). This function is called when adding data to this buffer to ensure\n  these types of strings are periodically joined to reduce the memory\n  footprint. */\nvar _MAX_CONSTRUCTED_STRING_LENGTH = 4096;\nutil.ByteStringBuffer.prototype._optimizeConstructedString = function(x) {\n  this._constructedStringLength += x;\n  if(this._constructedStringLength > _MAX_CONSTRUCTED_STRING_LENGTH) {\n    // this substr() should cause the constructed string to join\n    this.data.substr(0, 1);\n    this._constructedStringLength = 0;\n  }\n};\n\n/**\n * Gets the number of bytes in this buffer.\n *\n * @return the number of bytes in this buffer.\n */\nutil.ByteStringBuffer.prototype.length = function() {\n  return this.data.length - this.read;\n};\n\n/**\n * Gets whether or not this buffer is empty.\n *\n * @return true if this buffer is empty, false if not.\n */\nutil.ByteStringBuffer.prototype.isEmpty = function() {\n  return this.length() <= 0;\n};\n\n/**\n * Puts a byte in this buffer.\n *\n * @param b the byte to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putByte = function(b) {\n  return this.putBytes(String.fromCharCode(b));\n};\n\n/**\n * Puts a byte in this buffer N times.\n *\n * @param b the byte to put.\n * @param n the number of bytes of value b to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.fillWithByte = function(b, n) {\n  b = String.fromCharCode(b);\n  var d = this.data;\n  while(n > 0) {\n    if(n & 1) {\n      d += b;\n    }\n    n >>>= 1;\n    if(n > 0) {\n      b += b;\n    }\n  }\n  this.data = d;\n  this._optimizeConstructedString(n);\n  return this;\n};\n\n/**\n * Puts bytes in this buffer.\n *\n * @param bytes the bytes (as a binary encoded string) to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putBytes = function(bytes) {\n  this.data += bytes;\n  this._optimizeConstructedString(bytes.length);\n  return this;\n};\n\n/**\n * Puts a UTF-16 encoded string into this buffer.\n *\n * @param str the string to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putString = function(str) {\n  return this.putBytes(util.encodeUtf8(str));\n};\n\n/**\n * Puts a 16-bit integer in this buffer in big-endian order.\n *\n * @param i the 16-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt16 = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n/**\n * Puts a 24-bit integer in this buffer in big-endian order.\n *\n * @param i the 24-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt24 = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n/**\n * Puts a 32-bit integer in this buffer in big-endian order.\n *\n * @param i the 32-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt32 = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i >> 24 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n/**\n * Puts a 16-bit integer in this buffer in little-endian order.\n *\n * @param i the 16-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt16Le = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF));\n};\n\n/**\n * Puts a 24-bit integer in this buffer in little-endian order.\n *\n * @param i the 24-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt24Le = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF));\n};\n\n/**\n * Puts a 32-bit integer in this buffer in little-endian order.\n *\n * @param i the 32-bit integer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt32Le = function(i) {\n  return this.putBytes(\n    String.fromCharCode(i & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 24 & 0xFF));\n};\n\n/**\n * Puts an n-bit integer in this buffer in big-endian order.\n *\n * @param i the n-bit integer.\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putInt = function(i, n) {\n  _checkBitsParam(n);\n  var bytes = '';\n  do {\n    n -= 8;\n    bytes += String.fromCharCode((i >> n) & 0xFF);\n  } while(n > 0);\n  return this.putBytes(bytes);\n};\n\n/**\n * Puts a signed n-bit integer in this buffer in big-endian order. Two's\n * complement representation is used.\n *\n * @param i the n-bit integer.\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putSignedInt = function(i, n) {\n  // putInt checks n\n  if(i < 0) {\n    i += 2 << (n - 1);\n  }\n  return this.putInt(i, n);\n};\n\n/**\n * Puts the given buffer into this buffer.\n *\n * @param buffer the buffer to put into this one.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.putBuffer = function(buffer) {\n  return this.putBytes(buffer.getBytes());\n};\n\n/**\n * Gets a byte from this buffer and advances the read pointer by 1.\n *\n * @return the byte.\n */\nutil.ByteStringBuffer.prototype.getByte = function() {\n  return this.data.charCodeAt(this.read++);\n};\n\n/**\n * Gets a uint16 from this buffer in big-endian order and advances the read\n * pointer by 2.\n *\n * @return the uint16.\n */\nutil.ByteStringBuffer.prototype.getInt16 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 8 ^\n    this.data.charCodeAt(this.read + 1));\n  this.read += 2;\n  return rval;\n};\n\n/**\n * Gets a uint24 from this buffer in big-endian order and advances the read\n * pointer by 3.\n *\n * @return the uint24.\n */\nutil.ByteStringBuffer.prototype.getInt24 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 16 ^\n    this.data.charCodeAt(this.read + 1) << 8 ^\n    this.data.charCodeAt(this.read + 2));\n  this.read += 3;\n  return rval;\n};\n\n/**\n * Gets a uint32 from this buffer in big-endian order and advances the read\n * pointer by 4.\n *\n * @return the word.\n */\nutil.ByteStringBuffer.prototype.getInt32 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 24 ^\n    this.data.charCodeAt(this.read + 1) << 16 ^\n    this.data.charCodeAt(this.read + 2) << 8 ^\n    this.data.charCodeAt(this.read + 3));\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Gets a uint16 from this buffer in little-endian order and advances the read\n * pointer by 2.\n *\n * @return the uint16.\n */\nutil.ByteStringBuffer.prototype.getInt16Le = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) ^\n    this.data.charCodeAt(this.read + 1) << 8);\n  this.read += 2;\n  return rval;\n};\n\n/**\n * Gets a uint24 from this buffer in little-endian order and advances the read\n * pointer by 3.\n *\n * @return the uint24.\n */\nutil.ByteStringBuffer.prototype.getInt24Le = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) ^\n    this.data.charCodeAt(this.read + 1) << 8 ^\n    this.data.charCodeAt(this.read + 2) << 16);\n  this.read += 3;\n  return rval;\n};\n\n/**\n * Gets a uint32 from this buffer in little-endian order and advances the read\n * pointer by 4.\n *\n * @return the word.\n */\nutil.ByteStringBuffer.prototype.getInt32Le = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) ^\n    this.data.charCodeAt(this.read + 1) << 8 ^\n    this.data.charCodeAt(this.read + 2) << 16 ^\n    this.data.charCodeAt(this.read + 3) << 24);\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Gets an n-bit integer from this buffer in big-endian order and advances the\n * read pointer by ceil(n/8).\n *\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return the integer.\n */\nutil.ByteStringBuffer.prototype.getInt = function(n) {\n  _checkBitsParam(n);\n  var rval = 0;\n  do {\n    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.\n    rval = (rval << 8) + this.data.charCodeAt(this.read++);\n    n -= 8;\n  } while(n > 0);\n  return rval;\n};\n\n/**\n * Gets a signed n-bit integer from this buffer in big-endian order, using\n * two's complement, and advances the read pointer by n/8.\n *\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return the integer.\n */\nutil.ByteStringBuffer.prototype.getSignedInt = function(n) {\n  // getInt checks n\n  var x = this.getInt(n);\n  var max = 2 << (n - 2);\n  if(x >= max) {\n    x -= max << 1;\n  }\n  return x;\n};\n\n/**\n * Reads bytes out as a binary encoded string and clears them from the\n * buffer. Note that the resulting string is binary encoded (in node.js this\n * encoding is referred to as `binary`, it is *not* `utf8`).\n *\n * @param count the number of bytes to read, undefined or null for all.\n *\n * @return a binary encoded string of bytes.\n */\nutil.ByteStringBuffer.prototype.getBytes = function(count) {\n  var rval;\n  if(count) {\n    // read count bytes\n    count = Math.min(this.length(), count);\n    rval = this.data.slice(this.read, this.read + count);\n    this.read += count;\n  } else if(count === 0) {\n    rval = '';\n  } else {\n    // read all bytes, optimize to only copy when needed\n    rval = (this.read === 0) ? this.data : this.data.slice(this.read);\n    this.clear();\n  }\n  return rval;\n};\n\n/**\n * Gets a binary encoded string of the bytes from this buffer without\n * modifying the read pointer.\n *\n * @param count the number of bytes to get, omit to get all.\n *\n * @return a string full of binary encoded characters.\n */\nutil.ByteStringBuffer.prototype.bytes = function(count) {\n  return (typeof(count) === 'undefined' ?\n    this.data.slice(this.read) :\n    this.data.slice(this.read, this.read + count));\n};\n\n/**\n * Gets a byte at the given index without modifying the read pointer.\n *\n * @param i the byte index.\n *\n * @return the byte.\n */\nutil.ByteStringBuffer.prototype.at = function(i) {\n  return this.data.charCodeAt(this.read + i);\n};\n\n/**\n * Puts a byte at the given index without modifying the read pointer.\n *\n * @param i the byte index.\n * @param b the byte to put.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.setAt = function(i, b) {\n  this.data = this.data.substr(0, this.read + i) +\n    String.fromCharCode(b) +\n    this.data.substr(this.read + i + 1);\n  return this;\n};\n\n/**\n * Gets the last byte without modifying the read pointer.\n *\n * @return the last byte.\n */\nutil.ByteStringBuffer.prototype.last = function() {\n  return this.data.charCodeAt(this.data.length - 1);\n};\n\n/**\n * Creates a copy of this buffer.\n *\n * @return the copy.\n */\nutil.ByteStringBuffer.prototype.copy = function() {\n  var c = util.createBuffer(this.data);\n  c.read = this.read;\n  return c;\n};\n\n/**\n * Compacts this buffer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.compact = function() {\n  if(this.read > 0) {\n    this.data = this.data.slice(this.read);\n    this.read = 0;\n  }\n  return this;\n};\n\n/**\n * Clears this buffer.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.clear = function() {\n  this.data = '';\n  this.read = 0;\n  return this;\n};\n\n/**\n * Shortens this buffer by triming bytes off of the end of this buffer.\n *\n * @param count the number of bytes to trim off.\n *\n * @return this buffer.\n */\nutil.ByteStringBuffer.prototype.truncate = function(count) {\n  var len = Math.max(0, this.length() - count);\n  this.data = this.data.substr(this.read, len);\n  this.read = 0;\n  return this;\n};\n\n/**\n * Converts this buffer to a hexadecimal string.\n *\n * @return a hexadecimal string.\n */\nutil.ByteStringBuffer.prototype.toHex = function() {\n  var rval = '';\n  for(var i = this.read; i < this.data.length; ++i) {\n    var b = this.data.charCodeAt(i);\n    if(b < 16) {\n      rval += '0';\n    }\n    rval += b.toString(16);\n  }\n  return rval;\n};\n\n/**\n * Converts this buffer to a UTF-16 string (standard JavaScript string).\n *\n * @return a UTF-16 string.\n */\nutil.ByteStringBuffer.prototype.toString = function() {\n  return util.decodeUtf8(this.bytes());\n};\n\n/** End Buffer w/BinaryString backing */\n\n/** Buffer w/UInt8Array backing */\n\n/**\n * FIXME: Experimental. Do not use yet.\n *\n * Constructor for an ArrayBuffer-backed byte buffer.\n *\n * The buffer may be constructed from a string, an ArrayBuffer, DataView, or a\n * TypedArray.\n *\n * If a string is given, its encoding should be provided as an option,\n * otherwise it will default to 'binary'. A 'binary' string is encoded such\n * that each character is one byte in length and size.\n *\n * If an ArrayBuffer, DataView, or TypedArray is given, it will be used\n * *directly* without any copying. Note that, if a write to the buffer requires\n * more space, the buffer will allocate a new backing ArrayBuffer to\n * accommodate. The starting read and write offsets for the buffer may be\n * given as options.\n *\n * @param [b] the initial bytes for this buffer.\n * @param options the options to use:\n *          [readOffset] the starting read offset to use (default: 0).\n *          [writeOffset] the starting write offset to use (default: the\n *            length of the first parameter).\n *          [growSize] the minimum amount, in bytes, to grow the buffer by to\n *            accommodate writes (default: 1024).\n *          [encoding] the encoding ('binary', 'utf8', 'utf16', 'hex') for the\n *            first parameter, if it is a string (default: 'binary').\n */\nfunction DataBuffer(b, options) {\n  // default options\n  options = options || {};\n\n  // pointers for read from/write to buffer\n  this.read = options.readOffset || 0;\n  this.growSize = options.growSize || 1024;\n\n  var isArrayBuffer = util.isArrayBuffer(b);\n  var isArrayBufferView = util.isArrayBufferView(b);\n  if(isArrayBuffer || isArrayBufferView) {\n    // use ArrayBuffer directly\n    if(isArrayBuffer) {\n      this.data = new DataView(b);\n    } else {\n      // TODO: adjust read/write offset based on the type of view\n      // or specify that this must be done in the options ... that the\n      // offsets are byte-based\n      this.data = new DataView(b.buffer, b.byteOffset, b.byteLength);\n    }\n    this.write = ('writeOffset' in options ?\n      options.writeOffset : this.data.byteLength);\n    return;\n  }\n\n  // initialize to empty array buffer and add any given bytes using putBytes\n  this.data = new DataView(new ArrayBuffer(0));\n  this.write = 0;\n\n  if(b !== null && b !== undefined) {\n    this.putBytes(b);\n  }\n\n  if('writeOffset' in options) {\n    this.write = options.writeOffset;\n  }\n}\nutil.DataBuffer = DataBuffer;\n\n/**\n * Gets the number of bytes in this buffer.\n *\n * @return the number of bytes in this buffer.\n */\nutil.DataBuffer.prototype.length = function() {\n  return this.write - this.read;\n};\n\n/**\n * Gets whether or not this buffer is empty.\n *\n * @return true if this buffer is empty, false if not.\n */\nutil.DataBuffer.prototype.isEmpty = function() {\n  return this.length() <= 0;\n};\n\n/**\n * Ensures this buffer has enough empty space to accommodate the given number\n * of bytes. An optional parameter may be given that indicates a minimum\n * amount to grow the buffer if necessary. If the parameter is not given,\n * the buffer will be grown by some previously-specified default amount\n * or heuristic.\n *\n * @param amount the number of bytes to accommodate.\n * @param [growSize] the minimum amount, in bytes, to grow the buffer by if\n *          necessary.\n */\nutil.DataBuffer.prototype.accommodate = function(amount, growSize) {\n  if(this.length() >= amount) {\n    return this;\n  }\n  growSize = Math.max(growSize || this.growSize, amount);\n\n  // grow buffer\n  var src = new Uint8Array(\n    this.data.buffer, this.data.byteOffset, this.data.byteLength);\n  var dst = new Uint8Array(this.length() + growSize);\n  dst.set(src);\n  this.data = new DataView(dst.buffer);\n\n  return this;\n};\n\n/**\n * Puts a byte in this buffer.\n *\n * @param b the byte to put.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putByte = function(b) {\n  this.accommodate(1);\n  this.data.setUint8(this.write++, b);\n  return this;\n};\n\n/**\n * Puts a byte in this buffer N times.\n *\n * @param b the byte to put.\n * @param n the number of bytes of value b to put.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.fillWithByte = function(b, n) {\n  this.accommodate(n);\n  for(var i = 0; i < n; ++i) {\n    this.data.setUint8(b);\n  }\n  return this;\n};\n\n/**\n * Puts bytes in this buffer. The bytes may be given as a string, an\n * ArrayBuffer, a DataView, or a TypedArray.\n *\n * @param bytes the bytes to put.\n * @param [encoding] the encoding for the first parameter ('binary', 'utf8',\n *          'utf16', 'hex'), if it is a string (default: 'binary').\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putBytes = function(bytes, encoding) {\n  if(util.isArrayBufferView(bytes)) {\n    var src = new Uint8Array(bytes.buffer, bytes.byteOffset, bytes.byteLength);\n    var len = src.byteLength - src.byteOffset;\n    this.accommodate(len);\n    var dst = new Uint8Array(this.data.buffer, this.write);\n    dst.set(src);\n    this.write += len;\n    return this;\n  }\n\n  if(util.isArrayBuffer(bytes)) {\n    var src = new Uint8Array(bytes);\n    this.accommodate(src.byteLength);\n    var dst = new Uint8Array(this.data.buffer);\n    dst.set(src, this.write);\n    this.write += src.byteLength;\n    return this;\n  }\n\n  // bytes is a util.DataBuffer or equivalent\n  if(bytes instanceof util.DataBuffer ||\n    (typeof bytes === 'object' &&\n    typeof bytes.read === 'number' && typeof bytes.write === 'number' &&\n    util.isArrayBufferView(bytes.data))) {\n    var src = new Uint8Array(bytes.data.byteLength, bytes.read, bytes.length());\n    this.accommodate(src.byteLength);\n    var dst = new Uint8Array(bytes.data.byteLength, this.write);\n    dst.set(src);\n    this.write += src.byteLength;\n    return this;\n  }\n\n  if(bytes instanceof util.ByteStringBuffer) {\n    // copy binary string and process as the same as a string parameter below\n    bytes = bytes.data;\n    encoding = 'binary';\n  }\n\n  // string conversion\n  encoding = encoding || 'binary';\n  if(typeof bytes === 'string') {\n    var view;\n\n    // decode from string\n    if(encoding === 'hex') {\n      this.accommodate(Math.ceil(bytes.length / 2));\n      view = new Uint8Array(this.data.buffer, this.write);\n      this.write += util.binary.hex.decode(bytes, view, this.write);\n      return this;\n    }\n    if(encoding === 'base64') {\n      this.accommodate(Math.ceil(bytes.length / 4) * 3);\n      view = new Uint8Array(this.data.buffer, this.write);\n      this.write += util.binary.base64.decode(bytes, view, this.write);\n      return this;\n    }\n\n    // encode text as UTF-8 bytes\n    if(encoding === 'utf8') {\n      // encode as UTF-8 then decode string as raw binary\n      bytes = util.encodeUtf8(bytes);\n      encoding = 'binary';\n    }\n\n    // decode string as raw binary\n    if(encoding === 'binary' || encoding === 'raw') {\n      // one byte per character\n      this.accommodate(bytes.length);\n      view = new Uint8Array(this.data.buffer, this.write);\n      this.write += util.binary.raw.decode(view);\n      return this;\n    }\n\n    // encode text as UTF-16 bytes\n    if(encoding === 'utf16') {\n      // two bytes per character\n      this.accommodate(bytes.length * 2);\n      view = new Uint16Array(this.data.buffer, this.write);\n      this.write += util.text.utf16.encode(view);\n      return this;\n    }\n\n    throw new Error('Invalid encoding: ' + encoding);\n  }\n\n  throw Error('Invalid parameter: ' + bytes);\n};\n\n/**\n * Puts the given buffer into this buffer.\n *\n * @param buffer the buffer to put into this one.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putBuffer = function(buffer) {\n  this.putBytes(buffer);\n  buffer.clear();\n  return this;\n};\n\n/**\n * Puts a string into this buffer.\n *\n * @param str the string to put.\n * @param [encoding] the encoding for the string (default: 'utf16').\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putString = function(str) {\n  return this.putBytes(str, 'utf16');\n};\n\n/**\n * Puts a 16-bit integer in this buffer in big-endian order.\n *\n * @param i the 16-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt16 = function(i) {\n  this.accommodate(2);\n  this.data.setInt16(this.write, i);\n  this.write += 2;\n  return this;\n};\n\n/**\n * Puts a 24-bit integer in this buffer in big-endian order.\n *\n * @param i the 24-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt24 = function(i) {\n  this.accommodate(3);\n  this.data.setInt16(this.write, i >> 8 & 0xFFFF);\n  this.data.setInt8(this.write, i >> 16 & 0xFF);\n  this.write += 3;\n  return this;\n};\n\n/**\n * Puts a 32-bit integer in this buffer in big-endian order.\n *\n * @param i the 32-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt32 = function(i) {\n  this.accommodate(4);\n  this.data.setInt32(this.write, i);\n  this.write += 4;\n  return this;\n};\n\n/**\n * Puts a 16-bit integer in this buffer in little-endian order.\n *\n * @param i the 16-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt16Le = function(i) {\n  this.accommodate(2);\n  this.data.setInt16(this.write, i, true);\n  this.write += 2;\n  return this;\n};\n\n/**\n * Puts a 24-bit integer in this buffer in little-endian order.\n *\n * @param i the 24-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt24Le = function(i) {\n  this.accommodate(3);\n  this.data.setInt8(this.write, i >> 16 & 0xFF);\n  this.data.setInt16(this.write, i >> 8 & 0xFFFF, true);\n  this.write += 3;\n  return this;\n};\n\n/**\n * Puts a 32-bit integer in this buffer in little-endian order.\n *\n * @param i the 32-bit integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt32Le = function(i) {\n  this.accommodate(4);\n  this.data.setInt32(this.write, i, true);\n  this.write += 4;\n  return this;\n};\n\n/**\n * Puts an n-bit integer in this buffer in big-endian order.\n *\n * @param i the n-bit integer.\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putInt = function(i, n) {\n  _checkBitsParam(n);\n  this.accommodate(n / 8);\n  do {\n    n -= 8;\n    this.data.setInt8(this.write++, (i >> n) & 0xFF);\n  } while(n > 0);\n  return this;\n};\n\n/**\n * Puts a signed n-bit integer in this buffer in big-endian order. Two's\n * complement representation is used.\n *\n * @param i the n-bit integer.\n * @param n the number of bits in the integer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.putSignedInt = function(i, n) {\n  _checkBitsParam(n);\n  this.accommodate(n / 8);\n  if(i < 0) {\n    i += 2 << (n - 1);\n  }\n  return this.putInt(i, n);\n};\n\n/**\n * Gets a byte from this buffer and advances the read pointer by 1.\n *\n * @return the byte.\n */\nutil.DataBuffer.prototype.getByte = function() {\n  return this.data.getInt8(this.read++);\n};\n\n/**\n * Gets a uint16 from this buffer in big-endian order and advances the read\n * pointer by 2.\n *\n * @return the uint16.\n */\nutil.DataBuffer.prototype.getInt16 = function() {\n  var rval = this.data.getInt16(this.read);\n  this.read += 2;\n  return rval;\n};\n\n/**\n * Gets a uint24 from this buffer in big-endian order and advances the read\n * pointer by 3.\n *\n * @return the uint24.\n */\nutil.DataBuffer.prototype.getInt24 = function() {\n  var rval = (\n    this.data.getInt16(this.read) << 8 ^\n    this.data.getInt8(this.read + 2));\n  this.read += 3;\n  return rval;\n};\n\n/**\n * Gets a uint32 from this buffer in big-endian order and advances the read\n * pointer by 4.\n *\n * @return the word.\n */\nutil.DataBuffer.prototype.getInt32 = function() {\n  var rval = this.data.getInt32(this.read);\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Gets a uint16 from this buffer in little-endian order and advances the read\n * pointer by 2.\n *\n * @return the uint16.\n */\nutil.DataBuffer.prototype.getInt16Le = function() {\n  var rval = this.data.getInt16(this.read, true);\n  this.read += 2;\n  return rval;\n};\n\n/**\n * Gets a uint24 from this buffer in little-endian order and advances the read\n * pointer by 3.\n *\n * @return the uint24.\n */\nutil.DataBuffer.prototype.getInt24Le = function() {\n  var rval = (\n    this.data.getInt8(this.read) ^\n    this.data.getInt16(this.read + 1, true) << 8);\n  this.read += 3;\n  return rval;\n};\n\n/**\n * Gets a uint32 from this buffer in little-endian order and advances the read\n * pointer by 4.\n *\n * @return the word.\n */\nutil.DataBuffer.prototype.getInt32Le = function() {\n  var rval = this.data.getInt32(this.read, true);\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Gets an n-bit integer from this buffer in big-endian order and advances the\n * read pointer by n/8.\n *\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return the integer.\n */\nutil.DataBuffer.prototype.getInt = function(n) {\n  _checkBitsParam(n);\n  var rval = 0;\n  do {\n    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.\n    rval = (rval << 8) + this.data.getInt8(this.read++);\n    n -= 8;\n  } while(n > 0);\n  return rval;\n};\n\n/**\n * Gets a signed n-bit integer from this buffer in big-endian order, using\n * two's complement, and advances the read pointer by n/8.\n *\n * @param n the number of bits in the integer (8, 16, 24, or 32).\n *\n * @return the integer.\n */\nutil.DataBuffer.prototype.getSignedInt = function(n) {\n  // getInt checks n\n  var x = this.getInt(n);\n  var max = 2 << (n - 2);\n  if(x >= max) {\n    x -= max << 1;\n  }\n  return x;\n};\n\n/**\n * Reads bytes out as a binary encoded string and clears them from the\n * buffer.\n *\n * @param count the number of bytes to read, undefined or null for all.\n *\n * @return a binary encoded string of bytes.\n */\nutil.DataBuffer.prototype.getBytes = function(count) {\n  // TODO: deprecate this method, it is poorly named and\n  // this.toString('binary') replaces it\n  // add a toTypedArray()/toArrayBuffer() function\n  var rval;\n  if(count) {\n    // read count bytes\n    count = Math.min(this.length(), count);\n    rval = this.data.slice(this.read, this.read + count);\n    this.read += count;\n  } else if(count === 0) {\n    rval = '';\n  } else {\n    // read all bytes, optimize to only copy when needed\n    rval = (this.read === 0) ? this.data : this.data.slice(this.read);\n    this.clear();\n  }\n  return rval;\n};\n\n/**\n * Gets a binary encoded string of the bytes from this buffer without\n * modifying the read pointer.\n *\n * @param count the number of bytes to get, omit to get all.\n *\n * @return a string full of binary encoded characters.\n */\nutil.DataBuffer.prototype.bytes = function(count) {\n  // TODO: deprecate this method, it is poorly named, add \"getString()\"\n  return (typeof(count) === 'undefined' ?\n    this.data.slice(this.read) :\n    this.data.slice(this.read, this.read + count));\n};\n\n/**\n * Gets a byte at the given index without modifying the read pointer.\n *\n * @param i the byte index.\n *\n * @return the byte.\n */\nutil.DataBuffer.prototype.at = function(i) {\n  return this.data.getUint8(this.read + i);\n};\n\n/**\n * Puts a byte at the given index without modifying the read pointer.\n *\n * @param i the byte index.\n * @param b the byte to put.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.setAt = function(i, b) {\n  this.data.setUint8(i, b);\n  return this;\n};\n\n/**\n * Gets the last byte without modifying the read pointer.\n *\n * @return the last byte.\n */\nutil.DataBuffer.prototype.last = function() {\n  return this.data.getUint8(this.write - 1);\n};\n\n/**\n * Creates a copy of this buffer.\n *\n * @return the copy.\n */\nutil.DataBuffer.prototype.copy = function() {\n  return new util.DataBuffer(this);\n};\n\n/**\n * Compacts this buffer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.compact = function() {\n  if(this.read > 0) {\n    var src = new Uint8Array(this.data.buffer, this.read);\n    var dst = new Uint8Array(src.byteLength);\n    dst.set(src);\n    this.data = new DataView(dst);\n    this.write -= this.read;\n    this.read = 0;\n  }\n  return this;\n};\n\n/**\n * Clears this buffer.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.clear = function() {\n  this.data = new DataView(new ArrayBuffer(0));\n  this.read = this.write = 0;\n  return this;\n};\n\n/**\n * Shortens this buffer by triming bytes off of the end of this buffer.\n *\n * @param count the number of bytes to trim off.\n *\n * @return this buffer.\n */\nutil.DataBuffer.prototype.truncate = function(count) {\n  this.write = Math.max(0, this.length() - count);\n  this.read = Math.min(this.read, this.write);\n  return this;\n};\n\n/**\n * Converts this buffer to a hexadecimal string.\n *\n * @return a hexadecimal string.\n */\nutil.DataBuffer.prototype.toHex = function() {\n  var rval = '';\n  for(var i = this.read; i < this.data.byteLength; ++i) {\n    var b = this.data.getUint8(i);\n    if(b < 16) {\n      rval += '0';\n    }\n    rval += b.toString(16);\n  }\n  return rval;\n};\n\n/**\n * Converts this buffer to a string, using the given encoding. If no\n * encoding is given, 'utf8' (UTF-8) is used.\n *\n * @param [encoding] the encoding to use: 'binary', 'utf8', 'utf16', 'hex',\n *          'base64' (default: 'utf8').\n *\n * @return a string representation of the bytes in this buffer.\n */\nutil.DataBuffer.prototype.toString = function(encoding) {\n  var view = new Uint8Array(this.data, this.read, this.length());\n  encoding = encoding || 'utf8';\n\n  // encode to string\n  if(encoding === 'binary' || encoding === 'raw') {\n    return util.binary.raw.encode(view);\n  }\n  if(encoding === 'hex') {\n    return util.binary.hex.encode(view);\n  }\n  if(encoding === 'base64') {\n    return util.binary.base64.encode(view);\n  }\n\n  // decode to text\n  if(encoding === 'utf8') {\n    return util.text.utf8.decode(view);\n  }\n  if(encoding === 'utf16') {\n    return util.text.utf16.decode(view);\n  }\n\n  throw new Error('Invalid encoding: ' + encoding);\n};\n\n/** End Buffer w/UInt8Array backing */\n\n/**\n * Creates a buffer that stores bytes. A value may be given to populate the\n * buffer with data. This value can either be string of encoded bytes or a\n * regular string of characters. When passing a string of binary encoded\n * bytes, the encoding `raw` should be given. This is also the default. When\n * passing a string of characters, the encoding `utf8` should be given.\n *\n * @param [input] a string with encoded bytes to store in the buffer.\n * @param [encoding] (default: 'raw', other: 'utf8').\n */\nutil.createBuffer = function(input, encoding) {\n  // TODO: deprecate, use new ByteBuffer() instead\n  encoding = encoding || 'raw';\n  if(input !== undefined && encoding === 'utf8') {\n    input = util.encodeUtf8(input);\n  }\n  return new util.ByteBuffer(input);\n};\n\n/**\n * Fills a string with a particular value. If you want the string to be a byte\n * string, pass in String.fromCharCode(theByte).\n *\n * @param c the character to fill the string with, use String.fromCharCode\n *          to fill the string with a byte value.\n * @param n the number of characters of value c to fill with.\n *\n * @return the filled string.\n */\nutil.fillString = function(c, n) {\n  var s = '';\n  while(n > 0) {\n    if(n & 1) {\n      s += c;\n    }\n    n >>>= 1;\n    if(n > 0) {\n      c += c;\n    }\n  }\n  return s;\n};\n\n/**\n * Performs a per byte XOR between two byte strings and returns the result as a\n * string of bytes.\n *\n * @param s1 first string of bytes.\n * @param s2 second string of bytes.\n * @param n the number of bytes to XOR.\n *\n * @return the XOR'd result.\n */\nutil.xorBytes = function(s1, s2, n) {\n  var s3 = '';\n  var b = '';\n  var t = '';\n  var i = 0;\n  var c = 0;\n  for(; n > 0; --n, ++i) {\n    b = s1.charCodeAt(i) ^ s2.charCodeAt(i);\n    if(c >= 10) {\n      s3 += t;\n      t = '';\n      c = 0;\n    }\n    t += String.fromCharCode(b);\n    ++c;\n  }\n  s3 += t;\n  return s3;\n};\n\n/**\n * Converts a hex string into a 'binary' encoded string of bytes.\n *\n * @param hex the hexadecimal string to convert.\n *\n * @return the binary-encoded string of bytes.\n */\nutil.hexToBytes = function(hex) {\n  // TODO: deprecate: \"Deprecated. Use util.binary.hex.decode instead.\"\n  var rval = '';\n  var i = 0;\n  if(hex.length & 1 == 1) {\n    // odd number of characters, convert first character alone\n    i = 1;\n    rval += String.fromCharCode(parseInt(hex[0], 16));\n  }\n  // convert 2 characters (1 byte) at a time\n  for(; i < hex.length; i += 2) {\n    rval += String.fromCharCode(parseInt(hex.substr(i, 2), 16));\n  }\n  return rval;\n};\n\n/**\n * Converts a 'binary' encoded string of bytes to hex.\n *\n * @param bytes the byte string to convert.\n *\n * @return the string of hexadecimal characters.\n */\nutil.bytesToHex = function(bytes) {\n  // TODO: deprecate: \"Deprecated. Use util.binary.hex.encode instead.\"\n  return util.createBuffer(bytes).toHex();\n};\n\n/**\n * Converts an 32-bit integer to 4-big-endian byte string.\n *\n * @param i the integer.\n *\n * @return the byte string.\n */\nutil.int32ToBytes = function(i) {\n  return (\n    String.fromCharCode(i >> 24 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n// base64 characters, reverse mapping\nvar _base64 =\n  'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';\nvar _base64Idx = [\n/*43 -43 = 0*/\n/*'+',  1,  2,  3,'/' */\n   62, -1, -1, -1, 63,\n\n/*'0','1','2','3','4','5','6','7','8','9' */\n   52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n\n/*15, 16, 17,'=', 19, 20, 21 */\n  -1, -1, -1, 64, -1, -1, -1,\n\n/*65 - 43 = 22*/\n/*'A','B','C','D','E','F','G','H','I','J','K','L','M', */\n   0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n\n/*'N','O','P','Q','R','S','T','U','V','W','X','Y','Z' */\n   13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n\n/*91 - 43 = 48 */\n/*48, 49, 50, 51, 52, 53 */\n  -1, -1, -1, -1, -1, -1,\n\n/*97 - 43 = 54*/\n/*'a','b','c','d','e','f','g','h','i','j','k','l','m' */\n   26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n\n/*'n','o','p','q','r','s','t','u','v','w','x','y','z' */\n   39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51\n];\n\n// base58 characters (Bitcoin alphabet)\nvar _base58 = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz';\n\n/**\n * Base64 encodes a 'binary' encoded string of bytes.\n *\n * @param input the binary encoded string of bytes to base64-encode.\n * @param maxline the maximum number of encoded characters per line to use,\n *          defaults to none.\n *\n * @return the base64-encoded output.\n */\nutil.encode64 = function(input, maxline) {\n  // TODO: deprecate: \"Deprecated. Use util.binary.base64.encode instead.\"\n  var line = '';\n  var output = '';\n  var chr1, chr2, chr3;\n  var i = 0;\n  while(i < input.length) {\n    chr1 = input.charCodeAt(i++);\n    chr2 = input.charCodeAt(i++);\n    chr3 = input.charCodeAt(i++);\n\n    // encode 4 character group\n    line += _base64.charAt(chr1 >> 2);\n    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));\n    if(isNaN(chr2)) {\n      line += '==';\n    } else {\n      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));\n      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);\n    }\n\n    if(maxline && line.length > maxline) {\n      output += line.substr(0, maxline) + '\\r\\n';\n      line = line.substr(maxline);\n    }\n  }\n  output += line;\n  return output;\n};\n\n/**\n * Base64 decodes a string into a 'binary' encoded string of bytes.\n *\n * @param input the base64-encoded input.\n *\n * @return the binary encoded string.\n */\nutil.decode64 = function(input) {\n  // TODO: deprecate: \"Deprecated. Use util.binary.base64.decode instead.\"\n\n  // remove all non-base64 characters\n  input = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, '');\n\n  var output = '';\n  var enc1, enc2, enc3, enc4;\n  var i = 0;\n\n  while(i < input.length) {\n    enc1 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc2 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc3 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc4 = _base64Idx[input.charCodeAt(i++) - 43];\n\n    output += String.fromCharCode((enc1 << 2) | (enc2 >> 4));\n    if(enc3 !== 64) {\n      // decoded at least 2 bytes\n      output += String.fromCharCode(((enc2 & 15) << 4) | (enc3 >> 2));\n      if(enc4 !== 64) {\n        // decoded 3 bytes\n        output += String.fromCharCode(((enc3 & 3) << 6) | enc4);\n      }\n    }\n  }\n\n  return output;\n};\n\n/**\n * Encodes the given string of characters (a standard JavaScript\n * string) as a binary encoded string where the bytes represent\n * a UTF-8 encoded string of characters. Non-ASCII characters will be\n * encoded as multiple bytes according to UTF-8.\n *\n * @param str a standard string of characters to encode.\n *\n * @return the binary encoded string.\n */\nutil.encodeUtf8 = function(str) {\n  return unescape(encodeURIComponent(str));\n};\n\n/**\n * Decodes a binary encoded string that contains bytes that\n * represent a UTF-8 encoded string of characters -- into a\n * string of characters (a standard JavaScript string).\n *\n * @param str the binary encoded string to decode.\n *\n * @return the resulting standard string of characters.\n */\nutil.decodeUtf8 = function(str) {\n  return decodeURIComponent(escape(str));\n};\n\n// binary encoding/decoding tools\n// FIXME: Experimental. Do not use yet.\nutil.binary = {\n  raw: {},\n  hex: {},\n  base64: {},\n  base58: {},\n  baseN : {\n    encode: baseN.encode,\n    decode: baseN.decode\n  }\n};\n\n/**\n * Encodes a Uint8Array as a binary-encoded string. This encoding uses\n * a value between 0 and 255 for each character.\n *\n * @param bytes the Uint8Array to encode.\n *\n * @return the binary-encoded string.\n */\nutil.binary.raw.encode = function(bytes) {\n  return String.fromCharCode.apply(null, bytes);\n};\n\n/**\n * Decodes a binary-encoded string to a Uint8Array. This encoding uses\n * a value between 0 and 255 for each character.\n *\n * @param str the binary-encoded string to decode.\n * @param [output] an optional Uint8Array to write the output to; if it\n *          is too small, an exception will be thrown.\n * @param [offset] the start offset for writing to the output (default: 0).\n *\n * @return the Uint8Array or the number of bytes written if output was given.\n */\nutil.binary.raw.decode = function(str, output, offset) {\n  var out = output;\n  if(!out) {\n    out = new Uint8Array(str.length);\n  }\n  offset = offset || 0;\n  var j = offset;\n  for(var i = 0; i < str.length; ++i) {\n    out[j++] = str.charCodeAt(i);\n  }\n  return output ? (j - offset) : out;\n};\n\n/**\n * Encodes a 'binary' string, ArrayBuffer, DataView, TypedArray, or\n * ByteBuffer as a string of hexadecimal characters.\n *\n * @param bytes the bytes to convert.\n *\n * @return the string of hexadecimal characters.\n */\nutil.binary.hex.encode = util.bytesToHex;\n\n/**\n * Decodes a hex-encoded string to a Uint8Array.\n *\n * @param hex the hexadecimal string to convert.\n * @param [output] an optional Uint8Array to write the output to; if it\n *          is too small, an exception will be thrown.\n * @param [offset] the start offset for writing to the output (default: 0).\n *\n * @return the Uint8Array or the number of bytes written if output was given.\n */\nutil.binary.hex.decode = function(hex, output, offset) {\n  var out = output;\n  if(!out) {\n    out = new Uint8Array(Math.ceil(hex.length / 2));\n  }\n  offset = offset || 0;\n  var i = 0, j = offset;\n  if(hex.length & 1) {\n    // odd number of characters, convert first character alone\n    i = 1;\n    out[j++] = parseInt(hex[0], 16);\n  }\n  // convert 2 characters (1 byte) at a time\n  for(; i < hex.length; i += 2) {\n    out[j++] = parseInt(hex.substr(i, 2), 16);\n  }\n  return output ? (j - offset) : out;\n};\n\n/**\n * Base64-encodes a Uint8Array.\n *\n * @param input the Uint8Array to encode.\n * @param maxline the maximum number of encoded characters per line to use,\n *          defaults to none.\n *\n * @return the base64-encoded output string.\n */\nutil.binary.base64.encode = function(input, maxline) {\n  var line = '';\n  var output = '';\n  var chr1, chr2, chr3;\n  var i = 0;\n  while(i < input.byteLength) {\n    chr1 = input[i++];\n    chr2 = input[i++];\n    chr3 = input[i++];\n\n    // encode 4 character group\n    line += _base64.charAt(chr1 >> 2);\n    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));\n    if(isNaN(chr2)) {\n      line += '==';\n    } else {\n      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));\n      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);\n    }\n\n    if(maxline && line.length > maxline) {\n      output += line.substr(0, maxline) + '\\r\\n';\n      line = line.substr(maxline);\n    }\n  }\n  output += line;\n  return output;\n};\n\n/**\n * Decodes a base64-encoded string to a Uint8Array.\n *\n * @param input the base64-encoded input string.\n * @param [output] an optional Uint8Array to write the output to; if it\n *          is too small, an exception will be thrown.\n * @param [offset] the start offset for writing to the output (default: 0).\n *\n * @return the Uint8Array or the number of bytes written if output was given.\n */\nutil.binary.base64.decode = function(input, output, offset) {\n  var out = output;\n  if(!out) {\n    out = new Uint8Array(Math.ceil(input.length / 4) * 3);\n  }\n\n  // remove all non-base64 characters\n  input = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, '');\n\n  offset = offset || 0;\n  var enc1, enc2, enc3, enc4;\n  var i = 0, j = offset;\n\n  while(i < input.length) {\n    enc1 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc2 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc3 = _base64Idx[input.charCodeAt(i++) - 43];\n    enc4 = _base64Idx[input.charCodeAt(i++) - 43];\n\n    out[j++] = (enc1 << 2) | (enc2 >> 4);\n    if(enc3 !== 64) {\n      // decoded at least 2 bytes\n      out[j++] = ((enc2 & 15) << 4) | (enc3 >> 2);\n      if(enc4 !== 64) {\n        // decoded 3 bytes\n        out[j++] = ((enc3 & 3) << 6) | enc4;\n      }\n    }\n  }\n\n  // make sure result is the exact decoded length\n  return output ? (j - offset) : out.subarray(0, j);\n};\n\n// add support for base58 encoding/decoding with Bitcoin alphabet\nutil.binary.base58.encode = function(input, maxline) {\n  return util.binary.baseN.encode(input, _base58, maxline);\n};\nutil.binary.base58.decode = function(input, maxline) {\n  return util.binary.baseN.decode(input, _base58, maxline);\n};\n\n// text encoding/decoding tools\n// FIXME: Experimental. Do not use yet.\nutil.text = {\n  utf8: {},\n  utf16: {}\n};\n\n/**\n * Encodes the given string as UTF-8 in a Uint8Array.\n *\n * @param str the string to encode.\n * @param [output] an optional Uint8Array to write the output to; if it\n *          is too small, an exception will be thrown.\n * @param [offset] the start offset for writing to the output (default: 0).\n *\n * @return the Uint8Array or the number of bytes written if output was given.\n */\nutil.text.utf8.encode = function(str, output, offset) {\n  str = util.encodeUtf8(str);\n  var out = output;\n  if(!out) {\n    out = new Uint8Array(str.length);\n  }\n  offset = offset || 0;\n  var j = offset;\n  for(var i = 0; i < str.length; ++i) {\n    out[j++] = str.charCodeAt(i);\n  }\n  return output ? (j - offset) : out;\n};\n\n/**\n * Decodes the UTF-8 contents from a Uint8Array.\n *\n * @param bytes the Uint8Array to decode.\n *\n * @return the resulting string.\n */\nutil.text.utf8.decode = function(bytes) {\n  return util.decodeUtf8(String.fromCharCode.apply(null, bytes));\n};\n\n/**\n * Encodes the given string as UTF-16 in a Uint8Array.\n *\n * @param str the string to encode.\n * @param [output] an optional Uint8Array to write the output to; if it\n *          is too small, an exception will be thrown.\n * @param [offset] the start offset for writing to the output (default: 0).\n *\n * @return the Uint8Array or the number of bytes written if output was given.\n */\nutil.text.utf16.encode = function(str, output, offset) {\n  var out = output;\n  if(!out) {\n    out = new Uint8Array(str.length * 2);\n  }\n  var view = new Uint16Array(out.buffer);\n  offset = offset || 0;\n  var j = offset;\n  var k = offset;\n  for(var i = 0; i < str.length; ++i) {\n    view[k++] = str.charCodeAt(i);\n    j += 2;\n  }\n  return output ? (j - offset) : out;\n};\n\n/**\n * Decodes the UTF-16 contents from a Uint8Array.\n *\n * @param bytes the Uint8Array to decode.\n *\n * @return the resulting string.\n */\nutil.text.utf16.decode = function(bytes) {\n  return String.fromCharCode.apply(null, new Uint16Array(bytes.buffer));\n};\n\n/**\n * Deflates the given data using a flash interface.\n *\n * @param api the flash interface.\n * @param bytes the data.\n * @param raw true to return only raw deflate data, false to include zlib\n *          header and trailer.\n *\n * @return the deflated data as a string.\n */\nutil.deflate = function(api, bytes, raw) {\n  bytes = util.decode64(api.deflate(util.encode64(bytes)).rval);\n\n  // strip zlib header and trailer if necessary\n  if(raw) {\n    // zlib header is 2 bytes (CMF,FLG) where FLG indicates that\n    // there is a 4-byte DICT (alder-32) block before the data if\n    // its 5th bit is set\n    var start = 2;\n    var flg = bytes.charCodeAt(1);\n    if(flg & 0x20) {\n      start = 6;\n    }\n    // zlib trailer is 4 bytes of adler-32\n    bytes = bytes.substring(start, bytes.length - 4);\n  }\n\n  return bytes;\n};\n\n/**\n * Inflates the given data using a flash interface.\n *\n * @param api the flash interface.\n * @param bytes the data.\n * @param raw true if the incoming data has no zlib header or trailer and is\n *          raw DEFLATE data.\n *\n * @return the inflated data as a string, null on error.\n */\nutil.inflate = function(api, bytes, raw) {\n  // TODO: add zlib header and trailer if necessary/possible\n  var rval = api.inflate(util.encode64(bytes)).rval;\n  return (rval === null) ? null : util.decode64(rval);\n};\n\n/**\n * Sets a storage object.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n * @param obj the storage object, null to remove.\n */\nvar _setStorageObject = function(api, id, obj) {\n  if(!api) {\n    throw new Error('WebStorage not available.');\n  }\n\n  var rval;\n  if(obj === null) {\n    rval = api.removeItem(id);\n  } else {\n    // json-encode and base64-encode object\n    obj = util.encode64(JSON.stringify(obj));\n    rval = api.setItem(id, obj);\n  }\n\n  // handle potential flash error\n  if(typeof(rval) !== 'undefined' && rval.rval !== true) {\n    var error = new Error(rval.error.message);\n    error.id = rval.error.id;\n    error.name = rval.error.name;\n    throw error;\n  }\n};\n\n/**\n * Gets a storage object.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n *\n * @return the storage object entry or null if none exists.\n */\nvar _getStorageObject = function(api, id) {\n  if(!api) {\n    throw new Error('WebStorage not available.');\n  }\n\n  // get the existing entry\n  var rval = api.getItem(id);\n\n  /* Note: We check api.init because we can't do (api == localStorage)\n    on IE because of \"Class doesn't support Automation\" exception. Only\n    the flash api has an init method so this works too, but we need a\n    better solution in the future. */\n\n  // flash returns item wrapped in an object, handle special case\n  if(api.init) {\n    if(rval.rval === null) {\n      if(rval.error) {\n        var error = new Error(rval.error.message);\n        error.id = rval.error.id;\n        error.name = rval.error.name;\n        throw error;\n      }\n      // no error, but also no item\n      rval = null;\n    } else {\n      rval = rval.rval;\n    }\n  }\n\n  // handle decoding\n  if(rval !== null) {\n    // base64-decode and json-decode data\n    rval = JSON.parse(util.decode64(rval));\n  }\n\n  return rval;\n};\n\n/**\n * Stores an item in local storage.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n * @param key the key for the item.\n * @param data the data for the item (any javascript object/primitive).\n */\nvar _setItem = function(api, id, key, data) {\n  // get storage object\n  var obj = _getStorageObject(api, id);\n  if(obj === null) {\n    // create a new storage object\n    obj = {};\n  }\n  // update key\n  obj[key] = data;\n\n  // set storage object\n  _setStorageObject(api, id, obj);\n};\n\n/**\n * Gets an item from local storage.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n * @param key the key for the item.\n *\n * @return the item.\n */\nvar _getItem = function(api, id, key) {\n  // get storage object\n  var rval = _getStorageObject(api, id);\n  if(rval !== null) {\n    // return data at key\n    rval = (key in rval) ? rval[key] : null;\n  }\n\n  return rval;\n};\n\n/**\n * Removes an item from local storage.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n * @param key the key for the item.\n */\nvar _removeItem = function(api, id, key) {\n  // get storage object\n  var obj = _getStorageObject(api, id);\n  if(obj !== null && key in obj) {\n    // remove key\n    delete obj[key];\n\n    // see if entry has no keys remaining\n    var empty = true;\n    for(var prop in obj) {\n      empty = false;\n      break;\n    }\n    if(empty) {\n      // remove entry entirely if no keys are left\n      obj = null;\n    }\n\n    // set storage object\n    _setStorageObject(api, id, obj);\n  }\n};\n\n/**\n * Clears the local disk storage identified by the given ID.\n *\n * @param api the storage interface.\n * @param id the storage ID to use.\n */\nvar _clearItems = function(api, id) {\n  _setStorageObject(api, id, null);\n};\n\n/**\n * Calls a storage function.\n *\n * @param func the function to call.\n * @param args the arguments for the function.\n * @param location the location argument.\n *\n * @return the return value from the function.\n */\nvar _callStorageFunction = function(func, args, location) {\n  var rval = null;\n\n  // default storage types\n  if(typeof(location) === 'undefined') {\n    location = ['web', 'flash'];\n  }\n\n  // apply storage types in order of preference\n  var type;\n  var done = false;\n  var exception = null;\n  for(var idx in location) {\n    type = location[idx];\n    try {\n      if(type === 'flash' || type === 'both') {\n        if(args[0] === null) {\n          throw new Error('Flash local storage not available.');\n        }\n        rval = func.apply(this, args);\n        done = (type === 'flash');\n      }\n      if(type === 'web' || type === 'both') {\n        args[0] = localStorage;\n        rval = func.apply(this, args);\n        done = true;\n      }\n    } catch(ex) {\n      exception = ex;\n    }\n    if(done) {\n      break;\n    }\n  }\n\n  if(!done) {\n    throw exception;\n  }\n\n  return rval;\n};\n\n/**\n * Stores an item on local disk.\n *\n * The available types of local storage include 'flash', 'web', and 'both'.\n *\n * The type 'flash' refers to flash local storage (SharedObject). In order\n * to use flash local storage, the 'api' parameter must be valid. The type\n * 'web' refers to WebStorage, if supported by the browser. The type 'both'\n * refers to storing using both 'flash' and 'web', not just one or the\n * other.\n *\n * The location array should list the storage types to use in order of\n * preference:\n *\n * ['flash']: flash only storage\n * ['web']: web only storage\n * ['both']: try to store in both\n * ['flash','web']: store in flash first, but if not available, 'web'\n * ['web','flash']: store in web first, but if not available, 'flash'\n *\n * The location array defaults to: ['web', 'flash']\n *\n * @param api the flash interface, null to use only WebStorage.\n * @param id the storage ID to use.\n * @param key the key for the item.\n * @param data the data for the item (any javascript object/primitive).\n * @param location an array with the preferred types of storage to use.\n */\nutil.setItem = function(api, id, key, data, location) {\n  _callStorageFunction(_setItem, arguments, location);\n};\n\n/**\n * Gets an item on local disk.\n *\n * Set setItem() for details on storage types.\n *\n * @param api the flash interface, null to use only WebStorage.\n * @param id the storage ID to use.\n * @param key the key for the item.\n * @param location an array with the preferred types of storage to use.\n *\n * @return the item.\n */\nutil.getItem = function(api, id, key, location) {\n  return _callStorageFunction(_getItem, arguments, location);\n};\n\n/**\n * Removes an item on local disk.\n *\n * Set setItem() for details on storage types.\n *\n * @param api the flash interface.\n * @param id the storage ID to use.\n * @param key the key for the item.\n * @param location an array with the preferred types of storage to use.\n */\nutil.removeItem = function(api, id, key, location) {\n  _callStorageFunction(_removeItem, arguments, location);\n};\n\n/**\n * Clears the local disk storage identified by the given ID.\n *\n * Set setItem() for details on storage types.\n *\n * @param api the flash interface if flash is available.\n * @param id the storage ID to use.\n * @param location an array with the preferred types of storage to use.\n */\nutil.clearItems = function(api, id, location) {\n  _callStorageFunction(_clearItems, arguments, location);\n};\n\n/**\n * Check if an object is empty.\n *\n * Taken from:\n * http://stackoverflow.com/questions/679915/how-do-i-test-for-an-empty-javascript-object-from-json/679937#679937\n *\n * @param object the object to check.\n */\nutil.isEmpty = function(obj) {\n  for(var prop in obj) {\n    if(obj.hasOwnProperty(prop)) {\n      return false;\n    }\n  }\n  return true;\n};\n\n/**\n * Format with simple printf-style interpolation.\n *\n * %%: literal '%'\n * %s,%o: convert next argument into a string.\n *\n * @param format the string to format.\n * @param ... arguments to interpolate into the format string.\n */\nutil.format = function(format) {\n  var re = /%./g;\n  // current match\n  var match;\n  // current part\n  var part;\n  // current arg index\n  var argi = 0;\n  // collected parts to recombine later\n  var parts = [];\n  // last index found\n  var last = 0;\n  // loop while matches remain\n  while((match = re.exec(format))) {\n    part = format.substring(last, re.lastIndex - 2);\n    // don't add empty strings (ie, parts between %s%s)\n    if(part.length > 0) {\n      parts.push(part);\n    }\n    last = re.lastIndex;\n    // switch on % code\n    var code = match[0][1];\n    switch(code) {\n    case 's':\n    case 'o':\n      // check if enough arguments were given\n      if(argi < arguments.length) {\n        parts.push(arguments[argi++ + 1]);\n      } else {\n        parts.push('<?>');\n      }\n      break;\n    // FIXME: do proper formating for numbers, etc\n    //case 'f':\n    //case 'd':\n    case '%':\n      parts.push('%');\n      break;\n    default:\n      parts.push('<%' + code + '?>');\n    }\n  }\n  // add trailing part of format string\n  parts.push(format.substring(last));\n  return parts.join('');\n};\n\n/**\n * Formats a number.\n *\n * http://snipplr.com/view/5945/javascript-numberformat--ported-from-php/\n */\nutil.formatNumber = function(number, decimals, dec_point, thousands_sep) {\n  // http://kevin.vanzonneveld.net\n  // +   original by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)\n  // +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)\n  // +     bugfix by: Michael White (http://crestidg.com)\n  // +     bugfix by: Benjamin Lupton\n  // +     bugfix by: Allan Jensen (http://www.winternet.no)\n  // +    revised by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)\n  // *     example 1: number_format(1234.5678, 2, '.', '');\n  // *     returns 1: 1234.57\n\n  var n = number, c = isNaN(decimals = Math.abs(decimals)) ? 2 : decimals;\n  var d = dec_point === undefined ? ',' : dec_point;\n  var t = thousands_sep === undefined ?\n   '.' : thousands_sep, s = n < 0 ? '-' : '';\n  var i = parseInt((n = Math.abs(+n || 0).toFixed(c)), 10) + '';\n  var j = (i.length > 3) ? i.length % 3 : 0;\n  return s + (j ? i.substr(0, j) + t : '') +\n    i.substr(j).replace(/(\\d{3})(?=\\d)/g, '$1' + t) +\n    (c ? d + Math.abs(n - i).toFixed(c).slice(2) : '');\n};\n\n/**\n * Formats a byte size.\n *\n * http://snipplr.com/view/5949/format-humanize-file-byte-size-presentation-in-javascript/\n */\nutil.formatSize = function(size) {\n  if(size >= 1073741824) {\n    size = util.formatNumber(size / 1073741824, 2, '.', '') + ' GiB';\n  } else if(size >= 1048576) {\n    size = util.formatNumber(size / 1048576, 2, '.', '') + ' MiB';\n  } else if(size >= 1024) {\n    size = util.formatNumber(size / 1024, 0) + ' KiB';\n  } else {\n    size = util.formatNumber(size, 0) + ' bytes';\n  }\n  return size;\n};\n\n/**\n * Converts an IPv4 or IPv6 string representation into bytes (in network order).\n *\n * @param ip the IPv4 or IPv6 address to convert.\n *\n * @return the 4-byte IPv6 or 16-byte IPv6 address or null if the address can't\n *         be parsed.\n */\nutil.bytesFromIP = function(ip) {\n  if(ip.indexOf('.') !== -1) {\n    return util.bytesFromIPv4(ip);\n  }\n  if(ip.indexOf(':') !== -1) {\n    return util.bytesFromIPv6(ip);\n  }\n  return null;\n};\n\n/**\n * Converts an IPv4 string representation into bytes (in network order).\n *\n * @param ip the IPv4 address to convert.\n *\n * @return the 4-byte address or null if the address can't be parsed.\n */\nutil.bytesFromIPv4 = function(ip) {\n  ip = ip.split('.');\n  if(ip.length !== 4) {\n    return null;\n  }\n  var b = util.createBuffer();\n  for(var i = 0; i < ip.length; ++i) {\n    var num = parseInt(ip[i], 10);\n    if(isNaN(num)) {\n      return null;\n    }\n    b.putByte(num);\n  }\n  return b.getBytes();\n};\n\n/**\n * Converts an IPv6 string representation into bytes (in network order).\n *\n * @param ip the IPv6 address to convert.\n *\n * @return the 16-byte address or null if the address can't be parsed.\n */\nutil.bytesFromIPv6 = function(ip) {\n  var blanks = 0;\n  ip = ip.split(':').filter(function(e) {\n    if(e.length === 0) ++blanks;\n    return true;\n  });\n  var zeros = (8 - ip.length + blanks) * 2;\n  var b = util.createBuffer();\n  for(var i = 0; i < 8; ++i) {\n    if(!ip[i] || ip[i].length === 0) {\n      b.fillWithByte(0, zeros);\n      zeros = 0;\n      continue;\n    }\n    var bytes = util.hexToBytes(ip[i]);\n    if(bytes.length < 2) {\n      b.putByte(0);\n    }\n    b.putBytes(bytes);\n  }\n  return b.getBytes();\n};\n\n/**\n * Converts 4-bytes into an IPv4 string representation or 16-bytes into\n * an IPv6 string representation. The bytes must be in network order.\n *\n * @param bytes the bytes to convert.\n *\n * @return the IPv4 or IPv6 string representation if 4 or 16 bytes,\n *         respectively, are given, otherwise null.\n */\nutil.bytesToIP = function(bytes) {\n  if(bytes.length === 4) {\n    return util.bytesToIPv4(bytes);\n  }\n  if(bytes.length === 16) {\n    return util.bytesToIPv6(bytes);\n  }\n  return null;\n};\n\n/**\n * Converts 4-bytes into an IPv4 string representation. The bytes must be\n * in network order.\n *\n * @param bytes the bytes to convert.\n *\n * @return the IPv4 string representation or null for an invalid # of bytes.\n */\nutil.bytesToIPv4 = function(bytes) {\n  if(bytes.length !== 4) {\n    return null;\n  }\n  var ip = [];\n  for(var i = 0; i < bytes.length; ++i) {\n    ip.push(bytes.charCodeAt(i));\n  }\n  return ip.join('.');\n};\n\n/**\n * Converts 16-bytes into an IPv16 string representation. The bytes must be\n * in network order.\n *\n * @param bytes the bytes to convert.\n *\n * @return the IPv16 string representation or null for an invalid # of bytes.\n */\nutil.bytesToIPv6 = function(bytes) {\n  if(bytes.length !== 16) {\n    return null;\n  }\n  var ip = [];\n  var zeroGroups = [];\n  var zeroMaxGroup = 0;\n  for(var i = 0; i < bytes.length; i += 2) {\n    var hex = util.bytesToHex(bytes[i] + bytes[i + 1]);\n    // canonicalize zero representation\n    while(hex[0] === '0' && hex !== '0') {\n      hex = hex.substr(1);\n    }\n    if(hex === '0') {\n      var last = zeroGroups[zeroGroups.length - 1];\n      var idx = ip.length;\n      if(!last || idx !== last.end + 1) {\n        zeroGroups.push({start: idx, end: idx});\n      } else {\n        last.end = idx;\n        if((last.end - last.start) >\n          (zeroGroups[zeroMaxGroup].end - zeroGroups[zeroMaxGroup].start)) {\n          zeroMaxGroup = zeroGroups.length - 1;\n        }\n      }\n    }\n    ip.push(hex);\n  }\n  if(zeroGroups.length > 0) {\n    var group = zeroGroups[zeroMaxGroup];\n    // only shorten group of length > 0\n    if(group.end - group.start > 0) {\n      ip.splice(group.start, group.end - group.start + 1, '');\n      if(group.start === 0) {\n        ip.unshift('');\n      }\n      if(group.end === 7) {\n        ip.push('');\n      }\n    }\n  }\n  return ip.join(':');\n};\n\n/**\n * Estimates the number of processes that can be run concurrently. If\n * creating Web Workers, keep in mind that the main JavaScript process needs\n * its own core.\n *\n * @param options the options to use:\n *          update true to force an update (not use the cached value).\n * @param callback(err, max) called once the operation completes.\n */\nutil.estimateCores = function(options, callback) {\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n  if('cores' in util && !options.update) {\n    return callback(null, util.cores);\n  }\n  if(typeof navigator !== 'undefined' &&\n    'hardwareConcurrency' in navigator &&\n    navigator.hardwareConcurrency > 0) {\n    util.cores = navigator.hardwareConcurrency;\n    return callback(null, util.cores);\n  }\n  if(typeof Worker === 'undefined') {\n    // workers not available\n    util.cores = 1;\n    return callback(null, util.cores);\n  }\n  if(typeof Blob === 'undefined') {\n    // can't estimate, default to 2\n    util.cores = 2;\n    return callback(null, util.cores);\n  }\n\n  // create worker concurrency estimation code as blob\n  var blobUrl = URL.createObjectURL(new Blob(['(',\n    function() {\n      self.addEventListener('message', function(e) {\n        // run worker for 4 ms\n        var st = Date.now();\n        var et = st + 4;\n        while(Date.now() < et);\n        self.postMessage({st: st, et: et});\n      });\n    }.toString(),\n  ')()'], {type: 'application/javascript'}));\n\n  // take 5 samples using 16 workers\n  sample([], 5, 16);\n\n  function sample(max, samples, numWorkers) {\n    if(samples === 0) {\n      // get overlap average\n      var avg = Math.floor(max.reduce(function(avg, x) {\n        return avg + x;\n      }, 0) / max.length);\n      util.cores = Math.max(1, avg);\n      URL.revokeObjectURL(blobUrl);\n      return callback(null, util.cores);\n    }\n    map(numWorkers, function(err, results) {\n      max.push(reduce(numWorkers, results));\n      sample(max, samples - 1, numWorkers);\n    });\n  }\n\n  function map(numWorkers, callback) {\n    var workers = [];\n    var results = [];\n    for(var i = 0; i < numWorkers; ++i) {\n      var worker = new Worker(blobUrl);\n      worker.addEventListener('message', function(e) {\n        results.push(e.data);\n        if(results.length === numWorkers) {\n          for(var i = 0; i < numWorkers; ++i) {\n            workers[i].terminate();\n          }\n          callback(null, results);\n        }\n      });\n      workers.push(worker);\n    }\n    for(var i = 0; i < numWorkers; ++i) {\n      workers[i].postMessage(i);\n    }\n  }\n\n  function reduce(numWorkers, results) {\n    // find overlapping time windows\n    var overlaps = [];\n    for(var n = 0; n < numWorkers; ++n) {\n      var r1 = results[n];\n      var overlap = overlaps[n] = [];\n      for(var i = 0; i < numWorkers; ++i) {\n        if(n === i) {\n          continue;\n        }\n        var r2 = results[i];\n        if((r1.st > r2.st && r1.st < r2.et) ||\n          (r2.st > r1.st && r2.st < r1.et)) {\n          overlap.push(i);\n        }\n      }\n    }\n    // get maximum overlaps ... don't include overlapping worker itself\n    // as the main JS process was also being scheduled during the work and\n    // would have to be subtracted from the estimate anyway\n    return overlaps.reduce(function(max, overlap) {\n      return Math.max(max, overlap.length);\n    }, 0);\n  }\n};\n","/**\n * Javascript implementation of X.509 and related components (such as\n * Certification Signing Requests) of a Public Key Infrastructure.\n *\n * @author Dave Longley\n *\n * Copyright (c) 2010-2014 Digital Bazaar, Inc.\n *\n * The ASN.1 representation of an X.509v3 certificate is as follows\n * (see RFC 2459):\n *\n * Certificate ::= SEQUENCE {\n *   tbsCertificate       TBSCertificate,\n *   signatureAlgorithm   AlgorithmIdentifier,\n *   signatureValue       BIT STRING\n * }\n *\n * TBSCertificate ::= SEQUENCE {\n *   version         [0]  EXPLICIT Version DEFAULT v1,\n *   serialNumber         CertificateSerialNumber,\n *   signature            AlgorithmIdentifier,\n *   issuer               Name,\n *   validity             Validity,\n *   subject              Name,\n *   subjectPublicKeyInfo SubjectPublicKeyInfo,\n *   issuerUniqueID  [1]  IMPLICIT UniqueIdentifier OPTIONAL,\n *                        -- If present, version shall be v2 or v3\n *   subjectUniqueID [2]  IMPLICIT UniqueIdentifier OPTIONAL,\n *                        -- If present, version shall be v2 or v3\n *   extensions      [3]  EXPLICIT Extensions OPTIONAL\n *                        -- If present, version shall be v3\n * }\n *\n * Version ::= INTEGER  { v1(0), v2(1), v3(2) }\n *\n * CertificateSerialNumber ::= INTEGER\n *\n * Name ::= CHOICE {\n *   // only one possible choice for now\n *   RDNSequence\n * }\n *\n * RDNSequence ::= SEQUENCE OF RelativeDistinguishedName\n *\n * RelativeDistinguishedName ::= SET OF AttributeTypeAndValue\n *\n * AttributeTypeAndValue ::= SEQUENCE {\n *   type     AttributeType,\n *   value    AttributeValue\n * }\n * AttributeType ::= OBJECT IDENTIFIER\n * AttributeValue ::= ANY DEFINED BY AttributeType\n *\n * Validity ::= SEQUENCE {\n *   notBefore      Time,\n *   notAfter       Time\n * }\n *\n * Time ::= CHOICE {\n *   utcTime        UTCTime,\n *   generalTime    GeneralizedTime\n * }\n *\n * UniqueIdentifier ::= BIT STRING\n *\n * SubjectPublicKeyInfo ::= SEQUENCE {\n *   algorithm            AlgorithmIdentifier,\n *   subjectPublicKey     BIT STRING\n * }\n *\n * Extensions ::= SEQUENCE SIZE (1..MAX) OF Extension\n *\n * Extension ::= SEQUENCE {\n *   extnID      OBJECT IDENTIFIER,\n *   critical    BOOLEAN DEFAULT FALSE,\n *   extnValue   OCTET STRING\n * }\n *\n * The only key algorithm currently supported for PKI is RSA.\n *\n * RSASSA-PSS signatures are described in RFC 3447 and RFC 4055.\n *\n * PKCS#10 v1.7 describes certificate signing requests:\n *\n * CertificationRequestInfo:\n *\n * CertificationRequestInfo ::= SEQUENCE {\n *   version       INTEGER { v1(0) } (v1,...),\n *   subject       Name,\n *   subjectPKInfo SubjectPublicKeyInfo{{ PKInfoAlgorithms }},\n *   attributes    [0] Attributes{{ CRIAttributes }}\n * }\n *\n * Attributes { ATTRIBUTE:IOSet } ::= SET OF Attribute{{ IOSet }}\n *\n * CRIAttributes  ATTRIBUTE  ::= {\n *   ... -- add any locally defined attributes here -- }\n *\n * Attribute { ATTRIBUTE:IOSet } ::= SEQUENCE {\n *   type   ATTRIBUTE.&id({IOSet}),\n *   values SET SIZE(1..MAX) OF ATTRIBUTE.&Type({IOSet}{@type})\n * }\n *\n * CertificationRequest ::= SEQUENCE {\n *   certificationRequestInfo CertificationRequestInfo,\n *   signatureAlgorithm AlgorithmIdentifier{{ SignatureAlgorithms }},\n *   signature          BIT STRING\n * }\n */\nvar forge = require('./forge');\nrequire('./aes');\nrequire('./asn1');\nrequire('./des');\nrequire('./md');\nrequire('./mgf');\nrequire('./oids');\nrequire('./pem');\nrequire('./pss');\nrequire('./rsa');\nrequire('./util');\n\n// shortcut for asn.1 API\nvar asn1 = forge.asn1;\n\n/* Public Key Infrastructure (PKI) implementation. */\nvar pki = module.exports = forge.pki = forge.pki || {};\nvar oids = pki.oids;\n\n// short name OID mappings\nvar _shortNames = {};\n_shortNames['CN'] = oids['commonName'];\n_shortNames['commonName'] = 'CN';\n_shortNames['C'] = oids['countryName'];\n_shortNames['countryName'] = 'C';\n_shortNames['L'] = oids['localityName'];\n_shortNames['localityName'] = 'L';\n_shortNames['ST'] = oids['stateOrProvinceName'];\n_shortNames['stateOrProvinceName'] = 'ST';\n_shortNames['O'] = oids['organizationName'];\n_shortNames['organizationName'] = 'O';\n_shortNames['OU'] = oids['organizationalUnitName'];\n_shortNames['organizationalUnitName'] = 'OU';\n_shortNames['E'] = oids['emailAddress'];\n_shortNames['emailAddress'] = 'E';\n\n// validator for an SubjectPublicKeyInfo structure\n// Note: Currently only works with an RSA public key\nvar publicKeyValidator = forge.pki.rsa.publicKeyValidator;\n\n// validator for an X.509v3 certificate\nvar x509CertificateValidator = {\n  name: 'Certificate',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'Certificate.TBSCertificate',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    captureAsn1: 'tbsCertificate',\n    value: [{\n      name: 'Certificate.TBSCertificate.version',\n      tagClass: asn1.Class.CONTEXT_SPECIFIC,\n      type: 0,\n      constructed: true,\n      optional: true,\n      value: [{\n        name: 'Certificate.TBSCertificate.version.integer',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.INTEGER,\n        constructed: false,\n        capture: 'certVersion'\n      }]\n    }, {\n      name: 'Certificate.TBSCertificate.serialNumber',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.INTEGER,\n      constructed: false,\n      capture: 'certSerialNumber'\n    }, {\n      name: 'Certificate.TBSCertificate.signature',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [{\n        name: 'Certificate.TBSCertificate.signature.algorithm',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OID,\n        constructed: false,\n        capture: 'certinfoSignatureOid'\n      }, {\n        name: 'Certificate.TBSCertificate.signature.parameters',\n        tagClass: asn1.Class.UNIVERSAL,\n        optional: true,\n        captureAsn1: 'certinfoSignatureParams'\n      }]\n    }, {\n      name: 'Certificate.TBSCertificate.issuer',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: 'certIssuer'\n    }, {\n      name: 'Certificate.TBSCertificate.validity',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      // Note: UTC and generalized times may both appear so the capture\n      // names are based on their detected order, the names used below\n      // are only for the common case, which validity time really means\n      // \"notBefore\" and which means \"notAfter\" will be determined by order\n      value: [{\n        // notBefore (Time) (UTC time case)\n        name: 'Certificate.TBSCertificate.validity.notBefore (utc)',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.UTCTIME,\n        constructed: false,\n        optional: true,\n        capture: 'certValidity1UTCTime'\n      }, {\n        // notBefore (Time) (generalized time case)\n        name: 'Certificate.TBSCertificate.validity.notBefore (generalized)',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.GENERALIZEDTIME,\n        constructed: false,\n        optional: true,\n        capture: 'certValidity2GeneralizedTime'\n      }, {\n        // notAfter (Time) (only UTC time is supported)\n        name: 'Certificate.TBSCertificate.validity.notAfter (utc)',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.UTCTIME,\n        constructed: false,\n        optional: true,\n        capture: 'certValidity3UTCTime'\n      }, {\n        // notAfter (Time) (only UTC time is supported)\n        name: 'Certificate.TBSCertificate.validity.notAfter (generalized)',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.GENERALIZEDTIME,\n        constructed: false,\n        optional: true,\n        capture: 'certValidity4GeneralizedTime'\n      }]\n    }, {\n      // Name (subject) (RDNSequence)\n      name: 'Certificate.TBSCertificate.subject',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: 'certSubject'\n    },\n    // SubjectPublicKeyInfo\n    publicKeyValidator,\n    {\n      // issuerUniqueID (optional)\n      name: 'Certificate.TBSCertificate.issuerUniqueID',\n      tagClass: asn1.Class.CONTEXT_SPECIFIC,\n      type: 1,\n      constructed: true,\n      optional: true,\n      value: [{\n        name: 'Certificate.TBSCertificate.issuerUniqueID.id',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.BITSTRING,\n        constructed: false,\n        // TODO: support arbitrary bit length ids\n        captureBitStringValue: 'certIssuerUniqueId'\n      }]\n    }, {\n      // subjectUniqueID (optional)\n      name: 'Certificate.TBSCertificate.subjectUniqueID',\n      tagClass: asn1.Class.CONTEXT_SPECIFIC,\n      type: 2,\n      constructed: true,\n      optional: true,\n      value: [{\n        name: 'Certificate.TBSCertificate.subjectUniqueID.id',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.BITSTRING,\n        constructed: false,\n        // TODO: support arbitrary bit length ids\n        captureBitStringValue: 'certSubjectUniqueId'\n      }]\n    }, {\n      // Extensions (optional)\n      name: 'Certificate.TBSCertificate.extensions',\n      tagClass: asn1.Class.CONTEXT_SPECIFIC,\n      type: 3,\n      constructed: true,\n      captureAsn1: 'certExtensions',\n      optional: true\n    }]\n  }, {\n    // AlgorithmIdentifier (signature algorithm)\n    name: 'Certificate.signatureAlgorithm',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [{\n      // algorithm\n      name: 'Certificate.signatureAlgorithm.algorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.OID,\n      constructed: false,\n      capture: 'certSignatureOid'\n    }, {\n      name: 'Certificate.TBSCertificate.signature.parameters',\n      tagClass: asn1.Class.UNIVERSAL,\n      optional: true,\n      captureAsn1: 'certSignatureParams'\n    }]\n  }, {\n    // SignatureValue\n    name: 'Certificate.signatureValue',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.BITSTRING,\n    constructed: false,\n    captureBitStringValue: 'certSignature'\n  }]\n};\n\nvar rsassaPssParameterValidator = {\n  name: 'rsapss',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [{\n    name: 'rsapss.hashAlgorithm',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    constructed: true,\n    value: [{\n      name: 'rsapss.hashAlgorithm.AlgorithmIdentifier',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Class.SEQUENCE,\n      constructed: true,\n      optional: true,\n      value: [{\n        name: 'rsapss.hashAlgorithm.AlgorithmIdentifier.algorithm',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OID,\n        constructed: false,\n        capture: 'hashOid'\n        /* parameter block omitted, for SHA1 NULL anyhow. */\n      }]\n    }]\n  }, {\n    name: 'rsapss.maskGenAlgorithm',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 1,\n    constructed: true,\n    value: [{\n      name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Class.SEQUENCE,\n      constructed: true,\n      optional: true,\n      value: [{\n        name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.algorithm',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OID,\n        constructed: false,\n        capture: 'maskGenOid'\n      }, {\n        name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.params',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.SEQUENCE,\n        constructed: true,\n        value: [{\n          name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.params.algorithm',\n          tagClass: asn1.Class.UNIVERSAL,\n          type: asn1.Type.OID,\n          constructed: false,\n          capture: 'maskGenHashOid'\n          /* parameter block omitted, for SHA1 NULL anyhow. */\n        }]\n      }]\n    }]\n  }, {\n    name: 'rsapss.saltLength',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 2,\n    optional: true,\n    value: [{\n      name: 'rsapss.saltLength.saltLength',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Class.INTEGER,\n      constructed: false,\n      capture: 'saltLength'\n    }]\n  }, {\n    name: 'rsapss.trailerField',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 3,\n    optional: true,\n    value: [{\n      name: 'rsapss.trailer.trailer',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Class.INTEGER,\n      constructed: false,\n      capture: 'trailer'\n    }]\n  }]\n};\n\n// validator for a CertificationRequestInfo structure\nvar certificationRequestInfoValidator = {\n  name: 'CertificationRequestInfo',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  captureAsn1: 'certificationRequestInfo',\n  value: [{\n    name: 'CertificationRequestInfo.integer',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.INTEGER,\n    constructed: false,\n    capture: 'certificationRequestInfoVersion'\n  }, {\n    // Name (subject) (RDNSequence)\n    name: 'CertificationRequestInfo.subject',\n    tagClass: asn1.Class.UNIVERSAL,\n    type: asn1.Type.SEQUENCE,\n    constructed: true,\n    captureAsn1: 'certificationRequestInfoSubject'\n  },\n  // SubjectPublicKeyInfo\n  publicKeyValidator,\n  {\n    name: 'CertificationRequestInfo.attributes',\n    tagClass: asn1.Class.CONTEXT_SPECIFIC,\n    type: 0,\n    constructed: true,\n    optional: true,\n    capture: 'certificationRequestInfoAttributes',\n    value: [{\n      name: 'CertificationRequestInfo.attributes',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [{\n        name: 'CertificationRequestInfo.attributes.type',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OID,\n        constructed: false\n      }, {\n        name: 'CertificationRequestInfo.attributes.value',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.SET,\n        constructed: true\n      }]\n    }]\n  }]\n};\n\n// validator for a CertificationRequest structure\nvar certificationRequestValidator = {\n  name: 'CertificationRequest',\n  tagClass: asn1.Class.UNIVERSAL,\n  type: asn1.Type.SEQUENCE,\n  constructed: true,\n  captureAsn1: 'csr',\n  value: [\n    certificationRequestInfoValidator, {\n      // AlgorithmIdentifier (signature algorithm)\n      name: 'CertificationRequest.signatureAlgorithm',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [{\n        // algorithm\n        name: 'CertificationRequest.signatureAlgorithm.algorithm',\n        tagClass: asn1.Class.UNIVERSAL,\n        type: asn1.Type.OID,\n        constructed: false,\n        capture: 'csrSignatureOid'\n      }, {\n        name: 'CertificationRequest.signatureAlgorithm.parameters',\n        tagClass: asn1.Class.UNIVERSAL,\n        optional: true,\n        captureAsn1: 'csrSignatureParams'\n      }]\n    }, {\n      // signature\n      name: 'CertificationRequest.signature',\n      tagClass: asn1.Class.UNIVERSAL,\n      type: asn1.Type.BITSTRING,\n      constructed: false,\n      captureBitStringValue: 'csrSignature'\n    }\n  ]\n};\n\n/**\n * Converts an RDNSequence of ASN.1 DER-encoded RelativeDistinguishedName\n * sets into an array with objects that have type and value properties.\n *\n * @param rdn the RDNSequence to convert.\n * @param md a message digest to append type and value to if provided.\n */\npki.RDNAttributesAsArray = function(rdn, md) {\n  var rval = [];\n\n  // each value in 'rdn' in is a SET of RelativeDistinguishedName\n  var set, attr, obj;\n  for(var si = 0; si < rdn.value.length; ++si) {\n    // get the RelativeDistinguishedName set\n    set = rdn.value[si];\n\n    // each value in the SET is an AttributeTypeAndValue sequence\n    // containing first a type (an OID) and second a value (defined by\n    // the OID)\n    for(var i = 0; i < set.value.length; ++i) {\n      obj = {};\n      attr = set.value[i];\n      obj.type = asn1.derToOid(attr.value[0].value);\n      obj.value = attr.value[1].value;\n      obj.valueTagClass = attr.value[1].type;\n      // if the OID is known, get its name and short name\n      if(obj.type in oids) {\n        obj.name = oids[obj.type];\n        if(obj.name in _shortNames) {\n          obj.shortName = _shortNames[obj.name];\n        }\n      }\n      if(md) {\n        md.update(obj.type);\n        md.update(obj.value);\n      }\n      rval.push(obj);\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Converts ASN.1 CRIAttributes into an array with objects that have type and\n * value properties.\n *\n * @param attributes the CRIAttributes to convert.\n */\npki.CRIAttributesAsArray = function(attributes) {\n  var rval = [];\n\n  // each value in 'attributes' in is a SEQUENCE with an OID and a SET\n  for(var si = 0; si < attributes.length; ++si) {\n    // get the attribute sequence\n    var seq = attributes[si];\n\n    // each value in the SEQUENCE containing first a type (an OID) and\n    // second a set of values (defined by the OID)\n    var type = asn1.derToOid(seq.value[0].value);\n    var values = seq.value[1].value;\n    for(var vi = 0; vi < values.length; ++vi) {\n      var obj = {};\n      obj.type = type;\n      obj.value = values[vi].value;\n      obj.valueTagClass = values[vi].type;\n      // if the OID is known, get its name and short name\n      if(obj.type in oids) {\n        obj.name = oids[obj.type];\n        if(obj.name in _shortNames) {\n          obj.shortName = _shortNames[obj.name];\n        }\n      }\n      // parse extensions\n      if(obj.type === oids.extensionRequest) {\n        obj.extensions = [];\n        for(var ei = 0; ei < obj.value.length; ++ei) {\n          obj.extensions.push(pki.certificateExtensionFromAsn1(obj.value[ei]));\n        }\n      }\n      rval.push(obj);\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Gets an issuer or subject attribute from its name, type, or short name.\n *\n * @param obj the issuer or subject object.\n * @param options a short name string or an object with:\n *          shortName the short name for the attribute.\n *          name the name for the attribute.\n *          type the type for the attribute.\n *\n * @return the attribute.\n */\nfunction _getAttribute(obj, options) {\n  if(typeof options === 'string') {\n    options = {shortName: options};\n  }\n\n  var rval = null;\n  var attr;\n  for(var i = 0; rval === null && i < obj.attributes.length; ++i) {\n    attr = obj.attributes[i];\n    if(options.type && options.type === attr.type) {\n      rval = attr;\n    } else if(options.name && options.name === attr.name) {\n      rval = attr;\n    } else if(options.shortName && options.shortName === attr.shortName) {\n      rval = attr;\n    }\n  }\n  return rval;\n}\n\n/**\n * Converts signature parameters from ASN.1 structure.\n *\n * Currently only RSASSA-PSS supported.  The PKCS#1 v1.5 signature scheme had\n * no parameters.\n *\n * RSASSA-PSS-params  ::=  SEQUENCE  {\n *   hashAlgorithm      [0] HashAlgorithm DEFAULT\n *                             sha1Identifier,\n *   maskGenAlgorithm   [1] MaskGenAlgorithm DEFAULT\n *                             mgf1SHA1Identifier,\n *   saltLength         [2] INTEGER DEFAULT 20,\n *   trailerField       [3] INTEGER DEFAULT 1\n * }\n *\n * HashAlgorithm  ::=  AlgorithmIdentifier\n *\n * MaskGenAlgorithm  ::=  AlgorithmIdentifier\n *\n * AlgorithmIdentifer ::= SEQUENCE {\n *   algorithm OBJECT IDENTIFIER,\n *   parameters ANY DEFINED BY algorithm OPTIONAL\n * }\n *\n * @param oid The OID specifying the signature algorithm\n * @param obj The ASN.1 structure holding the parameters\n * @param fillDefaults Whether to use return default values where omitted\n * @return signature parameter object\n */\nvar _readSignatureParameters = function(oid, obj, fillDefaults) {\n  var params = {};\n\n  if(oid !== oids['RSASSA-PSS']) {\n    return params;\n  }\n\n  if(fillDefaults) {\n    params = {\n      hash: {\n        algorithmOid: oids['sha1']\n      },\n      mgf: {\n        algorithmOid: oids['mgf1'],\n        hash: {\n          algorithmOid: oids['sha1']\n        }\n      },\n      saltLength: 20\n    };\n  }\n\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, rsassaPssParameterValidator, capture, errors)) {\n    var error = new Error('Cannot read RSASSA-PSS parameter block.');\n    error.errors = errors;\n    throw error;\n  }\n\n  if(capture.hashOid !== undefined) {\n    params.hash = params.hash || {};\n    params.hash.algorithmOid = asn1.derToOid(capture.hashOid);\n  }\n\n  if(capture.maskGenOid !== undefined) {\n    params.mgf = params.mgf || {};\n    params.mgf.algorithmOid = asn1.derToOid(capture.maskGenOid);\n    params.mgf.hash = params.mgf.hash || {};\n    params.mgf.hash.algorithmOid = asn1.derToOid(capture.maskGenHashOid);\n  }\n\n  if(capture.saltLength !== undefined) {\n    params.saltLength = capture.saltLength.charCodeAt(0);\n  }\n\n  return params;\n};\n\n/**\n * Create signature digest for OID.\n *\n * @param options\n *   signatureOid: the OID specifying the signature algorithm.\n *   type: a human readable type for error messages\n * @return a created md instance. throws if unknown oid.\n */\nvar _createSignatureDigest = function(options) {\n  switch(oids[options.signatureOid]) {\n    case 'sha1WithRSAEncryption':\n    // deprecated alias\n    case 'sha1WithRSASignature':\n      return forge.md.sha1.create();\n    case 'md5WithRSAEncryption':\n      return forge.md.md5.create();\n    case 'sha256WithRSAEncryption':\n      return forge.md.sha256.create();\n    case 'sha384WithRSAEncryption':\n      return forge.md.sha384.create();\n    case 'sha512WithRSAEncryption':\n      return forge.md.sha512.create();\n    case 'RSASSA-PSS':\n      return forge.md.sha256.create();\n    default:\n      var error = new Error(\n        'Could not compute ' + options.type + ' digest. ' +\n        'Unknown signature OID.');\n      error.signatureOid = options.signatureOid;\n      throw error;\n  }\n};\n\n/**\n * Verify signature on certificate or CSR.\n *\n * @param options:\n *   certificate the certificate or CSR to verify.\n *   md the signature digest.\n *   signature the signature\n * @return a created md instance. throws if unknown oid.\n */\nvar _verifySignature = function(options) {\n  var cert = options.certificate;\n  var scheme;\n\n  switch(cert.signatureOid) {\n    case oids.sha1WithRSAEncryption:\n    // deprecated alias\n    case oids.sha1WithRSASignature:\n      /* use PKCS#1 v1.5 padding scheme */\n      break;\n    case oids['RSASSA-PSS']:\n      var hash, mgf;\n\n      /* initialize mgf */\n      hash = oids[cert.signatureParameters.mgf.hash.algorithmOid];\n      if(hash === undefined || forge.md[hash] === undefined) {\n        var error = new Error('Unsupported MGF hash function.');\n        error.oid = cert.signatureParameters.mgf.hash.algorithmOid;\n        error.name = hash;\n        throw error;\n      }\n\n      mgf = oids[cert.signatureParameters.mgf.algorithmOid];\n      if(mgf === undefined || forge.mgf[mgf] === undefined) {\n        var error = new Error('Unsupported MGF function.');\n        error.oid = cert.signatureParameters.mgf.algorithmOid;\n        error.name = mgf;\n        throw error;\n      }\n\n      mgf = forge.mgf[mgf].create(forge.md[hash].create());\n\n      /* initialize hash function */\n      hash = oids[cert.signatureParameters.hash.algorithmOid];\n      if(hash === undefined || forge.md[hash] === undefined) {\n        var error = new Error('Unsupported RSASSA-PSS hash function.');\n        error.oid = cert.signatureParameters.hash.algorithmOid;\n        error.name = hash;\n        throw error;\n      }\n\n      scheme = forge.pss.create(\n        forge.md[hash].create(), mgf, cert.signatureParameters.saltLength\n      );\n      break;\n  }\n\n  // verify signature on cert using public key\n  return cert.publicKey.verify(\n    options.md.digest().getBytes(), options.signature, scheme\n  );\n};\n\n/**\n * Converts an X.509 certificate from PEM format.\n *\n * Note: If the certificate is to be verified then compute hash should\n * be set to true. This will scan the TBSCertificate part of the ASN.1\n * object while it is converted so it doesn't need to be converted back\n * to ASN.1-DER-encoding later.\n *\n * @param pem the PEM-formatted certificate.\n * @param computeHash true to compute the hash for verification.\n * @param strict true to be strict when checking ASN.1 value lengths, false to\n *          allow truncated values (default: true).\n *\n * @return the certificate.\n */\npki.certificateFromPem = function(pem, computeHash, strict) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'CERTIFICATE' &&\n    msg.type !== 'X509 CERTIFICATE' &&\n    msg.type !== 'TRUSTED CERTIFICATE') {\n    var error = new Error(\n      'Could not convert certificate from PEM; PEM header type ' +\n      'is not \"CERTIFICATE\", \"X509 CERTIFICATE\", or \"TRUSTED CERTIFICATE\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error(\n      'Could not convert certificate from PEM; PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  var obj = asn1.fromDer(msg.body, strict);\n\n  return pki.certificateFromAsn1(obj, computeHash);\n};\n\n/**\n * Converts an X.509 certificate to PEM format.\n *\n * @param cert the certificate.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted certificate.\n */\npki.certificateToPem = function(cert, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var msg = {\n    type: 'CERTIFICATE',\n    body: asn1.toDer(pki.certificateToAsn1(cert)).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Converts an RSA public key from PEM format.\n *\n * @param pem the PEM-formatted public key.\n *\n * @return the public key.\n */\npki.publicKeyFromPem = function(pem) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'PUBLIC KEY' && msg.type !== 'RSA PUBLIC KEY') {\n    var error = new Error('Could not convert public key from PEM; PEM header ' +\n      'type is not \"PUBLIC KEY\" or \"RSA PUBLIC KEY\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert public key from PEM; PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  var obj = asn1.fromDer(msg.body);\n\n  return pki.publicKeyFromAsn1(obj);\n};\n\n/**\n * Converts an RSA public key to PEM format (using a SubjectPublicKeyInfo).\n *\n * @param key the public key.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted public key.\n */\npki.publicKeyToPem = function(key, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var msg = {\n    type: 'PUBLIC KEY',\n    body: asn1.toDer(pki.publicKeyToAsn1(key)).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Converts an RSA public key to PEM format (using an RSAPublicKey).\n *\n * @param key the public key.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted public key.\n */\npki.publicKeyToRSAPublicKeyPem = function(key, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var msg = {\n    type: 'RSA PUBLIC KEY',\n    body: asn1.toDer(pki.publicKeyToRSAPublicKey(key)).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Gets a fingerprint for the given public key.\n *\n * @param options the options to use.\n *          [md] the message digest object to use (defaults to forge.md.sha1).\n *          [type] the type of fingerprint, such as 'RSAPublicKey',\n *            'SubjectPublicKeyInfo' (defaults to 'RSAPublicKey').\n *          [encoding] an alternative output encoding, such as 'hex'\n *            (defaults to none, outputs a byte buffer).\n *          [delimiter] the delimiter to use between bytes for 'hex' encoded\n *            output, eg: ':' (defaults to none).\n *\n * @return the fingerprint as a byte buffer or other encoding based on options.\n */\npki.getPublicKeyFingerprint = function(key, options) {\n  options = options || {};\n  var md = options.md || forge.md.sha1.create();\n  var type = options.type || 'RSAPublicKey';\n\n  var bytes;\n  switch(type) {\n    case 'RSAPublicKey':\n      bytes = asn1.toDer(pki.publicKeyToRSAPublicKey(key)).getBytes();\n      break;\n    case 'SubjectPublicKeyInfo':\n      bytes = asn1.toDer(pki.publicKeyToAsn1(key)).getBytes();\n      break;\n    default:\n      throw new Error('Unknown fingerprint type \"' + options.type + '\".');\n  }\n\n  // hash public key bytes\n  md.start();\n  md.update(bytes);\n  var digest = md.digest();\n  if(options.encoding === 'hex') {\n    var hex = digest.toHex();\n    if(options.delimiter) {\n      return hex.match(/.{2}/g).join(options.delimiter);\n    }\n    return hex;\n  } else if(options.encoding === 'binary') {\n    return digest.getBytes();\n  } else if(options.encoding) {\n    throw new Error('Unknown encoding \"' + options.encoding + '\".');\n  }\n  return digest;\n};\n\n/**\n * Converts a PKCS#10 certification request (CSR) from PEM format.\n *\n * Note: If the certification request is to be verified then compute hash\n * should be set to true. This will scan the CertificationRequestInfo part of\n * the ASN.1 object while it is converted so it doesn't need to be converted\n * back to ASN.1-DER-encoding later.\n *\n * @param pem the PEM-formatted certificate.\n * @param computeHash true to compute the hash for verification.\n * @param strict true to be strict when checking ASN.1 value lengths, false to\n *          allow truncated values (default: true).\n *\n * @return the certification request (CSR).\n */\npki.certificationRequestFromPem = function(pem, computeHash, strict) {\n  var msg = forge.pem.decode(pem)[0];\n\n  if(msg.type !== 'CERTIFICATE REQUEST') {\n    var error = new Error('Could not convert certification request from PEM; ' +\n      'PEM header type is not \"CERTIFICATE REQUEST\".');\n    error.headerType = msg.type;\n    throw error;\n  }\n  if(msg.procType && msg.procType.type === 'ENCRYPTED') {\n    throw new Error('Could not convert certification request from PEM; ' +\n      'PEM is encrypted.');\n  }\n\n  // convert DER to ASN.1 object\n  var obj = asn1.fromDer(msg.body, strict);\n\n  return pki.certificationRequestFromAsn1(obj, computeHash);\n};\n\n/**\n * Converts a PKCS#10 certification request (CSR) to PEM format.\n *\n * @param csr the certification request.\n * @param maxline the maximum characters per line, defaults to 64.\n *\n * @return the PEM-formatted certification request.\n */\npki.certificationRequestToPem = function(csr, maxline) {\n  // convert to ASN.1, then DER, then PEM-encode\n  var msg = {\n    type: 'CERTIFICATE REQUEST',\n    body: asn1.toDer(pki.certificationRequestToAsn1(csr)).getBytes()\n  };\n  return forge.pem.encode(msg, {maxline: maxline});\n};\n\n/**\n * Creates an empty X.509v3 RSA certificate.\n *\n * @return the certificate.\n */\npki.createCertificate = function() {\n  var cert = {};\n  cert.version = 0x02;\n  cert.serialNumber = '00';\n  cert.signatureOid = null;\n  cert.signature = null;\n  cert.siginfo = {};\n  cert.siginfo.algorithmOid = null;\n  cert.validity = {};\n  cert.validity.notBefore = new Date();\n  cert.validity.notAfter = new Date();\n\n  cert.issuer = {};\n  cert.issuer.getField = function(sn) {\n    return _getAttribute(cert.issuer, sn);\n  };\n  cert.issuer.addField = function(attr) {\n    _fillMissingFields([attr]);\n    cert.issuer.attributes.push(attr);\n  };\n  cert.issuer.attributes = [];\n  cert.issuer.hash = null;\n\n  cert.subject = {};\n  cert.subject.getField = function(sn) {\n    return _getAttribute(cert.subject, sn);\n  };\n  cert.subject.addField = function(attr) {\n    _fillMissingFields([attr]);\n    cert.subject.attributes.push(attr);\n  };\n  cert.subject.attributes = [];\n  cert.subject.hash = null;\n\n  cert.extensions = [];\n  cert.publicKey = null;\n  cert.md = null;\n\n  /**\n   * Sets the subject of this certificate.\n   *\n   * @param attrs the array of subject attributes to use.\n   * @param uniqueId an optional a unique ID to use.\n   */\n  cert.setSubject = function(attrs, uniqueId) {\n    // set new attributes, clear hash\n    _fillMissingFields(attrs);\n    cert.subject.attributes = attrs;\n    delete cert.subject.uniqueId;\n    if(uniqueId) {\n      // TODO: support arbitrary bit length ids\n      cert.subject.uniqueId = uniqueId;\n    }\n    cert.subject.hash = null;\n  };\n\n  /**\n   * Sets the issuer of this certificate.\n   *\n   * @param attrs the array of issuer attributes to use.\n   * @param uniqueId an optional a unique ID to use.\n   */\n  cert.setIssuer = function(attrs, uniqueId) {\n    // set new attributes, clear hash\n    _fillMissingFields(attrs);\n    cert.issuer.attributes = attrs;\n    delete cert.issuer.uniqueId;\n    if(uniqueId) {\n      // TODO: support arbitrary bit length ids\n      cert.issuer.uniqueId = uniqueId;\n    }\n    cert.issuer.hash = null;\n  };\n\n  /**\n   * Sets the extensions of this certificate.\n   *\n   * @param exts the array of extensions to use.\n   */\n  cert.setExtensions = function(exts) {\n    for(var i = 0; i < exts.length; ++i) {\n      _fillMissingExtensionFields(exts[i], {cert: cert});\n    }\n    // set new extensions\n    cert.extensions = exts;\n  };\n\n  /**\n   * Gets an extension by its name or id.\n   *\n   * @param options the name to use or an object with:\n   *          name the name to use.\n   *          id the id to use.\n   *\n   * @return the extension or null if not found.\n   */\n  cert.getExtension = function(options) {\n    if(typeof options === 'string') {\n      options = {name: options};\n    }\n\n    var rval = null;\n    var ext;\n    for(var i = 0; rval === null && i < cert.extensions.length; ++i) {\n      ext = cert.extensions[i];\n      if(options.id && ext.id === options.id) {\n        rval = ext;\n      } else if(options.name && ext.name === options.name) {\n        rval = ext;\n      }\n    }\n    return rval;\n  };\n\n  /**\n   * Signs this certificate using the given private key.\n   *\n   * @param key the private key to sign with.\n   * @param md the message digest object to use (defaults to forge.md.sha1).\n   */\n  cert.sign = function(key, md) {\n    // TODO: get signature OID from private key\n    cert.md = md || forge.md.sha1.create();\n    var algorithmOid = oids[cert.md.algorithm + 'WithRSAEncryption'];\n    if(!algorithmOid) {\n      var error = new Error('Could not compute certificate digest. ' +\n        'Unknown message digest algorithm OID.');\n      error.algorithm = cert.md.algorithm;\n      throw error;\n    }\n    cert.signatureOid = cert.siginfo.algorithmOid = algorithmOid;\n\n    // get TBSCertificate, convert to DER\n    cert.tbsCertificate = pki.getTBSCertificate(cert);\n    var bytes = asn1.toDer(cert.tbsCertificate);\n\n    // digest and sign\n    cert.md.update(bytes.getBytes());\n    cert.signature = key.sign(cert.md);\n  };\n\n  /**\n   * Attempts verify the signature on the passed certificate using this\n   * certificate's public key.\n   *\n   * @param child the certificate to verify.\n   *\n   * @return true if verified, false if not.\n   */\n  cert.verify = function(child) {\n    var rval = false;\n\n    if(!cert.issued(child)) {\n      var issuer = child.issuer;\n      var subject = cert.subject;\n      var error = new Error(\n        'The parent certificate did not issue the given child ' +\n        'certificate; the child certificate\\'s issuer does not match the ' +\n        'parent\\'s subject.');\n      error.expectedIssuer = subject.attributes;\n      error.actualIssuer = issuer.attributes;\n      throw error;\n    }\n\n    var md = child.md;\n    if(md === null) {\n      // create digest for OID signature types\n      md = _createSignatureDigest({\n        signatureOid: child.signatureOid,\n        type: 'certificate'\n      });\n\n      // produce DER formatted TBSCertificate and digest it\n      var tbsCertificate = child.tbsCertificate || pki.getTBSCertificate(child);\n      var bytes = asn1.toDer(tbsCertificate);\n      md.update(bytes.getBytes());\n    }\n\n    if(md !== null) {\n      rval = _verifySignature({\n        certificate: cert, md: md, signature: child.signature\n      });\n    }\n\n    return rval;\n  };\n\n  /**\n   * Returns true if this certificate's issuer matches the passed\n   * certificate's subject. Note that no signature check is performed.\n   *\n   * @param parent the certificate to check.\n   *\n   * @return true if this certificate's issuer matches the passed certificate's\n   *         subject.\n   */\n  cert.isIssuer = function(parent) {\n    var rval = false;\n\n    var i = cert.issuer;\n    var s = parent.subject;\n\n    // compare hashes if present\n    if(i.hash && s.hash) {\n      rval = (i.hash === s.hash);\n    } else if(i.attributes.length === s.attributes.length) {\n      // all attributes are the same so issuer matches subject\n      rval = true;\n      var iattr, sattr;\n      for(var n = 0; rval && n < i.attributes.length; ++n) {\n        iattr = i.attributes[n];\n        sattr = s.attributes[n];\n        if(iattr.type !== sattr.type || iattr.value !== sattr.value) {\n          // attribute mismatch\n          rval = false;\n        }\n      }\n    }\n\n    return rval;\n  };\n\n  /**\n   * Returns true if this certificate's subject matches the issuer of the\n   * given certificate). Note that not signature check is performed.\n   *\n   * @param child the certificate to check.\n   *\n   * @return true if this certificate's subject matches the passed\n   *         certificate's issuer.\n   */\n  cert.issued = function(child) {\n    return child.isIssuer(cert);\n  };\n\n  /**\n   * Generates the subjectKeyIdentifier for this certificate as byte buffer.\n   *\n   * @return the subjectKeyIdentifier for this certificate as byte buffer.\n   */\n  cert.generateSubjectKeyIdentifier = function() {\n    /* See: 4.2.1.2 section of the the RFC3280, keyIdentifier is either:\n\n      (1) The keyIdentifier is composed of the 160-bit SHA-1 hash of the\n        value of the BIT STRING subjectPublicKey (excluding the tag,\n        length, and number of unused bits).\n\n      (2) The keyIdentifier is composed of a four bit type field with\n        the value 0100 followed by the least significant 60 bits of the\n        SHA-1 hash of the value of the BIT STRING subjectPublicKey\n        (excluding the tag, length, and number of unused bit string bits).\n    */\n\n    // skipping the tag, length, and number of unused bits is the same\n    // as just using the RSAPublicKey (for RSA keys, which are the\n    // only ones supported)\n    return pki.getPublicKeyFingerprint(cert.publicKey, {type: 'RSAPublicKey'});\n  };\n\n  /**\n   * Verifies the subjectKeyIdentifier extension value for this certificate\n   * against its public key. If no extension is found, false will be\n   * returned.\n   *\n   * @return true if verified, false if not.\n   */\n  cert.verifySubjectKeyIdentifier = function() {\n    var oid = oids['subjectKeyIdentifier'];\n    for(var i = 0; i < cert.extensions.length; ++i) {\n      var ext = cert.extensions[i];\n      if(ext.id === oid) {\n        var ski = cert.generateSubjectKeyIdentifier().getBytes();\n        return (forge.util.hexToBytes(ext.subjectKeyIdentifier) === ski);\n      }\n    }\n    return false;\n  };\n\n  return cert;\n};\n\n/**\n * Converts an X.509v3 RSA certificate from an ASN.1 object.\n *\n * Note: If the certificate is to be verified then compute hash should\n * be set to true. There is currently no implementation for converting\n * a certificate back to ASN.1 so the TBSCertificate part of the ASN.1\n * object needs to be scanned before the cert object is created.\n *\n * @param obj the asn1 representation of an X.509v3 RSA certificate.\n * @param computeHash true to compute the hash for verification.\n *\n * @return the certificate.\n */\npki.certificateFromAsn1 = function(obj, computeHash) {\n  // validate certificate and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, x509CertificateValidator, capture, errors)) {\n    var error = new Error('Cannot read X.509 certificate. ' +\n      'ASN.1 object is not an X509v3 Certificate.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // get oid\n  var oid = asn1.derToOid(capture.publicKeyOid);\n  if(oid !== pki.oids.rsaEncryption) {\n    throw new Error('Cannot read public key. OID is not RSA.');\n  }\n\n  // create certificate\n  var cert = pki.createCertificate();\n  cert.version = capture.certVersion ?\n    capture.certVersion.charCodeAt(0) : 0;\n  var serial = forge.util.createBuffer(capture.certSerialNumber);\n  cert.serialNumber = serial.toHex();\n  cert.signatureOid = forge.asn1.derToOid(capture.certSignatureOid);\n  cert.signatureParameters = _readSignatureParameters(\n    cert.signatureOid, capture.certSignatureParams, true);\n  cert.siginfo.algorithmOid = forge.asn1.derToOid(capture.certinfoSignatureOid);\n  cert.siginfo.parameters = _readSignatureParameters(cert.siginfo.algorithmOid,\n    capture.certinfoSignatureParams, false);\n  cert.signature = capture.certSignature;\n\n  var validity = [];\n  if(capture.certValidity1UTCTime !== undefined) {\n    validity.push(asn1.utcTimeToDate(capture.certValidity1UTCTime));\n  }\n  if(capture.certValidity2GeneralizedTime !== undefined) {\n    validity.push(asn1.generalizedTimeToDate(\n      capture.certValidity2GeneralizedTime));\n  }\n  if(capture.certValidity3UTCTime !== undefined) {\n    validity.push(asn1.utcTimeToDate(capture.certValidity3UTCTime));\n  }\n  if(capture.certValidity4GeneralizedTime !== undefined) {\n    validity.push(asn1.generalizedTimeToDate(\n      capture.certValidity4GeneralizedTime));\n  }\n  if(validity.length > 2) {\n    throw new Error('Cannot read notBefore/notAfter validity times; more ' +\n      'than two times were provided in the certificate.');\n  }\n  if(validity.length < 2) {\n    throw new Error('Cannot read notBefore/notAfter validity times; they ' +\n      'were not provided as either UTCTime or GeneralizedTime.');\n  }\n  cert.validity.notBefore = validity[0];\n  cert.validity.notAfter = validity[1];\n\n  // keep TBSCertificate to preserve signature when exporting\n  cert.tbsCertificate = capture.tbsCertificate;\n\n  if(computeHash) {\n    // create digest for OID signature type\n    cert.md = _createSignatureDigest({\n      signatureOid: cert.signatureOid,\n      type: 'certificate'\n    });\n\n    // produce DER formatted TBSCertificate and digest it\n    var bytes = asn1.toDer(cert.tbsCertificate);\n    cert.md.update(bytes.getBytes());\n  }\n\n  // handle issuer, build issuer message digest\n  var imd = forge.md.sha1.create();\n  var ibytes = asn1.toDer(capture.certIssuer);\n  imd.update(ibytes.getBytes());\n  cert.issuer.getField = function(sn) {\n    return _getAttribute(cert.issuer, sn);\n  };\n  cert.issuer.addField = function(attr) {\n    _fillMissingFields([attr]);\n    cert.issuer.attributes.push(attr);\n  };\n  cert.issuer.attributes = pki.RDNAttributesAsArray(capture.certIssuer);\n  if(capture.certIssuerUniqueId) {\n    cert.issuer.uniqueId = capture.certIssuerUniqueId;\n  }\n  cert.issuer.hash = imd.digest().toHex();\n\n  // handle subject, build subject message digest\n  var smd = forge.md.sha1.create();\n  var sbytes = asn1.toDer(capture.certSubject);\n  smd.update(sbytes.getBytes());\n  cert.subject.getField = function(sn) {\n    return _getAttribute(cert.subject, sn);\n  };\n  cert.subject.addField = function(attr) {\n    _fillMissingFields([attr]);\n    cert.subject.attributes.push(attr);\n  };\n  cert.subject.attributes = pki.RDNAttributesAsArray(capture.certSubject);\n  if(capture.certSubjectUniqueId) {\n    cert.subject.uniqueId = capture.certSubjectUniqueId;\n  }\n  cert.subject.hash = smd.digest().toHex();\n\n  // handle extensions\n  if(capture.certExtensions) {\n    cert.extensions = pki.certificateExtensionsFromAsn1(capture.certExtensions);\n  } else {\n    cert.extensions = [];\n  }\n\n  // convert RSA public key from ASN.1\n  cert.publicKey = pki.publicKeyFromAsn1(capture.subjectPublicKeyInfo);\n\n  return cert;\n};\n\n/**\n * Converts an ASN.1 extensions object (with extension sequences as its\n * values) into an array of extension objects with types and values.\n *\n * Supported extensions:\n *\n * id-ce-keyUsage OBJECT IDENTIFIER ::=  { id-ce 15 }\n * KeyUsage ::= BIT STRING {\n *   digitalSignature        (0),\n *   nonRepudiation          (1),\n *   keyEncipherment         (2),\n *   dataEncipherment        (3),\n *   keyAgreement            (4),\n *   keyCertSign             (5),\n *   cRLSign                 (6),\n *   encipherOnly            (7),\n *   decipherOnly            (8)\n * }\n *\n * id-ce-basicConstraints OBJECT IDENTIFIER ::=  { id-ce 19 }\n * BasicConstraints ::= SEQUENCE {\n *   cA                      BOOLEAN DEFAULT FALSE,\n *   pathLenConstraint       INTEGER (0..MAX) OPTIONAL\n * }\n *\n * subjectAltName EXTENSION ::= {\n *   SYNTAX GeneralNames\n *   IDENTIFIED BY id-ce-subjectAltName\n * }\n *\n * GeneralNames ::= SEQUENCE SIZE (1..MAX) OF GeneralName\n *\n * GeneralName ::= CHOICE {\n *   otherName      [0] INSTANCE OF OTHER-NAME,\n *   rfc822Name     [1] IA5String,\n *   dNSName        [2] IA5String,\n *   x400Address    [3] ORAddress,\n *   directoryName  [4] Name,\n *   ediPartyName   [5] EDIPartyName,\n *   uniformResourceIdentifier [6] IA5String,\n *   IPAddress      [7] OCTET STRING,\n *   registeredID   [8] OBJECT IDENTIFIER\n * }\n *\n * OTHER-NAME ::= TYPE-IDENTIFIER\n *\n * EDIPartyName ::= SEQUENCE {\n *   nameAssigner [0] DirectoryString {ub-name} OPTIONAL,\n *   partyName    [1] DirectoryString {ub-name}\n * }\n *\n * @param exts the extensions ASN.1 with extension sequences to parse.\n *\n * @return the array.\n */\npki.certificateExtensionsFromAsn1 = function(exts) {\n  var rval = [];\n  for(var i = 0; i < exts.value.length; ++i) {\n    // get extension sequence\n    var extseq = exts.value[i];\n    for(var ei = 0; ei < extseq.value.length; ++ei) {\n      rval.push(pki.certificateExtensionFromAsn1(extseq.value[ei]));\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Parses a single certificate extension from ASN.1.\n *\n * @param ext the extension in ASN.1 format.\n *\n * @return the parsed extension as an object.\n */\npki.certificateExtensionFromAsn1 = function(ext) {\n  // an extension has:\n  // [0] extnID      OBJECT IDENTIFIER\n  // [1] critical    BOOLEAN DEFAULT FALSE\n  // [2] extnValue   OCTET STRING\n  var e = {};\n  e.id = asn1.derToOid(ext.value[0].value);\n  e.critical = false;\n  if(ext.value[1].type === asn1.Type.BOOLEAN) {\n    e.critical = (ext.value[1].value.charCodeAt(0) !== 0x00);\n    e.value = ext.value[2].value;\n  } else {\n    e.value = ext.value[1].value;\n  }\n  // if the oid is known, get its name\n  if(e.id in oids) {\n    e.name = oids[e.id];\n\n    // handle key usage\n    if(e.name === 'keyUsage') {\n      // get value as BIT STRING\n      var ev = asn1.fromDer(e.value);\n      var b2 = 0x00;\n      var b3 = 0x00;\n      if(ev.value.length > 1) {\n        // skip first byte, just indicates unused bits which\n        // will be padded with 0s anyway\n        // get bytes with flag bits\n        b2 = ev.value.charCodeAt(1);\n        b3 = ev.value.length > 2 ? ev.value.charCodeAt(2) : 0;\n      }\n      // set flags\n      e.digitalSignature = (b2 & 0x80) === 0x80;\n      e.nonRepudiation = (b2 & 0x40) === 0x40;\n      e.keyEncipherment = (b2 & 0x20) === 0x20;\n      e.dataEncipherment = (b2 & 0x10) === 0x10;\n      e.keyAgreement = (b2 & 0x08) === 0x08;\n      e.keyCertSign = (b2 & 0x04) === 0x04;\n      e.cRLSign = (b2 & 0x02) === 0x02;\n      e.encipherOnly = (b2 & 0x01) === 0x01;\n      e.decipherOnly = (b3 & 0x80) === 0x80;\n    } else if(e.name === 'basicConstraints') {\n      // handle basic constraints\n      // get value as SEQUENCE\n      var ev = asn1.fromDer(e.value);\n      // get cA BOOLEAN flag (defaults to false)\n      if(ev.value.length > 0 && ev.value[0].type === asn1.Type.BOOLEAN) {\n        e.cA = (ev.value[0].value.charCodeAt(0) !== 0x00);\n      } else {\n        e.cA = false;\n      }\n      // get path length constraint\n      var value = null;\n      if(ev.value.length > 0 && ev.value[0].type === asn1.Type.INTEGER) {\n        value = ev.value[0].value;\n      } else if(ev.value.length > 1) {\n        value = ev.value[1].value;\n      }\n      if(value !== null) {\n        e.pathLenConstraint = asn1.derToInteger(value);\n      }\n    } else if(e.name === 'extKeyUsage') {\n      // handle extKeyUsage\n      // value is a SEQUENCE of OIDs\n      var ev = asn1.fromDer(e.value);\n      for(var vi = 0; vi < ev.value.length; ++vi) {\n        var oid = asn1.derToOid(ev.value[vi].value);\n        if(oid in oids) {\n          e[oids[oid]] = true;\n        } else {\n          e[oid] = true;\n        }\n      }\n    } else if(e.name === 'nsCertType') {\n      // handle nsCertType\n      // get value as BIT STRING\n      var ev = asn1.fromDer(e.value);\n      var b2 = 0x00;\n      if(ev.value.length > 1) {\n        // skip first byte, just indicates unused bits which\n        // will be padded with 0s anyway\n        // get bytes with flag bits\n        b2 = ev.value.charCodeAt(1);\n      }\n      // set flags\n      e.client = (b2 & 0x80) === 0x80;\n      e.server = (b2 & 0x40) === 0x40;\n      e.email = (b2 & 0x20) === 0x20;\n      e.objsign = (b2 & 0x10) === 0x10;\n      e.reserved = (b2 & 0x08) === 0x08;\n      e.sslCA = (b2 & 0x04) === 0x04;\n      e.emailCA = (b2 & 0x02) === 0x02;\n      e.objCA = (b2 & 0x01) === 0x01;\n    } else if(\n      e.name === 'subjectAltName' ||\n      e.name === 'issuerAltName') {\n      // handle subjectAltName/issuerAltName\n      e.altNames = [];\n\n      // ev is a SYNTAX SEQUENCE\n      var gn;\n      var ev = asn1.fromDer(e.value);\n      for(var n = 0; n < ev.value.length; ++n) {\n        // get GeneralName\n        gn = ev.value[n];\n\n        var altName = {\n          type: gn.type,\n          value: gn.value\n        };\n        e.altNames.push(altName);\n\n        // Note: Support for types 1,2,6,7,8\n        switch(gn.type) {\n          // rfc822Name\n          case 1:\n          // dNSName\n          case 2:\n          // uniformResourceIdentifier (URI)\n          case 6:\n            break;\n          // IPAddress\n          case 7:\n            // convert to IPv4/IPv6 string representation\n            altName.ip = forge.util.bytesToIP(gn.value);\n            break;\n          // registeredID\n          case 8:\n            altName.oid = asn1.derToOid(gn.value);\n            break;\n          default:\n            // unsupported\n        }\n      }\n    } else if(e.name === 'subjectKeyIdentifier') {\n      // value is an OCTETSTRING w/the hash of the key-type specific\n      // public key structure (eg: RSAPublicKey)\n      var ev = asn1.fromDer(e.value);\n      e.subjectKeyIdentifier = forge.util.bytesToHex(ev.value);\n    }\n  }\n  return e;\n};\n\n/**\n * Converts a PKCS#10 certification request (CSR) from an ASN.1 object.\n *\n * Note: If the certification request is to be verified then compute hash\n * should be set to true. There is currently no implementation for converting\n * a certificate back to ASN.1 so the CertificationRequestInfo part of the\n * ASN.1 object needs to be scanned before the csr object is created.\n *\n * @param obj the asn1 representation of a PKCS#10 certification request (CSR).\n * @param computeHash true to compute the hash for verification.\n *\n * @return the certification request (CSR).\n */\npki.certificationRequestFromAsn1 = function(obj, computeHash) {\n  // validate certification request and capture data\n  var capture = {};\n  var errors = [];\n  if(!asn1.validate(obj, certificationRequestValidator, capture, errors)) {\n    var error = new Error('Cannot read PKCS#10 certificate request. ' +\n      'ASN.1 object is not a PKCS#10 CertificationRequest.');\n    error.errors = errors;\n    throw error;\n  }\n\n  // get oid\n  var oid = asn1.derToOid(capture.publicKeyOid);\n  if(oid !== pki.oids.rsaEncryption) {\n    throw new Error('Cannot read public key. OID is not RSA.');\n  }\n\n  // create certification request\n  var csr = pki.createCertificationRequest();\n  csr.version = capture.csrVersion ? capture.csrVersion.charCodeAt(0) : 0;\n  csr.signatureOid = forge.asn1.derToOid(capture.csrSignatureOid);\n  csr.signatureParameters = _readSignatureParameters(\n    csr.signatureOid, capture.csrSignatureParams, true);\n  csr.siginfo.algorithmOid = forge.asn1.derToOid(capture.csrSignatureOid);\n  csr.siginfo.parameters = _readSignatureParameters(\n    csr.siginfo.algorithmOid, capture.csrSignatureParams, false);\n  csr.signature = capture.csrSignature;\n\n  // keep CertificationRequestInfo to preserve signature when exporting\n  csr.certificationRequestInfo = capture.certificationRequestInfo;\n\n  if(computeHash) {\n    // create digest for OID signature type\n    csr.md = _createSignatureDigest({\n      signatureOid: csr.signatureOid,\n      type: 'certification request'\n    });\n\n    // produce DER formatted CertificationRequestInfo and digest it\n    var bytes = asn1.toDer(csr.certificationRequestInfo);\n    csr.md.update(bytes.getBytes());\n  }\n\n  // handle subject, build subject message digest\n  var smd = forge.md.sha1.create();\n  csr.subject.getField = function(sn) {\n    return _getAttribute(csr.subject, sn);\n  };\n  csr.subject.addField = function(attr) {\n    _fillMissingFields([attr]);\n    csr.subject.attributes.push(attr);\n  };\n  csr.subject.attributes = pki.RDNAttributesAsArray(\n    capture.certificationRequestInfoSubject, smd);\n  csr.subject.hash = smd.digest().toHex();\n\n  // convert RSA public key from ASN.1\n  csr.publicKey = pki.publicKeyFromAsn1(capture.subjectPublicKeyInfo);\n\n  // convert attributes from ASN.1\n  csr.getAttribute = function(sn) {\n    return _getAttribute(csr, sn);\n  };\n  csr.addAttribute = function(attr) {\n    _fillMissingFields([attr]);\n    csr.attributes.push(attr);\n  };\n  csr.attributes = pki.CRIAttributesAsArray(\n    capture.certificationRequestInfoAttributes || []);\n\n  return csr;\n};\n\n/**\n * Creates an empty certification request (a CSR or certificate signing\n * request). Once created, its public key and attributes can be set and then\n * it can be signed.\n *\n * @return the empty certification request.\n */\npki.createCertificationRequest = function() {\n  var csr = {};\n  csr.version = 0x00;\n  csr.signatureOid = null;\n  csr.signature = null;\n  csr.siginfo = {};\n  csr.siginfo.algorithmOid = null;\n\n  csr.subject = {};\n  csr.subject.getField = function(sn) {\n    return _getAttribute(csr.subject, sn);\n  };\n  csr.subject.addField = function(attr) {\n    _fillMissingFields([attr]);\n    csr.subject.attributes.push(attr);\n  };\n  csr.subject.attributes = [];\n  csr.subject.hash = null;\n\n  csr.publicKey = null;\n  csr.attributes = [];\n  csr.getAttribute = function(sn) {\n    return _getAttribute(csr, sn);\n  };\n  csr.addAttribute = function(attr) {\n    _fillMissingFields([attr]);\n    csr.attributes.push(attr);\n  };\n  csr.md = null;\n\n  /**\n   * Sets the subject of this certification request.\n   *\n   * @param attrs the array of subject attributes to use.\n   */\n  csr.setSubject = function(attrs) {\n    // set new attributes\n    _fillMissingFields(attrs);\n    csr.subject.attributes = attrs;\n    csr.subject.hash = null;\n  };\n\n  /**\n   * Sets the attributes of this certification request.\n   *\n   * @param attrs the array of attributes to use.\n   */\n  csr.setAttributes = function(attrs) {\n    // set new attributes\n    _fillMissingFields(attrs);\n    csr.attributes = attrs;\n  };\n\n  /**\n   * Signs this certification request using the given private key.\n   *\n   * @param key the private key to sign with.\n   * @param md the message digest object to use (defaults to forge.md.sha1).\n   */\n  csr.sign = function(key, md) {\n    // TODO: get signature OID from private key\n    csr.md = md || forge.md.sha1.create();\n    var algorithmOid = oids[csr.md.algorithm + 'WithRSAEncryption'];\n    if(!algorithmOid) {\n      var error = new Error('Could not compute certification request digest. ' +\n        'Unknown message digest algorithm OID.');\n      error.algorithm = csr.md.algorithm;\n      throw error;\n    }\n    csr.signatureOid = csr.siginfo.algorithmOid = algorithmOid;\n\n    // get CertificationRequestInfo, convert to DER\n    csr.certificationRequestInfo = pki.getCertificationRequestInfo(csr);\n    var bytes = asn1.toDer(csr.certificationRequestInfo);\n\n    // digest and sign\n    csr.md.update(bytes.getBytes());\n    csr.signature = key.sign(csr.md);\n  };\n\n  /**\n   * Attempts verify the signature on the passed certification request using\n   * its public key.\n   *\n   * A CSR that has been exported to a file in PEM format can be verified using\n   * OpenSSL using this command:\n   *\n   * openssl req -in <the-csr-pem-file> -verify -noout -text\n   *\n   * @return true if verified, false if not.\n   */\n  csr.verify = function() {\n    var rval = false;\n\n    var md = csr.md;\n    if(md === null) {\n      md = _createSignatureDigest({\n        signatureOid: csr.signatureOid,\n        type: 'certification request'\n      });\n\n      // produce DER formatted CertificationRequestInfo and digest it\n      var cri = csr.certificationRequestInfo ||\n        pki.getCertificationRequestInfo(csr);\n      var bytes = asn1.toDer(cri);\n      md.update(bytes.getBytes());\n    }\n\n    if(md !== null) {\n      rval = _verifySignature({\n        certificate: csr, md: md, signature: csr.signature\n      });\n    }\n\n    return rval;\n  };\n\n  return csr;\n};\n\n/**\n * Converts an X.509 subject or issuer to an ASN.1 RDNSequence.\n *\n * @param obj the subject or issuer (distinguished name).\n *\n * @return the ASN.1 RDNSequence.\n */\nfunction _dnToAsn1(obj) {\n  // create an empty RDNSequence\n  var rval = asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n\n  // iterate over attributes\n  var attr, set;\n  var attrs = obj.attributes;\n  for(var i = 0; i < attrs.length; ++i) {\n    attr = attrs[i];\n    var value = attr.value;\n\n    // reuse tag class for attribute value if available\n    var valueTagClass = asn1.Type.PRINTABLESTRING;\n    if('valueTagClass' in attr) {\n      valueTagClass = attr.valueTagClass;\n\n      if(valueTagClass === asn1.Type.UTF8) {\n        value = forge.util.encodeUtf8(value);\n      }\n      // FIXME: handle more encodings\n    }\n\n    // create a RelativeDistinguishedName set\n    // each value in the set is an AttributeTypeAndValue first\n    // containing the type (an OID) and second the value\n    set = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n        // AttributeType\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n          asn1.oidToDer(attr.type).getBytes()),\n        // AttributeValue\n        asn1.create(asn1.Class.UNIVERSAL, valueTagClass, false, value)\n      ])\n    ]);\n    rval.value.push(set);\n  }\n\n  return rval;\n}\n\n/**\n * Gets all printable attributes (typically of an issuer or subject) in a\n * simplified JSON format for display.\n *\n * @param attrs the attributes.\n *\n * @return the JSON for display.\n */\nfunction _getAttributesAsJson(attrs) {\n  var rval = {};\n  for(var i = 0; i < attrs.length; ++i) {\n    var attr = attrs[i];\n    if(attr.shortName && (\n      attr.valueTagClass === asn1.Type.UTF8 ||\n      attr.valueTagClass === asn1.Type.PRINTABLESTRING ||\n      attr.valueTagClass === asn1.Type.IA5STRING)) {\n      var value = attr.value;\n      if(attr.valueTagClass === asn1.Type.UTF8) {\n        value = forge.util.encodeUtf8(attr.value);\n      }\n      if(!(attr.shortName in rval)) {\n        rval[attr.shortName] = value;\n      } else if(forge.util.isArray(rval[attr.shortName])) {\n        rval[attr.shortName].push(value);\n      } else {\n        rval[attr.shortName] = [rval[attr.shortName], value];\n      }\n    }\n  }\n  return rval;\n}\n\n/**\n * Fills in missing fields in attributes.\n *\n * @param attrs the attributes to fill missing fields in.\n */\nfunction _fillMissingFields(attrs) {\n  var attr;\n  for(var i = 0; i < attrs.length; ++i) {\n    attr = attrs[i];\n\n    // populate missing name\n    if(typeof attr.name === 'undefined') {\n      if(attr.type && attr.type in pki.oids) {\n        attr.name = pki.oids[attr.type];\n      } else if(attr.shortName && attr.shortName in _shortNames) {\n        attr.name = pki.oids[_shortNames[attr.shortName]];\n      }\n    }\n\n    // populate missing type (OID)\n    if(typeof attr.type === 'undefined') {\n      if(attr.name && attr.name in pki.oids) {\n        attr.type = pki.oids[attr.name];\n      } else {\n        var error = new Error('Attribute type not specified.');\n        error.attribute = attr;\n        throw error;\n      }\n    }\n\n    // populate missing shortname\n    if(typeof attr.shortName === 'undefined') {\n      if(attr.name && attr.name in _shortNames) {\n        attr.shortName = _shortNames[attr.name];\n      }\n    }\n\n    // convert extensions to value\n    if(attr.type === oids.extensionRequest) {\n      attr.valueConstructed = true;\n      attr.valueTagClass = asn1.Type.SEQUENCE;\n      if(!attr.value && attr.extensions) {\n        attr.value = [];\n        for(var ei = 0; ei < attr.extensions.length; ++ei) {\n          attr.value.push(pki.certificateExtensionToAsn1(\n            _fillMissingExtensionFields(attr.extensions[ei])));\n        }\n      }\n    }\n\n    if(typeof attr.value === 'undefined') {\n      var error = new Error('Attribute value not specified.');\n      error.attribute = attr;\n      throw error;\n    }\n  }\n}\n\n/**\n * Fills in missing fields in certificate extensions.\n *\n * @param e the extension.\n * @param [options] the options to use.\n *          [cert] the certificate the extensions are for.\n *\n * @return the extension.\n */\nfunction _fillMissingExtensionFields(e, options) {\n  options = options || {};\n\n  // populate missing name\n  if(typeof e.name === 'undefined') {\n    if(e.id && e.id in pki.oids) {\n      e.name = pki.oids[e.id];\n    }\n  }\n\n  // populate missing id\n  if(typeof e.id === 'undefined') {\n    if(e.name && e.name in pki.oids) {\n      e.id = pki.oids[e.name];\n    } else {\n      var error = new Error('Extension ID not specified.');\n      error.extension = e;\n      throw error;\n    }\n  }\n\n  if(typeof e.value !== 'undefined') {\n    return e;\n  }\n\n  // handle missing value:\n\n  // value is a BIT STRING\n  if(e.name === 'keyUsage') {\n    // build flags\n    var unused = 0;\n    var b2 = 0x00;\n    var b3 = 0x00;\n    if(e.digitalSignature) {\n      b2 |= 0x80;\n      unused = 7;\n    }\n    if(e.nonRepudiation) {\n      b2 |= 0x40;\n      unused = 6;\n    }\n    if(e.keyEncipherment) {\n      b2 |= 0x20;\n      unused = 5;\n    }\n    if(e.dataEncipherment) {\n      b2 |= 0x10;\n      unused = 4;\n    }\n    if(e.keyAgreement) {\n      b2 |= 0x08;\n      unused = 3;\n    }\n    if(e.keyCertSign) {\n      b2 |= 0x04;\n      unused = 2;\n    }\n    if(e.cRLSign) {\n      b2 |= 0x02;\n      unused = 1;\n    }\n    if(e.encipherOnly) {\n      b2 |= 0x01;\n      unused = 0;\n    }\n    if(e.decipherOnly) {\n      b3 |= 0x80;\n      unused = 7;\n    }\n\n    // create bit string\n    var value = String.fromCharCode(unused);\n    if(b3 !== 0) {\n      value += String.fromCharCode(b2) + String.fromCharCode(b3);\n    } else if(b2 !== 0) {\n      value += String.fromCharCode(b2);\n    }\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false, value);\n  } else if(e.name === 'basicConstraints') {\n    // basicConstraints is a SEQUENCE\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n    // cA BOOLEAN flag defaults to false\n    if(e.cA) {\n      e.value.value.push(asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.BOOLEAN, false,\n        String.fromCharCode(0xFF)));\n    }\n    if('pathLenConstraint' in e) {\n      e.value.value.push(asn1.create(\n        asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        asn1.integerToDer(e.pathLenConstraint).getBytes()));\n    }\n  } else if(e.name === 'extKeyUsage') {\n    // extKeyUsage is a SEQUENCE of OIDs\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n    var seq = e.value.value;\n    for(var key in e) {\n      if(e[key] !== true) {\n        continue;\n      }\n      // key is name in OID map\n      if(key in oids) {\n        seq.push(asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID,\n          false, asn1.oidToDer(oids[key]).getBytes()));\n      } else if(key.indexOf('.') !== -1) {\n        // assume key is an OID\n        seq.push(asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID,\n          false, asn1.oidToDer(key).getBytes()));\n      }\n    }\n  } else if(e.name === 'nsCertType') {\n    // nsCertType is a BIT STRING\n    // build flags\n    var unused = 0;\n    var b2 = 0x00;\n\n    if(e.client) {\n      b2 |= 0x80;\n      unused = 7;\n    }\n    if(e.server) {\n      b2 |= 0x40;\n      unused = 6;\n    }\n    if(e.email) {\n      b2 |= 0x20;\n      unused = 5;\n    }\n    if(e.objsign) {\n      b2 |= 0x10;\n      unused = 4;\n    }\n    if(e.reserved) {\n      b2 |= 0x08;\n      unused = 3;\n    }\n    if(e.sslCA) {\n      b2 |= 0x04;\n      unused = 2;\n    }\n    if(e.emailCA) {\n      b2 |= 0x02;\n      unused = 1;\n    }\n    if(e.objCA) {\n      b2 |= 0x01;\n      unused = 0;\n    }\n\n    // create bit string\n    var value = String.fromCharCode(unused);\n    if(b2 !== 0) {\n      value += String.fromCharCode(b2);\n    }\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false, value);\n  } else if(e.name === 'subjectAltName' || e.name === 'issuerAltName') {\n    // SYNTAX SEQUENCE\n    e.value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n\n    var altName;\n    for(var n = 0; n < e.altNames.length; ++n) {\n      altName = e.altNames[n];\n      var value = altName.value;\n      // handle IP\n      if(altName.type === 7 && altName.ip) {\n        value = forge.util.bytesFromIP(altName.ip);\n        if(value === null) {\n          var error = new Error(\n            'Extension \"ip\" value is not a valid IPv4 or IPv6 address.');\n          error.extension = e;\n          throw error;\n        }\n      } else if(altName.type === 8) {\n        // handle OID\n        if(altName.oid) {\n          value = asn1.oidToDer(asn1.oidToDer(altName.oid));\n        } else {\n          // deprecated ... convert value to OID\n          value = asn1.oidToDer(value);\n        }\n      }\n      e.value.value.push(asn1.create(\n        asn1.Class.CONTEXT_SPECIFIC, altName.type, false,\n        value));\n    }\n  } else if(e.name === 'nsComment' && options.cert) {\n    // sanity check value is ASCII (req'd) and not too big\n    if(!(/^[\\x00-\\x7F]*$/.test(e.comment)) ||\n      (e.comment.length < 1) || (e.comment.length > 128)) {\n      throw new Error('Invalid \"nsComment\" content.');\n    }\n    // IA5STRING opaque comment\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.IA5STRING, false, e.comment);\n  } else if(e.name === 'subjectKeyIdentifier' && options.cert) {\n    var ski = options.cert.generateSubjectKeyIdentifier();\n    e.subjectKeyIdentifier = ski.toHex();\n    // OCTETSTRING w/digest\n    e.value = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, ski.getBytes());\n  } else if(e.name === 'authorityKeyIdentifier' && options.cert) {\n    // SYNTAX SEQUENCE\n    e.value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n    var seq = e.value.value;\n\n    if(e.keyIdentifier) {\n      var keyIdentifier = (e.keyIdentifier === true ?\n        options.cert.generateSubjectKeyIdentifier().getBytes() :\n        e.keyIdentifier);\n      seq.push(\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, false, keyIdentifier));\n    }\n\n    if(e.authorityCertIssuer) {\n      var authorityCertIssuer = [\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 4, true, [\n          _dnToAsn1(e.authorityCertIssuer === true ?\n            options.cert.issuer : e.authorityCertIssuer)\n        ])\n      ];\n      seq.push(\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, authorityCertIssuer));\n    }\n\n    if(e.serialNumber) {\n      var serialNumber = forge.util.hexToBytes(e.serialNumber === true ?\n        options.cert.serialNumber : e.serialNumber);\n      seq.push(\n        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 2, false, serialNumber));\n    }\n  } else if(e.name === 'cRLDistributionPoints') {\n    e.value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n    var seq = e.value.value;\n\n    // Create sub SEQUENCE of DistributionPointName\n    var subSeq = asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n\n    // Create fullName CHOICE\n    var fullNameGeneralNames = asn1.create(\n      asn1.Class.CONTEXT_SPECIFIC, 0, true, []);\n    var altName;\n    for(var n = 0; n < e.altNames.length; ++n) {\n      altName = e.altNames[n];\n      var value = altName.value;\n      // handle IP\n      if(altName.type === 7 && altName.ip) {\n        value = forge.util.bytesFromIP(altName.ip);\n        if(value === null) {\n          var error = new Error(\n            'Extension \"ip\" value is not a valid IPv4 or IPv6 address.');\n          error.extension = e;\n          throw error;\n        }\n      } else if(altName.type === 8) {\n        // handle OID\n        if(altName.oid) {\n          value = asn1.oidToDer(asn1.oidToDer(altName.oid));\n        } else {\n          // deprecated ... convert value to OID\n          value = asn1.oidToDer(value);\n        }\n      }\n      fullNameGeneralNames.value.push(asn1.create(\n        asn1.Class.CONTEXT_SPECIFIC, altName.type, false,\n        value));\n    }\n\n    // Add to the parent SEQUENCE\n    subSeq.value.push(asn1.create(\n      asn1.Class.CONTEXT_SPECIFIC, 0, true, [fullNameGeneralNames]));\n    seq.push(subSeq);\n  }\n\n  // ensure value has been defined by now\n  if(typeof e.value === 'undefined') {\n    var error = new Error('Extension value not specified.');\n    error.extension = e;\n    throw error;\n  }\n\n  return e;\n}\n\n/**\n * Convert signature parameters object to ASN.1\n *\n * @param {String} oid Signature algorithm OID\n * @param params The signature parametrs object\n * @return ASN.1 object representing signature parameters\n */\nfunction _signatureParametersToAsn1(oid, params) {\n  switch(oid) {\n    case oids['RSASSA-PSS']:\n      var parts = [];\n\n      if(params.hash.algorithmOid !== undefined) {\n        parts.push(asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n              asn1.oidToDer(params.hash.algorithmOid).getBytes()),\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n          ])\n        ]));\n      }\n\n      if(params.mgf.algorithmOid !== undefined) {\n        parts.push(asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n              asn1.oidToDer(params.mgf.algorithmOid).getBytes()),\n            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n              asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n                asn1.oidToDer(params.mgf.hash.algorithmOid).getBytes()),\n              asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')\n            ])\n          ])\n        ]));\n      }\n\n      if(params.saltLength !== undefined) {\n        parts.push(asn1.create(asn1.Class.CONTEXT_SPECIFIC, 2, true, [\n          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n            asn1.integerToDer(params.saltLength).getBytes())\n        ]));\n      }\n\n      return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, parts);\n\n    default:\n      return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '');\n  }\n}\n\n/**\n * Converts a certification request's attributes to an ASN.1 set of\n * CRIAttributes.\n *\n * @param csr certification request.\n *\n * @return the ASN.1 set of CRIAttributes.\n */\nfunction _CRIAttributesToAsn1(csr) {\n  // create an empty context-specific container\n  var rval = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, []);\n\n  // no attributes, return empty container\n  if(csr.attributes.length === 0) {\n    return rval;\n  }\n\n  // each attribute has a sequence with a type and a set of values\n  var attrs = csr.attributes;\n  for(var i = 0; i < attrs.length; ++i) {\n    var attr = attrs[i];\n    var value = attr.value;\n\n    // reuse tag class for attribute value if available\n    var valueTagClass = asn1.Type.UTF8;\n    if('valueTagClass' in attr) {\n      valueTagClass = attr.valueTagClass;\n    }\n    if(valueTagClass === asn1.Type.UTF8) {\n      value = forge.util.encodeUtf8(value);\n    }\n    var valueConstructed = false;\n    if('valueConstructed' in attr) {\n      valueConstructed = attr.valueConstructed;\n    }\n    // FIXME: handle more encodings\n\n    // create a RelativeDistinguishedName set\n    // each value in the set is an AttributeTypeAndValue first\n    // containing the type (an OID) and second the value\n    var seq = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // AttributeType\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(attr.type).getBytes()),\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [\n        // AttributeValue\n        asn1.create(\n          asn1.Class.UNIVERSAL, valueTagClass, valueConstructed, value)\n      ])\n    ]);\n    rval.value.push(seq);\n  }\n\n  return rval;\n}\n\nvar jan_1_1950 = new Date('1950-01-01T00:00:00Z');\nvar jan_1_2050 = new Date('2050-01-01T00:00:00Z');\n\n/**\n * Converts a Date object to ASN.1\n * Handles the different format before and after 1st January 2050\n *\n * @param date date object.\n *\n * @return the ASN.1 object representing the date.\n */\nfunction _dateToAsn1(date) {\n  if(date >= jan_1_1950 && date < jan_1_2050) {\n    return asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.UTCTIME, false,\n      asn1.dateToUtcTime(date));\n  } else {\n    return asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.GENERALIZEDTIME, false,\n      asn1.dateToGeneralizedTime(date));\n  }\n}\n\n/**\n * Gets the ASN.1 TBSCertificate part of an X.509v3 certificate.\n *\n * @param cert the certificate.\n *\n * @return the asn1 TBSCertificate.\n */\npki.getTBSCertificate = function(cert) {\n  // TBSCertificate\n  var notBefore = _dateToAsn1(cert.validity.notBefore);\n  var notAfter = _dateToAsn1(cert.validity.notAfter);\n  var tbs = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version\n    asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n      // integer\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n        asn1.integerToDer(cert.version).getBytes())\n    ]),\n    // serialNumber\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      forge.util.hexToBytes(cert.serialNumber)),\n    // signature\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(cert.siginfo.algorithmOid).getBytes()),\n      // parameters\n      _signatureParametersToAsn1(\n        cert.siginfo.algorithmOid, cert.siginfo.parameters)\n    ]),\n    // issuer\n    _dnToAsn1(cert.issuer),\n    // validity\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      notBefore,\n      notAfter\n    ]),\n    // subject\n    _dnToAsn1(cert.subject),\n    // SubjectPublicKeyInfo\n    pki.publicKeyToAsn1(cert.publicKey)\n  ]);\n\n  if(cert.issuer.uniqueId) {\n    // issuerUniqueID (optional)\n    tbs.value.push(\n      asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, [\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false,\n          // TODO: support arbitrary bit length ids\n          String.fromCharCode(0x00) +\n          cert.issuer.uniqueId\n        )\n      ])\n    );\n  }\n  if(cert.subject.uniqueId) {\n    // subjectUniqueID (optional)\n    tbs.value.push(\n      asn1.create(asn1.Class.CONTEXT_SPECIFIC, 2, true, [\n        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false,\n          // TODO: support arbitrary bit length ids\n          String.fromCharCode(0x00) +\n          cert.subject.uniqueId\n        )\n      ])\n    );\n  }\n\n  if(cert.extensions.length > 0) {\n    // extensions (optional)\n    tbs.value.push(pki.certificateExtensionsToAsn1(cert.extensions));\n  }\n\n  return tbs;\n};\n\n/**\n * Gets the ASN.1 CertificationRequestInfo part of a\n * PKCS#10 CertificationRequest.\n *\n * @param csr the certification request.\n *\n * @return the asn1 CertificationRequestInfo.\n */\npki.getCertificationRequestInfo = function(csr) {\n  // CertificationRequestInfo\n  var cri = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // version\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,\n      asn1.integerToDer(csr.version).getBytes()),\n    // subject\n    _dnToAsn1(csr.subject),\n    // SubjectPublicKeyInfo\n    pki.publicKeyToAsn1(csr.publicKey),\n    // attributes\n    _CRIAttributesToAsn1(csr)\n  ]);\n\n  return cri;\n};\n\n/**\n * Converts a DistinguishedName (subject or issuer) to an ASN.1 object.\n *\n * @param dn the DistinguishedName.\n *\n * @return the asn1 representation of a DistinguishedName.\n */\npki.distinguishedNameToAsn1 = function(dn) {\n  return _dnToAsn1(dn);\n};\n\n/**\n * Converts an X.509v3 RSA certificate to an ASN.1 object.\n *\n * @param cert the certificate.\n *\n * @return the asn1 representation of an X.509v3 RSA certificate.\n */\npki.certificateToAsn1 = function(cert) {\n  // prefer cached TBSCertificate over generating one\n  var tbsCertificate = cert.tbsCertificate || pki.getTBSCertificate(cert);\n\n  // Certificate\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // TBSCertificate\n    tbsCertificate,\n    // AlgorithmIdentifier (signature algorithm)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(cert.signatureOid).getBytes()),\n      // parameters\n      _signatureParametersToAsn1(cert.signatureOid, cert.signatureParameters)\n    ]),\n    // SignatureValue\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false,\n      String.fromCharCode(0x00) + cert.signature)\n  ]);\n};\n\n/**\n * Converts X.509v3 certificate extensions to ASN.1.\n *\n * @param exts the extensions to convert.\n *\n * @return the extensions in ASN.1 format.\n */\npki.certificateExtensionsToAsn1 = function(exts) {\n  // create top-level extension container\n  var rval = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 3, true, []);\n\n  // create extension sequence (stores a sequence for each extension)\n  var seq = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n  rval.value.push(seq);\n\n  for(var i = 0; i < exts.length; ++i) {\n    seq.value.push(pki.certificateExtensionToAsn1(exts[i]));\n  }\n\n  return rval;\n};\n\n/**\n * Converts a single certificate extension to ASN.1.\n *\n * @param ext the extension to convert.\n *\n * @return the extension in ASN.1 format.\n */\npki.certificateExtensionToAsn1 = function(ext) {\n  // create a sequence for each extension\n  var extseq = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, []);\n\n  // extnID (OID)\n  extseq.value.push(asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n    asn1.oidToDer(ext.id).getBytes()));\n\n  // critical defaults to false\n  if(ext.critical) {\n    // critical BOOLEAN DEFAULT FALSE\n    extseq.value.push(asn1.create(\n      asn1.Class.UNIVERSAL, asn1.Type.BOOLEAN, false,\n      String.fromCharCode(0xFF)));\n  }\n\n  var value = ext.value;\n  if(typeof ext.value !== 'string') {\n    // value is asn.1\n    value = asn1.toDer(value).getBytes();\n  }\n\n  // extnValue (OCTET STRING)\n  extseq.value.push(asn1.create(\n    asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, value));\n\n  return extseq;\n};\n\n/**\n * Converts a PKCS#10 certification request to an ASN.1 object.\n *\n * @param csr the certification request.\n *\n * @return the asn1 representation of a certification request.\n */\npki.certificationRequestToAsn1 = function(csr) {\n  // prefer cached CertificationRequestInfo over generating one\n  var cri = csr.certificationRequestInfo ||\n    pki.getCertificationRequestInfo(csr);\n\n  // Certificate\n  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n    // CertificationRequestInfo\n    cri,\n    // AlgorithmIdentifier (signature algorithm)\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [\n      // algorithm\n      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,\n        asn1.oidToDer(csr.signatureOid).getBytes()),\n      // parameters\n      _signatureParametersToAsn1(csr.signatureOid, csr.signatureParameters)\n    ]),\n    // signature\n    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.BITSTRING, false,\n      String.fromCharCode(0x00) + csr.signature)\n  ]);\n};\n\n/**\n * Creates a CA store.\n *\n * @param certs an optional array of certificate objects or PEM-formatted\n *          certificate strings to add to the CA store.\n *\n * @return the CA store.\n */\npki.createCaStore = function(certs) {\n  // create CA store\n  var caStore = {\n    // stored certificates\n    certs: {}\n  };\n\n  /**\n   * Gets the certificate that issued the passed certificate or its\n   * 'parent'.\n   *\n   * @param cert the certificate to get the parent for.\n   *\n   * @return the parent certificate or null if none was found.\n   */\n  caStore.getIssuer = function(cert) {\n    var rval = getBySubject(cert.issuer);\n\n    // see if there are multiple matches\n    /*if(forge.util.isArray(rval)) {\n      // TODO: resolve multiple matches by checking\n      // authorityKey/subjectKey/issuerUniqueID/other identifiers, etc.\n      // FIXME: or alternatively do authority key mapping\n      // if possible (X.509v1 certs can't work?)\n      throw new Error('Resolving multiple issuer matches not implemented yet.');\n    }*/\n\n    return rval;\n  };\n\n  /**\n   * Adds a trusted certificate to the store.\n   *\n   * @param cert the certificate to add as a trusted certificate (either a\n   *          pki.certificate object or a PEM-formatted certificate).\n   */\n  caStore.addCertificate = function(cert) {\n    // convert from pem if necessary\n    if(typeof cert === 'string') {\n      cert = forge.pki.certificateFromPem(cert);\n    }\n\n    ensureSubjectHasHash(cert.subject);\n\n    if(!caStore.hasCertificate(cert)) { // avoid duplicate certificates in store\n      if(cert.subject.hash in caStore.certs) {\n        // subject hash already exists, append to array\n        var tmp = caStore.certs[cert.subject.hash];\n        if(!forge.util.isArray(tmp)) {\n          tmp = [tmp];\n        }\n        tmp.push(cert);\n        caStore.certs[cert.subject.hash] = tmp;\n      } else {\n        caStore.certs[cert.subject.hash] = cert;\n      }\n    }\n  };\n\n  /**\n   * Checks to see if the given certificate is in the store.\n   *\n   * @param cert the certificate to check (either a pki.certificate or a\n   *          PEM-formatted certificate).\n   *\n   * @return true if the certificate is in the store, false if not.\n   */\n  caStore.hasCertificate = function(cert) {\n    // convert from pem if necessary\n    if(typeof cert === 'string') {\n      cert = forge.pki.certificateFromPem(cert);\n    }\n\n    var match = getBySubject(cert.subject);\n    if(!match) {\n      return false;\n    }\n    if(!forge.util.isArray(match)) {\n      match = [match];\n    }\n    // compare DER-encoding of certificates\n    var der1 = asn1.toDer(pki.certificateToAsn1(cert)).getBytes();\n    for(var i = 0; i < match.length; ++i) {\n      var der2 = asn1.toDer(pki.certificateToAsn1(match[i])).getBytes();\n      if(der1 === der2) {\n        return true;\n      }\n    }\n    return false;\n  };\n\n  /**\n   * Lists all of the certificates kept in the store.\n   *\n   * @return an array of all of the pki.certificate objects in the store.\n   */\n  caStore.listAllCertificates = function() {\n    var certList = [];\n\n    for(var hash in caStore.certs) {\n      if(caStore.certs.hasOwnProperty(hash)) {\n        var value = caStore.certs[hash];\n        if(!forge.util.isArray(value)) {\n          certList.push(value);\n        } else {\n          for(var i = 0; i < value.length; ++i) {\n            certList.push(value[i]);\n          }\n        }\n      }\n    }\n\n    return certList;\n  };\n\n  /**\n   * Removes a certificate from the store.\n   *\n   * @param cert the certificate to remove (either a pki.certificate or a\n   *          PEM-formatted certificate).\n   *\n   * @return the certificate that was removed or null if the certificate\n   *           wasn't in store.\n   */\n  caStore.removeCertificate = function(cert) {\n    var result;\n\n    // convert from pem if necessary\n    if(typeof cert === 'string') {\n      cert = forge.pki.certificateFromPem(cert);\n    }\n    ensureSubjectHasHash(cert.subject);\n    if(!caStore.hasCertificate(cert)) {\n      return null;\n    }\n\n    var match = getBySubject(cert.subject);\n\n    if(!forge.util.isArray(match)) {\n      result = caStore.certs[cert.subject.hash];\n      delete caStore.certs[cert.subject.hash];\n      return result;\n    }\n\n    // compare DER-encoding of certificates\n    var der1 = asn1.toDer(pki.certificateToAsn1(cert)).getBytes();\n    for(var i = 0; i < match.length; ++i) {\n      var der2 = asn1.toDer(pki.certificateToAsn1(match[i])).getBytes();\n      if(der1 === der2) {\n        result = match[i];\n        match.splice(i, 1);\n      }\n    }\n    if(match.length === 0) {\n      delete caStore.certs[cert.subject.hash];\n    }\n\n    return result;\n  };\n\n  function getBySubject(subject) {\n    ensureSubjectHasHash(subject);\n    return caStore.certs[subject.hash] || null;\n  }\n\n  function ensureSubjectHasHash(subject) {\n    // produce subject hash if it doesn't exist\n    if(!subject.hash) {\n      var md = forge.md.sha1.create();\n      subject.attributes = pki.RDNAttributesAsArray(_dnToAsn1(subject), md);\n      subject.hash = md.digest().toHex();\n    }\n  }\n\n  // auto-add passed in certs\n  if(certs) {\n    // parse PEM-formatted certificates as necessary\n    for(var i = 0; i < certs.length; ++i) {\n      var cert = certs[i];\n      caStore.addCertificate(cert);\n    }\n  }\n\n  return caStore;\n};\n\n/**\n * Certificate verification errors, based on TLS.\n */\npki.certificateError = {\n  bad_certificate: 'forge.pki.BadCertificate',\n  unsupported_certificate: 'forge.pki.UnsupportedCertificate',\n  certificate_revoked: 'forge.pki.CertificateRevoked',\n  certificate_expired: 'forge.pki.CertificateExpired',\n  certificate_unknown: 'forge.pki.CertificateUnknown',\n  unknown_ca: 'forge.pki.UnknownCertificateAuthority'\n};\n\n/**\n * Verifies a certificate chain against the given Certificate Authority store\n * with an optional custom verify callback.\n *\n * @param caStore a certificate store to verify against.\n * @param chain the certificate chain to verify, with the root or highest\n *          authority at the end (an array of certificates).\n * @param options a callback to be called for every certificate in the chain or\n *                  an object with:\n *                  verify a callback to be called for every certificate in the\n *                    chain\n *                  validityCheckDate the date against which the certificate\n *                    validity period should be checked. Pass null to not check\n *                    the validity period. By default, the current date is used.\n *\n * The verify callback has the following signature:\n *\n * verified - Set to true if certificate was verified, otherwise the\n *   pki.certificateError for why the certificate failed.\n * depth - The current index in the chain, where 0 is the end point's cert.\n * certs - The certificate chain, *NOTE* an empty chain indicates an anonymous\n *   end point.\n *\n * The function returns true on success and on failure either the appropriate\n * pki.certificateError or an object with 'error' set to the appropriate\n * pki.certificateError and 'message' set to a custom error message.\n *\n * @return true if successful, error thrown if not.\n */\npki.verifyCertificateChain = function(caStore, chain, options) {\n  /* From: RFC3280 - Internet X.509 Public Key Infrastructure Certificate\n    Section 6: Certification Path Validation\n    See inline parentheticals related to this particular implementation.\n\n    The primary goal of path validation is to verify the binding between\n    a subject distinguished name or a subject alternative name and subject\n    public key, as represented in the end entity certificate, based on the\n    public key of the trust anchor. This requires obtaining a sequence of\n    certificates that support that binding. That sequence should be provided\n    in the passed 'chain'. The trust anchor should be in the given CA\n    store. The 'end entity' certificate is the certificate provided by the\n    end point (typically a server) and is the first in the chain.\n\n    To meet this goal, the path validation process verifies, among other\n    things, that a prospective certification path (a sequence of n\n    certificates or a 'chain') satisfies the following conditions:\n\n    (a) for all x in {1, ..., n-1}, the subject of certificate x is\n          the issuer of certificate x+1;\n\n    (b) certificate 1 is issued by the trust anchor;\n\n    (c) certificate n is the certificate to be validated; and\n\n    (d) for all x in {1, ..., n}, the certificate was valid at the\n          time in question.\n\n    Note that here 'n' is index 0 in the chain and 1 is the last certificate\n    in the chain and it must be signed by a certificate in the connection's\n    CA store.\n\n    The path validation process also determines the set of certificate\n    policies that are valid for this path, based on the certificate policies\n    extension, policy mapping extension, policy constraints extension, and\n    inhibit any-policy extension.\n\n    Note: Policy mapping extension not supported (Not Required).\n\n    Note: If the certificate has an unsupported critical extension, then it\n    must be rejected.\n\n    Note: A certificate is self-issued if the DNs that appear in the subject\n    and issuer fields are identical and are not empty.\n\n    The path validation algorithm assumes the following seven inputs are\n    provided to the path processing logic. What this specific implementation\n    will use is provided parenthetically:\n\n    (a) a prospective certification path of length n (the 'chain')\n    (b) the current date/time: ('now').\n    (c) user-initial-policy-set: A set of certificate policy identifiers\n          naming the policies that are acceptable to the certificate user.\n          The user-initial-policy-set contains the special value any-policy\n          if the user is not concerned about certificate policy\n          (Not implemented. Any policy is accepted).\n    (d) trust anchor information, describing a CA that serves as a trust\n          anchor for the certification path. The trust anchor information\n          includes:\n\n      (1)  the trusted issuer name,\n      (2)  the trusted public key algorithm,\n      (3)  the trusted public key, and\n      (4)  optionally, the trusted public key parameters associated\n             with the public key.\n\n      (Trust anchors are provided via certificates in the CA store).\n\n      The trust anchor information may be provided to the path processing\n      procedure in the form of a self-signed certificate. The trusted anchor\n      information is trusted because it was delivered to the path processing\n      procedure by some trustworthy out-of-band procedure. If the trusted\n      public key algorithm requires parameters, then the parameters are\n      provided along with the trusted public key (No parameters used in this\n      implementation).\n\n    (e) initial-policy-mapping-inhibit, which indicates if policy mapping is\n          allowed in the certification path.\n          (Not implemented, no policy checking)\n\n    (f) initial-explicit-policy, which indicates if the path must be valid\n          for at least one of the certificate policies in the user-initial-\n          policy-set.\n          (Not implemented, no policy checking)\n\n    (g) initial-any-policy-inhibit, which indicates whether the\n          anyPolicy OID should be processed if it is included in a\n          certificate.\n          (Not implemented, so any policy is valid provided that it is\n          not marked as critical) */\n\n  /* Basic Path Processing:\n\n    For each certificate in the 'chain', the following is checked:\n\n    1. The certificate validity period includes the current time.\n    2. The certificate was signed by its parent (where the parent is either\n       the next in the chain or from the CA store). Allow processing to\n       continue to the next step if no parent is found but the certificate is\n       in the CA store.\n    3. TODO: The certificate has not been revoked.\n    4. The certificate issuer name matches the parent's subject name.\n    5. TODO: If the certificate is self-issued and not the final certificate\n       in the chain, skip this step, otherwise verify that the subject name\n       is within one of the permitted subtrees of X.500 distinguished names\n       and that each of the alternative names in the subjectAltName extension\n       (critical or non-critical) is within one of the permitted subtrees for\n       that name type.\n    6. TODO: If the certificate is self-issued and not the final certificate\n       in the chain, skip this step, otherwise verify that the subject name\n       is not within one of the excluded subtrees for X.500 distinguished\n       names and none of the subjectAltName extension names are excluded for\n       that name type.\n    7. The other steps in the algorithm for basic path processing involve\n       handling the policy extension which is not presently supported in this\n       implementation. Instead, if a critical policy extension is found, the\n       certificate is rejected as not supported.\n    8. If the certificate is not the first or if its the only certificate in\n       the chain (having no parent from the CA store or is self-signed) and it\n       has a critical key usage extension, verify that the keyCertSign bit is\n       set. If the key usage extension exists, verify that the basic\n       constraints extension exists. If the basic constraints extension exists,\n       verify that the cA flag is set. If pathLenConstraint is set, ensure that\n       the number of certificates that precede in the chain (come earlier\n       in the chain as implemented below), excluding the very first in the\n       chain (typically the end-entity one), isn't greater than the\n       pathLenConstraint. This constraint limits the number of intermediate\n       CAs that may appear below a CA before only end-entity certificates\n       may be issued. */\n\n  // if a verify callback is passed as the third parameter, package it within\n  // the options object. This is to support a legacy function signature that\n  // expected the verify callback as the third parameter.\n  if(typeof options === 'function') {\n    options = {verify: options};\n  }\n  options = options || {};\n\n  // copy cert chain references to another array to protect against changes\n  // in verify callback\n  chain = chain.slice(0);\n  var certs = chain.slice(0);\n\n  var validityCheckDate = options.validityCheckDate;\n  // if no validityCheckDate is specified, default to the current date. Make\n  // sure to maintain the value null because it indicates that the validity\n  // period should not be checked.\n  if(typeof validityCheckDate === 'undefined') {\n    validityCheckDate = new Date();\n  }\n\n  // verify each cert in the chain using its parent, where the parent\n  // is either the next in the chain or from the CA store\n  var first = true;\n  var error = null;\n  var depth = 0;\n  do {\n    var cert = chain.shift();\n    var parent = null;\n    var selfSigned = false;\n\n    if(validityCheckDate) {\n      // 1. check valid time\n      if(validityCheckDate < cert.validity.notBefore ||\n         validityCheckDate > cert.validity.notAfter) {\n        error = {\n          message: 'Certificate is not valid yet or has expired.',\n          error: pki.certificateError.certificate_expired,\n          notBefore: cert.validity.notBefore,\n          notAfter: cert.validity.notAfter,\n          // TODO: we might want to reconsider renaming 'now' to\n          // 'validityCheckDate' should this API be changed in the future.\n          now: validityCheckDate\n        };\n      }\n    }\n\n    // 2. verify with parent from chain or CA store\n    if(error === null) {\n      parent = chain[0] || caStore.getIssuer(cert);\n      if(parent === null) {\n        // check for self-signed cert\n        if(cert.isIssuer(cert)) {\n          selfSigned = true;\n          parent = cert;\n        }\n      }\n\n      if(parent) {\n        // FIXME: current CA store implementation might have multiple\n        // certificates where the issuer can't be determined from the\n        // certificate (happens rarely with, eg: old certificates) so normalize\n        // by always putting parents into an array\n        // TODO: there's may be an extreme degenerate case currently uncovered\n        // where an old intermediate certificate seems to have a matching parent\n        // but none of the parents actually verify ... but the intermediate\n        // is in the CA and it should pass this check; needs investigation\n        var parents = parent;\n        if(!forge.util.isArray(parents)) {\n          parents = [parents];\n        }\n\n        // try to verify with each possible parent (typically only one)\n        var verified = false;\n        while(!verified && parents.length > 0) {\n          parent = parents.shift();\n          try {\n            verified = parent.verify(cert);\n          } catch(ex) {\n            // failure to verify, don't care why, try next one\n          }\n        }\n\n        if(!verified) {\n          error = {\n            message: 'Certificate signature is invalid.',\n            error: pki.certificateError.bad_certificate\n          };\n        }\n      }\n\n      if(error === null && (!parent || selfSigned) &&\n        !caStore.hasCertificate(cert)) {\n        // no parent issuer and certificate itself is not trusted\n        error = {\n          message: 'Certificate is not trusted.',\n          error: pki.certificateError.unknown_ca\n        };\n      }\n    }\n\n    // TODO: 3. check revoked\n\n    // 4. check for matching issuer/subject\n    if(error === null && parent && !cert.isIssuer(parent)) {\n      // parent is not issuer\n      error = {\n        message: 'Certificate issuer is invalid.',\n        error: pki.certificateError.bad_certificate\n      };\n    }\n\n    // 5. TODO: check names with permitted names tree\n\n    // 6. TODO: check names against excluded names tree\n\n    // 7. check for unsupported critical extensions\n    if(error === null) {\n      // supported extensions\n      var se = {\n        keyUsage: true,\n        basicConstraints: true\n      };\n      for(var i = 0; error === null && i < cert.extensions.length; ++i) {\n        var ext = cert.extensions[i];\n        if(ext.critical && !(ext.name in se)) {\n          error = {\n            message:\n              'Certificate has an unsupported critical extension.',\n            error: pki.certificateError.unsupported_certificate\n          };\n        }\n      }\n    }\n\n    // 8. check for CA if cert is not first or is the only certificate\n    // remaining in chain with no parent or is self-signed\n    if(error === null &&\n      (!first || (chain.length === 0 && (!parent || selfSigned)))) {\n      // first check keyUsage extension and then basic constraints\n      var bcExt = cert.getExtension('basicConstraints');\n      var keyUsageExt = cert.getExtension('keyUsage');\n      if(keyUsageExt !== null) {\n        // keyCertSign must be true and there must be a basic\n        // constraints extension\n        if(!keyUsageExt.keyCertSign || bcExt === null) {\n          // bad certificate\n          error = {\n            message:\n              'Certificate keyUsage or basicConstraints conflict ' +\n              'or indicate that the certificate is not a CA. ' +\n              'If the certificate is the only one in the chain or ' +\n              'isn\\'t the first then the certificate must be a ' +\n              'valid CA.',\n            error: pki.certificateError.bad_certificate\n          };\n        }\n      }\n      // basic constraints cA flag must be set\n      if(error === null && bcExt !== null && !bcExt.cA) {\n        // bad certificate\n        error = {\n          message:\n            'Certificate basicConstraints indicates the certificate ' +\n            'is not a CA.',\n          error: pki.certificateError.bad_certificate\n        };\n      }\n      // if error is not null and keyUsage is available, then we know it\n      // has keyCertSign and there is a basic constraints extension too,\n      // which means we can check pathLenConstraint (if it exists)\n      if(error === null && keyUsageExt !== null &&\n        'pathLenConstraint' in bcExt) {\n        // pathLen is the maximum # of intermediate CA certs that can be\n        // found between the current certificate and the end-entity (depth 0)\n        // certificate; this number does not include the end-entity (depth 0,\n        // last in the chain) even if it happens to be a CA certificate itself\n        var pathLen = depth - 1;\n        if(pathLen > bcExt.pathLenConstraint) {\n          // pathLenConstraint violated, bad certificate\n          error = {\n            message:\n              'Certificate basicConstraints pathLenConstraint violated.',\n            error: pki.certificateError.bad_certificate\n          };\n        }\n      }\n    }\n\n    // call application callback\n    var vfd = (error === null) ? true : error.error;\n    var ret = options.verify ? options.verify(vfd, depth, certs) : vfd;\n    if(ret === true) {\n      // clear any set error\n      error = null;\n    } else {\n      // if passed basic tests, set default message and alert\n      if(vfd === true) {\n        error = {\n          message: 'The application rejected the certificate.',\n          error: pki.certificateError.bad_certificate\n        };\n      }\n\n      // check for custom error info\n      if(ret || ret === 0) {\n        // set custom message and error\n        if(typeof ret === 'object' && !forge.util.isArray(ret)) {\n          if(ret.message) {\n            error.message = ret.message;\n          }\n          if(ret.error) {\n            error.error = ret.error;\n          }\n        } else if(typeof ret === 'string') {\n          // set custom error\n          error.error = ret;\n        }\n      }\n\n      // throw error\n      throw error;\n    }\n\n    // no longer first cert in chain\n    first = false;\n    ++depth;\n  } while(chain.length > 0);\n\n  return true;\n};\n","/*!\n * algorithms/aes-cbc-hmac-sha2.js - AES-CBC-HMAC-SHA2 Composited Encryption\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar helpers = require(\"./helpers.js\"),\n    HMAC = require(\"./hmac.js\"),\n    sha = require(\"./sha.js\"),\n    forge = require(\"../deps/forge.js\"),\n    DataBuffer = require(\"../util/databuffer.js\"),\n    util = require(\"../util\");\n\nfunction checkIv(iv) {\n  if (16 !== iv.length) {\n    throw new Error(\"invalid iv\");\n  }\n}\n\nfunction commonCbcEncryptFN(size) {\n  // ### 'fallback' implementation -- uses forge\n  var fallback = function(encKey, pdata, iv) {\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve();\n\n    promise = promise.then(function() {\n      var cipher = forge.cipher.createCipher(\"AES-CBC\", new DataBuffer(encKey));\n      cipher.start({\n        iv: new DataBuffer(iv)\n      });\n\n      // TODO: chunk data\n      cipher.update(new DataBuffer(pdata));\n      if (!cipher.finish()) {\n        return Promise.reject(new Error(\"encryption failed\"));\n      }\n\n      var cdata = Buffer.from(cipher.output.bytes(), \"binary\");\n      return cdata;\n    });\n\n    return promise;\n  };\n\n  // ### WebCryptoAPI implementation\n  // TODO: cache CryptoKey sooner\n  var webcrypto = function(encKey, pdata, iv) {\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve();\n\n    promise = promise.then(function() {\n      var alg = {\n        name: \"AES-CBC\"\n      };\n      return helpers.subtleCrypto.importKey(\"raw\", encKey, alg, true, [\"encrypt\"]);\n    });\n    promise = promise.then(function(key) {\n      var alg = {\n        name: \"AES-CBC\",\n        iv: iv\n      };\n      return helpers.subtleCrypto.encrypt(alg, key, pdata);\n    });\n    promise = promise.then(function(cdata) {\n      cdata = Buffer.from(cdata);\n      return cdata;\n    });\n\n    return promise;\n  };\n\n  // ### NodeJS implementation\n  var nodejs = function(encKey, pdata, iv) {\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve(pdata);\n\n    promise = promise.then(function(pdata) {\n      var name = \"AES-\" + size + \"-CBC\";\n      var cipher = helpers.nodeCrypto.createCipheriv(name, encKey, iv);\n      var cdata = Buffer.concat([\n        cipher.update(pdata),\n        cipher.final()\n      ]);\n      return cdata;\n    });\n\n    return promise;\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction commonCbcDecryptFN(size) {\n  // ### 'fallback' implementation -- uses forge\n  var fallback = function(encKey, cdata, iv) {\n    // validate inputs\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve();\n\n    promise = promise.then(function() {\n      var cipher = forge.cipher.createDecipher(\"AES-CBC\", new DataBuffer(encKey));\n      cipher.start({\n        iv: new DataBuffer(iv)\n      });\n\n      // TODO: chunk data\n      cipher.update(new DataBuffer(cdata));\n      if (!cipher.finish()) {\n        return Promise.reject(new Error(\"encryption failed\"));\n      }\n\n      var pdata = Buffer.from(cipher.output.bytes(), \"binary\");\n      return pdata;\n    });\n\n    return promise;\n  };\n\n  // ### WebCryptoAPI implementation\n  // TODO: cache CryptoKey sooner\n  var webcrypto = function(encKey, cdata, iv) {\n    // validate inputs\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve();\n\n    promise = promise.then(function() {\n      var alg = {\n        name: \"AES-CBC\"\n      };\n      return helpers.subtleCrypto.importKey(\"raw\", encKey, alg, true, [\"decrypt\"]);\n    });\n    promise = promise.then(function(key) {\n      var alg = {\n        name: \"AES-CBC\",\n        iv: iv\n      };\n      return helpers.subtleCrypto.decrypt(alg, key, cdata);\n    });\n    promise = promise.then(function(pdata) {\n      pdata = Buffer.from(pdata);\n      return pdata;\n    });\n\n    return promise;\n  };\n\n  // ### NodeJS implementation\n  var nodejs = function(encKey, cdata, iv) {\n    // validate inputs\n    try {\n      checkIv(iv);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var promise = Promise.resolve();\n\n    promise = promise.then(function() {\n      var name = \"AES-\" + size + \"-CBC\";\n      var cipher = helpers.nodeCrypto.createDecipheriv(name, encKey, iv);\n      var pdata = Buffer.concat([\n        cipher.update(cdata),\n        cipher.final()\n      ]);\n      return pdata;\n    });\n\n    return promise;\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction checkKey(key, size) {\n  if ((size << 1) !== (key.length << 3)) {\n    throw new Error(\"invalid encryption key size\");\n  }\n}\n\nfunction cbcHmacEncryptFN(size) {\n  var commonEncrypt = commonCbcEncryptFN(size);\n  return function(key, pdata, props) {\n    // validate inputs\n    try {\n      checkKey(key, size);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var eKey = key.slice(size / 8),\n        iKey = key.slice(0, size / 8),\n        iv = props.iv || Buffer.alloc(0),\n        adata = props.aad || props.adata || Buffer.alloc(0);\n\n    // STEP 1 -- Encrypt\n    var promise = commonEncrypt(eKey, pdata, iv);\n\n    // STEP 2 -- MAC\n    promise = promise.then(function(cdata){\n      var mdata = Buffer.concat([\n        adata,\n        iv,\n        cdata,\n        helpers.int64ToBuffer(adata.length * 8)\n      ]);\n\n      var promise;\n      promise = HMAC[\"HS\" + (size * 2)].sign(iKey, mdata, {\n        length: size\n      });\n      promise = promise.then(function(result) {\n        // TODO: move slice to hmac.js\n        var tag = result.mac.slice(0, size / 8);\n        return {\n          data: cdata,\n          tag: tag\n        };\n      });\n      return promise;\n    });\n\n    return promise;\n  };\n}\n\nfunction cbcHmacDecryptFN(size) {\n  var commonDecrypt = commonCbcDecryptFN(size);\n\n  return function(key, cdata, props) {\n    // validate inputs\n    try {\n      checkKey(key, size);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var eKey = key.slice(size / 8),\n        iKey = key.slice(0, size / 8),\n        iv = props.iv || Buffer.alloc(0),\n        adata = props.aad || props.adata || Buffer.alloc(0),\n        tag = props.tag || props.mac || Buffer.alloc(0);\n\n    var promise = Promise.resolve();\n\n    // STEP 1 -- MAC\n    promise = promise.then(function() {\n      var promise;\n      // construct MAC input\n      var mdata = Buffer.concat([\n        adata,\n        iv,\n        cdata,\n        helpers.int64ToBuffer(adata.length * 8)\n      ]);\n      promise = HMAC[\"HS\" + (size * 2)].verify(iKey, mdata, tag, {\n        length: size\n      });\n      promise = promise.then(function() {\n        return cdata;\n      }, function() {\n        // failure -- invalid tag error\n        throw new Error(\"mac check failed\");\n      });\n      return promise;\n    });\n\n    // STEP 2 -- Decrypt\n    promise = promise.then(function(){\n      return commonDecrypt(eKey, cdata, iv);\n    });\n\n    return promise;\n  };\n}\n\nvar EncryptionLabel = Buffer.from(\"Encryption\", \"utf8\");\nvar IntegrityLabel = Buffer.from(\"Integrity\", \"utf8\");\nvar DotLabel = Buffer.from(\".\", \"utf8\");\n\nfunction generateCek(masterKey, alg, epu, epv) {\n  var masterSize = masterKey.length * 8;\n  var cekSize = masterSize / 2;\n  var promise = Promise.resolve();\n\n  promise = promise.then(function(){\n    var input = Buffer.concat([\n      helpers.int32ToBuffer(1),\n      masterKey,\n      helpers.int32ToBuffer(cekSize),\n      Buffer.from(alg, \"utf8\"),\n      epu,\n      epv,\n      EncryptionLabel\n    ]);\n\n    return input;\n  });\n\n  promise = promise.then( function(input) {\n    return sha[\"SHA-\" + masterSize].digest(input).then(function(digest) {\n      return digest.slice(0, cekSize / 8);\n    });\n  });\n  promise = Promise.resolve(promise);\n\n  return promise;\n}\n\nfunction generateCik(masterKey, alg, epu, epv) {\n  var masterSize = masterKey.length * 8;\n  var cikSize = masterSize;\n  var promise = Promise.resolve();\n\n  promise = promise.then(function(){\n    var input = Buffer.concat([\n      helpers.int32ToBuffer(1),\n      masterKey,\n      helpers.int32ToBuffer(cikSize),\n      Buffer.from(alg, \"utf8\"),\n      epu,\n      epv,\n      IntegrityLabel\n    ]);\n\n    return input;\n  });\n\n  promise = promise.then( function(input) {\n    return sha[\"SHA-\" + masterSize].digest(input).then(function(digest) {\n      return digest.slice(0, cikSize / 8);\n    });\n  });\n  promise = Promise.resolve(promise);\n\n  return promise;\n}\n\nfunction concatKdfCbcHmacEncryptFN(size, alg) {\n  var commonEncrypt = commonCbcEncryptFN(size);\n\n  return function(key, pdata, props) {\n    var epu = props.epu || helpers.int32ToBuffer(0),\n        epv = props.epv || helpers.int32ToBuffer(0),\n        iv = props.iv || Buffer.alloc(0),\n        adata = props.aad || props.adata || Buffer.alloc(0),\n        kdata = props.kdata || Buffer.alloc(0);\n\n    // Pre Step 1 -- Generate Keys\n    var promises = [\n      generateCek(key, alg, epu, epv),\n      generateCik(key, alg, epu, epv)\n    ];\n\n    var cek,\n        cik;\n    var promise = Promise.all(promises).then(function(keys) {\n      cek = keys[0];\n      cik = keys[1];\n    });\n\n    // STEP 1 -- Encrypt\n    promise = promise.then(function(){\n      return commonEncrypt(cek, pdata, iv);\n    });\n\n    // STEP 2 -- Mac\n    promise = promise.then(function(cdata){\n      var mdata = Buffer.concat([\n        adata,\n        DotLabel,\n        Buffer.from(kdata),\n        DotLabel,\n        Buffer.from(util.base64url.encode(iv), \"utf8\"),\n        DotLabel,\n        Buffer.from(util.base64url.encode(cdata), \"utf8\")\n      ]);\n      return Promise.all([\n        Promise.resolve(cdata),\n        HMAC[\"HS\" + (size * 2)].sign(cik, mdata, { length: size })\n      ]);\n    });\n    promise = promise.then(function(result){\n      return {\n        data: result[0],\n        tag: result[1].mac\n      };\n    });\n\n    return promise;\n  };\n}\n\nfunction concatKdfCbcHmacDecryptFN(size, alg) {\n  var commonDecrypt = commonCbcDecryptFN(size);\n\n  return function(key, cdata, props) {\n    var epu = props.epu || helpers.int32ToBuffer(0),\n        epv = props.epv || helpers.int32ToBuffer(0),\n        iv = props.iv || Buffer.alloc(0),\n        adata = props.aad || props.adata || Buffer.alloc(0),\n        kdata = props.kdata || Buffer.alloc(0),\n        tag = props.tag || props.mac || Buffer.alloc(0);\n\n    // Pre Step 1 -- Generate Keys\n    var promises = [\n      generateCek(key, alg, epu, epv),\n      generateCik(key, alg, epu, epv)\n    ];\n\n    var cek,\n        cik;\n    var promise = Promise.all(promises).then(function(keys){\n      cek = keys[0];\n      cik = keys[1];\n    });\n\n\n    // STEP 1 -- MAC\n    promise = promise.then(function() {\n      // construct MAC input\n      var mdata = Buffer.concat([\n        adata,\n        DotLabel,\n        Buffer.from(kdata),\n        DotLabel,\n        Buffer.from(util.base64url.encode(iv), \"utf8\"),\n        DotLabel,\n        Buffer.from(util.base64url.encode(cdata), \"utf8\")\n      ]);\n\n      try {\n        return HMAC[\"HS\" + (size * 2)].verify(cik, mdata, tag, {\n          loose: false\n        });\n      } catch (e) {\n        throw new Error(\"mac check failed\");\n      }\n    });\n\n    // STEP 2 -- Decrypt\n    promise = promise.then(function(){\n      return commonDecrypt(cek, cdata, iv);\n    });\n\n    return promise;\n  };\n}\n\n// ### Public API\n// * [name].encrypt\n// * [name].decrypt\nvar aesCbcHmacSha2 = {};\n[\n  \"A128CBC-HS256\",\n  \"A192CBC-HS384\",\n  \"A256CBC-HS512\"\n].forEach(function(alg) {\n  var size = parseInt(/A(\\d+)CBC-HS(\\d+)?/g.exec(alg)[1]);\n  aesCbcHmacSha2[alg] = {\n    encrypt: cbcHmacEncryptFN(size),\n    decrypt: cbcHmacDecryptFN(size)\n  };\n});\n\n[\n  \"A128CBC+HS256\",\n  \"A192CBC+HS384\",\n  \"A256CBC+HS512\"\n].forEach(function(alg) {\n  var size = parseInt(/A(\\d+)CBC\\+HS(\\d+)?/g.exec(alg)[1]);\n  aesCbcHmacSha2[alg] = {\n    encrypt: concatKdfCbcHmacEncryptFN(size, alg),\n    decrypt: concatKdfCbcHmacDecryptFN(size, alg)\n  };\n});\n\nmodule.exports = aesCbcHmacSha2;\n","/*!\n * algorithms/aes-gcm.js - AES-GCM Encryption and Key-Wrapping\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar helpers = require(\"./helpers.js\"),\n    util = require(\"../util\"),\n    CONSTANTS = require(\"./constants.js\"),\n    GCM = require(\"../deps/ciphermodes/gcm\");\n\nfunction gcmEncryptFN(size, wrap) {\n  function commonChecks(key, iv) {\n    if (size !== (key.length << 3)) {\n       throw new Error(\"invalid key size\");\n    }\n    if (!iv && !wrap) {\n      throw new Error(\"invalid iv\");\n    }\n    if (iv && 12 !== iv.length) {\n      throw new Error(\"invalid iv\");\n    }\n  }\n\n  function prepareResults(results) {\n    if (wrap) {\n      var iv = util.base64url.encode(results.iv);\n      var tag = util.base64url.encode(results.tag);\n\n      results = {\n        data: results.data,\n        header: {\n          iv: iv,\n          tag: tag\n        }\n      };\n    }\n\n    return results;\n  }\n\n  // ### 'fallback' implementation -- uses forge\n  var fallback = function(key, pdata, props) {\n    var iv = props.iv,\n        adata = props.aad || props.adata || Buffer.alloc(0),\n        cipher,\n        cdata;\n\n    // validate inputs\n    try {\n      commonChecks(key, iv, adata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    iv = iv || util.randomBytes(12);\n\n    // setup cipher\n    cipher = GCM.createCipher({\n      key: key,\n      iv: iv,\n      additionalData: adata\n    });\n    // ciphertext is the same length as plaintext\n    cdata = Buffer.alloc(pdata.length);\n\n    var promise = new Promise(function(resolve, reject) {\n      var amt = CONSTANTS.CHUNK_SIZE,\n          clen = 0,\n          poff = 0;\n\n      (function doChunk() {\n        var plen = Math.min(amt, pdata.length - poff);\n        clen += cipher.update(pdata,\n                              poff,\n                              plen,\n                              cdata,\n                              clen);\n        poff += plen;\n        if (pdata.length > poff) {\n          setTimeout(doChunk, 0);\n          return;\n        }\n\n        // finish it\n        clen += cipher.finish(cdata, clen);\n        if (clen !== pdata.length) {\n          reject(new Error(\"encryption failed\"));\n          return;\n        }\n\n        // resolve with output\n        var tag = cipher.tag;\n        resolve(prepareResults({\n          data: cdata,\n          iv: iv,\n          tag: tag\n        }));\n      })();\n    });\n\n    return promise;\n  };\n\n  // ### WebCryptoAPI implementation\n  // TODO: cache CryptoKey sooner\n  var webcrypto = function(key, pdata, props) {\n    var iv = props.iv,\n        adata = props.aad || props.adata || Buffer.alloc(0);\n\n    try {\n      commonChecks(key, iv, adata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    iv = iv || util.randomBytes(12);\n\n    var alg = {\n      name: \"AES-GCM\"\n    };\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"encrypt\"]);\n    promise = promise.then(function(key) {\n      alg.iv = iv;\n      alg.tagLength = 128;\n      if (adata.length) {\n        alg.additionalData = adata;\n      }\n\n      return helpers.subtleCrypto.encrypt(alg, key, pdata);\n    });\n    promise = promise.then(function(result) {\n      var tagStart = result.byteLength - 16;\n\n      var tag = result.slice(tagStart);\n      tag = Buffer.from(tag);\n\n      var cdata = result.slice(0, tagStart);\n      cdata = Buffer.from(cdata);\n\n      return prepareResults({\n        data: cdata,\n        iv: iv,\n        tag: tag\n      });\n    });\n\n    return promise;\n  };\n\n  // ### NodeJS implementation\n  var nodejs = function(key, pdata, props) {\n    var iv = props.iv,\n        adata = props.aad || props.adata || Buffer.alloc(0);\n\n    try {\n      commonChecks(key, iv, adata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    iv = iv || util.randomBytes(12);\n\n    var alg = \"aes-\" + (key.length * 8) + \"-gcm\";\n    var cipher;\n    try {\n      cipher = helpers.nodeCrypto.createCipheriv(alg, key, iv);\n    } catch (err) {\n      throw new Error(\"unsupported algorithm: \" + alg);\n    }\n    if (\"function\" !== typeof cipher.setAAD) {\n      throw new Error(\"unsupported algorithm: \" + alg);\n    }\n    if (adata.length) {\n      cipher.setAAD(adata);\n    }\n\n    var cdata = Buffer.concat([\n      cipher.update(pdata),\n      cipher.final()\n    ]);\n    var tag = cipher.getAuthTag();\n\n    return prepareResults({\n      data: cdata,\n      iv: iv,\n      tag: tag\n    });\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction gcmDecryptFN(size) {\n  function commonChecks(key, iv, tag) {\n    if (size !== (key.length << 3)) {\n      throw new Error(\"invalid key size\");\n    }\n    if (12 !== iv.length) {\n      throw new Error(\"invalid iv\");\n    }\n    if (16 !== tag.length) {\n      throw new Error(\"invalid tag length\");\n    }\n  }\n\n  // ### fallback implementation -- uses forge\n  var fallback = function(key, cdata, props) {\n    var adata = props.aad || props.adata || Buffer.alloc(0),\n        iv = props.iv || Buffer.alloc(0),\n        tag = props.tag || props.mac || Buffer.alloc(0),\n        cipher,\n        pdata;\n\n    // validate inputs\n    try {\n      commonChecks(key, iv, tag);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    // setup cipher\n    cipher = GCM.createDecipher({\n      key: key,\n      iv: iv,\n      additionalData: adata,\n      tag: tag\n    });\n    // plaintext is the same length as ciphertext\n    pdata = Buffer.alloc(cdata.length);\n\n    var promise = new Promise(function(resolve, reject) {\n      var amt = CONSTANTS.CHUNK_SIZE,\n          plen = 0,\n          coff = 0;\n\n      (function doChunk() {\n        var clen = Math.min(amt, cdata.length - coff);\n        plen += cipher.update(cdata,\n                              coff,\n                              clen,\n                              pdata,\n                              plen);\n        coff += clen;\n        if (cdata.length > coff) {\n          setTimeout(doChunk, 0);\n          return;\n        }\n\n        try {\n          plen += cipher.finish(pdata, plen);\n        } catch (err) {\n          reject(new Error(\"decryption failed\"));\n          return;\n        }\n\n        if (plen !== cdata.length) {\n          reject(new Error(\"decryption failed\"));\n          return;\n        }\n\n        // resolve with output\n        resolve(pdata);\n      })();\n    });\n\n    return promise;\n  };\n\n  // ### WebCryptoAPI implementation\n  // TODO: cache CryptoKey sooner\n  var webcrypto = function(key, cdata, props) {\n    var adata = props.aad || props.adata || Buffer.alloc(0),\n        iv = props.iv || Buffer.alloc(0),\n        tag = props.tag || props.mac || Buffer.alloc(0);\n\n    // validate inputs\n    try {\n      commonChecks(key, iv, tag);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var alg = {\n      name: \"AES-GCM\"\n    };\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"decrypt\"]);\n    promise = promise.then(function(key) {\n      alg.iv = iv;\n      alg.tagLength = 128;\n      if (adata.length) {\n        alg.additionalData = adata;\n      }\n\n      // concatenate cdata and tag\n      cdata = Buffer.concat([cdata, tag], cdata.length + tag.length);\n\n      return helpers.subtleCrypto.decrypt(alg, key, cdata);\n    });\n    promise = promise.then(function(pdata) {\n      pdata = Buffer.from(pdata);\n      return pdata;\n    });\n\n    return promise;\n  };\n\n  var nodejs = function(key, cdata, props) {\n    var adata = props.aad || props.adata || Buffer.alloc(0),\n        iv = props.iv || Buffer.alloc(0),\n        tag = props.tag || props.mac || Buffer.alloc(0);\n\n    // validate inputs\n    try {\n      commonChecks(key, iv, tag);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var alg = \"aes-\" + (key.length * 8) + \"-gcm\";\n    var cipher;\n    try {\n      cipher = helpers.nodeCrypto.createDecipheriv(alg, key, iv);\n    } catch(err) {\n      throw new Error(\"unsupported algorithm: \" + alg);\n    }\n    if (\"function\" !== typeof cipher.setAAD) {\n      throw new Error(\"unsupported algorithm: \" + alg);\n    }\n    cipher.setAuthTag(tag);\n    if (adata.length) {\n      cipher.setAAD(adata);\n    }\n\n    try {\n      var pdata = Buffer.concat([\n        cipher.update(cdata),\n        cipher.final()\n      ]);\n\n      return pdata;\n    } catch (err) {\n      throw new Error(\"decryption failed\");\n    }\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### Public API\n// * [name].encrypt\n// * [name].decrypt\nvar aesGcm = {};\n[\n  \"A128GCM\",\n  \"A192GCM\",\n  \"A256GCM\",\n  \"A128GCMKW\",\n  \"A192GCMKW\",\n  \"A256GCMKW\"\n].forEach(function(alg) {\n  var parts = /A(\\d+)GCM(KW)?/g.exec(alg);\n  var size = parseInt(parts[1]);\n  var wrap = (parts[2] === \"KW\");\n  aesGcm[alg] = {\n    encrypt: gcmEncryptFN(size, wrap),\n    decrypt: gcmDecryptFN(size, wrap)\n  };\n});\n\nmodule.exports = aesGcm;\n","/*!\n * algorithms/aes-kw.js - AES-KW Key-Wrapping\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar helpers = require(\"./helpers.js\"),\n    forge = require(\"../deps/forge.js\"),\n    DataBuffer = require(\"../util/databuffer.js\");\n\nvar A0 = Buffer.from(\"a6a6a6a6a6a6a6a6\", \"hex\");\n\n// ### helpers\nfunction xor(a, b) {\n  var len = Math.max(a.length, b.length);\n  var result = Buffer.alloc(len);\n  for (var idx = 0; len > idx; idx++) {\n    result[idx] = (a[idx] || 0) ^ (b[idx] || 0);\n  }\n  return result;\n}\n\nfunction split(input, size) {\n  var output = [];\n  for (var idx = 0; input.length > idx; idx += size) {\n    output.push(input.slice(idx, idx + size));\n  }\n  return output;\n}\n\nfunction longToBigEndian(input) {\n  var hi = Math.floor(input / 4294967296),\n      lo = input % 4294967296;\n  var output = Buffer.alloc(8);\n  output[0] = 0xff & (hi >>> 24);\n  output[1] = 0xff & (hi >>> 16);\n  output[2] = 0xff & (hi >>> 8);\n  output[3] = 0xff & (hi >>> 0);\n  output[4] = 0xff & (lo >>> 24);\n  output[5] = 0xff & (lo >>> 16);\n  output[6] = 0xff & (lo >>> 8);\n  output[7] = 0xff & (lo >>> 0);\n  return output;\n}\n\nfunction kwEncryptFN(size) {\n  function commonChecks(key, data) {\n    if (size !== (key.length << 3)) {\n      throw new Error(\"invalid key size\");\n    }\n    if (0 < data.length && 0 !== (data.length % 8)) {\n      throw new Error(\"invalid data length\");\n    }\n  }\n\n  // ### 'fallback' implementation -- uses forge\n  var fallback = function(key, pdata) {\n    try {\n      commonChecks(key, pdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    // setup cipher\n    var cipher = forge.cipher.createCipher(\"AES\", new DataBuffer(key));\n\n    // split input into chunks\n    var R = split(pdata, 8);\n    var A,\n        B,\n        count;\n    A = A0;\n    for (var jdx = 0; 6 > jdx; jdx++) {\n      for (var idx = 0; R.length > idx; idx++) {\n        count = (R.length * jdx) + idx + 1;\n        B = Buffer.concat([A, R[idx]]);\n        cipher.start();\n        cipher.update(new DataBuffer(B));\n        cipher.finish();\n        B = Buffer.from(cipher.output.bytes(), \"binary\");\n\n        A = xor(B.slice(0, 8),\n                longToBigEndian(count));\n        R[idx] = B.slice(8, 16);\n      }\n    }\n    R = [A].concat(R);\n    var cdata = Buffer.concat(R);\n    return Promise.resolve({\n      data: cdata\n    });\n  };\n  // ### WebCryptoAPI implementation\n  var webcrypto = function(key, pdata) {\n    try {\n      commonChecks(key, pdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var alg = {\n      name: \"AES-KW\"\n    };\n    var promise = [\n      helpers.subtleCrypto.importKey(\"raw\", pdata, { name: \"HMAC\", hash: \"SHA-256\" }, true, [\"sign\"]),\n      helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"wrapKey\"])\n    ];\n    promise = Promise.all(promise);\n    promise = promise.then(function(keys) {\n      return helpers.subtleCrypto.wrapKey(\"raw\",\n                                          keys[0], // key\n                                          keys[1], // wrappingKey\n                                          alg);\n    });\n    promise = promise.then(function(result) {\n      result = Buffer.from(result);\n\n      return {\n        data: result\n      };\n    });\n    return promise;\n  };\n  var node = function(key, pdata) {\n    try {\n      commonChecks(key, pdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    // split input into chunks\n    var R = split(pdata, 8),\n        iv = Buffer.alloc(16);\n    var A,\n        B,\n        count;\n    A = A0;\n    for (var jdx = 0; 6 > jdx; jdx++) {\n      for (var idx = 0; R.length > idx; idx++) {\n        count = (R.length * jdx) + idx + 1;\n        B = Buffer.concat([A, R[idx]]);\n        var cipher = helpers.nodeCrypto.createCipheriv(\"AES\" + size, key, iv);\n        B = cipher.update(B);\n\n        A = xor(B.slice(0, 8),\n                longToBigEndian(count));\n        R[idx] = B.slice(8, 16);\n      }\n    }\n    R = [A].concat(R);\n    var cdata = Buffer.concat(R);\n    return Promise.resolve({\n      data: cdata\n    });\n  };\n\n  return helpers.setupFallback(node, webcrypto, fallback);\n}\nfunction kwDecryptFN(size) {\n  function commonChecks(key, data) {\n    if (size !== (key.length << 3)) {\n      throw new Error(\"invalid key size\");\n    }\n    if (0 < (data.length - 8) && 0 !== (data.length % 8)) {\n      throw new Error(\"invalid data length\");\n    }\n  }\n\n  // ### 'fallback' implementation -- uses forge\n  var fallback = function(key, cdata) {\n    try {\n      commonChecks(key, cdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    // setup cipher\n    var cipher = forge.cipher.createDecipher(\"AES\", new DataBuffer(key));\n\n    // prepare inputs\n    var R = split(cdata, 8),\n        A,\n        B,\n        count;\n    A = R[0];\n    R = R.slice(1);\n    for (var jdx = 5; 0 <= jdx; --jdx) {\n      for (var idx = R.length - 1; 0 <= idx; --idx) {\n        count = (R.length * jdx) + idx + 1;\n        B = xor(A,\n                longToBigEndian(count));\n        B = Buffer.concat([B, R[idx]]);\n        cipher.start();\n        cipher.update(new DataBuffer(B));\n        cipher.finish();\n        B = Buffer.from(cipher.output.bytes(), \"binary\");\n\n        A = B.slice(0, 8);\n        R[idx] = B.slice(8, 16);\n      }\n    }\n    if (A.toString() !== A0.toString()) {\n      return Promise.reject(new Error(\"decryption failed\"));\n    }\n    var pdata = Buffer.concat(R);\n    return Promise.resolve(pdata);\n  };\n  // ### WebCryptoAPI implementation\n  var webcrypto = function(key, cdata) {\n    try {\n      commonChecks(key, cdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var alg = {\n      name: \"AES-KW\"\n    };\n    var promise = helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"unwrapKey\"]);\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.unwrapKey(\"raw\", cdata, key, alg, {name: \"HMAC\", hash: \"SHA-256\"}, true, [\"sign\"]);\n    });\n    promise = promise.then(function(result) {\n      // unwrapped CryptoKey -- extract raw\n      return helpers.subtleCrypto.exportKey(\"raw\", result);\n    });\n    promise = promise.then(function(result) {\n      result = Buffer.from(result);\n      return result;\n    });\n    return promise;\n  };\n  var node = function(key, cdata) {\n    try {\n      commonChecks(key, cdata);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    // prepare inputs\n    var R = split(cdata, 8),\n        iv = Buffer.alloc(16),\n        A,\n        B,\n        count;\n    A = R[0];\n    R = R.slice(1);\n    for (var jdx = 5; 0 <= jdx; --jdx) {\n      for (var idx = R.length - 1; 0 <= idx; --idx) {\n        count = (R.length * jdx) + idx + 1;\n        B = xor(A,\n                longToBigEndian(count));\n        B = Buffer.concat([B, R[idx], iv]);\n        var cipher = helpers.nodeCrypto.createDecipheriv(\"AES\" + size, key, iv);\n        B = cipher.update(B);\n\n        A = B.slice(0, 8);\n        R[idx] = B.slice(8, 16);\n      }\n    }\n    if (A.toString() !== A0.toString()) {\n      return Promise.reject(new Error(\"decryption failed\"));\n    }\n    var pdata = Buffer.concat(R);\n    return Promise.resolve(pdata);\n  };\n\n  return helpers.setupFallback(node, webcrypto, fallback);\n}\n\n// ### Public API\n// * [name].encrypt\n// * [name].decrypt\nvar aesKw = {};\n[\n  \"A128KW\",\n  \"A192KW\",\n  \"A256KW\"\n].forEach(function(alg) {\n  var size = parseInt(/A(\\d+)KW/g.exec(alg)[1]);\n  aesKw[alg] = {\n    encrypt: kwEncryptFN(size),\n    decrypt: kwDecryptFN(size)\n  };\n});\n\nmodule.exports = aesKw;\n","/*!\n * algorithms/concat.js - Concat Key Derivation\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar CONSTANTS = require(\"./constants.js\"),\n    sha = require(\"./sha.js\");\n\nfunction concatDeriveFn(name) {\n  name = name.replace(\"CONCAT-\", \"\");\n\n  // NOTE: no nodejs/webcrypto/fallback model, since ConcatKDF is\n  //       implemented using the SHA algorithms\n\n  var fn = function(key, props) {\n    props = props || {};\n\n    var keyLen = props.length,\n        hashLen = CONSTANTS.HASHLENGTH[name];\n    if (!keyLen) {\n      return Promise.reject(new Error(\"invalid key length\"));\n    }\n\n    // setup otherInfo\n    if (!props.otherInfo) {\n      return Promise.reject(new Error(\"invalid otherInfo\"));\n    }\n    var otherInfo = props.otherInfo;\n\n    var op = sha[name].digest;\n    var N = Math.ceil(keyLen / hashLen),\n        idx = 0,\n        okm = [];\n    function step() {\n      if (N === idx++) {\n        return Buffer.concat(okm).slice(0, keyLen);\n      }\n\n      var T = Buffer.alloc(4 + key.length + otherInfo.length);\n      T.writeUInt32BE(idx, 0);\n      key.copy(T, 4);\n      otherInfo.copy(T, 4 + key.length);\n      return op(T).then(function(result) {\n        okm.push(result);\n        return step();\n      });\n    }\n\n    return step();\n  };\n\n  return fn;\n}\n\n// Public API\n// * [name].derive\nvar concat = {};\n[\n  \"CONCAT-SHA-1\",\n  \"CONCAT-SHA-256\",\n  \"CONCAT-SHA-384\",\n  \"CONCAT-SHA-512\"\n].forEach(function(name) {\n  concat[name] = {\n    derive: concatDeriveFn(name)\n  };\n});\n\nmodule.exports = concat;\n","/*!\n * algorithms/constants.js - Constants used in Cryptographic Algorithms\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n \"use strict\";\n\nmodule.exports = {\n  CHUNK_SIZE: 1024,\n  HASHLENGTH: {\n    \"SHA-1\": 160,\n    \"SHA-256\": 256,\n    \"SHA-384\": 384,\n    \"SHA-512\": 512\n  },\n  ENCLENGTH: {\n    \"AES-128-CBC\": 128,\n    \"AES-192-CBC\": 192,\n    \"AES-256-CBC\": 256,\n    \"AES-128-KW\": 128,\n    \"AES-192-KW\": 192,\n    \"AES-256-KW\": 256\n  },\n  KEYLENGTH: {\n    \"A128CBC-HS256\": 256,\n    \"A192CBC-HS384\": 384,\n    \"A256CBC-HS512\": 512,\n    \"A128CBC+HS256\": 256,\n    \"A192CBC+HS384\": 384,\n    \"A256CBC+HS512\": 512,\n    \"A128GCM\": 128,\n    \"A192GCM\": 192,\n    \"A256GCM\": 256,\n    \"A128KW\": 128,\n    \"A192KW\": 192,\n    \"A256KW\": 256,\n    \"ECDH-ES+A128KW\": 128,\n    \"ECDH-ES+A192KW\": 192,\n    \"ECDH-ES+A256KW\": 256\n  },\n  NONCELENGTH: {\n    \"A128CBC-HS256\": 128,\n    \"A192CBC-HS384\": 128,\n    \"A256CBC-HS512\": 128,\n    \"A128CBC+HS256\": 128,\n    \"A192CBC+HS384\": 128,\n    \"A256CBC+HS512\": 128,\n    \"A128GCM\": 96,\n    \"A192GCM\": 96,\n    \"A256GCM\": 96\n  }\n};\n","/*!\n * algorithms/dir.js - Direct key mode\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nfunction dirEncryptFN(key) {\n  // NOTE: pdata unused\n  // NOTE: props unused\n  return Promise.resolve({\n    data: key,\n    once: true,\n    direct: true\n  });\n}\nfunction dirDecryptFN(key) {\n  // NOTE: pdata unused\n  // NOTE: props unused\n  return Promise.resolve(key);\n}\n\n// ### Public API\n// * [name].encrypt\n// * [name].decrypt\nvar direct = {\n  dir: {\n    encrypt: dirEncryptFN,\n    decrypt: dirDecryptFN\n  }\n};\n\nmodule.exports = direct;\n","/*!\n * algorithms/ec-util.js - Elliptic Curve Utility Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar clone = require(\"lodash/clone\"),\n    ecc = require(\"../deps/ecc\"),\n    forge = require(\"../deps/forge.js\"),\n    util = require(\"../util\");\n\nvar EC_KEYSIZES = {\n  \"P-256\": 256,\n  \"P-384\": 384,\n  \"P-521\": 521\n};\n\nfunction convertToForge(key, isPublic) {\n  var parts = isPublic ?\n              [\"x\", \"y\"] :\n              [\"d\"];\n  parts = parts.map(function(f) {\n    return new forge.jsbn.BigInteger(key[f].toString(\"hex\"), 16);\n  });\n  // prefix with curve\n  parts = [key.crv].concat(parts);\n  var fn = isPublic ?\n           ecc.asPublicKey :\n           ecc.asPrivateKey;\n  return fn.apply(ecc, parts);\n}\n\nfunction convertToJWK(key, isPublic) {\n  var result = clone(key);\n  var parts = isPublic ?\n              [\"x\", \"y\"] :\n              [\"x\", \"y\", \"d\"];\n  parts.forEach(function(f) {\n    result[f] = util.base64url.encode(result[f]);\n  });\n\n  // remove potentially troublesome properties\n  delete result.key_ops;\n  delete result.use;\n  delete result.alg;\n\n  if (isPublic) {\n    delete result.d;\n  }\n\n  return result;\n}\n\nfunction convertToObj(key, isPublic) {\n  var result = clone(key);\n  var parts = isPublic ?\n              [\"x\", \"y\"] :\n              [\"d\"];\n  parts.forEach(function(f) {\n    // assume string if base64url-encoded\n    result[f] = util.asBuffer(result[f], \"base64url\");\n  });\n\n  return result;\n}\n\nvar UNCOMPRESSED = Buffer.from([0x04]);\nfunction convertToBuffer(key, isPublic) {\n  key = convertToObj(key, isPublic);\n  var result = isPublic ?\n               Buffer.concat([UNCOMPRESSED, key.x, key.y]) :\n               key.d;\n  return result;\n}\n\nfunction curveSize(crv) {\n  return EC_KEYSIZES[crv || \"\"] || NaN;\n}\n\nfunction curveNameToOid(crv) {\n  switch (crv) {\n    case \"P-256\":\n      return \"1.2.840.10045.3.1.7\";\n    case \"P-384\":\n      return \"1.3.132.0.34\";\n    case \"P-521\":\n      return \"1.3.132.0.35\";\n    default:\n      return null;\n  }\n}\n\nvar EC_OID = \"1.2.840.10045.2.1\";\nfunction convertToPEM(key, isPrivate) {\n  // curveName to OID\n  var oid = key.crv;\n  oid = curveNameToOid(oid);\n  oid = forge.asn1.oidToDer(oid);\n  // key as bytes\n  var type,\n      pub,\n      asn1;\n  if (isPrivate) {\n    type = \"EC PRIVATE KEY\";\n    pub = Buffer.concat([\n      Buffer.from([0x00, 0x04]),\n      key.x,\n      key.y\n    ]).toString(\"binary\");\n    key = key.d.toString(\"binary\");\n    asn1 = forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.SEQUENCE, true, [\n      forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.INTEGER, false, \"\\u0001\"),\n      forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.OCTETSTRING, false, key),\n      forge.asn1.create(forge.asn1.Class.CONTEXT_SPECIFIC, 0, true, [\n        forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.OID, false, oid.bytes())\n      ]),\n      forge.asn1.create(forge.asn1.Class.CONTEXT_SPECIFIC, 1, true, [\n        forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.BITSTRING, false, pub)\n      ])\n    ]);\n  } else {\n    type = \"PUBLIC KEY\";\n    key = Buffer.concat([\n      Buffer.from([0x00, 0x04]),\n      key.x,\n      key.y\n    ]).toString(\"binary\");\n    asn1 = forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.SEQUENCE, true, [\n      forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.SEQUENCE, true, [\n        forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.OID, false, forge.asn1.oidToDer(EC_OID).bytes()),\n        forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.OID, false, oid.bytes())\n      ]),\n      forge.asn1.create(forge.asn1.Class.UNIVERSAL, forge.asn1.Type.BITSTRING, false, key)\n    ]);\n  }\n  asn1 = forge.asn1.toDer(asn1).bytes();\n  var pem = forge.pem.encode({\n    type: type,\n    body: asn1\n  });\n  return pem;\n}\n\n// Inspired by teifip/node-webtokens/blob/master/lib/ecdsa.js\nvar ERR_MSG = \"Could not extract parameters from DER signature\";\nfunction derToConcat(signature, size) {\n  var offset = 0;\n  if (signature[offset++] !== 0x30) {\n    throw new Error(ERR_MSG);\n  }\n  var seqLength = signature[offset++];\n  if (seqLength === 0x81) {\n    seqLength = signature[offset++];\n  }\n  if (seqLength > signature.length - offset) {\n    throw new Error(ERR_MSG);\n  }\n  if (signature[offset++] !== 0x02) {\n    throw new Error(ERR_MSG);\n  }\n  var rLength = signature[offset++];\n  if (rLength > signature.length - offset - 2) {\n    throw new Error(ERR_MSG);\n  }\n  if (rLength > size + 1) {\n    throw new Error(ERR_MSG);\n  }\n  var rOffset = offset;\n  offset += rLength;\n  if (signature[offset++] !== 0x02) {\n    throw new Error(ERR_MSG);\n  }\n  var sLength = signature[offset++];\n  if (sLength !== signature.length - offset) {\n    throw new Error(ERR_MSG);\n  }\n  if (sLength > size + 1) {\n    throw new Error(ERR_MSG);\n  }\n  var sOffset = offset;\n  offset += sLength;\n  if (offset !== signature.length) {\n    throw new Error(ERR_MSG);\n  }\n  var rPadding = size - rLength;\n  var sPadding = size - sLength;\n  var dst = Buffer.alloc(rPadding + rLength + sPadding + sLength);\n  for (offset = 0; offset < rPadding; ++offset) {\n    dst[offset] = 0;\n  }\n  var rPad = Math.max(-rPadding, 0);\n  signature.copy(dst, offset, rOffset + rPad, rOffset + rLength);\n  offset = size;\n  for (var o = offset; offset < o + sPadding; ++offset) {\n    dst[offset] = 0;\n  }\n  var sPad = Math.max(-sPadding, 0);\n  signature.copy(dst, offset, sOffset + sPad, sOffset + sLength);\n  return dst;\n}\n\nfunction countPadding(buf, start, stop) {\n  var padding = 0;\n  while (start + padding < stop && buf[start + padding] === 0) {\n    ++padding;\n  }\n  var needsSign = buf[start + padding] >= 0x80;\n  if (needsSign) {\n    --padding;\n  }\n  return padding;\n}\n\nfunction concatToDer(signature, size) {\n  var rPadding = countPadding(signature, 0, size);\n  var sPadding = countPadding(signature, size, signature.length);\n  var rLength = size - rPadding;\n  var sLength = size - sPadding;\n  var rsBytes = rLength + sLength + 4;\n  var shortLength = rsBytes < 0x80;\n  var dst = Buffer.alloc((shortLength ? 2 : 3) + rsBytes);\n  var offset = 0;\n  dst[offset++] = 0x30;\n  if (shortLength) {\n    dst[offset++] = rsBytes;\n  } else {\n    dst[offset++] = 0x81;\n    dst[offset++] = rsBytes & 0xFF;\n  }\n  dst[offset++] = 0x02;\n  dst[offset++] = rLength;\n  if (rPadding < 0) {\n    dst[offset++] = 0;\n    offset += signature.copy(dst, offset, 0, size);\n  } else {\n    offset += signature.copy(dst, offset, rPadding, size);\n  }\n  dst[offset++] = 0x02;\n  dst[offset++] = sLength;\n  if (sPadding < 0) {\n    dst[offset++] = 0;\n    signature.copy(dst, offset, size);\n  } else {\n    signature.copy(dst, offset, size + sPadding);\n  }\n  return dst;\n}\n\nmodule.exports = {\n  convertToForge: convertToForge,\n  convertToJWK: convertToJWK,\n  convertToObj: convertToObj,\n  convertToBuffer: convertToBuffer,\n  curveSize: curveSize,\n  derToConcat: derToConcat,\n  concatToDer: concatToDer,\n  convertToPEM: convertToPEM,\n  EC_OID: EC_OID\n};\n","/*!\n * algorithms/ecdh.js - Elliptic Curve Diffie-Hellman algorithms\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar merge = require(\"../util/merge\"),\n    util = require(\"../util\"),\n    ecUtil = require(\"./ec-util.js\"),\n    hkdf = require(\"./hkdf.js\"),\n    concat = require(\"./concat.js\"),\n    aesKw = require(\"./aes-kw.js\"),\n    helpers = require(\"./helpers.js\"),\n    CONSTANTS = require(\"./constants.js\");\n\nvar clone = require(\"lodash/clone\");\nvar omit = require(\"lodash/omit\");\nvar pick = require(\"lodash/pick\");\n\nfunction idealHash(curve) {\n  switch (curve) {\n    case \"P-256\":\n      return \"SHA-256\";\n    case \"P-384\":\n      return \"SHA-384\";\n    case \"P-521\":\n      return \"SHA-512\";\n    default:\n      throw new Error(\"unsupported curve: \" + curve);\n  }\n}\n\n// ### Exported\nvar ecdh = module.exports = {};\n\n// ### Derivation algorithms\n// ### \"raw\" ECDH\nfunction ecdhDeriveFn() {\n  var alg = {\n    name: \"ECDH\"\n  };\n\n  var validatePublic = function(pk, form) {\n    var pubKey = pk && ecUtil.convertToForge(pk, true);\n    if (!pubKey || !pubKey.isValid()) {\n      return Promise.reject(new Error(\"invalid EC public key\"));\n    }\n\n    switch (form) {\n      case \"jwk\":\n        pubKey = ecUtil.convertToJWK(pk, true);\n        break;\n      case \"buffer\":\n        pubKey = ecUtil.convertToBuffer(pk, true);\n        break;\n    }\n    return Promise.resolve(pubKey);\n  }\n\n  // ### fallback implementation -- uses ecc + forge\n  var fallback = function(key, props) {\n    props = props || {};\n    var keyLen = props.length || 0;\n    // assume {key} is privateKey\n    // assume {props.public} is publicKey\n    var privKey = ecUtil.convertToForge(key, false);\n\n    var p = validatePublic(props.public, \"forge\");\n    p = p.then(function(pubKey) {\n      // {pubKey} is \"forge\"\n\n      var secret = privKey.computeSecret(pubKey);\n      if (keyLen) {\n        // truncate to requested key length\n        if (secret.length < keyLen) {\n          return Promise.reject(new Error(\"key length too large: \" + keyLen));\n        }\n        secret = secret.slice(0, keyLen);\n      }\n\n      return secret;\n    });\n    return p;\n  };\n\n  // ### WebCryptoAPI implementation\n  // TODO: cache CryptoKey sooner\n  var webcrypto = function(key, props) {\n    key = key || {};\n    props = props || {};\n\n    var keyLen = props.length || 0,\n        algParams = merge(clone(alg), {\n          namedCurve: key.crv\n        });\n\n    // assume {key} is privateKey\n    if (!keyLen) {\n      // calculate key length from private key size\n      keyLen = key.d.length;\n    }\n    var privKey = ecUtil.convertToJWK(key, false);\n    privKey = helpers.subtleCrypto.importKey(\"jwk\",\n                                             privKey,\n                                             algParams,\n                                             false,\n                                             [ \"deriveBits\" ]);\n\n    // assume {props.public} is publicKey\n    var pubKey = validatePublic(props.public, \"jwk\");\n    pubKey = pubKey.then(function(pubKey) {\n      // {pubKey} is \"jwk\"\n      return helpers.subtleCrypto.importKey(\"jwk\",\n                                            pubKey,\n                                            algParams,\n                                            false,\n                                            []);\n    });\n\n    var p = Promise.all([privKey, pubKey]);\n    p = p.then(function(keypair) {\n      var privKey = keypair[0],\n          pubKey = keypair[1];\n\n      var algParams = merge(clone(alg), {\n        public: pubKey\n      });\n      return helpers.subtleCrypto.deriveBits(algParams, privKey, keyLen * 8);\n    });\n    p = p.then(function(result) {\n      result = Buffer.from(result);\n      return result;\n    });\n    return p;\n  };\n\n  var nodejs = function(key, props) {\n    if (\"function\" !== typeof helpers.nodeCrypto.createECDH) {\n      throw new Error(\"unsupported algorithm: ECDH\");\n    }\n\n    props = props || {};\n    var keyLen = props.length || 0;\n    var curve;\n    switch (key.crv) {\n      case \"P-256\":\n        curve = \"prime256v1\";\n        break;\n      case \"P-384\":\n        curve = \"secp384r1\";\n        break;\n      case \"P-521\":\n        curve = \"secp521r1\";\n        break;\n      default:\n        return Promise.reject(new Error(\"invalid curve: \" + curve));\n    }\n\n    // assume {key} is privateKey\n    // assume {props.public} is publicKey\n    var privKey = ecUtil.convertToBuffer(key, false);\n\n    var p = validatePublic(props.public, \"buffer\");\n    p = p.then(function(pubKey) {\n      // {pubKey} is \"buffer\"\n      var ecdh = helpers.nodeCrypto.createECDH(curve);\n      // dummy call so computeSecret doesn't fail\n      // ecdh.generateKeys();\n      ecdh.setPrivateKey(privKey);\n      var secret = ecdh.computeSecret(pubKey);\n      if (keyLen) {\n        if (secret.length < keyLen) {\n          return Promise.reject(new Error(\"key length too large: \" + keyLen));\n        }\n        secret = secret.slice(0, keyLen);\n      }\n      return secret;\n    });\n    return p;\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction ecdhConcatDeriveFn() {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n\n  var fn = function(key, props) {\n    props = props || {};\n\n    var hash;\n    try {\n      hash = props.hash || idealHash(key.crv);\n      if (!hash) {\n        throw new Error(\"invalid hash: \" + hash);\n      }\n      hash.toUpperCase();\n    } catch (ex) {\n      return Promise.reject(ex);\n    }\n\n    var params = [\"public\"];\n    // derive shared secret\n    // NOTE: whitelist items from {props} for ECDH\n    var promise = ecdh.ECDH.derive(key, pick(props, params));\n    // expand\n    promise = promise.then(function(shared) {\n      // NOTE: blacklist items from {props} for ECDH\n      return concat[\"CONCAT-\" + hash].derive(shared, omit(props, params));\n    });\n    return promise;\n  };\n\n  return fn;\n}\n\nfunction ecdhHkdfDeriveFn() {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n\n  var fn = function(key, props) {\n    props = props || {};\n\n    var hash;\n    try {\n      hash = props.hash || idealHash(key.crv);\n      if (!hash) {\n        throw new Error(\"invalid hash: \" + hash);\n      }\n      hash.toUpperCase();\n    } catch (ex) {\n      return Promise.reject(ex);\n    }\n\n    var params = [\"public\"];\n    // derive shared secret\n    // NOTE: whitelist items from {props} for ECDH\n    var promise = ecdh.ECDH.derive(key, pick(props, params));\n    // extract-and-expand\n    promise = promise.then(function(shared) {\n      // NOTE: blacklist items from {props} for ECDH\n      return hkdf[\"HKDF-\" + hash].derive(shared, omit(props, params));\n    });\n    return promise;\n  };\n\n  return fn;\n}\n\n// ### Wrap/Unwrap algorithms\nfunction doEcdhesCommonDerive(privKey, pubKey, props) {\n  function prependLen(input) {\n    return Buffer.concat([\n      helpers.int32ToBuffer(input.length),\n      input\n    ]);\n  }\n\n  var algId = props.algorithm || \"\",\n      keyLen = CONSTANTS.KEYLENGTH[algId],\n      apu = util.asBuffer(props.apu || \"\", \"base64url\"),\n      apv = util.asBuffer(props.apv || \"\", \"base64url\");\n  var otherInfo = Buffer.concat([\n    prependLen(Buffer.from(algId, \"utf8\")),\n    prependLen(apu),\n    prependLen(apv),\n    helpers.int32ToBuffer(keyLen)\n  ]);\n\n  var params = {\n    public: pubKey,\n    length: keyLen / 8,\n    hash: \"SHA-256\",\n    otherInfo: otherInfo\n  };\n  return ecdh[\"ECDH-CONCAT\"].derive(privKey, params);\n}\n\nfunction ecdhesDirEncryptFn() {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n  var fn = function(key, pdata, props) {\n    props = props || {};\n\n    // {props.epk} is private\n    if (!props.epk || !props.epk.d) {\n      return Promise.reject(new Error(\"missing ephemeral private key\"));\n    }\n    var epk = ecUtil.convertToObj(props.epk, false);\n\n    // {key} is public\n    if (!key || !key.x || !key.y) {\n      return Promise.reject(new Error(\"missing static public key\"));\n    }\n    var spk = ecUtil.convertToObj(key, true);\n\n    // derive ECDH shared\n    var promise = doEcdhesCommonDerive(epk, spk, {\n      algorithm: props.enc,\n      apu: props.apu,\n      apv: props.apv\n    });\n    promise = promise.then(function(shared) {\n      return {\n        data: shared,\n        once: true,\n        direct: true\n      };\n    });\n    return promise;\n  };\n\n  return fn;\n}\nfunction ecdhesDirDecryptFn() {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n  var fn = function(key, cdata, props) {\n    props = props || {};\n\n    // {props.epk} is public\n    if (!props.epk || !props.epk.x || !props.epk.y) {\n      return Promise.reject(new Error(\"missing ephemeral public key\"));\n    }\n    var epk = ecUtil.convertToObj(props.epk, true);\n\n    // {key} is private\n    if (!key || !key.d) {\n      return Promise.reject(new Error(\"missing static private key\"));\n    }\n    var spk = ecUtil.convertToObj(key, false);\n\n    // derive ECDH shared\n    var promise = doEcdhesCommonDerive(spk, epk, {\n      algorithm: props.enc,\n      apu: props.apu,\n      apv: props.apv\n    });\n    promise = promise.then(function(shared) {\n      return shared;\n    });\n    return promise;\n  };\n\n  return fn;\n}\n\nfunction ecdhesKwEncryptFn(wrap) {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n  var fn = function(key, pdata, props) {\n    props = props || {};\n\n    // {props.epk} is private\n    if (!props.epk || !props.epk.d) {\n      return Promise.reject(new Error(\"missing ephemeral private key\"));\n    }\n    var epk = ecUtil.convertToObj(props.epk, false);\n\n    // {key} is public\n    if (!key || !key.x || !key.y) {\n      return Promise.reject(new Error(\"missing static public key\"));\n    }\n    var spk = ecUtil.convertToObj(key, true);\n\n    // derive ECDH shared\n    var promise = doEcdhesCommonDerive(epk, spk, {\n      algorithm: props.alg,\n      apu: props.apu,\n      apv: props.apv\n    });\n    promise = promise.then(function(shared) {\n      // wrap provided key with ECDH shared\n      return wrap(shared, pdata);\n    });\n    return promise;\n  };\n\n  return fn;\n}\n\nfunction ecdhesKwDecryptFn(unwrap) {\n  // NOTE: no nodejs/webcrypto/fallback model, since this algorithm is\n  //       implemented using other primitives\n  var fn = function(key, cdata, props) {\n    props = props || {};\n\n    // {props.epk} is public\n    if (!props.epk || !props.epk.x || !props.epk.y) {\n      return Promise.reject(new Error(\"missing ephemeral public key\"));\n    }\n    var epk = ecUtil.convertToObj(props.epk, true);\n\n    // {key} is private\n    if (!key || !key.d) {\n      return Promise.reject(new Error(\"missing static private key\"));\n    }\n    var spk = ecUtil.convertToObj(key, false);\n\n    // derive ECDH shared\n    var promise = doEcdhesCommonDerive(spk, epk, {\n      algorithm: props.alg,\n      apu: props.apu,\n      apv: props.apv\n    });\n    promise = promise.then(function(shared) {\n      // unwrap provided key with ECDH shared\n      return unwrap(shared, cdata);\n    });\n    return promise;\n  };\n\n  return fn;\n}\n\n// ### Public API\n// * [name].derive\n[\n  \"ECDH\",\n  \"ECDH-HKDF\",\n  \"ECDH-CONCAT\"\n].forEach(function(name) {\n  var kdf = /^ECDH(?:-(\\w+))?$/g.exec(name || \"\")[1];\n  var op = ecdh[name] = ecdh[name] || {};\n  switch (kdf || \"\") {\n    case \"CONCAT\":\n      op.derive = ecdhConcatDeriveFn();\n      break;\n    case \"HKDF\":\n      op.derive = ecdhHkdfDeriveFn();\n      break;\n    case \"\":\n      op.derive = ecdhDeriveFn();\n      break;\n    default:\n      op.derive = null;\n  }\n});\n\n// * [name].encrypt\n// * [name].decrypt\n[\n  \"ECDH-ES\",\n  \"ECDH-ES+A128KW\",\n  \"ECDH-ES+A192KW\",\n  \"ECDH-ES+A256KW\"\n].forEach(function(name) {\n  var kw = /^ECDH-ES(?:\\+(.+))?/g.exec(name || \"\")[1];\n  var op = ecdh[name] = ecdh[name] || {};\n  if (!kw) {\n    op.encrypt = ecdhesDirEncryptFn();\n    op.decrypt = ecdhesDirDecryptFn();\n  } else {\n    kw = aesKw[kw];\n    if (kw) {\n      op.encrypt = ecdhesKwEncryptFn(kw.encrypt);\n      op.decrypt = ecdhesKwDecryptFn(kw.decrypt);\n    } else {\n      op.ecrypt = op.decrypt = null;\n    }\n  }\n});\n//*/\n","/*!\n * algorithms/ecdsa.js - Elliptic Curve Digitial Signature Algorithms\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar ecUtil = require(\"./ec-util.js\"),\n    helpers = require(\"./helpers.js\"),\n    sha = require(\"./sha.js\");\n\nfunction idealCurve(hash) {\n  switch (hash) {\n    case \"SHA-256\":\n      return \"P-256\";\n    case \"SHA-384\":\n      return \"P-384\";\n    case \"SHA-512\":\n      return \"P-521\";\n    default:\n      throw new Error(\"unsupported hash: \" + hash);\n  }\n}\n\nfunction ecdsaSignFN(hash) {\n  var curve = idealCurve(hash);\n\n  // ### Fallback implementation -- uses forge\n  var fallback = function(key, pdata /*, props */) {\n    if (curve !== key.crv) {\n      return Promise.reject(new Error(\"invalid curve\"));\n    }\n    var pk = ecUtil.convertToForge(key, false);\n\n    var promise;\n    // generate hash\n    promise = sha[hash].digest(pdata);\n    // sign hash\n    promise = promise.then(function(result) {\n      result = pk.sign(result);\n      result = Buffer.concat([result.r, result.s]);\n      return {\n        data: pdata,\n        mac: result\n      };\n    });\n    return promise;\n  };\n\n  // ### WebCrypto API implementation\n  var webcrypto = function(key, pdata /*, props */) {\n    if (curve !== key.crv) {\n      return Promise.reject(new Error(\"invalid curve\"));\n    }\n    var pk = ecUtil.convertToJWK(key, false);\n\n    var promise;\n    var alg = {\n      name: \"ECDSA\",\n      namedCurve: pk.crv,\n      hash: {\n        name: hash\n      }\n    };\n    promise = helpers.subtleCrypto.importKey(\"jwk\",\n                                             pk,\n                                             alg,\n                                             true,\n                                             [ \"sign\" ]);\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.sign(alg, key, pdata);\n    });\n    promise = promise.then(function(result) {\n      result = Buffer.from(result);\n      return {\n        data: pdata,\n        mac: result\n      };\n    });\n    return promise;\n  };\n\n  var nodejs;\n  var nodeHash = hash.toLowerCase().replace(\"-\", \"\");\n  if (helpers.nodeCrypto && helpers.nodeCrypto.getHashes().indexOf(nodeHash) > -1) {\n    nodejs = function(key, pdata) {\n      if (curve !== key.crv) {\n        return Promise.reject(new Error(\"invalid curve\"));\n      }\n\n      var promise;\n      promise = Promise.resolve(helpers.nodeCrypto.createSign(nodeHash));\n      promise = promise.then(function (sign) {\n        sign.update(pdata);\n        return sign;\n      });\n\n      var size;\n\n      switch (nodeHash.slice(-3)) {\n        case \"384\":\n          size = 48;\n          break;\n        case \"512\":\n          size = 66;\n          break;\n        default:\n          size = 32;\n      }\n\n      promise = promise.then(function (sign) {\n        return ecUtil.derToConcat(sign.sign(ecUtil.convertToPEM(key, true)), size);\n      });\n\n      promise = promise.then(function (result) {\n        return {\n          data: pdata,\n          mac: result\n        };\n      });\n\n      return promise;\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction ecdsaVerifyFN(hash) {\n  var curve = idealCurve(hash);\n\n  // ### Fallback implementation -- uses forge\n  var fallback = function(key, pdata, mac /*, props */) {\n    if (curve !== key.crv) {\n      return Promise.reject(new Error(\"invalid curve\"));\n    }\n    var pk = ecUtil.convertToForge(key, true);\n\n    var promise;\n    // generate hash\n    promise = sha[hash].digest(pdata);\n    // verify hash\n    promise = promise.then(function(result) {\n      var len = mac.length / 2;\n      var rs = {\n        r: mac.slice(0, len),\n        s: mac.slice(len)\n      };\n      if (!pk.verify(result, rs)) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    });\n    return promise;\n  };\n\n  // ### WebCrypto API implementation\n  var webcrypto = function(key, pdata, mac /* , props */) {\n    if (curve !== key.crv) {\n      return Promise.reject(new Error(\"invalid curve\"));\n    }\n    var pk = ecUtil.convertToJWK(key, true);\n\n    var promise;\n    var alg = {\n      name: \"ECDSA\",\n      namedCurve: pk.crv,\n      hash: {\n        name: hash\n      }\n    };\n    promise = helpers.subtleCrypto.importKey(\"jwk\",\n                                             pk,\n                                             alg,\n                                             true,\n                                             [\"verify\"]);\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.verify(alg, key, mac, pdata);\n    });\n    promise = promise.then(function(result) {\n      if (!result) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    });\n    return promise;\n  };\n\n  var nodejs;\n  var nodeHash = hash.toLowerCase().replace(\"-\", \"\");\n  if (helpers.nodeCrypto && helpers.nodeCrypto.getHashes().indexOf(nodeHash) > -1) {\n    nodejs = function(key, pdata, mac /* , props */) {\n      if (curve !== key.crv) {\n        return Promise.reject(new Error(\"invalid curve\"));\n      }\n\n      var size;\n      switch (nodeHash.slice(-3)) {\n        case \"384\":\n          size = 48;\n          break;\n        case \"512\":\n          size = 66;\n          break;\n        default:\n          size = 32;\n      }\n\n      var promise;\n      promise = Promise.resolve(helpers.nodeCrypto.createVerify(nodeHash));\n      promise = promise.then(function (verify) {\n        verify.update(pdata);\n        verify.end();\n        return verify.verify(ecUtil.convertToPEM(key, false), ecUtil.concatToDer(mac, size));\n      });\n      promise = promise.then(function (result) {\n        if (!result) {\n          throw new Error(\"verification failed\");\n        }\n        return {\n          data: pdata,\n          mac: mac,\n          valid: true\n        };\n      });\n\n      return promise;\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### Public API\nvar ecdsa = {};\n\n// * [name].sign\n// * [name].verify\n[\n  \"ES256\",\n  \"ES384\",\n  \"ES512\"\n].forEach(function(name) {\n  var hash = name.replace(/ES(\\d+)/g, function(m, size) {\n    return \"SHA-\" + size;\n  });\n  ecdsa[name] = {\n    sign: ecdsaSignFN(hash),\n    verify: ecdsaVerifyFN(hash)\n  };\n});\n\nmodule.exports = ecdsa;\n","/*!\n * algorithms/helpers.js - Internal functions and fields used in Cryptographic\n * Algorithms\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nif (typeof Promise === \"undefined\") {\n  require(\"es6-promise\").polyfill();\n}\n\n// ###\nexports.int32ToBuffer = function(v, b) {\n  b = b || Buffer.alloc(4);\n  b[0] = (v >>> 24) & 0xff;\n  b[1] = (v >>> 16) & 0xff;\n  b[2] = (v >>> 8) & 0xff;\n  b[3] = v & 0xff;\n  return b;\n};\n\nvar MAX_INT32 = Math.pow(2, 32);\nexports.int64ToBuffer = function(v, b) {\n  b = b || Buffer.alloc(8);\n  var hi = Math.floor(v / MAX_INT32),\n      lo = v % MAX_INT32;\n  hi = exports.int32ToBuffer(hi);\n  lo = exports.int32ToBuffer(lo);\n  b = Buffer.concat([hi, lo]);\n  return b;\n};\n\n// ### crypto and DOMException in browsers ###\n/* global crypto:false, DOMException:false */\n\nfunction getCryptoSubtle() {\n  if (\"undefined\" !== typeof crypto) {\n    if (\"undefined\" !== typeof crypto.subtle) {\n      return crypto.subtle;\n    }\n  }\n\n  return undefined;\n}\nfunction getCryptoNodeJS() {\n  var crypto;\n  try {\n    crypto = require(\"crypto\");\n  } catch (err) {\n    return undefined;\n  }\n\n  if (!Object.keys(crypto).length) {\n    // treat empty the same as missing\n    return undefined;\n  }\n\n  return crypto;\n}\n\nvar supported = {};\nObject.defineProperty(exports, \"subtleCrypto\", {\n  get: function() {\n    var result;\n\n    if (\"subtleCrypto\" in supported) {\n      result = supported.subtleCrypto;\n    } else {\n      result = supported.subtleCrypto = getCryptoSubtle();\n    }\n\n    return result;\n  },\n  enumerable: true\n});\nObject.defineProperty(exports, \"nodeCrypto\", {\n  get: function() {\n    var result;\n\n    if (\"nodeCrypto\" in supported) {\n      result = supported.nodeCrypto;\n    } else {\n      result = supported.nodeCrypto = getCryptoNodeJS();\n    }\n\n    return result;\n  },\n  enumerable: true\n});\n\nexports.setupFallback = function(nodejs, webcrypto, fallback) {\n  var impl;\n\n  if (nodejs && exports.nodeCrypto) {\n    impl = function main() {\n      var args = arguments,\n          promise;\n\n      function check(err) {\n        if (0 === err.message.indexOf(\"unsupported algorithm:\")) {\n          impl = fallback;\n          return impl.apply(null, args);\n        }\n\n        return Promise.reject(err);\n      }\n\n      try {\n        promise = Promise.resolve(nodejs.apply(null, args));\n      } catch(err) {\n        promise = check(err);\n      }\n\n      return promise;\n    };\n  } else if (webcrypto && exports.subtleCrypto) {\n    impl = function main() {\n      var args = arguments,\n         promise;\n\n      function check(err) {\n        if (err.code === DOMException.NOT_SUPPORTED_ERR ||\n            // Firefox rejects some operations erroneously complaining about inputs\n            err.message === \"Only ArrayBuffer and ArrayBufferView objects can be passed as CryptoOperationData\" ||\n            // MS Edge rejects with not an Error\n            !(err instanceof Error)) {\n          // not actually supported -- always use fallback\n          impl = fallback;\n          return impl.apply(null, args);\n        }\n\n       return Promise.reject(err);\n      }\n\n      try {\n        promise = webcrypto.apply(null, args);\n        promise = promise.catch(check);\n      } catch(err) {\n        promise = check(err);\n      }\n\n      return promise;\n    };\n  } else {\n    impl = fallback;\n  }\n\n  return impl;\n};\n","/*!\n * algorithms/hkdf.js - HMAC-based Extract-and-Expand Key Derivation\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar CONSTANTS = require(\"./constants.js\"),\n    hmac = require(\"./hmac.js\");\n\nfunction hkdfDeriveFn(name) {\n  var hash = name.replace(\"HKDF-\", \"\"),\n      op = name.replace(\"HKDF-SHA-\", \"HS\");\n\n  // NOTE: no nodejs/webcrypto/fallback model, since this HKDF is\n  //       implemented using the HMAC algorithms\n\n  var fn = function(key, props) {\n    var hashLen = CONSTANTS.HASHLENGTH[hash] / 8;\n\n    if (\"string\" === typeof op) {\n      op = hmac[op].sign;\n    }\n\n    // prepare options\n    props = props || {};\n    var salt = props.salt;\n    if (!salt || 0 === salt.length) {\n      salt = Buffer.alloc(hashLen);\n    }\n    var info = props.info || Buffer.alloc(0);\n    var keyLen = props.length || hashLen;\n\n    var promise;\n\n    // Setup Expansion\n    var N = Math.ceil(keyLen / hashLen),\n        okm = [],\n        idx = 0;\n    function expand(key, T) {\n      if (N === idx++) {\n        return Buffer.concat(okm).slice(0, keyLen);\n      }\n\n      if (!T) {\n        T = Buffer.alloc(0);\n      }\n      T = Buffer.concat([T, info, Buffer.from([idx])]);\n      T = op(key, T);\n      T = T.then(function(result) {\n        T = result.mac;\n        okm.push(T);\n\n        return expand(key, T);\n      });\n      return T;\n    }\n\n    // Step 1: Extract\n    promise = op(salt, key, { length: salt.length * 8 });\n    promise = promise.then(function(result) {\n      // Step 2: Expand\n      return expand(result.mac);\n    });\n\n    return promise;\n  };\n\n  return fn;\n}\n\n// Public API\n// * [name].derive\nvar hkdf = {};\n[\n  \"HKDF-SHA-1\",\n  \"HKDF-SHA-256\",\n  \"HKDF-SHA-384\",\n  \"HKDF-SHA-512\"\n].forEach(function(name) {\n  hkdf[name] = {\n    derive: hkdfDeriveFn(name)\n  };\n});\n\nmodule.exports = hkdf;\n","/*!\n * algorithms/hmac.js - HMAC-based \"signatures\"\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar CONSTANTS = require(\"./constants\"),\n    forge = require(\"../deps/forge.js\"),\n    DataBuffer = require(\"../util/databuffer.js\"),\n    helpers = require(\"./helpers.js\");\n\nfunction hmacSignFN(name) {\n  var md = name.replace(\"HS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"HS\", \"SHA-\");\n\n  function checkKeyLength(len, key) {\n    len = (len || CONSTANTS.HASHLENGTH[hash]) / 8;\n    if (len > key.length) {\n      return Promise.reject(new Error(\"invalid key length\"));\n    }\n\n    return Promise.resolve(key);\n  }\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(key, pdata, props) {\n    props = props || {};\n    var promise;\n    promise = checkKeyLength(props.length, key);\n    promise = promise.then(function() {\n      var sig = forge.hmac.create();\n      sig.start(md, key.toString(\"binary\"));\n      sig.update(pdata.toString(\"binary\"));\n      sig = Buffer.from(sig.digest().bytes(), \"binary\");\n\n      return {\n        data: pdata,\n        mac: sig\n      }\n    });\n    return promise;\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(key, pdata, props) {\n    props = props || {};\n\n    var alg = {\n      name: \"HMAC\",\n      hash: {\n        name: hash\n      }\n    };\n    var promise;\n    promise = checkKeyLength(props.length, key);\n    promise = promise.then(function() {\n      return helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"sign\"]);\n    });\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.sign(alg, key, pdata);\n    });\n    promise = promise.then(function(result) {\n      var sig = Buffer.from(result);\n      return {\n        data: pdata,\n        mac: sig\n      };\n    });\n\n    return promise;\n  };\n\n  // ### NodeJS implementation\n  var nodejs = function(key, pdata, props) {\n    props = props || {};\n\n    var promise;\n    promise = checkKeyLength(props.length, key);\n    promise = promise.then(function() {\n      var hmac = helpers.nodeCrypto.createHmac(md, key);\n      hmac.update(pdata);\n\n      var sig = hmac.digest();\n      return {\n        data: pdata,\n        mac: sig\n      };\n    });\n    return promise;\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction hmacVerifyFN(name) {\n  var md = name.replace(\"HS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"HS\", \"SHA-\");\n\n  function compare(len, expected, actual) {\n    len = (len || CONSTANTS.HASHLENGTH[hash]) / 8;\n    var valid = true;\n    for (var idx = 0; len > idx; idx++) {\n      valid = valid && (expected[idx] === actual[idx]);\n    }\n    return valid;\n  }\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(key, pdata, mac, props) {\n    props = props || {};\n\n    var vrfy = forge.hmac.create();\n    vrfy.start(md, new DataBuffer(key));\n    vrfy.update(pdata.toString(\"binary\"));\n    vrfy = Buffer.from(vrfy.digest().bytes(), \"binary\");\n\n    if (compare(props.length, mac, vrfy)) {\n      return Promise.resolve({\n        data: pdata,\n        mac: mac,\n        valid: true\n      });\n    } else {\n      return Promise.reject(new Error(\"verification failed\"));\n    }\n  };\n\n  var webcrypto = function(key, pdata, mac, props) {\n    props = props || {};\n\n    var alg = {\n      name: \"HMAC\",\n      hash: {\n        name: hash\n      }\n    };\n    var promise;\n    if (props.length) {\n      promise = helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"sign\"]);\n      promise = promise.then(function(key) {\n        return helpers.subtleCrypto.sign(alg, key, pdata);\n      });\n      promise = promise.then(function(result) {\n        var sig = Buffer.from(result);\n        return compare(props.length, mac, sig);\n      });\n    } else {\n      promise = helpers.subtleCrypto.importKey(\"raw\", key, alg, true, [\"verify\"]);\n      promise = promise.then(function(key) {\n        return helpers.subtleCrypto.verify(alg, key, mac, pdata);\n      });\n    }\n    promise = promise.then(function(result) {\n      if (!result) {\n        return Promise.reject(new Error(\"verifaction failed\"));\n      }\n\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    });\n\n    return promise;\n  };\n\n  var nodejs = function(key, pdata, mac, props) {\n    props = props || {};\n\n    var hmac = helpers.nodeCrypto.createHmac(md, key);\n    hmac.update(pdata);\n\n    var sig = hmac.digest();\n    if (!compare(props.length, mac, sig)) {\n      throw new Error(\"verification failed\");\n    }\n    return {\n      data: pdata,\n      mac: sig,\n      valid: true\n    };\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### Public API\n// * [name].sign\n// * [name].verify\nvar hmac = {};\n[\n  \"HS1\",\n  \"HS256\",\n  \"HS384\",\n  \"HS512\"\n].forEach(function(alg) {\n  hmac[alg] = {\n    sign: hmacSignFN(alg),\n    verify: hmacVerifyFN(alg)\n  };\n});\n\nmodule.exports = hmac;\n","/*!\n * algorithms/index.js - Cryptographic Algorithms Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\n// setup implementations\nvar implementations = [\n  require(\"./aes-cbc-hmac-sha2.js\"),\n  require(\"./aes-gcm.js\"),\n  require(\"./aes-kw.js\"),\n  require(\"./concat.js\"),\n  require(\"./dir.js\"),\n  require(\"./ecdh.js\"),\n  require(\"./ecdsa.js\"),\n  require(\"./hkdf.js\"),\n  require(\"./hmac.js\"),\n  require(\"./pbes2.js\"),\n  require(\"./rsaes.js\"),\n  require(\"./rsassa.js\"),\n  require(\"./sha.js\")\n];\n\nvar ALGS_DIGEST = {};\nvar ALGS_DERIVE = {};\nvar ALGS_SIGN = {},\n    ALGS_VRFY = {};\nvar ALGS_ENC = {},\n    ALGS_DEC = {};\n\nimplementations.forEach(function(mod) {\n  Object.keys(mod).forEach(function(alg) {\n    var op = mod[alg];\n\n    if (\"function\" === typeof op.encrypt) {\n      ALGS_ENC[alg] = op.encrypt;\n    }\n    if (\"function\" === typeof op.decrypt) {\n      ALGS_DEC[alg] = op.decrypt;\n    }\n    if (\"function\" === typeof op.sign) {\n      ALGS_SIGN[alg] = op.sign;\n    }\n    if (\"function\" === typeof op.verify) {\n      ALGS_VRFY[alg] = op.verify;\n    }\n    if (\"function\" === typeof op.digest) {\n      ALGS_DIGEST[alg] = op.digest;\n    }\n    if (\"function\" === typeof op.derive) {\n      ALGS_DERIVE[alg] = op.derive;\n    }\n  });\n});\n\n// public API\nexports.digest = function(alg, data, props) {\n  var op = ALGS_DIGEST[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(data, props);\n};\n\nexports.derive = function(alg, key, props) {\n  var op = ALGS_DERIVE[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(key, props);\n};\n\nexports.sign = function(alg, key, pdata, props) {\n  var op = ALGS_SIGN[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(key, pdata, props || {});\n};\n\nexports.verify = function(alg, key, pdata, mac, props) {\n  var op = ALGS_VRFY[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(key, pdata, mac, props || {});\n};\n\nexports.encrypt = function(alg, key, pdata, props) {\n  var op = ALGS_ENC[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(key, pdata, props || {});\n};\n\nexports.decrypt = function(alg, key, cdata, props) {\n  var op = ALGS_DEC[alg];\n  if (!op) {\n    return Promise.reject(new Error(\"unsupported algorithm: \" + alg));\n  }\n\n  return op(key, cdata, props || {});\n};\n","/*!\n * algorithms/pbes2.js - Password-Based Encryption (v2) Algorithms\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    merge = require(\"../util/merge.js\"),\n    util = require(\"../util\"),\n    helpers = require(\"./helpers.js\"),\n    CONSTANTS = require(\"./constants.js\"),\n    KW = require(\"./aes-kw.js\");\n\nvar NULL_BUFFER = Buffer.from([0]);\nvar DEFAULT_ITERATIONS = 8192;\nvar DEFAULT_SALT_LENGTH = 16;\n\nfunction fixSalt(hmac, kw, salt) {\n  var alg = \"PBES2-\" + hmac + \"+\" + kw;\n  var output = [\n    Buffer.from(alg, \"utf8\"),\n    NULL_BUFFER,\n    salt\n  ];\n  return Buffer.concat(output);\n}\n\nfunction pbkdf2Fn(hash) {\n  function prepareProps(props) {\n    props = props || {};\n    var keyLen = props.length || 0;\n    var salt = util.asBuffer(props.salt || Buffer.alloc(0), \"base64u4l\"),\n        itrs = props.iterations || 0;\n\n    if (0 >= keyLen) {\n      throw new Error(\"invalid key length\");\n    }\n    if (0 >= itrs) {\n      throw new Error(\"invalid iteration count\");\n    }\n\n    props.length = keyLen;\n    props.salt = salt;\n    props.iterations = itrs;\n\n    return props;\n  }\n\n  var fallback = function(key, props) {\n    try {\n      props = prepareProps(props);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var keyLen = props.length,\n        salt = props.salt,\n        itrs = props.iterations;\n\n    var promise = new Promise(function(resolve, reject) {\n      var md = forge.md[hash.replace(\"-\", \"\").toLowerCase()].create();\n      var cb = function(err, dk) {\n        if (err) {\n          reject(err);\n        } else {\n          dk = Buffer.from(dk, \"binary\");\n          resolve(dk);\n        }\n      };\n\n      forge.pkcs5.pbkdf2(key.toString(\"binary\"),\n                         salt.toString(\"binary\"),\n                         itrs,\n                         keyLen,\n                         md,\n                         cb);\n    });\n    return promise;\n  };\n  var webcrypto = function(key, props) {\n    try {\n      props = prepareProps(props);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var keyLen = props.length,\n        salt = props.salt,\n        itrs = props.iterations;\n\n    var promise = Promise.resolve(key);\n    promise = promise.then(function(keyval) {\n      return helpers.subtleCrypto.importKey(\"raw\", keyval, \"PBKDF2\", false, [\"deriveBits\"]);\n    });\n    promise = promise.then(function(key) {\n      var mainAlgo = {\n        name: \"PBKDF2\",\n        salt: new Uint8Array(salt),\n        iterations: itrs,\n        hash: hash\n      };\n\n      return helpers.subtleCrypto.deriveBits(mainAlgo, key, keyLen * 8);\n    });\n    promise = promise.then(function(result) {\n      return util.asBuffer(result);\n    });\n    return promise;\n  };\n  var nodejs = function(key, props) {\n    if (6 > helpers.nodeCrypto.pbkdf2.length) {\n      throw new Error(\"unsupported algorithm: PBKDF2-\" + hash);\n    }\n\n    try {\n      props = prepareProps(props);\n    } catch (err) {\n      return Promise.reject(err);\n    }\n\n    var keyLen = props.length,\n        salt = props.salt,\n        itrs = props.iterations;\n\n        var md = hash.replace(\"-\", \"\");\n    var promise = new Promise(function(resolve, reject) {\n      function cb(err, dk) {\n        if (err) {\n          reject(err);\n        } else {\n          resolve(dk);\n        }\n      }\n      helpers.nodeCrypto.pbkdf2(key, salt, itrs, keyLen, md, cb);\n    });\n    return promise;\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction pbes2EncryptFN(hmac, kw) {\n  var deriveAlg = \"PBKDF2-\" + hmac.replace(\"HS\", \"SHA-\");\n  var keyLen = CONSTANTS.KEYLENGTH[kw] / 8;\n\n  return function(key, pdata, props) {\n    props = props || {};\n\n    var salt = util.asBuffer(props.p2s || Buffer.alloc(0), \"base64url\"),\n      itrs = props.p2c || DEFAULT_ITERATIONS;\n\n    if (0 >= itrs) {\n      throw new Error(\"invalid iteration count\");\n    }\n    if (0 === salt.length) {\n      salt = util.randomBytes(DEFAULT_SALT_LENGTH);\n    } else if (8 > salt.length) {\n      throw new Error(\"salt too small\");\n    }\n    var header = {\n      p2s: util.base64url.encode(salt),\n      p2c: itrs\n    };\n    salt = fixSalt(hmac, kw, salt);\n    props = merge(props, {\n      salt: salt,\n      iterations: itrs,\n      length: keyLen\n    });\n\n    var promise = Promise.resolve(key);\n    // STEP 1: derive shared key\n    promise = promise.then(function (key) {\n      return pbes2[deriveAlg].derive(key, props);\n    });\n    // STEP 2: encrypt cek\n    promise = promise.then(function (dk) {\n      return KW[kw].encrypt(dk, pdata);\n    });\n    // STEP 3: (re-)apply headers\n    promise = promise.then(function (results) {\n      results.header = merge(results.header || {}, header);\n      return results;\n    });\n\n    return promise;\n  };\n}\n\nfunction pbes2DecryptFN(hmac, kw) {\n  var deriveAlg = \"PBKDF2-\" + hmac.replace(\"HS\", \"SHA-\");\n  var keyLen = CONSTANTS.KEYLENGTH[kw] / 8;\n\n  return function(key, cdata, props) {\n    props = props || {};\n\n    var salt = util.asBuffer(props.p2s || Buffer.alloc(0), \"base64url\"),\n        itrs = props.p2c || 0;\n\n    if (0 >= itrs) {\n      return Promise.reject(new Error(\"invalid iteration count\"));\n    }\n\n    if (8 > salt.length) {\n      return Promise.reject(new Error(\"salt too small\"));\n    }\n    salt = fixSalt(hmac, kw, salt);\n    props = merge(props, {\n      salt: salt,\n      iterations: itrs,\n      length: keyLen\n    });\n\n    var promise = Promise.resolve(key);\n\n    // STEP 1: derived shared key\n    promise = promise.then(function(key) {\n      return pbes2[deriveAlg].derive(key, props);\n    });\n    // STEP 2: decrypt cek\n    promise = promise.then(function(dk) {\n      return KW[kw].decrypt(dk, cdata);\n    });\n\n    return promise;\n  };\n}\n\n// ### Public API\nvar pbes2 = {};\n\n// * [name].derive\n[\n  \"PBKDF2-SHA-256\",\n  \"PBKDF2-SHA-384\",\n  \"PBKDF2-SHA-512\"\n].forEach(function(alg) {\n  var hash = alg.replace(\"PBKDF2-\", \"\");\n  pbes2[alg] = {\n    derive: pbkdf2Fn(hash)\n  };\n});\n\n// [name].encrypt\n// [name].decrypt\n[\n  \"PBES2-HS256+A128KW\",\n  \"PBES2-HS384+A192KW\",\n  \"PBES2-HS512+A256KW\"\n].forEach(function(alg) {\n  var parts = /PBES2-(HS\\d+)\\+(A\\d+KW)/g.exec(alg);\n  var hmac = parts[1],\n      kw = parts[2];\n  pbes2[alg] = {\n    encrypt: pbes2EncryptFN(hmac, kw),\n    decrypt: pbes2DecryptFN(hmac, kw)\n  };\n});\n\nmodule.exports = pbes2;\n","/*!\n * algorithms/rsa-util.js - RSA Utility Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar clone = require(\"lodash/clone\"),\n    forge = require(\"../deps/forge.js\"),\n    util = require(\"../util\");\n\n// ### RSA-specific Helpers\nfunction convertToForge(key, isPublic) {\n  var parts = isPublic ?\n              [\"n\", \"e\"] :\n              [\"n\", \"e\", \"d\", \"p\", \"q\", \"dp\", \"dq\", \"qi\"];\n  parts = parts.map(function(f) {\n    return new forge.jsbn.BigInteger(key[f].toString(\"hex\"), 16);\n  });\n\n  var fn = isPublic ?\n           forge.pki.rsa.setPublicKey :\n           forge.pki.rsa.setPrivateKey;\n  return fn.apply(forge.pki.rsa, parts);\n}\n\nfunction convertToJWK(key, isPublic) {\n  var result = clone(key);\n  var parts = isPublic ?\n              [\"n\", \"e\"] :\n              [\"n\", \"e\", \"d\", \"p\", \"q\", \"dp\", \"dq\", \"qi\"];\n  parts.forEach(function(f) {\n    result[f] = util.base64url.encode(result[f]);\n  });\n\n  // remove potentially troublesome properties\n  delete result.key_ops;\n  delete result.use;\n  delete result.alg;\n\n  if (isPublic) {\n    delete result.d;\n    delete result.p;\n    delete result.q;\n    delete result.dp;\n    delete result.dq;\n    delete result.qi;\n  }\n\n  return result;\n}\n\nfunction convertToPem(key, isPublic) {\n  var cacheKey = isPublic ? \"__cachedPublicPem\" : \"__cachedPrivatePem\";\n  if (key[cacheKey]) {\n    return key[cacheKey];\n  }\n\n  var value;\n  if (isPublic) {\n    value = forge.pki.publicKeyToPem(convertToForge(key, isPublic));\n  } else {\n    value = forge.pki.privateKeyToPem(convertToForge(key, isPublic));\n  }\n\n  Object.defineProperty(key, cacheKey, { value: value });\n  return value;\n}\n\nmodule.exports = {\n  convertToForge: convertToForge,\n  convertToJWK: convertToJWK,\n  convertToPem: convertToPem\n};\n","/*!\n * algorithms/rsaes.js - RSA Signatures\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    helpers = require(\"./helpers.js\"),\n    DataBuffer = require(\"../util/databuffer.js\"),\n    rsaUtil = require(\"./rsa-util.js\");\n\nvar nodeSupport = {\n  \"RSA-OAEP\": \"RSA_PKCS1_OAEP_PADDING\",\n  RSA1_5: \"RSA_PKCS1_PADDING\"\n};\n\nfunction nodeSupportCheck(name) {\n  return helpers.nodeCrypto && helpers.nodeCrypto.constants && Object.keys(nodeSupport).indexOf(name) !== -1;\n}\n\n// ### RSAES-PKCS1-v1_5\n\n// ### RSAES-OAEP\nfunction rsaesEncryptFn(name) {\n  var alg = {\n    name: name\n  };\n\n  if (\"RSA-OAEP-256\" === name) {\n    alg.name = \"RSA-OAEP\";\n    alg.hash = {\n      name: \"SHA-256\"\n    };\n  } else if (\"RSA-OAEP\" === name) {\n    alg.hash = {\n      name: \"SHA-1\"\n    };\n  } else {\n    alg.name = \"RSAES-PKCS1-v1_5\";\n  }\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(key, pdata) {\n    // convert pdata to byte string\n    pdata = new DataBuffer(pdata).bytes();\n\n    // encrypt it\n    var pki = rsaUtil.convertToForge(key, true),\n        params = {};\n    if (\"RSA-OAEP\" === alg.name) {\n      params.md = alg.hash.name.toLowerCase().replace(/-/g, \"\");\n      params.md = forge.md[params.md].create();\n    }\n    var cdata = pki.encrypt(pdata, alg.name.toUpperCase(), params);\n\n    // convert cdata to Buffer\n    cdata = new DataBuffer(cdata).native();\n\n    return Promise.resolve({\n      data: cdata\n    });\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto;\n  if (\"RSAES-PKCS1-v1_5\" !== alg.name) {\n    webcrypto = function(key, pdata) {\n      key = rsaUtil.convertToJWK(key, true);\n      var promise;\n      promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"encrypt\"]);\n      promise = promise.then(function(key) {\n        return helpers.subtleCrypto.encrypt(alg, key, pdata);\n      });\n      promise = promise.then(function(result) {\n        var cdata = Buffer.from(result);\n        return {\n          data: cdata\n        };\n      });\n\n      return promise;\n    };\n  } else {\n    webcrypto = null;\n  }\n\n  var nodejs;\n  if (nodeSupportCheck(name)) {\n    nodejs = function (key, pdata) {\n      key = rsaUtil.convertToPem(key, true);\n\n      var cdata = helpers.nodeCrypto.publicEncrypt({\n        key: key,\n        padding: helpers.nodeCrypto.constants[nodeSupport[name]]\n      }, pdata);\n\n      return {\n        data: cdata\n      };\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction rsaesDecryptFn(name) {\n  var alg = {\n    name: name\n  };\n\n  if (\"RSA-OAEP-256\" === name) {\n    alg.name = \"RSA-OAEP\";\n    alg.hash = {\n      name: \"SHA-256\"\n    };\n  } else if (\"RSA-OAEP\" === name) {\n    alg.hash = {\n      name: \"SHA-1\"\n    };\n  } else {\n    alg.name = \"RSAES-PKCS1-v1_5\";\n  }\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(key, cdata) {\n    // convert cdata to byte string\n    cdata = new DataBuffer(cdata).bytes();\n\n    // decrypt it\n    var pki = rsaUtil.convertToForge(key, false),\n        params = {};\n    if (\"RSA-OAEP\" === alg.name) {\n      params.md = alg.hash.name.toLowerCase().replace(/-/g, \"\");\n      params.md = forge.md[params.md].create();\n    }\n    var pdata = pki.decrypt(cdata, alg.name.toUpperCase(), params);\n\n    // convert pdata to Buffer\n    pdata = new DataBuffer(pdata).native();\n\n    return Promise.resolve(pdata);\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto;\n  if (\"RSAES-PKCS1-v1_5\" !== alg.name) {\n    webcrypto = function(key, pdata) {\n      key = rsaUtil.convertToJWK(key, false);\n      var promise;\n      promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"decrypt\"]);\n      promise = promise.then(function(key) {\n        return helpers.subtleCrypto.decrypt(alg, key, pdata);\n      });\n      promise = promise.then(function(result) {\n        var pdata = Buffer.from(result);\n        return pdata;\n      });\n\n      return promise;\n    };\n  } else {\n    webcrypto = null;\n  }\n\n  var nodejs;\n  if (nodeSupportCheck(name)) { // node ^6.12.0 || >= 8.0.0\n    nodejs = function(key, pdata) {\n      key = rsaUtil.convertToPem(key, false);\n      return helpers.nodeCrypto.privateDecrypt({\n        key: key,\n        padding: helpers.nodeCrypto.constants[nodeSupport[name]]\n      }, pdata);\n    };\n  } else if (helpers.nodeCrypto && name === \"RSA-OAEP\") { // node (>= 6.0.0 && < 6.12.0) || ^7.0.0\n    nodejs = function(key, pdata) {\n      key = rsaUtil.convertToPem(key, false);\n      return helpers.nodeCrypto.privateDecrypt(key, pdata);\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### Public API\n// * [name].encrypt\n// * [name].decrypt\nvar rsaes = {};\n[\n  \"RSA-OAEP\",\n  \"RSA-OAEP-256\",\n  \"RSA1_5\"\n].forEach(function(name) {\n  rsaes[name] = {\n    encrypt: rsaesEncryptFn(name),\n    decrypt: rsaesDecryptFn(name)\n  };\n});\n\nmodule.exports = rsaes;\n","/*!\n * algorithms/rsassa.js - RSA Signatures\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    CONSTANTS = require(\"./constants\"),\n    helpers = require(\"./helpers.js\"),\n    rsaUtil = require(\"./rsa-util.js\");\n\nfunction nodePSSsupport() {\n  return helpers.nodeCrypto && helpers.nodeCrypto.constants && helpers.nodeCrypto.constants.RSA_PSS_SALTLEN_DIGEST;\n}\n\n// ### RSASSA-PKCS1-v1_5\n\nfunction rsassaV15SignFn(name) {\n  var md = name.replace(\"RS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"RS\", \"SHA-\");\n\n  var alg = {\n    name: \"RSASSA-PKCS1-V1_5\",\n    hash: {\n      name: hash\n    }\n  };\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(key, pdata) {\n    // create the digest\n    var digest = forge.md[md].create();\n    digest.start();\n    digest.update(pdata);\n\n    // sign it\n    var pki = rsaUtil.convertToForge(key, false);\n    var sig = pki.sign(digest, \"RSASSA-PKCS1-V1_5\");\n    sig = Buffer.from(sig, \"binary\");\n\n    return Promise.resolve({\n      data: pdata,\n      mac: sig\n    });\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(key, pdata) {\n    key = rsaUtil.convertToJWK(key, false);\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"sign\"]);\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.sign(alg, key, pdata);\n    });\n    promise = promise.then(function(result) {\n      var sig = Buffer.from(result);\n      return {\n        data: pdata,\n        mac: sig\n      };\n    });\n\n    return promise;\n  };\n\n  var nodejs;\n  var nodeHash = \"RSA-\" + hash.replace(\"-\", \"\");\n  if (helpers.nodeCrypto && helpers.nodeCrypto.getHashes().indexOf(nodeHash) > -1) {\n    nodejs = function(key, pdata) {\n      var sign = helpers.nodeCrypto.createSign(nodeHash);\n      sign.update(pdata);\n\n      return {\n        data: pdata,\n        mac: sign.sign(rsaUtil.convertToPem(key, false))\n      };\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction rsassaV15VerifyFn(name) {\n  var md = name.replace(\"RS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"RS\", \"SHA-\");\n  var alg = {\n    name: \"RSASSA-PKCS1-V1_5\",\n    hash: {\n      name: hash\n    }\n  };\n\n  // ### Fallback implementation -- uses forge\n  var fallback = function(key, pdata, mac) {\n    // create the digest\n    var digest = forge.md[md].create();\n    digest.start();\n    digest.update(pdata);\n    digest = digest.digest().bytes();\n\n    // verify it\n    var pki = rsaUtil.convertToForge(key, true);\n    var sig = mac.toString(\"binary\");\n    var result = pki.verify(digest, sig, \"RSASSA-PKCS1-V1_5\");\n    if (!result) {\n      return Promise.reject(new Error(\"verification failed\"));\n    }\n    return Promise.resolve({\n      data: pdata,\n      mac: mac,\n      valid: true\n    });\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(key, pdata, mac) {\n    key = rsaUtil.convertToJWK(key, true);\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"verify\"]);\n    promise = promise.then(function(key) {\n      return helpers.subtleCrypto.verify(alg, key, mac, pdata);\n    });\n    promise = promise.then(function(result) {\n      if (!result) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    });\n\n    return promise;\n  };\n\n  var nodejs;\n  if (helpers.nodeCrypto && helpers.nodeCrypto.getHashes().indexOf(md) > -1) {\n    nodejs = function(key, pdata, mac) {\n      var verify = helpers.nodeCrypto.createVerify(md);\n      verify.update(pdata);\n      verify.end();\n      var result = verify.verify(rsaUtil.convertToPem(key, true), mac);\n      if (!result) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### RSA-PSS\nfunction rsassaPssSignFn(name) {\n  var md = name.replace(\"PS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"PS\", \"SHA-\");\n\n  var alg = {\n    name: \"RSA-PSS\",\n    hash: {\n      name: hash\n    },\n    saltLength: CONSTANTS.HASHLENGTH[hash] / 8\n  };\n\n  // ### Fallback implementation -- uses forge\n  var fallback = function (key, pdata) {\n    // create the digest\n    var digest = forge.md[md].create();\n    digest.start();\n    digest.update(pdata);\n\n    // setup padding\n    var pss = forge.pss.create({\n      md: forge.md[md].create(),\n      mgf: forge.mgf.mgf1.create(forge.md[md].create()),\n      saltLength: CONSTANTS.HASHLENGTH[hash] / 8\n    });\n\n    // sign it\n    var pki = rsaUtil.convertToForge(key, false);\n    var sig = pki.sign(digest, pss);\n    sig = Buffer.from(sig, \"binary\");\n\n    return Promise.resolve({\n      data: pdata,\n      mac: sig\n    });\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(key, pdata) {\n    key = rsaUtil.convertToJWK(key, false);\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"sign\"]);\n    promise = promise.then(function (key) {\n      return helpers.subtleCrypto.sign(alg, key, pdata);\n    });\n    promise = promise.then(function (result) {\n      var sig = Buffer.from(result);\n      return {\n        data: pdata,\n        mac: sig\n      };\n    });\n\n    return promise;\n  };\n\n  var nodejs;\n  var nodeHash = \"RSA-\" + hash.replace(\"-\", \"\");\n  if (nodePSSsupport()) {\n    nodejs = function(key, pdata) {\n      var sign = helpers.nodeCrypto.createSign(nodeHash);\n      sign.update(pdata);\n\n      var sig = sign.sign({\n        key: rsaUtil.convertToPem(key, false),\n        padding: helpers.nodeCrypto.constants.RSA_PKCS1_PSS_PADDING,\n        saltLength: helpers.nodeCrypto.constants.RSA_PSS_SALTLEN_DIGEST\n      });\n\n      return {\n        data: pdata,\n        mac: sig\n      };\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\nfunction rsassaPssVerifyFn(name) {\n  var md = name.replace(\"PS\", \"SHA\").toLowerCase(),\n      hash = name.replace(\"PS\", \"SHA-\");\n\n  var alg = {\n    name: \"RSA-PSS\",\n    hash: {\n      name: hash\n    },\n    saltLength: CONSTANTS.HASHLENGTH[hash] / 8\n  };\n\n  // ### Fallback implementation -- uses forge\n  var fallback = function (key, pdata, mac) {\n    // create the digest\n    var digest = forge.md[md].create();\n    digest.start();\n    digest.update(pdata);\n    digest = digest.digest().bytes();\n\n    // setup padding\n    var pss = forge.pss.create({\n      md: forge.md[md].create(),\n      mgf: forge.mgf.mgf1.create(forge.md[md].create()),\n      saltLength: CONSTANTS.HASHLENGTH[hash] / 8\n    });\n\n    // verify it\n    var pki = rsaUtil.convertToForge(key, true);\n    var sig = mac.toString(\"binary\");\n    var result = pki.verify(digest, sig, pss);\n    if (!result) {\n      return Promise.reject(new Error(\"verification failed\"));\n    }\n    return Promise.resolve({\n      data: pdata,\n      mac: mac,\n      valid: true\n    });\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(key, pdata, mac) {\n    key = rsaUtil.convertToJWK(key, true);\n    var promise;\n    promise = helpers.subtleCrypto.importKey(\"jwk\", key, alg, true, [\"verify\"]);\n    promise = promise.then(function (key) {\n      return helpers.subtleCrypto.verify(alg, key, mac, pdata);\n    });\n    promise = promise.then(function (result) {\n      if (!result) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    });\n\n    return promise;\n  };\n\n  var nodejs;\n  if (nodePSSsupport()) {\n    nodejs = function(key, pdata, mac) {\n      var verify = helpers.nodeCrypto.createVerify(md);\n      verify.update(pdata);\n      verify.end();\n      var result = verify.verify({\n        key: rsaUtil.convertToPem(key, true),\n        padding: helpers.nodeCrypto.constants.RSA_PKCS1_PSS_PADDING,\n        saltLength: helpers.nodeCrypto.constants.RSA_PSS_SALTLEN_DIGEST\n      }, mac);\n      if (!result) {\n        return Promise.reject(new Error(\"verification failed\"));\n      }\n\n      return {\n        data: pdata,\n        mac: mac,\n        valid: true\n      };\n    };\n  }\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// ### Public API\n// * [name].sign\n// * [name].verify\nvar rsassa = {};\n[\n  \"PS256\",\n  \"PS384\",\n  \"PS512\"\n].forEach(function(name) {\n  rsassa[name] = {\n    sign: rsassaPssSignFn(name),\n    verify: rsassaPssVerifyFn(name)\n  };\n});\n\n[\n  \"RS256\",\n  \"RS384\",\n  \"RS512\"\n].forEach(function(name) {\n  rsassa[name] = {\n    sign: rsassaV15SignFn(name),\n    verify: rsassaV15VerifyFn(name)\n  };\n});\n\nmodule.exports = rsassa;\n","/*!\n * algorithms/sha.js - Cryptographic Secure Hash Algorithms, versions 1 and 2\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    helpers = require(\"./helpers.js\");\n\nfunction hashDigestFN(hash) {\n  var md = hash.replace(\"SHA-\", \"SHA\").toLowerCase();\n\n  var alg = {\n    name: hash\n  };\n\n  // ### Fallback Implementation -- uses forge\n  var fallback = function(pdata /* props */) {\n    var digest = forge.md[md].create();\n    digest.update(pdata.toString(\"binary\"));\n    digest = Buffer.from(digest.digest().bytes(), \"binary\");\n\n    return Promise.resolve(digest);\n  };\n\n  // ### WebCryptoAPI Implementation\n  var webcrypto = function(pdata /* props */) {\n    var promise;\n    promise = helpers.subtleCrypto.digest(alg, pdata);\n    promise = promise.then(function(result) {\n      result = Buffer.from(result);\n      return result;\n    });\n    return promise;\n  };\n\n  // ### nodejs Implementation\n  var nodejs = function(pdata /* props */) {\n    var digest = helpers.nodeCrypto.createHash(md);\n    digest.update(pdata);\n    return digest.digest();\n  };\n\n  return helpers.setupFallback(nodejs, webcrypto, fallback);\n}\n\n// Public API\n// * [name].digest\nvar sha = {};\n[\n  \"SHA-1\",\n  \"SHA-256\",\n  \"SHA-384\",\n  \"SHA-512\"\n].forEach(function(name) {\n  sha[name] = {\n    digest: hashDigestFN(name)\n  };\n});\n\nmodule.exports = sha;\n","/*!\n * deps/ciphermodes/gcm/helpers.js - AES-GCM Helper Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar Long = require(\"long\"),\n    fill = require(\"lodash/fill\"),\n    pack = require(\"../pack.js\");\n\nvar E1 = 0xe1000000,\n    E1B = 0xe1,\n    E1L = new Long(E1 >> 8);\n\nfunction generateLookup() {\n  var lookup = [];\n\n  for (var c = 0; c < 256; ++c) {\n    var v = 0;\n    for (var i = 7; i >= 0; --i) {\n      if ((c & (1 << i)) !== 0) {\n        v ^= (E1 >>> (7 - i));\n      }\n    }\n    lookup.push(v);\n  }\n\n  return lookup;\n}\n\nvar helpers = module.exports = {\n  // ### Constants\n  E1: E1,\n  E1B: E1B,\n  E1L: E1L,\n  LOOKUP: generateLookup(),\n\n  // ### Array Helpers\n  arrayCopy: function(src, srcPos, dest, destPos, length) {\n    // Start by checking for negatives since arrays in JS auto-expand\n    if (srcPos < 0 || destPos < 0 || length < 0) {\n      throw new TypeError(\"Invalid input.\");\n    }\n\n    if (dest instanceof Uint8Array) {\n      // Check for overflow if dest is a typed-array\n      if (destPos >= dest.length || (destPos + length) > dest.length) {\n        throw new TypeError(\"Invalid input.\");\n      }\n\n      if (srcPos !== 0 || length < src.length) {\n        if (src instanceof Uint8Array) {\n          src = src.subarray(srcPos, srcPos + length);\n        } else {\n          src = src.slice(srcPos, srcPos + length);\n        }\n      }\n\n      dest.set(src, destPos);\n    } else {\n      for (var i = 0; i < length; ++i) {\n        dest[destPos + i] = src[srcPos + i];\n      }\n    }\n  },\n  arrayEqual: function(a1, a2) {\n    a1 = a1 || [];\n    a2 = a2 || [];\n\n    var len = Math.min(a1.length, a2.length),\n        result = (a1.length === a2.length);\n\n    for (var idx = 0; idx < len; idx++) {\n      result = result &&\n               (\"undefined\" !== typeof a1[idx]) &&\n               (\"undefined\" !== typeof a2[idx]) &&\n               (a1[idx] === a2[idx]);\n    }\n\n    return result;\n  },\n\n  // ### Conversions\n  asBytes: function(x, z) {\n    switch (arguments.length) {\n      case 1:\n        z = Buffer.alloc(16);\n        pack.intToBigEndian(x, z, 0);\n        return z;\n      case 2:\n        pack.intToBigEndian(x, z, 0);\n        break;\n      default:\n        throw new TypeError(\"Expected 1 or 2 arguments.\");\n    }\n  },\n  asInts: function(x, z) {\n    switch (arguments.length) {\n      case 1:\n        z = [];\n        fill(z, 0, 0, 4);\n        pack.bigEndianToInt(x, 0, z);\n        return z;\n      case 2:\n        pack.bigEndianToInt(x, 0, z);\n        break;\n      default:\n        throw new TypeError(\"Expected 1 or 2 arguments.\");\n    }\n  },\n  oneAsInts: function() {\n    var tmp = [];\n    for (var c = 0; c < 4; ++c) {\n        tmp.push(1 << 31);\n    }\n    return tmp;\n  },\n\n  // ## Bit-wise\n  shiftRight: function(x, z) {\n    var b, c;\n    switch (arguments.length) {\n      case 1:\n        b = x[0];\n        x[0] = b >>> 1;\n        c = b << 31;\n        b = x[1];\n        x[1] = (b >>> 1) | c;\n        c = b << 31;\n        b = x[2];\n        x[2] = (b >>> 1) | c;\n        c = b << 31;\n        b = x[3];\n        x[3] = (b >>> 1) | c;\n        return (b << 31) & 0xffffffff;\n      case 2:\n        b = x[0];\n        z[0] = b >>> 1;\n        c = b << 31;\n        b = x[1];\n        z[1] = (b >>> 1) | c;\n        c = b << 31;\n        b = x[2];\n        z[2] = (b >>> 1) | c;\n        c = b << 31;\n        b = x[3];\n        z[3] = (b >>> 1) | c;\n        return (b << 31) & 0xffffffff;\n      default:\n        throw new TypeError(\"Expected 1 or 2 arguments.\");\n    }\n  },\n  shiftRightN: function(x, n, z) {\n    var nInv, b, c;\n    switch (arguments.length) {\n      case 2:\n        b = x[0];\n        nInv = 32 - n;\n        x[0] = b >>> n;\n        c = b << nInv;\n        b = x[1];\n        x[1] = (b >>> n) | c;\n        c = b << nInv;\n        b = x[2];\n        x[2] = (b >>> n) | c;\n        c = b << nInv;\n        b = x[3];\n        x[3] = (b >>> n) | c;\n        return b << nInv;\n      case 3:\n        b = x[0];\n        nInv = 32 - n;\n        z[0] = b >>> n;\n        c = b << nInv;\n        b = x[1];\n        z[1] = (b >>> n) | c;\n        c = b << nInv;\n        b = x[2];\n        z[2] = (b >>> n) | c;\n        c = b << nInv;\n        b = x[3];\n        z[3] = (b >>> n) | c;\n        return b << nInv;\n      default:\n        throw new TypeError(\"Expected 2 or 3 arguments.\");\n    }\n  },\n  xor: function(x, y, z) {\n    switch (arguments.length) {\n      case 2:\n        x[0] ^= y[0];\n        x[1] ^= y[1];\n        x[2] ^= y[2];\n        x[3] ^= y[3];\n        break;\n      case 3:\n        z[0] = x[0] ^ y[0];\n        z[1] = x[1] ^ y[1];\n        z[2] = x[2] ^ y[2];\n        z[3] = x[3] ^ y[3];\n        break;\n      default:\n        throw new TypeError(\"Expected 2 or 3 arguments.\");\n    }\n  },\n\n  multiply: function(x, y) {\n    var r0 = x.slice();\n    var r1 = [];\n\n    for (var i = 0; i < 4; ++i) {\n      var bits = y[i];\n      for (var j = 31; j >= 0; --j) {\n        if ((bits & (1 << j)) !== 0) {\n          helpers.xor(r1, r0);\n        }\n\n        if (helpers.shiftRight(r0) !== 0) {\n          r0[0] ^= helpers.E1;\n        }\n      }\n    }\n\n    helpers.arrayCopy(r1, 0, x, 0, 4);\n  },\n  multiplyP: function(x, y) {\n    switch (arguments.length) {\n      case 1:\n        if (helpers.shiftRight(x) !== 0) {\n          x[0] ^= helpers.E1;\n        }\n        break;\n      case 2:\n        if (helpers.shiftRight(x, y) !== 0) {\n          y[0] ^= helpers.E1;\n        }\n        break;\n      default:\n        throw new TypeError(\"Expected 1 or 2 arguments.\");\n    }\n  },\n  multiplyP8: function(x, y) {\n    var c;\n    switch (arguments.length) {\n      case 1:\n        c = helpers.shiftRightN(x, 8);\n        x[0] ^= helpers.LOOKUP[c >>> 24];\n        break;\n      case 2:\n        c = helpers.shiftRightN(x, 8, y);\n        y[0] ^= helpers.LOOKUP[c >>> 24];\n        break;\n      default:\n        throw new TypeError(\"Expected 1 or 2 arguments.\");\n    }\n  }\n};\n","/*!\n * deps/ciphermodes/gcm/index.js - AES-GCM implementation Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n \"use strict\";\n\nvar Long = require(\"long\"),\n    forge = require(\"../../../deps/forge.js\"),\n    multipliers = require(\"./multipliers.js\"),\n    helpers = require(\"./helpers.js\"),\n    pack = require(\"../pack.js\"),\n    DataBuffer = require(\"../../../util/databuffer.js\"),\n    cipherHelpers = require(\"../helpers.js\");\n\nvar BLOCK_SIZE = 16;\n\n// ### GCM Mode\n// ### Constructor\nfunction Gcm(options) {\n  options = options || {};\n\n  this.name = \"GCM\";\n  this.cipher = options.cipher;\n  this.blockSize = this.blockSize || 16;\n}\n\n// ### exports\nmodule.exports = {\n  createCipher: function(options) {\n    var alg = new forge.aes.Algorithm(\"AES-GCM\", Gcm);\n    alg.initialize({\n      key: new DataBuffer(options.key)\n    });\n    alg.mode.start(options);\n\n    return alg.mode;\n  },\n  createDecipher: function(options) {\n    var alg = new forge.aes.Algorithm(\"AES-GCM\", Gcm);\n    alg.initialize({\n      key: new DataBuffer(options.key)\n    });\n    alg.mode._decrypt = true;\n    alg.mode.start(options);\n\n    return alg.mode;\n  }\n};\n\n// ### Public API\nGcm.prototype.start = function(options) {\n  this.tag = null;\n\n  options = options || {};\n\n  if (!(\"iv\" in options)) {\n    throw new Error(\"Gcm needs ParametersWithIV or AEADParameters\");\n  }\n  this.nonce = options.iv;\n  if (this.nonce == null || this.nonce.length < 1) {\n    throw new Error(\"IV must be at least 1 byte\");\n  }\n\n  // TODO: variable tagLength?\n  this.tagLength = 16;\n\n  // TODO: validate tag\n  if (\"tag\" in options) {\n    this.tag = Buffer.from(options.tag);\n  }\n\n  var bufLength = !this._decrypt ?\n                  this.blockSize :\n                  (this.blockSize + this.tagLength);\n  this.bufBlock = Buffer.alloc(bufLength);\n\n  var multiplier = options.multiplier;\n  if (multiplier == null) {\n    multiplier = new (multipliers[\"8k\"])();\n  }\n  this.multiplier = multiplier;\n\n  this.H = this.zeroBlock();\n  cipherHelpers.encrypt(this.cipher, this.H, 0, this.H, 0);\n\n  // GcmMultiplier tables don\"t change unless the key changes\n  // (and are expensive to init)\n  this.multiplier.init(this.H);\n  this.exp = null;\n\n  this.J0 = this.zeroBlock();\n\n  if (this.nonce.length === 12) {\n    this.nonce.copy(this.J0, 0, 0, this.nonce.length);\n    this.J0[this.blockSize - 1] = 0x01;\n  } else {\n    this.gHASH(this.J0, this.nonce, this.nonce.length);\n    var X = this.zeroBlock();\n    pack.longToBigEndian(new Long(this.nonce.length).\n                         multiply(8), X, 8);\n    this.gHASHBlock(this.J0, X);\n  }\n\n  this.S = this.zeroBlock();\n  this.SAt = this.zeroBlock();\n  this.SAtPre = this.zeroBlock();\n  this.atBlock = this.zeroBlock();\n  this.atBlockPos = 0;\n  this.atLength = Long.ZERO;\n  this.atLengthPre = Long.ZERO;\n  this.counter = Buffer.from(this.J0);\n  this.bufOff = 0;\n  this.totalLength = Long.ZERO;\n\n  if (\"additionalData\" in options) {\n    this.processAADBytes(options.additionalData, 0, options.additionalData.length);\n  }\n};\n\nGcm.prototype.update = function(inV, inOff, len, out, outOff) {\n  var resultLen = 0;\n\n  while (len > 0) {\n    var inLen = Math.min(len, this.bufBlock.length - this.bufOff);\n    inV.copy(this.bufBlock, this.bufOff, inOff, inOff + inLen);\n    len -= inLen;\n    inOff += inLen;\n    this.bufOff += inLen;\n    if (this.bufOff === this.bufBlock.length) {\n      this.outputBlock(out, outOff + resultLen);\n      resultLen += this.blockSize;\n    }\n  }\n\n  return resultLen;\n};\nGcm.prototype.finish = function(out, outOff) {\n  var resultLen = 0;\n\n  if (this._decrypt) {\n    // append tag\n    resultLen += this.update(this.tag, 0, this.tag.length, out, outOff);\n  }\n\n  if (this.totalLength.isZero()) {\n    this.initCipher();\n  }\n\n  var extra = this.bufOff;\n  if (this._decrypt) {\n    if (extra < this.tagLength) {\n      throw new Error(\"data too short\");\n    }\n    extra -= this.tagLength;\n  }\n\n  if (extra > 0) {\n    this.gCTRPartial(this.bufBlock, 0, extra, out, outOff + resultLen);\n    resultLen += extra;\n  }\n\n  this.atLength = this.atLength.add(this.atBlockPos);\n\n  // Final gHASH\n  var X = this.zeroBlock();\n  pack.longToBigEndian(this.atLength.multiply(8),\n                       X,\n                       0);\n  pack.longToBigEndian(this.totalLength.multiply(8),\n                       X,\n                       8);\n\n  this.gHASHBlock(this.S, X);\n\n  // TODO Fix this if tagLength becomes configurable\n  // T = MSBt(GCTRk(J0,S))\n  var tag = Buffer.alloc(this.blockSize);\n  cipherHelpers.encrypt(this.cipher, this.J0, 0, tag, 0);\n  this.xor(tag, this.S);\n\n  if (this._decrypt) {\n    if (!helpers.arrayEqual(this.tag, tag)) {\n      throw new Error(\"mac check in Gcm failed\");\n    }\n  } else {\n    // We place into tag our calculated value for T\n    this.tag = Buffer.alloc(this.tagLength);\n    tag.copy(this.tag, 0, 0, this.tagLength);\n  }\n\n  return resultLen;\n};\n\n// ### \"Internal\" Helper Functions\nGcm.prototype.initCipher = function() {\n  if (this.atLength.greaterThan(Long.ZERO)) {\n    this.SAt.copy(this.SAtPre, 0, 0, this.blockSize);\n    this.atLengthPre = this.atLength.add(Long.ZERO);\n  }\n\n  // Finish hash for partial AAD block\n  if (this.atBlockPos > 0) {\n    this.gHASHPartial(this.SAtPre, this.atBlock, 0, this.atBlockPos);\n    this.atLengthPre = this.atLengthPre.add(this.atBlockPos);\n  }\n\n  if (this.atLengthPre.greaterThan(Long.ZERO)) {\n    this.SAtPre.copy(this.S, 0, 0, this.blockSize);\n  }\n};\n\nGcm.prototype.outputBlock = function(output, offset) {\n  if (this.totalLength.isZero()) {\n    this.initCipher();\n  }\n  this.gCTRBlock(this.bufBlock, output, offset);\n  if (!this._decrypt) {\n    this.bufOff = 0;\n  } else {\n    this.bufBlock.copy(this.bufBlock, 0, this.blockSize, this.blockSize + this.tagLength);\n    this.bufOff = this.tagLength;\n  }\n};\n\nGcm.prototype.processAADBytes = function(inV, inOff, len) {\n  for (var i = 0; i < len; ++i) {\n    this.atBlock[this.atBlockPos] = inV[inOff + i];\n    if (++this.atBlockPos === this.blockSize) {\n      // Hash each block as it fills\n      this.gHASHBlock(this.SAt, this.atBlock);\n      this.atBlockPos = 0;\n      this.atLength = this.atLength.add(this.blockSize);\n    }\n  }\n};\n\nGcm.prototype.getNextCounterBlock = function() {\n  for (var i = 15; i >= 12; --i) {\n    var b = ((this.counter[i] + 1) & 0xff);\n    this.counter[i] = b;\n\n    if (b !== 0) {\n      break;\n    }\n  }\n\n  // encrypt counter\n  var outb = Buffer.alloc(this.blockSize);\n  cipherHelpers.encrypt(this.cipher, this.counter, 0, outb, 0);\n\n  return outb;\n};\n\nGcm.prototype.gCTRBlock = function(block, out, outOff) {\n  var tmp = this.getNextCounterBlock();\n\n  this.xor(tmp, block);\n  tmp.copy(out, outOff, 0, this.blockSize);\n\n  this.gHASHBlock(this.S, !this._decrypt ? tmp : block);\n\n  this.totalLength = this.totalLength.add(this.blockSize);\n};\nGcm.prototype.gCTRPartial = function(buf, off, len, out, outOff) {\n  var tmp = this.getNextCounterBlock();\n\n  this.xor(tmp, buf, off, len);\n  tmp.copy(out, outOff, 0, len);\n\n  this.gHASHPartial(this.S, !this._decrypt ? tmp : buf, 0, len);\n\n  this.totalLength = this.totalLength.add(len);\n};\n\nGcm.prototype.gHASHBlock = function(Y, b) {\n  this.xor(Y, b);\n  this.multiplier.multiplyH(Y);\n};\nGcm.prototype.gHASHPartial = function(Y, b, off, len) {\n  this.xor(Y, b, off, len);\n  this.multiplier.multiplyH(Y);\n};\n\nGcm.prototype.xor = function(block, val, off, len) {\n  switch (arguments.length) {\n    case 2:\n      for (var i = 15; i >= 0; --i) {\n        block[i] ^= val[i];\n      }\n      break;\n    case 4:\n      while (len-- > 0) {\n        block[len] ^= val[off + len];\n      }\n      break;\n    default:\n      throw new TypeError(\"Expected 2 or 4 arguments.\");\n  }\n\n  return block;\n};\n\nGcm.prototype.zeroBlock = function() {\n  var block = Buffer.alloc(BLOCK_SIZE);\n  return block;\n};\n","/*!\n * deps/ciphermodes/gcm/multipliers.js - AES-GCM Multipliers\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n \"use strict\";\n\nvar helpers = require(\"./helpers.js\"),\n    pack = require(\"../pack.js\");\n\n\n// ### 8K Table Multiplier\nfunction Gcm8KMultiplier() {\n  this.H = [];\n  this.M = null;\n}\n\nGcm8KMultiplier.prototype.init = function(H) {\n  var i, j, k;\n  if (this.M == null) {\n    // sc: I realize this UGLY...\n    //M = new int[32][16][4];\n    this.M = [];\n    for (i = 0; i < 32; ++i) {\n      this.M[i] = [];\n      for (j = 0; j < 16; ++j) {\n        this.M[i][j] = [];\n        for (k = 0; k < 4; ++k) {\n          this.M[i][j][k] = 0;\n        }\n      }\n    }\n  } else if (helpers.arrayEqual(this.H, H)) {\n    return;\n  }\n\n  this.H = H.slice();\n\n  // M[0][0] is ZEROES;\n  // M[1][0] is ZEROES;\n  helpers.asInts(H, this.M[1][8]);\n\n  for (j = 4; j >= 1; j >>= 1) {\n    helpers.multiplyP(this.M[1][j + j], this.M[1][j]);\n  }\n  helpers.multiplyP(this.M[1][1], this.M[0][8]);\n\n  for (j = 4; j >= 1; j >>= 1) {\n    helpers.multiplyP(this.M[0][j + j], this.M[0][j]);\n  }\n\n  i = 0;\n  for (;;) {\n    for (j = 2; j < 16; j += j) {\n      for (k = 1; k < j; ++k) {\n        helpers.xor(this.M[i][j], this.M[i][k], this.M[i][j + k]);\n      }\n    }\n\n    if (++i === 32) {\n      return;\n    }\n\n    if (i > 1) {\n      // M[i][0] is ZEROES;\n      for (j = 8; j > 0; j >>= 1) {\n        helpers.multiplyP8(this.M[i - 2][j], this.M[i][j]);\n      }\n    }\n  }\n};\nGcm8KMultiplier.prototype.multiplyH = function(x) {\n  var z = [];\n  for (var i = 15; i >= 0; --i) {\n    var m = this.M[i + i][x[i] & 0x0f];\n    z[0] ^= m[0];\n    z[1] ^= m[1];\n    z[2] ^= m[2];\n    z[3] ^= m[3];\n    m = this.M[i + i + 1][(x[i] & 0xf0) >>> 4];\n    z[0] ^= m[0];\n    z[1] ^= m[1];\n    z[2] ^= m[2];\n    z[3] ^= m[3];\n  }\n\n  pack.intToBigEndian(z, x, 0);\n};\n\n\nmodule.exports = {\n  \"8k\": Gcm8KMultiplier\n};\n","/*!\n * deps/ciphermodes/helpers.js - Cipher Helper Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar pack = require(\"./pack.js\");\n\nfunction doEncrypt(cipher, inb, inOff, outb, outOff) {\n  var input = new Array(4),\n      output = new Array(4);\n\n  pack.bigEndianToInt(inb, inOff, input);\n  cipher.encrypt(input, output);\n  pack.intToBigEndian(output, outb, outOff);\n}\n\nmodule.exports = {\n  encrypt: doEncrypt\n};\n","/*!\n * deps/ciphermodes/pack.js - Pack/Unpack Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar Long = require(\"long\");\n\nvar pack = module.exports = {\n  intToBigEndian: function(n, bs, off) {\n    if (typeof n === \"number\") {\n      switch (arguments.length) {\n        case 1:\n          bs = Buffer.alloc(4);\n          pack.intToBigEndian(n, bs, 0);\n          break;\n        case 3:\n          bs[off] = 0xff & (n >>> 24);\n          bs[++off] = 0xff & (n >>> 16);\n          bs[++off] = 0xff & (n >>> 8);\n          bs[++off] = 0xff & (n);\n          break;\n        default:\n          throw new TypeError(\"Expected 1 or 3 arguments.\");\n      }\n    } else {\n      switch (arguments.length) {\n        case 1:\n          bs = Buffer.alloc(4 * n.length);\n          pack.intToBigEndian(n, bs, 0);\n          break;\n        case 3:\n          for (var i = 0; i < n.length; ++i) {\n            pack.intToBigEndian(n[i], bs, off);\n            off += 4;\n          }\n          break;\n        default:\n          throw new TypeError(\"Expected 1 or 3 arguments.\");\n      }\n    }\n\n    return bs;\n  },\n  longToBigEndian: function(n, bs, off) {\n    if (!Array.isArray(n)) {\n      // Single\n      switch (arguments.length) {\n        case 1:\n          bs = Buffer.alloc(8);\n          pack.longToBigEndian(n, bs, 0);\n          break;\n        case 3:\n          var lo = n.low,\n              hi = n.high;\n          pack.intToBigEndian(hi, bs, off);\n          pack.intToBigEndian(lo, bs, off + 4);\n          break;\n        default:\n          throw new TypeError(\"Expected 1 or 3 arguments.\");\n      }\n    } else {\n      // Array\n      switch (arguments.length) {\n        case 1:\n          bs = Buffer.alloc(8 * n.length);\n          pack.longToBigEndian(n, bs, 0);\n          break;\n        case 3:\n          for (var i = 0; i < n.length; ++i) {\n            pack.longToBigEndian(n[i], bs, off);\n            off += 8;\n          }\n          break;\n        default:\n          throw new TypeError(\"Expected 1 or 3 arguments.\");\n      }\n    }\n\n    return bs;\n  },\n\n  bigEndianToInt: function(bs, off, ns) {\n    switch (arguments.length) {\n      case 2:\n        var n = bs[off] << 24;\n        n |= (bs[++off] & 0xff) << 16;\n        n |= (bs[++off] & 0xff) << 8;\n        n |= (bs[++off] & 0xff);\n        return n;\n      case 3:\n        for (var i = 0; i < ns.length; ++i) {\n          ns[i] = pack.bigEndianToInt(bs, off);\n          off += 4;\n        }\n        break;\n      default:\n        throw new TypeError(\"Expected 2 or 3 arguments.\");\n    }\n  },\n  bigEndianToLong: function(bs, off, ns) {\n    switch (arguments.length) {\n      case 2:\n        var hi = pack.bigEndianToInt(bs, off);\n        var lo = pack.bigEndianToInt(bs, off + 4);\n        var num = new Long(lo, hi);\n        return num;\n      case 3:\n        for (var i = 0; i < ns.length; ++i) {\n          ns[i] = pack.bigEndianToLong(bs, off);\n          off += 8;\n        }\n        break;\n      default:\n        throw new TypeError(\"Expected 2 or 3 arguments.\");\n    }\n  }\n};\n","/**\n * deps/ecc/curves.js - Elliptic Curve NIST/SECG/X9.62 Parameters\n * Original Copyright (c) 2003-2005  Tom Wu.\n * Modifications Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n *\n * Ported from Tom Wu, which is ported from BouncyCastle\n * Modified to reuse existing external NPM modules, restricted to the\n * NIST//SECG/X9.62 prime curves only, and formatted to match project\n * coding styles.\n */\n\"use strict\";\n\n// Named EC curves\n\nvar BigInteger = require(\"../../deps/forge\").jsbn.BigInteger,\n    ec = require(\"./math.js\");\n\n// ----------------\n// X9ECParameters\n\n// constructor\nfunction X9ECParameters(curve, g, n, h) {\n  this.curve = curve;\n  this.g = g;\n  this.n = n;\n  this.h = h;\n}\n\nfunction x9getCurve() {\n  return this.curve;\n}\n\nfunction x9getG() {\n  return this.g;\n}\n\nfunction x9getN() {\n  return this.n;\n}\n\nfunction x9getH() {\n  return this.h;\n}\n\nX9ECParameters.prototype.getCurve = x9getCurve;\nX9ECParameters.prototype.getG = x9getG;\nX9ECParameters.prototype.getN = x9getN;\nX9ECParameters.prototype.getH = x9getH;\n\n// ----------------\n// SECNamedCurves\n\nfunction fromHex(s) { return new BigInteger(s, 16); }\n\nfunction secp256r1() {\n  // p = 2^224 (2^32 - 1) + 2^192 + 2^96 - 1\n  var p = fromHex(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF\");\n  var a = fromHex(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC\");\n  var b = fromHex(\"5AC635D8AA3A93E7B3EBBD55769886BC651D06B0CC53B0F63BCE3C3E27D2604B\");\n  var n = fromHex(\"FFFFFFFF00000000FFFFFFFFFFFFFFFFBCE6FAADA7179E84F3B9CAC2FC632551\");\n  var h = BigInteger.ONE;\n  var curve = new ec.ECCurveFp(p, a, b);\n  var G = curve.decodePointHex(\"04\"\n              + \"6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296\"\n              + \"4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5\");\n  return new X9ECParameters(curve, G, n, h);\n}\n\nfunction secp384r1() {\n  // p = 2^384 - 2^128 - 2^96 + 2^32 - 1\n  var p = fromHex(\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFF\");\n  var a = fromHex(\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFC\");\n  var b = fromHex(\"B3312FA7E23EE7E4988E056BE3F82D19181D9C6EFE8141120314088F5013875AC656398D8A2ED19D2A85C8EDD3EC2AEF\");\n  var n = fromHex(\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC7634D81F4372DDF581A0DB248B0A77AECEC196ACCC52973\");\n  var h = BigInteger.ONE;\n  var curve = new ec.ECCurveFp(p, a, b);\n  var G = curve.decodePointHex(\"04\"\n              + \"AA87CA22BE8B05378EB1C71EF320AD746E1D3B628BA79B9859F741E082542A385502F25DBF55296C3A545E3872760AB7\"\n              + \"3617DE4A96262C6F5D9E98BF9292DC29F8F41DBD289A147CE9DA3113B5F0B8C00A60B1CE1D7E819D7A431D7C90EA0E5F\");\n  return new X9ECParameters(curve, G, n, h);\n}\n\nfunction secp521r1() {\n  // p = 2^521 - 1\n  var p = fromHex(\"01FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\");\n  var a = fromHex(\"01FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC\");\n  var b = fromHex(\"0051953EB9618E1C9A1F929A21A0B68540EEA2DA725B99B315F3B8B489918EF109E156193951EC7E937B1652C0BD3BB1BF073573DF883D2C34F1EF451FD46B503F00\");\n  var n = fromHex(\"01FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFA51868783BF2F966B7FCC0148F709A5D03BB5C9B8899C47AEBB6FB71E91386409\");\n  var h = BigInteger.ONE;\n  var curve = new ec.ECCurveFp(p, a, b);\n  var G = curve.decodePointHex(\"04\"\n                + \"00C6858E06B70404E9CD9E3ECB662395B4429C648139053FB521F828AF606B4D3DBAA14B5E77EFE75928FE1DC127A2FFA8DE3348B3C1856A429BF97E7E31C2E5BD66\"\n                + \"011839296A789A3BC0045C8A5FB42C7D1BD998F54449579B446817AFBD17273E662C97EE72995EF42640C550B9013FAD0761353C7086A272C24088BE94769FD16650\");\n  return new X9ECParameters(curve, G, n, h);\n}\n\n// ----------------\n// Public API\n\nvar CURVES = module.exports = {\n  \"secp256r1\": secp256r1(),\n  \"secp384r1\": secp384r1(),\n  \"secp521r1\": secp521r1()\n};\n\n// also export NIST names\nCURVES[\"P-256\"] = CURVES.secp256r1;\nCURVES[\"P-384\"] = CURVES.secp384r1;\nCURVES[\"P-521\"] = CURVES.secp521r1;\n","/**\n * deps/ecc/index.js - Elliptic Curve Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../../deps/forge\"),\n    BigInteger = forge.jsbn.BigInteger,\n    ec = require(\"./math.js\"),\n    CURVES = require(\"./curves.js\");\n\n// ### Helpers\nfunction hex2bn(s) {\n  return new BigInteger(s, 16);\n}\n\nfunction bn2bin(bn, len) {\n  if (!len) {\n    len = Math.ceil(bn.bitLength() / 8);\n  }\n  len = len * 2;\n\n  var hex = bn.toString(16);\n  // truncate-left if too large\n  hex = hex.substring(Math.max(hex.length - len, 0));\n  // pad-left if too small\n  while (len > hex.length) {\n    hex = \"0\" + hex;\n  }\n\n  return Buffer.from(hex, \"hex\");\n}\nfunction bin2bn(s) {\n  if (\"string\" === typeof s) {\n    s = Buffer.from(s, \"binary\");\n  }\n  return hex2bn(s.toString(\"hex\"));\n}\n\nfunction keySizeBytes(params) {\n  return Math.ceil(params.getN().bitLength() / 8);\n}\n\nfunction namedCurve(curve) {\n  var params = CURVES[curve];\n  if (!params) {\n    throw new TypeError(\"unsupported named curve: \" + curve);\n  }\n\n  return params;\n}\n\nfunction normalizeEcdsa(params, md) {\n  var log2n = params.getN().bitLength(),\n      mdLen = md.length * 8;\n\n  var e = bin2bn(md);\n  if (log2n < mdLen) {\n    e = e.shiftRight(mdLen - log2n);\n  }\n\n  return e;\n}\n\n// ### EC Public Key\n\n/**\n *\n * @param {String} curve The named curve\n * @param {BigInteger} x The X coordinate\n * @param {BigInteger} y The Y coordinate\n */\nfunction ECPublicKey(curve, x, y) {\n  var params = namedCurve(curve),\n      c = params.getCurve();\n  var key = new ec.ECPointFp(c,\n                             c.fromBigInteger(x),\n                             c.fromBigInteger(y));\n\n  this.curve = curve;\n  this.params = params;\n  this.point = key;\n\n  var size = keySizeBytes(params);\n  this.x = bn2bin(x, size);\n  this.y = bn2bin(y, size);\n}\n\n// basics\nECPublicKey.prototype.isValid = function() {\n  return this.params.curve.contains(this.point);\n}\n\n// ECDSA\nECPublicKey.prototype.verify = function(md, sig) {\n  var N = this.params.getN(),\n      G = this.params.getG();\n\n  // prepare and validate (r, s)\n  var r = bin2bn(sig.r),\n      s = bin2bn(sig.s);\n  if (r.compareTo(BigInteger.ONE) < 0 || r.compareTo(N) >= 0) {\n    return false;\n  }\n  if (s.compareTo(BigInteger.ONE) < 0 || r.compareTo(N) >= 0) {\n    return false;\n  }\n\n  // normalize input\n  var e = normalizeEcdsa(this.params, md);\n  // verify (r, s)\n  var w = s.modInverse(N),\n      u1 = e.multiply(w).mod(N),\n      u2 = r.multiply(w).mod(N);\n\n  var v = G.multiplyTwo(u1, this.point, u2).getX().toBigInteger();\n  v = v.mod(N);\n\n  return v.equals(r);\n};\n\n// ### EC Private Key\n\n/**\n * @param {String} curve The named curve\n * @param {Buffer} key The private key value\n */\nfunction ECPrivateKey(curve, key) {\n  var params = namedCurve(curve);\n  this.curve = curve;\n  this.params = params;\n\n  var size = keySizeBytes(params);\n  this.d = bn2bin(key, size);\n}\n\nECPrivateKey.prototype.toPublicKey = function() {\n  var d = bin2bn(this.d);\n  var P = this.params.getG().multiply(d);\n  return new ECPublicKey(this.curve,\n                         P.getX().toBigInteger(),\n                         P.getY().toBigInteger());\n};\n\n// ECDSA\nECPrivateKey.prototype.sign = function(md) {\n  var keysize = keySizeBytes(this.params),\n      N = this.params.getN(),\n      G = this.params.getG(),\n      e = normalizeEcdsa(this.params, md),\n      d = bin2bn(this.d);\n\n  var r, s;\n  var k, x1, z;\n  do {\n    do {\n      // determine random nonce\n      do {\n        k = bin2bn(forge.random.getBytes(keysize));\n      } while (k.equals(BigInteger.ZERO) || k.compareTo(N) >= 0);\n      // (x1, y1) = k * G\n      x1 = G.multiply(k).getX().toBigInteger();\n      // r = x1 mod N\n      r = x1.mod(N);\n    } while (r.equals(BigInteger.ZERO));\n    // s = (k^-1 * (e + r * d)) mod N\n    z = d.multiply(r);\n    z = e.add(z);\n    s = k.modInverse(N).multiply(z).mod(N);\n  } while (s.equals(BigInteger.ONE));\n\n  // convert (r, s) to bytes\n  var len = keySizeBytes(this.params);\n  r = bn2bin(r, len);\n  s = bn2bin(s, len);\n\n  return {\n    r: r,\n    s: s\n  };\n};\n\n// basics\nECPrivateKey.prototype.isValid = function() {\n  var d = bin2bn(this.d),\n      n1 = this.params.getN().subtract(BigInteger.ONE);\n\n  return (d.compareTo(BigInteger.ONE) >= 0) &&\n         (d.compareTo(n1) < 0);\n}\n\n// ECDH\nECPrivateKey.prototype.computeSecret = function(pubkey) {\n  var d = bin2bn(this.d);\n  var S = pubkey.point.multiply(d).getX().toBigInteger();\n  S = bn2bin(S, keySizeBytes(this.params));\n  return S;\n};\n\n// ### Public API\nexports.generateKeyPair = function(curve) {\n  var params = namedCurve(curve),\n      n = params.getN();\n\n  // generate random within range [1, N-1)\n  var r = forge.random.getBytes(keySizeBytes(params));\n  r = bin2bn(r);\n\n  var n1 = n.subtract(BigInteger.ONE);\n  var d = r.mod(n1).add(BigInteger.ONE);\n\n  var privkey = new ECPrivateKey(curve, d),\n      pubkey = privkey.toPublicKey();\n\n  return {\n    \"private\": privkey,\n    \"public\": pubkey\n  };\n};\n\nexports.asPublicKey = function(curve, x, y) {\n  if (\"string\" === typeof x) {\n    x = hex2bn(x);\n  } else if (Buffer.isBuffer(x)) {\n    x = bin2bn(x);\n  }\n\n  if (\"string\" === typeof y) {\n    y = hex2bn(y);\n  } else if (Buffer.isBuffer(y)) {\n    y = bin2bn(y);\n  }\n\n  var pubkey = new ECPublicKey(curve, x, y);\n  return pubkey;\n};\nexports.asPrivateKey = function(curve, d) {\n  // Elaborate way to get to a Buffer from a (String|Buffer|BigInteger)\n  if (\"string\" === typeof d) {\n    d = hex2bn(d);\n  } else if (Buffer.isBuffer(d)) {\n    d = bin2bn(d);\n  }\n\n  var privkey = new ECPrivateKey(curve, d);\n  return privkey;\n};\n","/**\n * deps/ecc/math.js - Elliptic Curve Math\n * Original Copyright (c) 2003-2005  Tom Wu.\n * Modifications Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n *\n * Ported from Tom Wu, which is ported from BouncyCastle\n * Modified to reuse existing external NPM modules, restricted to the\n * NIST//SECG/X9.62 prime curves only, and formatted to match project\n * coding styles.\n */\n\"use strict\";\n\n// Basic Javascript Elliptic Curve implementation\n// Ported loosely from BouncyCastle's Java EC code\n// Only Fp curves implemented for now\n\nvar BigInteger = require(\"../../deps/forge\").jsbn.BigInteger;\n\n// ----------------\n// Helpers\n\nfunction nbi() {\n  return new BigInteger(null);\n}\n\n// ----------------\n// Barrett modular reduction\n\n// constructor\nfunction Barrett(m) {\n  // setup Barrett\n  this.r2 = nbi();\n  this.q3 = nbi();\n  BigInteger.ONE.dlShiftTo(2*m.t,this.r2);\n  this.mu = this.r2.divide(m);\n  this.m = m;\n}\n\nfunction barrettConvert(x) {\n  if(x.s < 0 || x.t > 2*this.m.t) return x.mod(this.m);\n  else if(x.compareTo(this.m) < 0) return x;\n  else { var r = nbi(); x.copyTo(r); this.reduce(r); return r; }\n}\n\nfunction barrettRevert(x) { return x; }\n\n// x = x mod m (HAC 14.42)\nfunction barrettReduce(x) {\n  if (x.s < 0) { throw Error(\"Barrett reduction on negative input\"); }\n  x.drShiftTo(this.m.t-1,this.r2);\n  if(x.t > this.m.t+1) { x.t = this.m.t+1; x.clamp(); }\n  this.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);\n  this.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);\n  while(x.compareTo(this.r2) < 0) x.dAddOffset(1,this.m.t+1);\n  x.subTo(this.r2,x);\n  while(x.compareTo(this.m) >= 0) x.subTo(this.m,x);\n}\n\n// r = x^2 mod m; x != r\nfunction barrettSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\n// r = x*y mod m; x,y != r\nfunction barrettMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\n\nBarrett.prototype.convert = barrettConvert;\nBarrett.prototype.revert = barrettRevert;\nBarrett.prototype.reduce = barrettReduce;\nBarrett.prototype.mulTo = barrettMulTo;\nBarrett.prototype.sqrTo = barrettSqrTo;\n\n// ----------------\n// ECFieldElementFp\n\n// constructor\nfunction ECFieldElementFp(q, x) {\n  this.x = x;\n  // TODO if(x.compareTo(q) >= 0) error\n  this.p = q;\n}\n\nfunction feFpEquals(other) {\n  if (other === this) {\n    return true;\n  }\n  return (this.p.equals(other.p) && this.x.equals(other.x));\n}\n\nfunction feFpToBigInteger() {\n  return this.x;\n}\n\nfunction feFpNegate() {\n  return new ECFieldElementFp(this.p, this.x.negate().mod(this.p));\n}\n\nfunction feFpAdd(b) {\n  return new ECFieldElementFp(this.p, this.x.add(b.toBigInteger()).mod(this.p));\n}\n\nfunction feFpSubtract(b) {\n  return new ECFieldElementFp(this.p, this.x.subtract(b.toBigInteger()).mod(this.p));\n}\n\nfunction feFpMultiply(b) {\n  return new ECFieldElementFp(this.p, this.x.multiply(b.toBigInteger()).mod(this.p));\n}\n\nfunction feFpSquare() {\n  return new ECFieldElementFp(this.p, this.x.pow(2).mod(this.p));\n}\n\nfunction feFpDivide(b) {\n  return new ECFieldElementFp(this.p, this.x.multiply(b.toBigInteger().modInverse(this.p)).mod(this.p));\n}\n\nECFieldElementFp.prototype.equals = feFpEquals;\nECFieldElementFp.prototype.toBigInteger = feFpToBigInteger;\nECFieldElementFp.prototype.negate = feFpNegate;\nECFieldElementFp.prototype.add = feFpAdd;\nECFieldElementFp.prototype.subtract = feFpSubtract;\nECFieldElementFp.prototype.multiply = feFpMultiply;\nECFieldElementFp.prototype.square = feFpSquare;\nECFieldElementFp.prototype.divide = feFpDivide;\n\n// ----------------\n// ECPointFp\n\n// constructor\nfunction ECPointFp(curve, x, y, z) {\n  this.curve = curve;\n  this.x = x;\n  this.y = y;\n  // Projective coordinates: either zinv == null or z * zinv == 1\n  // z and zinv are just BigIntegers, not fieldElements\n  if (!z) {\n    this.z = BigInteger.ONE;\n  } else {\n    this.z = z;\n  }\n  this.zinv = null;\n  //TODO: compression flag\n}\n\nfunction pointFpGetX() {\n  if(!this.zinv) {\n    this.zinv = this.z.modInverse(this.curve.p);\n  }\n  var r = this.x.toBigInteger().multiply(this.zinv);\n  this.curve.reduce(r);\n  return this.curve.fromBigInteger(r);\n}\n\nfunction pointFpGetY() {\n  if(!this.zinv) {\n    this.zinv = this.z.modInverse(this.curve.p);\n  }\n  var r = this.y.toBigInteger().multiply(this.zinv);\n  this.curve.reduce(r);\n  return this.curve.fromBigInteger(r);\n}\n\nfunction pointFpEquals(other) {\n  if (other === this) {\n    return true;\n  }\n  if (this.isInfinity()) {\n    return other.isInfinity();\n  }\n  if (other.isInfinity()) {\n    return this.isInfinity();\n  }\n  var u, v;\n  // u = Y2 * Z1 - Y1 * Z2\n  u = other.y.toBigInteger().multiply(this.z).subtract(this.y.toBigInteger().multiply(other.z)).mod(this.curve.p);\n  if (!u.equals(BigInteger.ZERO)) {\n    return false;\n  }\n  // v = X2 * Z1 - X1 * Z2\n  v = other.x.toBigInteger().multiply(this.z).subtract(this.x.toBigInteger().multiply(other.z)).mod(this.curve.p);\n  return v.equals(BigInteger.ZERO);\n}\n\nfunction pointFpIsInfinity() {\n  if ((this.x == null) && (this.y == null)) {\n    return true;\n  }\n  return (this.z.equals(BigInteger.ZERO) && !this.y.toBigInteger().equals(BigInteger.ZERO));\n}\n\nfunction pointFpNegate() {\n    return new ECPointFp(this.curve, this.x, this.y.negate(), this.z);\n}\n\nfunction pointFpAdd(b) {\n  if (this.isInfinity()) {\n    return b;\n  }\n  if (b.isInfinity()) {\n    return this;\n  }\n\n  // u = Y2 * Z1 - Y1 * Z2\n  var u = b.y.toBigInteger().multiply(this.z).subtract(this.y.toBigInteger().multiply(b.z)).mod(this.curve.p);\n  // v = X2 * Z1 - X1 * Z2\n  var v = b.x.toBigInteger().multiply(this.z).subtract(this.x.toBigInteger().multiply(b.z)).mod(this.curve.p);\n\n  if (BigInteger.ZERO.equals(v)) {\n    if (BigInteger.ZERO.equals(u)) {\n      return this.twice(); // this == b, so double\n    }\n    return this.curve.getInfinity(); // this = -b, so infinity\n  }\n\n  var THREE = new BigInteger(\"3\");\n  var x1 = this.x.toBigInteger();\n  var y1 = this.y.toBigInteger();\n\n  var v2 = v.pow(2);\n  var v3 = v2.multiply(v);\n  var x1v2 = x1.multiply(v2);\n  var zu2 = u.pow(2).multiply(this.z);\n\n  // x3 = v * (z2 * (z1 * u^2 - 2 * x1 * v^2) - v^3)\n  var x3 = zu2.subtract(x1v2.shiftLeft(1)).multiply(b.z).subtract(v3).multiply(v).mod(this.curve.p);\n  // y3 = z2 * (3 * x1 * u * v^2 - y1 * v^3 - z1 * u^3) + u * v^3\n  var y3 = x1v2.multiply(THREE).multiply(u).subtract(y1.multiply(v3)).subtract(zu2.multiply(u)).multiply(b.z).add(u.multiply(v3)).mod(this.curve.p);\n  // z3 = v^3 * z1 * z2\n  var z3 = v3.multiply(this.z).multiply(b.z).mod(this.curve.p);\n\n  return new ECPointFp(this.curve, this.curve.fromBigInteger(x3), this.curve.fromBigInteger(y3), z3);\n}\n\nfunction pointFpTwice() {\n  if(this.isInfinity()) {\n    return this;\n  }\n  if (this.y.toBigInteger().signum() === 0) {\n    return this.curve.getInfinity();\n  }\n\n  // TODO: optimized handling of constants\n  var THREE = new BigInteger(\"3\");\n  var x1 = this.x.toBigInteger();\n  var y1 = this.y.toBigInteger();\n\n  var y1z1 = y1.multiply(this.z);\n  var y1sqz1 = y1z1.multiply(y1).mod(this.curve.p);\n  var a = this.curve.a.toBigInteger();\n\n  // w = 3 * x1^2 + a * z1^2\n  var w = x1.pow(2).multiply(THREE);\n  if (!BigInteger.ZERO.equals(a)) {\n    w = w.add(this.z.pow(2).multiply(a));\n  }\n  w = w.mod(this.curve.p);\n  //this.curve.reduce(w);\n  // x3 = 2 * y1 * z1 * (w^2 - 8 * x1 * y1^2 * z1)\n  var x3 = w.pow(2).subtract(x1.shiftLeft(3).multiply(y1sqz1)).shiftLeft(1).multiply(y1z1).mod(this.curve.p);\n  // y3 = 4 * y1^2 * z1 * (3 * w * x1 - 2 * y1^2 * z1) - w^3\n  var y3 = w.multiply(THREE).multiply(x1).subtract(y1sqz1.shiftLeft(1)).shiftLeft(2).multiply(y1sqz1).subtract(w.pow(2).multiply(w)).mod(this.curve.p);\n  // z3 = 8 * (y1 * z1)^3\n  var z3 = y1z1.pow(2).multiply(y1z1).shiftLeft(3).mod(this.curve.p);\n\n  return new ECPointFp(this.curve, this.curve.fromBigInteger(x3), this.curve.fromBigInteger(y3), z3);\n}\n\n// Simple NAF (Non-Adjacent Form) multiplication algorithm\n// TODO: modularize the multiplication algorithm\nfunction pointFpMultiply(k) {\n  if (this.isInfinity()) {\n    return this;\n  }\n  if (k.signum() === 0) {\n    return this.curve.getInfinity();\n  }\n\n  var e = k;\n  var h = e.multiply(new BigInteger(\"3\"));\n\n  var neg = this.negate();\n  var R = this;\n\n  var i;\n  for(i = h.bitLength() - 2; i > 0; --i) {\n    R = R.twice();\n\n    var hBit = h.testBit(i);\n    var eBit = e.testBit(i);\n\n    if (hBit !== eBit) {\n      R = R.add(hBit ? this : neg);\n    }\n  }\n\n  return R;\n}\n\n// Compute this*j + x*k (simultaneous multiplication)\nfunction pointFpMultiplyTwo(j, x, k) {\n  var i;\n  if (j.bitLength() > k.bitLength()) {\n    i = j.bitLength() - 1;\n  } else {\n    i = k.bitLength() - 1;\n  }\n\n  var R = this.curve.getInfinity();\n  var both = this.add(x);\n  while (i >= 0) {\n    R = R.twice();\n    if (j.testBit(i)) {\n      if (k.testBit(i)) {\n        R = R.add(both);\n      }\n      else {\n        R = R.add(this);\n      }\n    }\n    else {\n      if (k.testBit(i)) {\n        R = R.add(x);\n      }\n    }\n    --i;\n  }\n\n  return R;\n}\n\nECPointFp.prototype.getX = pointFpGetX;\nECPointFp.prototype.getY = pointFpGetY;\nECPointFp.prototype.equals = pointFpEquals;\nECPointFp.prototype.isInfinity = pointFpIsInfinity;\nECPointFp.prototype.negate = pointFpNegate;\nECPointFp.prototype.add = pointFpAdd;\nECPointFp.prototype.twice = pointFpTwice;\nECPointFp.prototype.multiply = pointFpMultiply;\nECPointFp.prototype.multiplyTwo = pointFpMultiplyTwo;\n\n// ----------------\n// ECCurveFp\n\n// constructor\nfunction ECCurveFp(p, a, b) {\n  this.p = p;\n  this.a = this.fromBigInteger(a);\n  this.b = this.fromBigInteger(b);\n  this.infinity = new ECPointFp(this, null, null);\n  this.reducer = new Barrett(this.p);\n}\n\nfunction curveFpgetP() {\n  return this.p;\n}\n\nfunction curveFpGetA() {\n  return this.a;\n}\n\nfunction curveFpGetB() {\n  return this.b;\n}\n\nfunction curveFpEquals(other) {\n  if (other === this) {\n    return true;\n  }\n  return (this.p.equals(other.p) && this.a.equals(other.a) && this.b.equals(other.b));\n}\n\nfunction curveFpContains(pt) {\n  // y^2 = x^3 + a*x + b mod p\n  var x = pt.getX().toBigInteger(),\n      y = pt.getY().toBigInteger(),\n      a = this.a.toBigInteger(),\n      b = this.b.toBigInteger(),\n      p = this.p;\n\n  var left = y.pow(2).mod(p),\n      right = x.pow(3).add(a.multiply(x)).add(b).mod(p)\n\n  return left.equals(right);\n}\n\nfunction curveFpGetInfinity() {\n  return this.infinity;\n}\n\nfunction curveFpFromBigInteger(x) {\n  return new ECFieldElementFp(this.p, x);\n}\n\nfunction curveReduce(x) {\n  this.reducer.reduce(x);\n}\n\n// for now, work with hex strings because they're easier in JS\nfunction curveFpDecodePointHex(s) {\n  switch (parseInt(s.substring(0, 2), 16)) {\n    // first byte\n    case 0:\n      return this.infinity;\n    case 2:\n    case 3:\n      // point compression not supported yet\n      return null;\n    case 4:\n    case 6:\n    case 7:\n      var len = (s.length - 2) / 2;\n      var xHex = s.substr(2, len);\n      var yHex = s.substr(len + 2, len);\n\n      return new ECPointFp(this,\n                           this.fromBigInteger(new BigInteger(xHex, 16)),\n                           this.fromBigInteger(new BigInteger(yHex, 16)));\n\n    default: // unsupported\n      return null;\n    }\n}\n\nfunction curveFpEncodePointHex(p) {\n  if (p.isInfinity()) {\n    return \"00\";\n  }\n  var xHex = p.getX().toBigInteger().toString(16);\n  var yHex = p.getY().toBigInteger().toString(16);\n  var oLen = this.getP().toString(16).length;\n  if ((oLen % 2) !== 0) {\n    oLen++;\n  }\n  while (xHex.length < oLen) {\n    xHex = \"0\" + xHex;\n  }\n  while (yHex.length < oLen) {\n    yHex = \"0\" + yHex;\n  }\n  return \"04\" + xHex + yHex;\n}\n\nECCurveFp.prototype.getP = curveFpgetP;\nECCurveFp.prototype.getA = curveFpGetA;\nECCurveFp.prototype.getB = curveFpGetB;\nECCurveFp.prototype.equals = curveFpEquals;\nECCurveFp.prototype.contains = curveFpContains;\nECCurveFp.prototype.getInfinity = curveFpGetInfinity;\nECCurveFp.prototype.fromBigInteger = curveFpFromBigInteger;\nECCurveFp.prototype.reduce = curveReduce;\nECCurveFp.prototype.decodePointHex = curveFpDecodePointHex;\nECCurveFp.prototype.encodePointHex = curveFpEncodePointHex;\n\n// Exports\nmodule.exports = {\n  ECFieldElementFp: ECFieldElementFp,\n  ECPointFp: ECPointFp,\n  ECCurveFp: ECCurveFp\n};\n","/*!\n * deps/forge.js - Forge Package Customization\n *\n * Copyright (c) 2015 Cisco Systems, Inc.  See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"node-forge/lib/forge\");\nrequire(\"node-forge/lib/aes\");\nrequire(\"node-forge/lib/asn1\");\nrequire(\"node-forge/lib/cipher\");\nrequire(\"node-forge/lib/hmac\");\nrequire(\"node-forge/lib/mgf1\");\nrequire(\"node-forge/lib/pbkdf2\");\nrequire(\"node-forge/lib/pem\");\nrequire(\"node-forge/lib/pkcs1\");\nrequire(\"node-forge/lib/pkcs7\");\nrequire(\"node-forge/lib/pki\");\nrequire(\"node-forge/lib/prime\");\nrequire(\"node-forge/lib/prng\");\nrequire(\"node-forge/lib/pss\");\nrequire(\"node-forge/lib/random\");\nrequire(\"node-forge/lib/sha1\");\nrequire(\"node-forge/lib/sha256\");\nrequire(\"node-forge/lib/sha512\");\nrequire(\"node-forge/lib/util\");\n\n// Define AES \"raw\" cipher mode\nfunction modeRaw(options) {\n  options = options || {};\n  this.name = \"\";\n  this.cipher = options.cipher;\n  this.blockSize = options.blockSize || 16;\n  this._blocks = this.blockSize / 4;\n  this._inBlock = new Array(this._blocks);\n  this._outBlock = new Array(this._blocks);\n}\n\nmodeRaw.prototype.start = function() {};\n\nmodeRaw.prototype.encrypt = function(input, output, finish) {\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  var i;\n\n  // get next block\n  for(i = 0; i < this._blocks; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // encrypt block\n  this.cipher.encrypt(this._inBlock, this._outBlock);\n\n  // write output\n  for(i = 0; i < this._blocks; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n};\n\nmodeRaw.prototype.decrypt = function(input, output, finish) {\n  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {\n    return true;\n  }\n\n  var i;\n\n  // get next block\n  for(i = 0; i < this._blocks; ++i) {\n    this._inBlock[i] = input.getInt32();\n  }\n\n  // decrypt block\n  this.cipher.decrypt(this._inBlock, this._outBlock);\n\n  // write output\n  for(i = 0; i < this._blocks; ++i) {\n    output.putInt32(this._outBlock[i]);\n  }\n};\n\n(function() {\n  var name = \"AES\",\n      mode = modeRaw,\n      factory;\n  factory = function() { return new forge.aes.Algorithm(name, mode); };\n  forge.cipher.registerAlgorithm(name, factory);\n})();\n\n// Ensure that the jsbn modInverse function always returns a positive result\nconst originalModInverse = forge.jsbn.BigInteger.prototype.modInverse;\nconst positiveModInverse = function(m) {\n  const inv = originalModInverse.apply(this, [m]);\n  return inv.mod(m);\n}\n\nforge.jsbn.BigInteger.prototype.modInverse = positiveModInverse;\n\nmodule.exports = forge;\n","/*!\n * index.js - Main Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nif (typeof Promise === \"undefined\") {\n  require(\"es6-promise\").polyfill();\n}\n\nif (typeof Buffer === \"undefined\") {\n  (global || window).Buffer = require(\"buffer\").Buffer;\n}\n\nif (typeof process === \"undefined\") {\n  (global || window).process = require(\"process\");\n}\n\nif (!process.version) {\n  process.version = \"\";\n}\n\nvar JWS = require(\"./jws\");\n\nmodule.exports = {\n  JWA: require(\"./algorithms\"),\n  JWE: require(\"./jwe\"),\n  JWK: require(\"./jwk\"),\n  JWS: JWS,\n  util: require(\"./util\"),\n  parse: require(\"./parse\"),\n  canYouSee: JWS.createVerify\n};\n","/*!\n * jwe/decrypt.js - Decrypt from a JWE\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar base64url = require(\"../util/base64url\"),\n    AlgConfig = require(\"../util/algconfig\"),\n    JWK = require(\"../jwk\"),\n    merge = require(\"../util/merge\"),\n    pako = require(\"pako\");\n\nvar DEFAULT_OPTIONS = {\n  algorithms: \"*\"\n};\n\n/**\n * @class JWE.Decrypter\n * @classdesc Processor of encrypted data.\n *\n * @description\n * **NOTE:** This class cannot be instantiated directly. Instead\n * call {@link JWE.createDecrypt}.\n */\nfunction JWEDecrypter(ks, globalOpts) {\n  var assumedKey,\n    keystore;\n\n  if (JWK.isKey(ks)) {\n    assumedKey = ks;\n    keystore = assumedKey.keystore;\n  } else if (JWK.isKeyStore(ks)) {\n    keystore = ks;\n  } else {\n    throw new TypeError(\"Keystore must be provided\");\n  }\n\n  globalOpts = merge({}, DEFAULT_OPTIONS, globalOpts);\n\n  /**\n   * Decrypts the given input.\n   *\n   * {opts}, if provided, is used to customize this specific decrypt operation.\n   * This argument has the same semantics as {JWE.createDecrypt}, and takes\n   * precedence over those options.\n   *\n   * The returned PRomise, when fulfilled, returns an object with the\n   * following members:\n   *\n   * - `header` - The JOSE Header, combined from the relevant \"header\" and\n   *            \"protected\" fields from the original JWE object.\n   * - `protected` - An array containing the names of the protected fields\n   * - `key` - The used to decrypt the content\n   * - `payload` - The decrypted content (as a Buffer)\n   * - `plaintext` - An alias for `payload`\n   *\n   * @param {Object|String} input The encrypted content\n   * @param {Object} [opts] The options for this decryption operation.\n   * @returns {Promise} A promise for the decyprted plaintext\n   */\n  Object.defineProperty(this, \"decrypt\", {\n    value: function(input, opts) {\n      opts = merge({}, globalOpts, opts || {});\n      var extraHandlers = opts.handlers || {};\n      var handlerKeys = Object.keys(extraHandlers);\n      var algSpec = new AlgConfig(opts.algorithms);\n\n      /* eslint camelcase: [0] */\n      if (typeof input === \"string\") {\n        input = input.split(\".\");\n        input = {\n          protected: input[0],\n          recipients: [\n            {\n              encrypted_key: input[1]\n            }\n          ],\n          iv: input[2],\n          ciphertext: input[3],\n          tag: input[4]\n        };\n      } else if (!input || typeof input !== \"object\") {\n        throw new Error(\"invalid input\");\n      }\n      if (\"encrypted_key\" in input) {\n        input.recipients = [\n          {\n            encrypted_key: input.encrypted_key\n          }\n        ];\n      }\n\n      var promise;\n\n      // ensure recipients exists\n      var rcptList = input.recipients || [{}];\n      promise = Promise.resolve(rcptList);\n\n      //combine fields\n      var fields,\n          protect;\n      promise = promise.then(function(rcptList) {\n        if (input.protected) {\n          protect = base64url.decode(input.protected).toString(\"utf8\");\n          protect = JSON.parse(protect);\n\n          // verify \"crit\" field first\n          var crit = protect.crit;\n          if (crit) {\n            if (!Array.isArray(crit)) {\n              return Promise.reject(new Error(\"Invalid 'crit' header\"));\n            }\n            for (var idx = 0; crit.length > idx; idx++) {\n              if (-1 === handlerKeys.indexOf(crit[idx])) {\n                return Promise.reject(new Error(\n                    \"Critical extension is not supported: \" + crit[idx]\n                ));\n              }\n            }\n          }\n\n          fields = protect;\n          protect = Object.keys(protect);\n        } else {\n          fields = {};\n          protect = [];\n        }\n        fields = merge(input.unprotected || {}, fields);\n\n        rcptList = rcptList.map(function(r) {\n          var promise = Promise.resolve();\n          var header = r.header || {};\n          header = merge(header, fields);\n          r.header = header;\n          r.protected = protect;\n\n          // check on allowed algorithms\n          if (!algSpec.match(header.alg)) {\n            promise = promise.then(function() {\n              return Promise.reject(new Error(\"Algorithm not allowed: \" + header.alg));\n            });\n          }\n          if (!algSpec.match(header.enc)) {\n            promise = promise.then(function () {\n              return Promise.reject(new Error(\"Algorithm not allowed: \" + header.enc));\n            });\n          }\n\n          if (header.epk) {\n            promise = promise.then(function() {\n              return JWK.asKey(header.epk);\n            });\n            promise = promise.then(function(epk) {\n              header.epk = epk.toObject(false);\n            });\n          }\n          return promise.then(function() {\n            return r;\n          });\n        });\n\n        return Promise.all(rcptList);\n      });\n\n      // decrypt with first key found\n      var algKey,\n        encKey,\n        kdata;\n      promise = promise.then(function(rcptList) {\n        var jwe = {};\n        return new Promise(function(resolve, reject) {\n          var processKey = function() {\n            var rcpt = rcptList.shift();\n            if (!rcpt) {\n              reject(new Error(\"no key found\"));\n              return;\n            }\n\n            var algPromise = Promise.resolve(rcpt);\n            algPromise = algPromise.then(function(rcpt) {\n              // try to unwrap encrypted key\n              var prekey = kdata = rcpt.encrypted_key || \"\";\n              prekey = base64url.decode(prekey);\n              algKey = assumedKey || keystore.get({\n                use: \"enc\",\n                alg: rcpt.header.alg,\n                kid: rcpt.header.kid\n              });\n              if (algKey) {\n                return algKey.unwrap(rcpt.header.alg, prekey, rcpt.header);\n              } else {\n                return Promise.reject();\n              }\n            });\n            algPromise = algPromise.then(function(key) {\n              encKey = {\n                \"kty\": \"oct\",\n                \"k\": base64url.encode(key)\n              };\n              encKey = JWK.asKey(encKey);\n              jwe.key = algKey;\n              jwe.header = rcpt.header;\n              jwe.protected = rcpt.protected;\n              resolve(jwe);\n            });\n            algPromise.catch(processKey);\n          };\n          processKey();\n        });\n      });\n\n      // assign decipher inputs\n      promise = promise.then(function(jwe) {\n        jwe.iv = input.iv;\n        jwe.tag = input.tag;\n        jwe.ciphertext = input.ciphertext;\n\n        return jwe;\n      });\n\n      // process any prepare-decrypt handlers\n      promise = promise.then(function(jwe) {\n        var processing = [];\n        handlerKeys.forEach(function(h) {\n          h = extraHandlers[h];\n          var p;\n          if (\"function\" === typeof h) {\n            p = h(jwe);\n          } else if (\"object\" === typeof h && \"function\" === typeof h.prepare) {\n            p = h.prepare(jwe);\n          }\n          if (p) {\n            processing.push(Promise.resolve(p));\n          }\n        });\n        return Promise.all(processing).then(function() {\n          // don't actually care about individual handler results\n          // assume {jwe} is updated\n          return jwe;\n        });\n      });\n\n      // prepare decrypt inputs\n      promise = promise.then(function(jwe) {\n        if (!Buffer.isBuffer(jwe.ciphertext)) {\n          jwe.ciphertext = base64url.decode(jwe.ciphertext);\n        }\n\n        return jwe;\n      });\n\n      // decrypt it!\n      promise = promise.then(function(jwe) {\n        var adata = input.protected;\n        if (\"aad\" in input && null != input.aad) {\n          adata += \".\" + input.aad;\n        }\n\n        var params = {\n          iv: jwe.iv,\n          adata: adata,\n          tag: jwe.tag,\n          kdata: kdata,\n          epu: jwe.epu,\n          epv: jwe.epv\n        };\n        var cdata = jwe.ciphertext;\n\n        delete jwe.iv;\n        delete jwe.tag;\n        delete jwe.ciphertext;\n\n        return encKey.\n          then(function(enkKey) {\n            return enkKey.decrypt(jwe.header.enc, cdata, params).\n              then(function(pdata) {\n                jwe.payload = jwe.plaintext = pdata;\n                return jwe;\n              });\n          });\n      });\n\n      // (OPTIONAL) decompress plaintext\n      promise = promise.then(function(jwe) {\n        if (\"DEF\" === jwe.header.zip) {\n          return new Promise(function(resolve, reject) {\n            try {\n              var data = pako.inflateRaw(Buffer.from(jwe.plaintext))\n\n              jwe.payload = jwe.plaintext = Buffer.from(data);\n              resolve(jwe);\n            } catch (err) {\n              reject(err);\n            }\n          });\n        }\n\n        return jwe;\n      });\n\n      // process any post-decrypt handlers\n      promise = promise.then(function(jwe) {\n        var processing = [];\n        handlerKeys.forEach(function(h) {\n          h = extraHandlers[h];\n          var p;\n          if (\"object\" === typeof h && \"function\" === typeof h.complete) {\n            p = h.complete(jwe);\n          }\n          if (p) {\n            processing.push(Promise.resolve(p));\n          }\n        });\n        return Promise.all(processing).then(function() {\n          // don't actually care about individual handler results\n          // assume {jwe} is updated\n          return jwe;\n        });\n      });\n\n      return promise;\n    }\n  });\n}\n\n/**\n * @description\n * Creates a new Decrypter for the given Key or KeyStore.\n *\n * {opts}, when provided, is used to customize decryption processes. The\n * following options are currently supported:\n *\n * - `handlers` - An object where each name is a JOSE header member name and\n *   the value can be a boolean, function, or an object.\n *\n * Handlers are intended to support 'crit' extensions. When a boolean value,\n * the member is expected to be processed once decryption is fully complete.\n * When a function, it is called just before the ciphertext is decrypted\n * (processed as if it were a `prepare` handler, as decribed below). When an\n * object, it can contain any of the following members:\n *\n * - `recipient` - A function called after a valid key is determined; it takes\n *   an object describing the recipient, and returns a Promise that is\n *   fulfilled once the handler's processing is complete.\n * - `prepare` - A function called just prior to decrypting the ciphertext;\n *   it takes an object describing the decryption result (but containing\n *   `ciphertext` and `tag' instead of `payload` and `plaintext`), and\n *   returns a Promise that is fulfilled once the handler's processing is\n *   complete.\n * - `complete` - A function called once decryption is complete, just prior\n *   to fulfilling the Promise returned by `decrypt()`; it takes the object\n *   that will be returned by `decrypt()`'s fulfilled Promise, and returns\n *   a Promise that is fulfilled once the handler's processing is complete.\n *\n * Note that normal processing of `decrypt()` does not continue until all\n * relevant handlers have completed. Any changes handlers make to the\n * provided objects affects `decrypt()`'s processing.\n *\n * @param {JWK.Key|JWK.KeyStore} ks The Key or KeyStore to use for decryption.\n * @param {Object} [opts] The options for this Decrypter.\n * @returns {JWE.Decrypter} The new Decrypter.\n */\nfunction createDecrypt(ks, opts) {\n  var dec = new JWEDecrypter(ks, opts);\n  return dec;\n}\n\nmodule.exports = {\n  decrypter: JWEDecrypter,\n  createDecrypt: createDecrypt\n};\n","/*!\n * jwe/defaults.js - Defaults for JWEs\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\n/**\n * @description\n * The default options for {@link JWE.createEncrypt}.\n *\n * @property {Boolean|String} zip Determines the compression algorithm to\n *           apply to the plaintext (if any) before it is encrypted. This can\n *           also be `true` (which is equivalent to `\"DEF\"`) or **`false`**\n *           (the default, which is equivalent to no compression).\n * @property {String} format Determines the serialization format of the\n *           output.  Expected to be `\"general\"` for general JSON\n *           Serialization, `\"flattened\"` for flattened JSON Serialization,\n *           or `\"compact\"` for Compact Serialization (default is\n *           **`\"general\"`**).\n * @property {Boolean} compact Determines if the output is the Compact\n *           serialization (`true`) or the JSON serialization (**`false`**,\n *           the default).\n * @property {String} contentAlg The algorithm used to encrypt the plaintext\n *           (default is **`\"A128CBC-HS256\"`**).\n * @property {String|String[]} protect The names of the headers to integrity\n *           protect.  The value `\"\"` means that none of the header parameters\n *           are integrity protected, while `\"*\"` (the default) means that all\n *           header parameters are integrity protected.\n */\nvar JWEDefaults = {\n  zip: false,\n  format: \"general\",\n  contentAlg: \"A128CBC-HS256\",\n  protect: \"*\"\n};\n\nmodule.exports = JWEDefaults;\n","/*!\n * jwe/encrypt.js - Encrypt to a JWE\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar util = require(\"../util\"),\n    generateCEK = require(\"./helpers\").generateCEK,\n    JWK = require(\"../jwk\"),\n    slice = require(\"./helpers\").slice,\n    pako = require(\"pako\"),\n    CONSTANTS = require(\"../algorithms/constants\");\n\nvar assign = require(\"lodash/assign\");\nvar clone = require(\"lodash/clone\");\nvar DEFAULTS = require(\"./defaults\");\n\n/**\n * @class JWE.Encrypter\n * @classdesc\n * Generator of encrypted data.\n *\n * @description\n * **NOTE:** This class cannot be instantiated directly. Instead call {@link\n * JWE.createEncrypt}.\n */\nfunction JWEEncrypter(cfg, fields, recipients) {\n  var finalized = false,\n    format = cfg.format || \"general\",\n    protectAll = !!cfg.protectAll,\n    content = Buffer.alloc(0);\n\n  /**\n   * @member {String} JWE.Encrypter#zip\n   * @readonly\n   * @description\n   * Indicates the compression algorithm applied to the plaintext\n   * before it is encrypted.  The possible values are:\n   *\n   * + **`\"DEF\"`**: Compress the plaintext using the DEFLATE algorithm.\n   * + **`\"\"`**: Do not compress the plaintext.\n   */\n  Object.defineProperty(this, \"zip\", {\n    get: function() {\n      return fields.zip || \"\";\n    },\n    enumerable: true\n  });\n  /**\n   * @member {Boolean} JWE.Encrypter#compact\n   * @readonly\n   * @description\n   * Indicates whether the output of this encryption generator is\n   * using the Compact serialization (`true`) or the JSON\n   * serialization (`false`).\n   */\n  Object.defineProperty(this, \"compact\", {\n    get: function() { return \"compact\" === format; },\n    enumerable: true\n  });\n  /**\n   * @member {String} JWE.Encrypter#format\n   * @readonly\n   * @description\n   * Indicates the format the output of this encryption generator takes.\n   */\n  Object.defineProperty(this, \"format\", {\n    get: function() { return format; },\n    enumerable: true\n  });\n  /**\n   * @member {String[]} JWE.Encrypter#protected\n   * @readonly\n   * @description\n   * The header parameter names that are protected. Protected header fields\n   * are first serialized to UTF-8 then encoded as util.base64url, then used as\n   * the additional authenticated data in the encryption operation.\n   */\n  Object.defineProperty(this, \"protected\", {\n    get: function() {\n      return clone(cfg.protect);\n    },\n    enumerable: true\n  });\n  /**\n   * @member {Object} JWE.Encrypter#header\n   * @readonly\n   * @description\n   * The global header parameters, both protected and unprotected. Call\n   * {@link JWE.Encrypter#protected} to determine which parameters will\n   * be protected.\n   */\n  Object.defineProperty(this, \"header\", {\n    get: function() {\n      return clone(fields);\n    },\n    enumerable: true\n  });\n\n  /**\n   * @method JWE.Encrypter#update\n   * @description\n   * Updates the plaintext data for the encryption generator. The plaintext\n   * is appended to the end of any other plaintext already applied.\n   *\n   * If {data} is a Buffer, {encoding} is ignored. Otherwise, {data} is\n   * converted to a Buffer internally to {encoding}.\n   *\n   * @param {Buffer|String} [data] The plaintext to apply.\n   * @param {String} [encoding] The encoding of the plaintext.\n   * @returns {JWE.Encrypter} This encryption generator.\n   * @throws {Error} If ciphertext has already been generated.\n   */\n  Object.defineProperty(this, \"update\", {\n    value: function(data, encoding) {\n      if (finalized) {\n        throw new Error(\"already final\");\n      }\n      if (data != null) {\n        data = util.asBuffer(data, encoding);\n        if (content.length) {\n          content = Buffer.concat([content, data],\n                      content.length + data.length);\n        } else {\n          content = data;\n        }\n      }\n\n      return this;\n    }\n  });\n  /**\n   * @method JWE.Encrypter#final\n   * @description\n   * Finishes the encryption operation.\n   *\n   * The returned Promise, when fulfilled, is the JSON Web Encryption (JWE)\n   * object, either in the Compact (if {@link JWE.Encrypter#compact} is\n   * `true`) or the JSON serialization.\n   *\n   * @param {Buffer|String} [data] The final plaintext data to apply.\n   * @param {String} [encoding] The encoding of the final plaintext data\n   *        (if any).\n   * @returns {Promise} A promise for the encryption operation.\n   * @throws {Error} If ciphertext has already been generated.\n   */\n  Object.defineProperty(this, \"final\", {\n    value: function(data, encoding) {\n      if (finalized) {\n        return Promise.reject(new Error(\"already final\"));\n      }\n\n      // last-minute data\n      this.update(data, encoding);\n\n      // mark as done...ish\n      finalized = true;\n      var promise = Promise.resolve({});\n\n      // determine CEK and IV\n      var encAlg = fields.enc;\n      var encKey;\n      promise = promise.then(function(jwe) {\n        if (cfg.cek) {\n          encKey = JWK.asKey(cfg.cek);\n        }\n        return jwe;\n      });\n\n      // process recipients\n      promise = promise.then(function(jwe) {\n        var procR = function(r, one) {\n          var props = {};\n          props = assign(props, fields);\n          props = assign(props, r.header);\n\n          var algKey = r.key,\n              algAlg = props.alg;\n\n          // generate Ephemeral EC Key\n          var tks,\n              rpromise;\n          if ((props.alg || \"\").indexOf(\"ECDH-ES\") === 0) {\n            tks = algKey.keystore.temp();\n            if (r.epk) {\n              rpromise = Promise.resolve(r.epk).\n                then(function(epk) {\n                  r.header.epk = epk.toJSON(false, [\"kid\"]);\n                  props.epk = epk.toObject(true, [\"kid\"]);\n                });\n            } else {\n              rpromise = tks.generate(\"EC\", algKey.get(\"crv\")).\n                then(function(epk) {\n                  r.header.epk = epk.toJSON(false, [\"kid\"]);\n                  props.epk = epk.toObject(true, [\"kid\"]);\n                });\n            }\n          } else {\n            rpromise = Promise.resolve();\n          }\n\n          // encrypt the CEK\n          rpromise = rpromise.then(function() {\n            var cek,\n                p;\n            // special case 'alg=dir'\n            if (\"dir\" === algAlg && one) {\n              encKey = Promise.resolve(algKey);\n              p = encKey.then(function(jwk) {\n                // fixup encAlg\n                if (!encAlg) {\n                  props.enc = fields.enc = encAlg = jwk.algorithms(JWK.MODE_ENCRYPT)[0];\n                }\n                return {\n                  once: true,\n                  direct: true\n                };\n              });\n            } else {\n              if (!encKey) {\n                if (!encAlg) {\n                  props.enc = fields.enc = encAlg = cfg.contentAlg;\n                }\n                encKey = generateCEK(encAlg);\n              }\n              p = encKey.then(function(jwk) {\n                cek = jwk.get(\"k\", true);\n                // algKey may or may not be a promise\n                return algKey;\n              });\n              p = p.then(function(algKey) {\n                return algKey.wrap(algAlg, cek, props);\n              });\n            }\n            return p;\n          });\n          rpromise = rpromise.then(function(wrapped) {\n            if (wrapped.once && !one) {\n              return Promise.reject(new Error(\"cannot use 'alg':'\" + algAlg + \"' with multiple recipients\"));\n            }\n\n            var rjwe = {},\n                cek;\n            if (wrapped.data) {\n              cek = wrapped.data;\n              cek = util.base64url.encode(cek);\n            }\n\n            if (wrapped.direct && cek) {\n              // replace content key\n              encKey = JWK.asKey({\n                kty: \"oct\",\n                k: cek\n              });\n            } else if (cek) {\n              /* eslint camelcase: [0] */\n              rjwe.encrypted_key = cek;\n            }\n\n            if (r.header && Object.keys(r.header).length) {\n              rjwe.header = clone(r.header || {});\n            }\n            if (wrapped.header) {\n              rjwe.header = assign(rjwe.header || {},\n                                     wrapped.header);\n            }\n\n            return rjwe;\n           });\n           return rpromise;\n        };\n\n        var p = Promise.all(recipients);\n        p = p.then(function(rcpts) {\n          var single = (1 === rcpts.length);\n          rcpts = rcpts.map(function(r) {\n            return procR(r, single);\n          });\n          return Promise.all(rcpts);\n        });\n        p = p.then(function(rcpts) {\n          jwe.recipients = rcpts.filter(function(r) { return !!r; });\n          return jwe;\n        });\n        return p;\n      });\n\n      // normalize headers\n      var props = {};\n      promise = promise.then(function(jwe) {\n        var protect,\n          lenProtect,\n          unprotect,\n          lenUnprotect;\n\n        unprotect = clone(fields);\n        if ((protectAll && jwe.recipients.length === 1) || \"compact\" === format) {\n          // merge single recipient into fields\n          protect = {};\n          protect = assign({},\n                     unprotect,\n                    jwe.recipients[0].header);\n          lenProtect = Object.keys(protect).length;\n\n          unprotect = undefined;\n          lenUnprotect = 0;\n\n          delete jwe.recipients[0].header;\n          if (Object.keys(jwe.recipients[0]).length === 0) {\n            jwe.recipients.splice(0, 1);\n          }\n        } else {\n          protect = {};\n          lenProtect = 0;\n          lenUnprotect = Object.keys(unprotect).length;\n          cfg.protect.forEach(function(f) {\n            // remove protected header values from body unprotected header\n            if (!(f in unprotect)) {\n              return;\n            }\n            protect[f] = unprotect[f];\n            lenProtect++;\n\n            delete unprotect[f];\n            lenUnprotect--;\n          });\n\n          jwe.recipients = (jwe.recipients || []).map(function(rcpt) {\n            rcpt = rcpt || {};\n            var header = rcpt.header;\n            if (header) {\n              Object.keys(header).forEach(function (f) {\n                if (f in protect) { delete header[f]; }\n              });\n              if (!Object.keys(header).length) {\n                delete rcpt.header;\n              }\n            }\n            return rcpt;\n          });\n        }\n\n        if (!jwe.recipients || jwe.recipients.length === 0) {\n          delete jwe.recipients;\n        }\n\n        // \"serialize\" (and setup merged props)\n        if (unprotect && lenUnprotect > 0) {\n          props = assign(props, unprotect);\n          jwe.unprotected = unprotect;\n        }\n        if (protect && lenProtect > 0) {\n          props = assign(props, protect);\n          protect = JSON.stringify(protect);\n          jwe.protected = util.base64url.encode(protect, \"utf8\");\n        }\n\n        return jwe;\n      });\n\n      // (OPTIONAL) compress plaintext\n      promise = promise.then(function(jwe) {\n        var pdata = content;\n        if (!props.zip) {\n          jwe.plaintext = pdata;\n          return jwe;\n        } else if (props.zip === \"DEF\") {\n          return new Promise(function(resolve, reject) {\n            try {\n              var data = pako.deflateRaw(Buffer.from(pdata, \"binary\"));\n\n              jwe.plaintext = Buffer.from(data);\n              resolve(jwe);\n            } catch (error) {\n              reject(error);\n            }\n          });\n        }\n        return Promise.reject(new Error(\"unsupported 'zip' mode\"));\n      });\n\n      // encrypt plaintext\n      promise = promise.then(function(jwe) {\n        props.adata = jwe.protected;\n        if (\"aad\" in cfg && cfg.aad != null) {\n          props.adata += \".\" + cfg.aad;\n          props.adata = Buffer.from(props.adata, \"utf8\");\n        }\n        // calculate IV\n        var iv = cfg.iv ||\n                 util.randomBytes(CONSTANTS.NONCELENGTH[encAlg] / 8);\n        if (\"string\" === typeof iv) {\n          iv = util.base64url.decode(iv);\n        }\n        props.iv = iv;\n\n        if (\"recipients\" in jwe && jwe.recipients.length === 1) {\n          props.kdata = jwe.recipients[0].encrypted_key;\n        }\n\n        if (\"epu\" in cfg && cfg.epu != null) {\n          props.epu = cfg.epu;\n        }\n\n        if (\"epv\" in cfg && cfg.epv != null) {\n          props.epv = cfg.epv;\n        }\n\n        var pdata = jwe.plaintext;\n        delete jwe.plaintext;\n        return encKey.then(function(encKey) {\n          var p = encKey.encrypt(encAlg, pdata, props);\n          p = p.then(function(result) {\n            jwe.iv = util.base64url.encode(iv, \"binary\");\n            if (\"aad\" in cfg && cfg.aad != null) {\n             jwe.aad = cfg.aad;\n            }\n            jwe.ciphertext = util.base64url.encode(result.data, \"binary\");\n            jwe.tag = util.base64url.encode(result.tag, \"binary\");\n            return jwe;\n          });\n          return p;\n        });\n      });\n\n      // (OPTIONAL) compact/flattened results\n      switch (format) {\n        case \"compact\":\n          promise = promise.then(function(jwe) {\n            var compact = new Array(5);\n\n            compact[0] = jwe.protected;\n            if (jwe.recipients && jwe.recipients[0]) {\n              compact[1] = jwe.recipients[0].encrypted_key;\n            }\n\n            compact[2] = jwe.iv;\n            compact[3] = jwe.ciphertext;\n            compact[4] = jwe.tag;\n            compact = compact.join(\".\");\n\n            return compact;\n          });\n          break;\n        case \"flattened\":\n          promise = promise.then(function(jwe) {\n            var flattened = {},\n                rcpt = jwe.recipients && jwe.recipients[0];\n\n            if (jwe.protected) {\n              flattened.protected = jwe.protected;\n            }\n            if (jwe.unprotected) {\n              flattened.unprotected = jwe.unprotected;\n            }\n            [\"header\", \"encrypted_key\"].forEach(function(f) {\n              if (!rcpt) { return; }\n              if (!(f in rcpt)) { return; }\n              if (!rcpt[f]) { return; }\n              if (\"object\" === typeof rcpt[f] && !Object.keys(rcpt[f]).length) { return; }\n              flattened[f] = rcpt[f];\n            });\n            if (jwe.aad) {\n              flattened.aad = jwe.aad;\n            }\n            flattened.iv = jwe.iv;\n            flattened.ciphertext = jwe.ciphertext;\n            flattened.tag = jwe.tag;\n\n            return flattened;\n          });\n          break;\n        case \"general\":\n          promise = promise.then(function(jwe) {\n            var recipients = jwe.recipients || [];\n            recipients = recipients.map(function (rcpt) {\n              if (!Object.keys(rcpt).length) { return undefined; }\n              return rcpt;\n            });\n            recipients = recipients.filter(function (rcpt) { return !!rcpt; });\n            if (recipients.length) {\n              jwe.recipients = recipients;\n            } else {\n              delete jwe.recipients;\n            }\n\n            return jwe;\n          });\n      }\n\n      return promise;\n    }\n  });\n}\n\nfunction createEncrypt(opts, rcpts) {\n  // fixup recipients\n  var options = opts,\n    rcptStart = 1,\n    rcptList = rcpts;\n\n  if (arguments.length === 0) {\n    throw new Error(\"at least one recipient must be provided\");\n  }\n  if (arguments.length === 1) {\n    // assume opts is the recipient list\n    rcptList = opts;\n    rcptStart = 0;\n    options = {};\n  } else if (JWK.isKey(opts) ||\n        (opts && \"kty\" in opts) ||\n        (opts && \"key\" in opts &&\n        (JWK.isKey(opts.key) || \"kty\" in opts.key))) {\n    rcptList = opts;\n    rcptStart = 0;\n    options = {};\n  } else {\n    options = clone(opts);\n  }\n  if (!Array.isArray(rcptList)) {\n    rcptList = slice(arguments, rcptStart);\n  }\n\n  // fixup options\n  options = assign(clone(DEFAULTS), options);\n\n  // setup header fields\n  var fields = clone(options.fields || {});\n  if (options.zip) {\n    fields.zip = (typeof options.zip === \"boolean\") ?\n           (options.zip ? \"DEF\" : false) :\n           options.zip;\n  }\n  options.format = (options.compact ? \"compact\" : options.format) || \"general\";\n  switch (options.format) {\n    case \"compact\":\n      if (\"aad\" in opts) {\n        throw new Error(\"additional authenticated data cannot be used for compact serialization\");\n      }\n      /* eslint no-fallthrough: [0] */\n    case \"flattened\":\n      if (rcptList.length > 1) {\n        throw new Error(\"too many recipients for compact serialization\");\n      }\n      break;\n  }\n\n  // note protected fields (globally)\n  // protected fields are global only\n  var protectAll = false;\n  if (\"compact\" === options.format || \"*\" === options.protect) {\n    protectAll = true;\n    options.protect = Object.keys(fields).concat(\"enc\");\n  } else if (typeof options.protect === \"string\") {\n    options.protect = [options.protect];\n  } else if (Array.isArray(options.protect)) {\n    options.protect = options.protect.concat();\n  } else if (!options.protect) {\n    options.protect = [];\n  } else {\n    throw new Error(\"protect must be a list of fields\");\n  }\n\n  if (protectAll && 1 < rcptList.length) {\n    throw new Error(\"too many recipients to protect all header parameters\");\n  }\n\n  rcptList = rcptList.map(function(r, idx) {\n    var p;\n\n    // resolve a key\n    if (r && \"kty\" in r) {\n      p = JWK.asKey(r);\n      p = p.then(function(k) {\n        return {\n          key: k\n        };\n      });\n    } else if (r) {\n      p = JWK.asKey(r.key);\n      p = p.then(function(k) {\n        return {\n          header: r.header,\n          reference: r.reference,\n          key: k\n        };\n      });\n    } else {\n      p = Promise.reject(new Error(\"missing key for recipient \" + idx));\n    }\n\n    // convert ephemeral key (if present)\n    if (r.epk) {\n      p = p.then(function(recipient) {\n        return JWK.asKey(r.epk).\n          then(function(epk) {\n            recipient.epk = epk;\n            return recipient;\n          });\n      });\n    }\n\n    // resolve the complete recipient\n    p = p.then(function(recipient) {\n      var key = recipient.key;\n\n      // prepare the recipient header\n      var header = recipient.header || {};\n      recipient.header = header;\n      var props = {};\n      props = assign(props, fields);\n      props = assign(props, recipient.header);\n\n      // ensure key protection algorithm is set\n      if (!props.alg) {\n        props.alg = key.algorithms(JWK.MODE_WRAP)[0];\n        header.alg = props.alg;\n      }\n      if (!props.alg) {\n        return Promise.reject(new Error(\"key not valid for encrypting to recipient \" + idx));\n      }\n      header.alg = props.alg;\n\n      // determine the key reference\n      var ref = recipient.reference;\n      delete recipient.reference;\n      if (undefined === ref) {\n        // header already contains the key reference\n        ref = [\"kid\", \"jku\", \"x5c\", \"x5t\", \"x5u\"].some(function(k) {\n          return (k in header);\n        });\n        ref = !ref ? \"kid\" : null;\n      } else if (\"boolean\" === typeof ref) {\n        // explicit (positive | negative) request for key reference\n        ref = ref ? \"kid\" : null;\n      }\n      var jwk;\n      if (ref) {\n        jwk = key.toJSON();\n        if (\"jwk\" === ref) {\n          if (\"oct\" === key.kty) {\n            return Promise.reject(new Error(\"cannot embed key\"));\n          }\n          header.jwk = jwk;\n        } else if (ref in jwk) {\n          header[ref] = jwk[ref];\n        }\n      }\n\n      // freeze recipient\n      recipient = Object.freeze(recipient);\n      return recipient;\n    });\n\n    return p;\n  });\n\n  // create and configure encryption\n  var cfg = {\n    aad: (\"aad\" in options) ? util.base64url.encode(options.aad || \"\") : null,\n    contentAlg: options.contentAlg,\n    format: options.format,\n    protect: options.protect,\n    cek: options.cek,\n    iv: options.iv,\n    protectAll: protectAll\n  };\n  var enc = new JWEEncrypter(cfg, fields, rcptList);\n\n  return enc;\n}\n\nmodule.exports = {\n  encrypter: JWEEncrypter,\n  createEncrypt: createEncrypt\n};\n","/*!\n * jwe/helpers.js - JWE Internal Helper Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar CONSTANTS = require(\"../algorithms/constants\"),\n    JWK = require(\"../jwk\");\n\nmodule.exports = {\n  slice: function(input, start) {\n    return Array.prototype.slice.call(input, start || 0);\n  },\n  generateCEK: function(enc) {\n    var ks = JWK.createKeyStore();\n    var len = CONSTANTS.KEYLENGTH[enc];\n\n    if (len) {\n        return ks.generate(\"oct\", len);\n    }\n\n    throw new Error(\"unsupported encryption algorithm\");\n  }\n};\n","/*!\n * jwe/index.js - JSON Web Encryption (JWE) Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar JWE = {\n  createEncrypt: require(\"./encrypt\").createEncrypt,\n  createDecrypt: require(\"./decrypt\").createDecrypt\n};\n\nmodule.exports = JWE;\n","/*!\n * jwk/basekey.js - JWK Key Base Class Implementation\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar merge = require(\"../util/merge\");\nconst { v4: uuidv4 } = require(\"uuid\");\n\nvar assign = require(\"lodash/assign\");\nvar clone = require(\"lodash/clone\");\nvar flatten = require(\"lodash/flatten\");\nvar intersection = require(\"lodash/intersection\");\nvar omit = require(\"lodash/omit\");\nvar pick = require(\"lodash/pick\");\nvar uniq = require(\"lodash/uniq\");\n\nvar ALGORITHMS = require(\"../algorithms\"),\n    CONSTANTS = require(\"./constants.js\"),\n    HELPERS = require(\"./helpers.js\"),\n    UTIL = require(\"../util\");\n\n/**\n * @class JWK.Key\n * @classdesc\n * Represents a JSON Web Key instance.\n *\n * @description\n * **NOTE:** This class cannot be instantiated directly. Instead call\n * {@link JWK.asKey}, {@link JWK.KeyStore#add}, or\n * {@link JWK.KeyStore#generate}.\n */\nvar JWKBaseKeyObject = function(kty, ks, props, cfg) {\n  // ### validate/coerce arguments ###\n  if (!kty) {\n    throw new Error(\"kty cannot be null\");\n  }\n\n  if (!ks) {\n    throw new Error(\"keystore cannot be null\");\n  }\n\n  if (!props) {\n    throw new Error(\"props cannot be null\");\n  } else if (\"string\" === typeof props) {\n    props = JSON.parse(props);\n  }\n\n  if (!cfg) {\n    throw new Error(\"cfg cannot be null\");\n  }\n\n  var excluded = [];\n  var keys = {},\n      json = {},\n      prints,\n      kid;\n\n  props = clone(props);\n  // strip thumbprints if present\n  prints = assign({}, props[HELPERS.INTERNALS.THUMBPRINT_KEY] || {});\n  delete props[HELPERS.INTERNALS.THUMBPRINT_KEY];\n  Object.keys(prints).forEach(function(a) {\n    var h = prints[a];\n    if (!kid) {\n      kid = h;\n      if (Buffer.isBuffer(kid)) {\n        kid = UTIL.base64url.encode(kid);\n      }\n    }\n    if (!Buffer.isBuffer(h)) {\n      h = UTIL.base64url.decode(h);\n      prints[a] = h;\n    }\n  });\n\n  // force certain values\n  props.kty = kty;\n  props.kid = props.kid || kid || uuidv4();\n\n  // setup base info\n  var included = Object.keys(HELPERS.COMMON_PROPS).map(function(p) {\n    return HELPERS.COMMON_PROPS[p].name;\n  });\n  json.base = pick(props, included);\n  excluded = excluded.concat(Object.keys(json.base));\n\n  // setup public information\n  json.public = clone(props);\n  keys.public = cfg.publicKey(json.public);\n  if (keys.public) {\n    // exclude public values from extra\n    excluded = excluded.concat(Object.keys(json.public));\n  }\n\n  // setup private information\n  json.private = clone(props);\n  keys.private = cfg.privateKey(json.private);\n  if (keys.private) {\n    // exclude private values from extra\n    excluded = excluded.concat(Object.keys(json.private));\n  }\n\n  // setup extra information\n  json.extra = omit(props, excluded);\n\n  // TODO: validate 'alg' against supported algorithms\n\n  // setup calculated values\n  var keyLen;\n  if (keys.public && (\"length\" in keys.public)) {\n    keyLen = keys.public.length;\n  } else if (keys.private && (\"length\" in keys.private)) {\n    keyLen = keys.private.length;\n  } else {\n    keyLen = NaN;\n  }\n\n  // ### Public Properties ###\n  /**\n   * @member {JWK.KeyStore} JWK.Key#keystore\n   * @description\n   * The owning keystore.\n   */\n  Object.defineProperty(this, \"keystore\", {\n    value: ks,\n    enumerable: true\n  });\n  /**\n   * @member {Number} JWK.Key#length\n   * @description\n   * The size of this Key, in bits.\n   */\n  Object.defineProperty(this, \"length\", {\n    value: keyLen,\n    enumerable: true\n  });\n  /**\n   * @member {String} JWK.Key#kty\n   * @description\n   * The type of Key.\n   */\n  Object.defineProperty(this, \"kty\", {\n    value: kty,\n    enumerable: true\n  });\n\n  /**\n   * @member {String} JWK.Key#kid\n   * @description\n   * The identifier for this Key.\n   */\n  Object.defineProperty(this, \"kid\", {\n    value: json.base.kid,\n    enumerable: true\n  });\n  /**\n   * @member {String} JWK.Key#use\n   * @description\n   * The usage for this Key.\n   */\n  Object.defineProperty(this, \"use\", {\n    value: json.base.use || \"\",\n    enumerable: true\n  });\n  /**\n   * @member {String} JWK.Key#alg\n   * @description\n   * The sole algorithm this key can be used for.\n   */\n  Object.defineProperty(this, \"alg\", {\n    value: json.base.alg || \"\",\n    enumerable: true\n  });\n\n  // ### Public Methods ###\n  /**\n   * Generates the thumbprint of this Key.\n   *\n   * @param {String} [] The hash algorithm to use\n   * @returns {Promise} The promise for the thumbprint generation.\n   */\n  Object.defineProperty(this, \"thumbprint\", {\n    value: function(hash) {\n      hash = (hash || HELPERS.INTERNALS.THUMBPRINT_HASH).toUpperCase();\n      if (prints[hash]) {\n        // return cached value\n        return Promise.resolve(prints[hash]);\n      }\n      var p = HELPERS.thumbprint(cfg, json, hash);\n      p = p.then(function(result) {\n        if (result) {\n          prints[hash] = result;\n        }\n        return result;\n      });\n      return p;\n    }\n  });\n  /**\n   * @method JWK.Key#algorithms\n   * @description\n   * The possible algorithms this Key can be used for. The returned\n   * list is not any particular order, but is filtered based on the\n   * Key's intended usage.\n   *\n   * @param {String} mode The operation mode\n   * @returns {String[]} The list of supported algorithms\n   * @see JWK.Key#supports\n   */\n  Object.defineProperty(this, \"algorithms\", {\n    value: function(mode) {\n      var modes = [];\n      if (!this.use || this.use === \"sig\") {\n        if (!mode || CONSTANTS.MODE_SIGN === mode) {\n          modes.push(CONSTANTS.MODE_SIGN);\n        }\n        if (!mode || CONSTANTS.MODE_VERIFY === mode) {\n          modes.push(CONSTANTS.MODE_VERIFY);\n        }\n      }\n      if (!this.use || this.use === \"enc\") {\n        if (!mode || CONSTANTS.MODE_ENCRYPT === mode) {\n          modes.push(CONSTANTS.MODE_ENCRYPT);\n        }\n        if (!mode || CONSTANTS.MODE_DECRYPT === mode) {\n          modes.push(CONSTANTS.MODE_DECRYPT);\n        }\n        if (!mode || CONSTANTS.MODE_WRAP === mode) {\n          modes.push(CONSTANTS.MODE_WRAP);\n        }\n        if (!mode || CONSTANTS.MODE_UNWRAP === mode) {\n          modes.push(CONSTANTS.MODE_UNWRAP);\n        }\n      }\n\n      var self = this;\n      var algs = modes.map(function(m) {\n        return cfg.algorithms.call(self, keys, m);\n      });\n      algs = flatten(algs);\n      algs = uniq(algs);\n      if (this.alg) {\n        // TODO: fix this correctly\n        var valid;\n        if (\"oct\" === kty) {\n          valid = [this.alg, \"dir\"];\n        } else {\n          valid = [this.alg];\n        }\n        algs = intersection(algs, valid);\n      }\n\n      return algs;\n    }\n  });\n  /**\n   * @method JWK.Key#supports\n   * @description\n   * Determines if the given algorithm is supported.\n   *\n   * @param {String} alg The algorithm in question\n   * @param {String} [mode] The operation mode\n   * @returns {Boolean} `true` if {alg} is supported, and `false` otherwise.\n   * @see JWK.Key#algorithms\n   */\n  Object.defineProperty(this, \"supports\", {\n    value: function(alg, mode) {\n      return (this.algorithms(mode).indexOf(alg) !== -1);\n    }\n  });\n  /**\n   * @method JWK.Key#has\n   * @description\n   * Determines if this Key contains the given parameter.\n   *\n   * @param {String} name The name of the parameter\n   * @param {Boolean} [isPrivate=false] `true` if private parameters should be\n   *        checked.\n   * @returns {Boolean} `true` if the given parameter is present; `false`\n   *          otherwise.\n   */\n  Object.defineProperty(this, \"has\", {\n    value: function(name, isPrivate) {\n      var contains = false;\n      contains = contains || !!(json.base &&\n                                (name in json.base));\n      contains = contains || !!(keys.public &&\n                                (name in keys.public));\n      contains = contains || !!(json.extra &&\n                                (name in json.extra));\n      contains = contains || !!(isPrivate &&\n                                keys.private &&\n                                (name in keys.private));\n      // TODO: check for export restrictions\n\n      return contains;\n    }\n  });\n  /**\n   * @method JWK.Key#get\n   * @description\n   * Retrieves the value of the given parameter. The value returned by this\n   * method is in its natural format, which might not exactly match its\n   * JSON encoding (e.g., a binary string rather than a base64url-encoded\n   * string).\n   *\n   * **NOTE:** This method can return `false`. Call\n   * {@link JWK.Key#has} to determine if the parameter is present.\n   *\n   * @param {String} name The name of the parameter\n   * @param {Boolean} [isPrivate=false] `true` if private parameters should\n   *        be checked.\n   * @returns {any} The value of the named parameter, or undefined if\n   *          it is not present.\n   */\n  Object.defineProperty(this, \"get\", {\n    value: function(name, isPrivate) {\n      var src;\n      if (json.base && (name in json.base)) {\n        src = json.base;\n      } else if (keys.public && (name in keys.public)) {\n        src = keys.public;\n      } else if (json.extra && (name in json.extra)) {\n        src = json.extra;\n      } else if (isPrivate && keys.private && (name in keys.private)) {\n        // TODO: check for export restrictions\n        src = keys.private;\n      }\n\n      return src && src[name] || null;\n    }\n  });\n  /**\n   * @method JWK.Key#toJSON\n   * @description\n   * Returns the JSON representation of this Key.  All properties of the\n   * returned JSON object are properly encoded (e.g., base64url encoding for\n   * any binary strings).\n   *\n   * @param {Boolean} [isPrivate=false] `true` if private parameters should be\n   *        included.\n   * @param {String[]} [excluded] The list of parameters to exclude from\n   *        the returned JSON.\n   * @returns {Object} The plain JSON object\n   */\n  Object.defineProperty(this, \"toJSON\", {\n    value: function(isPrivate, excluded) {\n      // coerce arguments\n      if (Array.isArray(isPrivate)) {\n        excluded = isPrivate;\n        isPrivate = false;\n      }\n      var result = {};\n\n      // TODO: check for export restrictions\n      result = merge(result,\n                       json.base,\n                       json.public,\n                       (\"boolean\" === typeof isPrivate && isPrivate) ? json.private : {},\n                       json.extra);\n      result = omit(result, excluded || []);\n\n      return result;\n    }\n  });\n\n  /**\n   * @method JWK.Key#toPEM\n   * @description\n   * Returns the PEM representation of this Key as a string.\n   *\n   * @param {Boolean} [isPrivate=false] `true` if private parameters should be\n   *        included.\n   * @returns {string} The PEM-encoded string\n   */\n  Object.defineProperty(this, \"toPEM\", {\n    value: function(isPrivate) {\n      if (isPrivate === null) {\n        isPrivate = false;\n      }\n\n      if (!cfg.convertToPEM) {\n        throw new Error(\"Unsupported key type for PEM encoding\");\n      }\n      var k = (isPrivate) ? keys.private : keys.public;\n      if (!k) {\n        throw new Error(\"Invalid key\");\n      }\n      return cfg.convertToPEM.call(this, k, isPrivate);\n    }\n  });\n\n  /**\n   * @method JWK.Key#toObject\n   * @description\n   * Returns the plain object representing this Key.  All properties of the\n   * returned object are in their natural encoding (e.g., binary strings\n   * instead of base64url encoded).\n   *\n   * @param {Boolean} [isPrivate=false] `true` if private parameters should be\n   *        included.\n   * @param {String[]} [excluded] The list of parameters to exclude from\n   *        the returned object.\n   * @returns {Object} The plain Object.\n   */\n  Object.defineProperty(this, \"toObject\", {\n    value: function(isPrivate, excluded) {\n      // coerce arguments\n      if (Array.isArray(isPrivate)) {\n        excluded = isPrivate;\n        isPrivate = false;\n      }\n      var result = {};\n\n      // TODO: check for export restrictions\n      result = merge(result,\n                       json.base,\n                       keys.public,\n                       (\"boolean\" === typeof isPrivate && isPrivate) ? keys.private : {},\n                       json.extra);\n      result = omit(result, (excluded || []).concat(\"length\"));\n\n      return result;\n    }\n  });\n\n  /**\n   * @method JWK.Key#sign\n   * @description\n   * Sign the given data using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive signing operation; the output is\n   * _**NOT**_ a JSON Web Signature (JWS) object.\n   *\n   * The Promise, when fulfilled, returns an Object with the following\n   * properties:\n   *\n   * + **data**: The data that was signed (and should be equal to {data}).\n   * + **mac**: The signature or message authentication code (MAC).\n   *\n   * @param {String} alg The signing algorithm\n   * @param {String|Buffer} data The data to sign\n   * @param {Object} [props] Additional properties for the signing\n   *        algorithm.\n   * @returns {Promise} The promise for the signing operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         this Key does not contain the appropriate parameters.\n   */\n  Object.defineProperty(this, \"sign\", {\n    value: function(alg, data, props) {\n      // validate appropriateness\n      if (this.algorithms(\"sign\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.signKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.signProps) {\n        props = merge(props, cfg.signProps.call(this, alg, props));\n      }\n      return ALGORITHMS.sign(alg, k, data, props);\n    }\n  });\n  /**\n   * @method JWK.Key#verify\n   * @description\n   * Verify the given data and signature using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive verification operation; the input is\n   * _**NOT**_ a JSON Web Signature.</p>\n   *\n   * The Promise, when fulfilled, returns an Object with the following\n   * properties:\n   *\n   * + **data**: The data that was verified (and should be equal to\n   *   {data}).\n   * + **mac**: The signature or MAC that was verified (and should be equal\n   *   to {mac}).\n   * + **valid**: `true` if {mac} is valid for {data}.\n   *\n   * @param {String} alg The verification algorithm\n   * @param {String|Buffer} data The data to verify\n   * @param {String|Buffer} mac The signature or MAC to verify\n   * @param {Object} [props] Additional properties for the verification\n   *        algorithm.\n   * @returns {Promise} The promise for the verification operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         the Key does not contain the appropriate properties.\n   */\n  Object.defineProperty(this, \"verify\", {\n    value: function(alg, data, mac, props) {\n      // validate appropriateness\n      if (this.algorithms(\"verify\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.verifyKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.verifyProps) {\n        props = merge(props, cfg.verifyProps.call(this, alg, props));\n      }\n      return ALGORITHMS.verify(alg, k, data, mac, props);\n    }\n  });\n\n  /**\n   * @method JWK.Key#encrypt\n   * @description\n   * Encrypts the given data using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive encryption operation; the output is\n   * _**NOT**_ a JSON Web Encryption (JWE) object.\n   *\n   * **NOTE:** This operation is treated as distinct from {@link\n   * JWK.Key#wrap}, as different algorithms and properties are often\n   * used for wrapping a key versues encrypting arbitrary data.\n   *\n   * The Promise, when fulfilled, returns an object with the following\n   * properties:\n   *\n   * + **data**: The ciphertext data\n   * + **mac**: The associated message authentication code (MAC).\n   *\n   * @param {String} alg The encryption algorithm\n   * @param {Buffer|String} data The data to encrypt\n   * @param {Object} [props] Additional properties for the encryption\n   *        algorithm.\n   * @returns {Promise} The promise for the encryption operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         this Key does not contain the appropriate parameters.\n   */\n  Object.defineProperty(this, \"encrypt\", {\n    value: function(alg, data, props) {\n      // validate appropriateness\n      if (this.algorithms(\"encrypt\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.encryptKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.encryptProps) {\n        props = merge(props, cfg.encryptProps.call(this, alg, props));\n      }\n      return ALGORITHMS.encrypt(alg, k, data, props);\n    }\n  });\n  /**\n   * @method JWK.Key#decrypt\n   * @description\n   * Decrypts the given data using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive decryption operation; the input is\n   * _**NOT**_ a JSON Web Encryption (JWE) object.\n   *\n   * **NOTE:** This operation is treated as distinct from {@link\n   * JWK.Key#unwrap}, as different algorithms and properties are often used\n   * for unwrapping a key versues decrypting arbitrary data.\n   *\n   * The Promise, when fulfilled, returns the plaintext data.\n   *\n   * @param {String} alg The decryption algorithm.\n   * @param {Buffer|String} data The data to decypt.\n   * @param {Object} [props] Additional data for the decryption operation.\n   * @returns {Promise} The promise for the decryption operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         the Key does not contain the appropriate properties.\n   */\n  Object.defineProperty(this, \"decrypt\", {\n    value: function(alg, data, props) {\n      // validate appropriateness\n      if (this.algorithms(\"decrypt\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.decryptKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.decryptProps) {\n        props = merge(props, cfg.decryptProps.call(this, alg, props));\n      }\n      return ALGORITHMS.decrypt(alg, k, data, props);\n    }\n  });\n\n  /**\n   * @method JWK.Key#wrap\n   * @description\n   * Wraps the given key using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive encryption operation; the output is\n   * _**NOT**_ a JSON Web Encryption (JWE) object.\n   *\n   * **NOTE:** This operation is treated as distinct from {@link\n   * JWK.Key#encrypt}, as different algorithms and properties are\n   * often used for wrapping a key versues encrypting arbitrary data.\n   *\n   * The Promise, when fulfilled, returns an object with the following\n   * properties:\n   *\n   * + **data**: The ciphertext data\n   * + **headers**: The additional header parameters to apply to a JWE.\n   *\n   * @param {String} alg The encryption algorithm\n   * @param {Buffer|String} data The data to encrypt\n   * @param {Object} [props] Additional properties for the encryption\n   *        algorithm.\n   * @returns {Promise} The promise for the encryption operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         this Key does not contain the appropriate parameters.\n   */\n  Object.defineProperty(this, \"wrap\", {\n    value: function(alg, data, props) {\n      // validate appropriateness\n      if (this.algorithms(\"wrap\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.wrapKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.wrapProps) {\n        props = merge(props, cfg.wrapProps.call(this, alg, props));\n      }\n      return ALGORITHMS.encrypt(alg, k, data, props);\n    }\n  });\n  /**\n   * @method JWK.Key#unwrap\n   * @description\n   * Unwraps the given key using the specified algorithm.\n   *\n   * **NOTE:** This is the primitive unwrap operation; the input is\n   * _**NOT**_ a JSON Web Encryption (JWE) object.\n   *\n   * **NOTE:** This operation is treated as distinct from {@link\n   * JWK.Key#decrypt}, as different algorithms and properties are often used\n   * for unwrapping a key versues decrypting arbitrary data.\n   *\n   * The Promise, when fulfilled, returns the unwrapped key.\n   *\n   * @param {String} alg The unwrap algorithm.\n   * @param {Buffer|String} data The data to unwrap.\n   * @param {Object} [props] Additional data for the unwrap operation.\n   * @returns {Promise} The promise for the unwrap operation.\n   * @throws {Error} If {alg} is not appropriate for this Key; or if\n   *         the Key does not contain the appropriate properties.\n   */\n  Object.defineProperty(this, \"unwrap\", {\n    value: function(alg, data, props) {\n      // validate appropriateness\n      if (this.algorithms(\"unwrap\").indexOf(alg) === -1) {\n        return Promise.reject(new Error(\"unsupported algorithm\"));\n      }\n      var k = cfg.unwrapKey.call(this, alg, keys);\n      if (!k) {\n        return Promise.reject(new Error(\"improper key\"));\n      }\n\n      // prepare properties (if any)\n      props = (props) ?\n              clone(props) :\n              {};\n      if (cfg.unwrapProps) {\n        props = merge(props, cfg.unwrapProps.call(this, alg, props));\n      }\n      return ALGORITHMS.decrypt(alg, k, data, props);\n    }\n  });\n};\n\nmodule.exports = JWKBaseKeyObject;\n","/*!\n * jwk/constants.js - Constants for JWKs\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nmodule.exports = {\n  MODE_SIGN: \"sign\",\n  MODE_VERIFY: \"verify\",\n  MODE_ENCRYPT: \"encrypt\",\n  MODE_DECRYPT: \"decrypt\",\n  MODE_WRAP: \"wrap\",\n  MODE_UNWRAP: \"unwrap\"\n};\n","/*!\n * jwk/rsa.js - RSA Key Representation\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar ecutil = require(\"../algorithms/ec-util.js\"),\n    forge = require(\"../deps/forge\"),\n    depsecc = require(\"../deps/ecc\");\n\nvar JWK = {\n  BaseKey: require(\"./basekey.js\"),\n  helpers: require(\"./helpers.js\")\n};\n\nvar SIG_ALGS = [\n  \"ES256\",\n  \"ES384\",\n  \"ES512\"\n];\nvar WRAP_ALGS = [\n  \"ECDH-ES\",\n  \"ECDH-ES+A128KW\",\n  \"ECDH-ES+A192KW\",\n  \"ECDH-ES+A256KW\"\n];\n\nvar EC_OID = ecutil.EC_OID;\nfunction oidToCurveName(oid) {\n  switch (oid) {\n    case \"1.2.840.10045.3.1.7\":\n      return \"P-256\";\n    case \"1.3.132.0.34\":\n      return \"P-384\";\n    case \"1.3.132.0.35\":\n      return \"P-521\";\n    default:\n      return null;\n  }\n}\n\nvar JWKEcCfg = {\n  publicKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n      {name: \"crv\", type: \"string\"},\n      {name: \"x\", type: \"binary\"},\n      {name: \"y\", type: \"binary\"}\n    ]);\n    var pk = JWK.helpers.unpackProps(props, fields);\n    if (pk && pk.crv && pk.x && pk.y) {\n      pk.length = ecutil.curveSize(pk.crv);\n    } else {\n      delete pk.crv;\n      delete pk.x;\n      delete pk.y;\n    }\n\n    return pk;\n  },\n  privateKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n      {name: \"crv\", type: \"string\"},\n      {name: \"x\", type: \"binary\"},\n      {name: \"y\", type: \"binary\"},\n      {name: \"d\", type: \"binary\"}\n    ]);\n    var pk = JWK.helpers.unpackProps(props, fields);\n    if (pk && pk.crv && pk.x && pk.y && pk.d) {\n      pk.length = ecutil.curveSize(pk.crv);\n    } else {\n      pk = undefined;\n    }\n\n    return pk;\n  },\n  thumbprint: function(json) {\n    if (json.public) {\n      json = json.public;\n    }\n    var fields = {\n      crv: json.crv,\n      kty: \"EC\",\n      x: json.x,\n      y: json.y\n    };\n    return fields;\n  },\n  algorithms: function(keys, mode) {\n    var len = (keys.public && keys.public.length) ||\n              (keys.private && keys.private.length) ||\n              0;\n    // NOTE: 521 is the actual, but 512 is the expected\n    if (len === 521) {\n        len = 512;\n    }\n\n    switch (mode) {\n      case \"encrypt\":\n      case \"decrypt\":\n        return [];\n      case \"wrap\":\n        return (keys.public && WRAP_ALGS) || [];\n      case \"unwrap\":\n        return (keys.private && WRAP_ALGS) || [];\n      case \"sign\":\n        if (!keys.private) {\n          return [];\n        }\n        return SIG_ALGS.filter(function(a) {\n          return (a === (\"ES\" + len));\n        });\n      case \"verify\":\n        if (!keys.public) {\n          return [];\n        }\n        return SIG_ALGS.filter(function(a) {\n          return (a === (\"ES\" + len));\n        });\n    }\n  },\n\n  encryptKey: function(alg, keys) {\n    return keys.public;\n  },\n  decryptKey: function(alg, keys) {\n    return keys.private;\n  },\n\n  wrapKey: function(alg, keys) {\n    return keys.public;\n  },\n  unwrapKey: function(alg, keys) {\n    return keys.private;\n  },\n\n  signKey: function(alg, keys) {\n    return keys.private;\n  },\n  verifyKey: function(alg, keys) {\n    return keys.public;\n  }\n};\nJWKEcCfg.convertToPEM = ecutil.convertToPEM;\n\n// Inspired by digitalbaazar/node-forge/js/rsa.js\nvar validators = {\n  oid: EC_OID,\n  privateKey: {\n    // ECPrivateKey\n    name: \"ECPrivateKey\",\n    tagClass: forge.asn1.Class.UNIVERSAL,\n    type: forge.asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [\n      {\n        // EC version\n        name: \"ECPrivateKey.version\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false\n      },\n      {\n        // private value (d)\n        name: \"ECPrivateKey.private\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.OCTETSTRING,\n        constructed: false,\n        capture: \"d\"\n      },\n      {\n        // EC parameters\n        tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n        name: \"ECPrivateKey.parameters\",\n        constructed: true,\n        value: [\n          {\n            // namedCurve (crv)\n            name: \"ECPrivateKey.namedCurve\",\n            tagClass: forge.asn1.Class.UNIVERSAL,\n            type: forge.asn1.Type.OID,\n            constructed: false,\n            capture: \"crv\"\n          }\n        ]\n      },\n      {\n        // publicKey\n        name: \"ECPrivateKey.publicKey\",\n        tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n        constructed: true,\n        value: [\n          {\n            name: \"ECPrivateKey.point\",\n            tagClass: forge.asn1.Class.UNIVERSAL,\n            type: forge.asn1.Type.BITSTRING,\n            constructed: false,\n            capture: \"point\"\n          }\n        ]\n      }\n    ]\n  },\n  embeddedPrivateKey: {\n    // ECPrivateKey\n    name: \"ECPrivateKey\",\n    tagClass: forge.asn1.Class.UNIVERSAL,\n    type: forge.asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [\n      {\n        // EC version\n        name: \"ECPrivateKey.version\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false\n      },\n      {\n        // private value (d)\n        name: \"ECPrivateKey.private\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.OCTETSTRING,\n        constructed: false,\n        capture: \"d\"\n      },\n      {\n        // publicKey\n        name: \"ECPrivateKey.publicKey\",\n        tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n        constructed: true,\n        value: [\n          {\n            name: \"ECPrivateKey.point\",\n            tagClass: forge.asn1.Class.UNIVERSAL,\n            type: forge.asn1.Type.BITSTRING,\n            constructed: false,\n            capture: \"point\"\n          }\n        ]\n      }\n    ]\n  }\n};\n\nvar JWKEcFactory = {\n  kty: \"EC\",\n  validators: validators,\n  prepare: function(props) {\n    // TODO: validate key properties\n    var cfg = JWKEcCfg;\n    var p = Promise.resolve(props);\n    p = p.then(function(json) {\n      return JWK.helpers.thumbprint(cfg, json);\n    });\n    p = p.then(function(hash) {\n      var prints = {};\n      prints[JWK.helpers.INTERNALS.THUMBPRINT_HASH] = hash;\n      props[JWK.helpers.INTERNALS.THUMBPRINT_KEY] = prints;\n      return cfg;\n    });\n    return p;\n  },\n  generate: function(size) {\n    var keypair = depsecc.generateKeyPair(size);\n    var result = {\n      \"crv\": size,\n      \"x\": keypair.public.x,\n      \"y\": keypair.public.y,\n      \"d\": keypair.private.d\n    };\n    return Promise.resolve(result);\n  },\n  import: function(input) {\n    if (validators.oid !== input.keyOid) {\n      return null;\n    }\n\n    // coerce key params to OID\n    var crv;\n    if (input.keyParams && forge.asn1.Type.OID === input.keyParams.type) {\n      crv = forge.asn1.derToOid(input.keyParams.value);\n      crv = oidToCurveName(crv);\n    } else if (input.crv) {\n      crv = forge.asn1.derToOid(input.crv);\n      crv = oidToCurveName(crv);\n    }\n    if (!crv) {\n      return null;\n    }\n\n    if (!input.parsed) {\n      var capture = {},\n          errors = [];\n      if (\"private\" === input.type) {\n        // coerce capture.value to DER *iff* private\n        if (\"string\" === typeof input.keyValue) {\n          input.keyValue = forge.asn1.fromDer(input.keyValue);\n        } else if (Array.isArray(input.keyValue)) {\n          input.keyValue = input.keyValue[0];\n        }\n\n        if (!forge.asn1.validate(input.keyValue,\n                                 validators.embeddedPrivateKey,\n                                 capture,\n                                 errors)) {\n          return null;\n        }\n      } else {\n        capture.point = input.keyValue;\n      }\n      input = capture;\n    }\n\n    // convert factors to Buffers\n    var output = {\n      kty: \"EC\",\n      crv: crv\n    };\n    if (input.d) {\n      output.d = Buffer.from(input.d, \"binary\");\n    }\n    if (input.point) {\n      var pt = Buffer.from(input.point, \"binary\");\n      // only support uncompressed\n      if (4 !== pt.readUInt16BE(0)) {\n        return null;\n      }\n      pt = pt.slice(2);\n      var len = pt.length / 2;\n      output.x = pt.slice(0, len);\n      output.y = pt.slice(len);\n    }\n    return output;\n  }\n};\n// public API\nmodule.exports = Object.freeze({\n  config: JWKEcCfg,\n  factory: JWKEcFactory\n});\n\n// registration\n(function(REGISTRY) {\n  REGISTRY.register(JWKEcFactory);\n})(require(\"./keystore\").registry);\n","/*!\n * jwk/helpers.js - JWK Internal Helper Functions and Constants\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar clone = require(\"lodash/clone\"),\n    util = require(\"../util\"),\n    forge = require(\"../deps/forge\");\n\nvar ALGORITHMS = require(\"../algorithms\");\n\n// ### ASN.1 Validators\n// Adapted from digitalbazaar/node-forge/js/asn1.js\n// PrivateKeyInfo\nvar privateKeyValidator = {\n  name: \"PrivateKeyInfo\",\n  tagClass: forge.asn1.Class.UNIVERSAL,\n  type: forge.asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [\n    {\n      // Version (INTEGER)\n      name: \"PrivateKeyInfo.version\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.INTEGER,\n      constructed: false,\n      capture: \"keyVersion\"\n    },\n    {\n      name: \"PrivateKeyInfo.privateKeyAlgorithm\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [\n        {\n          name: \"AlgorithmIdentifier.algorithm\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.OID,\n          constructed: false,\n          capture: \"keyOid\"\n        },\n        {\n          name: \"AlgorithmIdentifier.parameters\",\n          captureAsn1: \"keyParams\"\n        }\n      ]\n    },\n    {\n      name: \"PrivateKeyInfo\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.OCTETSTRING,\n      constructed: false,\n      capture: \"keyValue\"\n    }\n  ]\n};\n// Adapted from digitalbazaar/node-forge/x509.js\nvar publicKeyValidator = {\n  name: \"SubjectPublicKeyInfo\",\n  tagClass: forge.asn1.Class.UNIVERSAL,\n  type: forge.asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [\n    {\n      name: \"SubjectPublicKeyInfo.AlgorithmIdentifier\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [\n        {\n          name: \"AlgorithmIdentifier.algorithm\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.OID,\n          constructed: false,\n          capture: \"keyOid\"\n        },\n        {\n          name: \"AlgorithmIdentifier.parameters\",\n          captureAsn1: \"keyParams\"\n        }\n      ]\n    },\n    {\n      name: \"SubjectPublicKeyInfo.subjectPublicKey\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.BITSTRING,\n      constructed: false,\n      capture: \"keyValue\"\n    }\n  ]\n};\n// Adapted from digitalbazaar/node-forge/x509.js\nvar X509CertificateValidator = {\n  name: \"Certificate\",\n  tagClass: forge.asn1.Class.UNIVERSAL,\n  type: forge.asn1.Type.SEQUENCE,\n  constructed: true,\n  value: [\n    {\n      name: \"Certificate.TBSCertificate\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.SEQUENCE,\n      constructed: true,\n      captureAsn1: \"certificate\",\n      value: [\n        {\n          name: \"Certificate.TBSCertificate.version\",\n          tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n          type: 0,\n          constructed: true,\n          optional: true,\n          value: [\n            {\n              name: \"Certificate.TBSCertificate.version.integer\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.INTEGER,\n              constructed: false,\n              capture: \"certVersion\"\n            }\n          ]\n        },\n        {\n          name: \"Certificate.TBSCertificate.serialNumber\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.INTEGER,\n          constructed: false,\n          capture: \"certSerialNumber\"\n        },\n        {\n          name: \"Certificate.TBSCertificate.signature\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.SEQUENCE,\n          constructed: true,\n          value: [\n            {\n              name: \"Certificate.TBSCertificate.signature.algorithm\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.OID,\n              constructed: false,\n              capture: \"certSignatureOid\"\n            }, {\n              name: \"Certificate.TBSCertificate.signature.parameters\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              optional: true,\n              captureAsn1: \"certSignatureParams\"\n            }\n          ]\n        },\n        {\n          name: \"Certificate.TBSCertificate.issuer\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.SEQUENCE,\n          constructed: true,\n          captureAsn1: \"certIssuer\"\n        },\n        {\n          name: \"Certificate.TBSCertificate.validity\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.SEQUENCE,\n          constructed: true,\n          // Note: UTC and generalized times may both appear so the capture\n          // names are based on their detected order, the names used below\n          // are only for the common case, which validity time really means\n          // \"notBefore\" and which means \"notAfter\" will be determined by order\n          value: [\n            {\n              // notBefore (Time) (UTC time case)\n              name: \"Certificate.TBSCertificate.validity.notBefore (utc)\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.UTCTIME,\n              constructed: false,\n              optional: true,\n              capture: \"certValidity1UTCTime\"\n            },\n            {\n              // notBefore (Time) (generalized time case)\n              name: \"Certificate.TBSCertificate.validity.notBefore (generalized)\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.GENERALIZEDTIME,\n              constructed: false,\n              optional: true,\n              capture: \"certValidity2GeneralizedTime\"\n            },\n            {\n              // notAfter (Time) (only UTC time is supported)\n              name: \"Certificate.TBSCertificate.validity.notAfter (utc)\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.UTCTIME,\n              constructed: false,\n              optional: true,\n              capture: \"certValidity3UTCTime\"\n            },\n            {\n              // notAfter (Time) (only UTC time is supported)\n              name: \"Certificate.TBSCertificate.validity.notAfter (generalized)\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.GENERALIZEDTIME,\n              constructed: false,\n              optional: true,\n              capture: \"certValidity4GeneralizedTime\"\n            }\n          ]\n        }, {\n          // Name (subject) (RDNSequence)\n          name: \"Certificate.TBSCertificate.subject\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.SEQUENCE,\n          constructed: true,\n          captureAsn1: \"certSubject\"\n        },\n        // SubjectPublicKeyInfo\n        publicKeyValidator,\n        {\n          // issuerUniqueID (optional)\n          name: \"Certificate.TBSCertificate.issuerUniqueID\",\n          tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n          type: 1,\n          constructed: true,\n          optional: true,\n          value: [\n            {\n              name: \"Certificate.TBSCertificate.issuerUniqueID.id\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.BITSTRING,\n              constructed: false,\n              capture: \"certIssuerUniqueId\"\n            }\n          ]\n        },\n        {\n          // subjectUniqueID (optional)\n          name: \"Certificate.TBSCertificate.subjectUniqueID\",\n          tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n          type: 2,\n          constructed: true,\n          optional: true,\n          value: [\n            {\n              name: \"Certificate.TBSCertificate.subjectUniqueID.id\",\n              tagClass: forge.asn1.Class.UNIVERSAL,\n              type: forge.asn1.Type.BITSTRING,\n              constructed: false,\n              capture: \"certSubjectUniqueId\"\n            }\n          ]\n        },\n        {\n          // Extensions (optional)\n          name: \"Certificate.TBSCertificate.extensions\",\n          tagClass: forge.asn1.Class.CONTEXT_SPECIFIC,\n          type: 3,\n          constructed: true,\n          captureAsn1: \"certExtensions\",\n          optional: true\n        }\n      ]\n    },\n    {\n      // AlgorithmIdentifier (signature algorithm)\n      name: \"Certificate.signatureAlgorithm\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.SEQUENCE,\n      constructed: true,\n      value: [\n        {\n          // algorithm\n          name: \"Certificate.signatureAlgorithm.algorithm\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          type: forge.asn1.Type.OID,\n          constructed: false,\n          capture: \"certSignatureOid\"\n        },\n        {\n          name: \"Certificate.TBSCertificate.signature.parameters\",\n          tagClass: forge.asn1.Class.UNIVERSAL,\n          optional: true,\n          captureAsn1: \"certSignatureParams\"\n        }\n      ]\n    },\n    {\n      // SignatureValue\n      name: \"Certificate.signatureValue\",\n      tagClass: forge.asn1.Class.UNIVERSAL,\n      type: forge.asn1.Type.BITSTRING,\n      constructed: false,\n      capture: \"certSignature\"\n    }\n  ]\n};\n\nvar INTERNALS = {\n  THUMBPRINT_KEY: \"internal\\u0000thumbprint\",\n  THUMBPRINT_HASH: \"SHA-256\"\n};\n\nmodule.exports = {\n  validators: {\n    privateKey: privateKeyValidator,\n    publicKey: publicKeyValidator,\n    certificate: X509CertificateValidator\n  },\n\n  thumbprint: function(cfg, json, hash) {\n    if (\"function\" !== typeof cfg.thumbprint) {\n      return Promise.reject(new Error(\"thumbprint not supported\"));\n    }\n\n    hash = (hash || INTERNALS.THUMBPRINT_HASH).toUpperCase();\n    var fields = cfg.thumbprint(json);\n    var input = Object.keys(fields).\n                sort().\n                map(function(k) {\n      var v = fields[k];\n      if (Buffer.isBuffer(v)) {\n        v = util.base64url.encode(v);\n      }\n      return JSON.stringify(k) + \":\" + JSON.stringify(v);\n    });\n    input = \"{\" + input.join(\",\") + \"}\";\n    try {\n      return ALGORITHMS.digest(hash, Buffer.from(input, \"utf8\"));\n    } catch (err) {\n      return Promise.reject(err);\n    }\n  },\n  unpackProps: function(props, allowed) {\n    var output;\n\n    // apply all of the existing values\n    allowed.forEach(function(cfg) {\n      if (!(cfg.name in props)) {\n        return;\n      }\n      output = output || {};\n      var value = props[cfg.name];\n      switch (cfg.type) {\n        case \"binary\":\n          if (Buffer.isBuffer(value)) {\n            props[cfg.name] = util.base64url.encode(value);\n          } else {\n            value = util.base64url.decode(value);\n          }\n          break;\n        case \"string\":\n        case \"number\":\n        case \"boolean\":\n          break;\n        case \"array\":\n          value = [].concat(value);\n          break;\n        case \"object\":\n          value = clone(value);\n          break;\n        default:\n          // TODO: deep clone?\n          break;\n      }\n      output[cfg.name] = value;\n    });\n\n    // remove any from json that didn't apply\n    var check = output || {};\n    Object.keys(props).\n           forEach(function(n) {\n              if (n in check) { return; }\n              delete props[n];\n           });\n\n    return output;\n  },\n  COMMON_PROPS: [\n    {name: \"kty\", type: \"string\"},\n    {name: \"kid\", type: \"string\"},\n    {name: \"use\", type: \"string\"},\n    {name: \"alg\", type: \"string\"},\n    {name: \"x5c\", type: \"array\"},\n    {name: \"x5t\", type: \"binary\"},\n    {name: \"x5u\", type: \"string\"},\n    {name: \"key_ops\", type: \"array\"}\n  ],\n  INTERNALS: INTERNALS\n};\n","/*!\n * jwk/index.js - JSON Web Key (JWK) Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar JWKStore = require(\"./keystore.js\");\n\n// Public API -- Key and KeyStore methods\nObject.keys(JWKStore.KeyStore).forEach(function(name) {\n  exports[name] = JWKStore.KeyStore[name];\n});\n\n// Public API -- constants\nvar CONSTANTS = require(\"./constants.js\");\nObject.keys(CONSTANTS).forEach(function(name) {\n  exports[name] = CONSTANTS[name];\n});\n\n// Registered Key Types\nrequire(\"./octkey.js\");\nrequire(\"./rsakey.js\");\nrequire(\"./eckey.js\");\n","/*!\n * jwk/keystore.js - JWK KeyStore Implementation\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar clone = require(\"lodash/clone\"),\n    merge = require(\"../util/merge\"),\n    forge = require(\"../deps/forge\"),\n    util = require(\"../util\");\n\nvar JWK = {\n  BaseKey: require(\"./basekey.js\"),\n  helpers: require(\"./helpers.js\")\n};\n\n/**\n * @class JWK.KeyStoreRegistry\n * @classdesc\n * A registry of JWK.Key types that can be used.\n *\n * @description\n * **NOTE:** This constructor cannot be called directly. Instead use the\n * global {JWK.registry}\n */\nvar JWKRegistry = function() {\n  var types = {};\n\n  Object.defineProperty(this, \"register\", {\n    value: function(factory) {\n      if (!factory || \"string\" !== typeof factory.kty || !factory.kty) {\n        throw new Error(\"invalid Key factory\");\n      }\n\n      var kty = factory.kty;\n      types[kty] = factory;\n      return this;\n    }\n  });\n  Object.defineProperty(this, \"unregister\", {\n    value: function(factory) {\n      if (!factory || \"string\" !== typeof factory.kty || !factory.kty) {\n        throw new Error(\"invalid Key factory\");\n      }\n\n      var kty = factory.kty;\n      if (factory === types[kty]) {\n        delete types[kty];\n      }\n      return this;\n    }\n  });\n\n  Object.defineProperty(this, \"get\", {\n    value: function(kty) {\n      return types[kty || \"\"] || undefined;\n    }\n  });\n  Object.defineProperty(this, \"all\", {\n    value: function() {\n      return Object.keys(types).map(function(t) { return types[t]; });\n    }\n  });\n};\n\n// Globals\nvar GLOBAL_REGISTRY = new JWKRegistry();\n\n// importer\nfunction processCert(input) {\n  // convert certIssuer to readable attributes\n  [\"certIssuer\", \"certSubject\"].forEach(function(field) {\n    /* eslint new-cap: [0] */\n    var attrs = forge.pki.RDNAttributesAsArray(input[field]);\n    var result = input[field] = {};\n    attrs.forEach(function(a) {\n      result[a.name || a.type] = a.value;\n    });\n  });\n\n  return input;\n}\n\nfunction fromPEM(input) {\n  var result = {};\n  var pems = forge.pem.decode(input);\n  var found = pems.some(function(p) {\n    switch (p.type) {\n      case \"CERTIFICATE\":\n        result.form = \"pkix\";\n        break;\n      case \"PUBLIC KEY\":\n        result.form = \"spki\";\n        break;\n      case \"PRIVATE KEY\":\n        result.form = \"pkcs8\";\n        break;\n      case \"EC PRIVATE KEY\":\n        /* eslint no-fallthrough: [0] */\n      case \"RSA PRIVATE KEY\":\n        result.form = \"private\";\n        break;\n      default:\n        return false;\n    }\n\n    result.body = p.body;\n    return true;\n  });\n  if (!found) {\n    throw new Error(\"supported PEM type not found\");\n  }\n  return result;\n}\nfunction importFrom(registry, input) {\n  // form can be one of:\n  //  'private' | 'pkcs8' | 'public' | 'spki' | 'pkix' | 'x509'\n  var capture = {},\n      errors = [],\n      result;\n\n  // conver from DER to ASN1\n  var form = input.form,\n      der = input.body,\n      thumbprint = null;\n  input = forge.asn1.fromDer(der);\n  switch(form) {\n    case \"private\":\n      registry.all().some(function(factory) {\n        if (result) {\n          return false;\n        }\n        if (!factory.validators) {\n          return false;\n        }\n\n        var oid = factory.validators.oid,\n            validator = factory.validators.privateKey;\n        if (!validator) {\n          return false;\n        }\n        capture = {};\n        errors = [];\n        result = forge.asn1.validate(input, validator, capture, errors);\n        if (result) {\n          capture.keyOid = forge.asn1.oidToDer(oid);\n          capture.parsed = true;\n        }\n        return result;\n      });\n      capture.type = \"private\";\n      break;\n    case \"pkcs8\":\n      result = forge.asn1.validate(input, JWK.helpers.validators.privateKey, capture, errors);\n      capture.type = \"private\";\n      break;\n    case \"public\":\n      // eslint no-fallthrough: [0] */\n    case \"spki\":\n      result = forge.asn1.validate(input, JWK.helpers.validators.publicKey, capture, errors);\n      capture.type = \"public\";\n      break;\n    case \"pkix\":\n      /* eslint no-fallthrough: [0] */\n    case \"x509\":\n      result = forge.asn1.validate(input, JWK.helpers.validators.certificate, capture, errors);\n      if (result) {\n        capture = processCert(capture);\n        var md = forge.md.sha1.create();\n        md.update(der);\n        thumbprint = util.base64url.encode(Buffer.from(md.digest().toHex(), \"hex\"));\n      }\n      capture.type = \"public\";\n      break;\n  }\n  if (!result) {\n    return null;\n  }\n\n  // convert oids\n  if (capture.keyOid) {\n    capture.keyOid = forge.asn1.derToOid(capture.keyOid);\n  }\n\n  // find and invoke the importer\n  result = null;\n  GLOBAL_REGISTRY.all().forEach(function(factory) {\n    if (result) {\n      return;\n    }\n    if (!factory) {\n      return;\n    }\n    if (\"function\" !== typeof factory.import) {\n      return;\n    }\n    result = factory.import(capture);\n  });\n  if (result && capture.certSubject && capture.certSubject.commonName) {\n    result.kid = capture.certSubject.commonName;\n  }\n  if (result && thumbprint) {\n    result.x5t = thumbprint;\n  }\n  return result;\n}\n\n/**\n * @class JWK.KeyStore\n * @classdesc\n * Represents a collection of Keys.\n *\n * @description\n * **NOTE:** This constructor cannot be called directly. Instead call {@link\n * JWK.createKeyStore}.\n */\nvar JWKStore = function(registry, parent) {\n  var keysets = {};\n\n  /**\n   * @method JWK.KeyStore#generate\n   * @description\n   * Generates a new random Key into this KeyStore.\n   *\n   * The type of {size} depends on the value of {kty}:\n   *\n   * + **`EC`**: String naming the curve to use, which can be one of:\n   *   `\"P-256\"`, `\"P-384\"`, or `\"P-521\"` (default is **`\"P-256\"`**).\n   * + **`RSA`**: Number describing the size of the key, in bits (default is\n   *   **`2048`**).\n   * + **`oct`**: Number describing the size of the key, in bits (default is\n   *   **`256`**).\n   *\n   * Any properties in {props} are applied before the key is generated,\n   * and are expected to be data types acceptable in JSON.  This allows the\n   * generated key to have a specific key identifier, or to specify its\n   * acceptable usage.\n   *\n   * The returned Promise, when fulfilled, returns the generated Key.\n   *\n   * @param {String} kty The type of generated key\n   * @param {String|Number} [size] The size of the generated key\n   * @param {Object} [props] Additional properties to apply to the generated\n   *        key.\n   * @returns {Promise} The promise for the generated Key\n   * @throws {Error} If {kty} is not supported\n   */\n  Object.defineProperty(this, \"generate\", {\n    value: function(kty, size, props) {\n      var keytype = registry.get(kty);\n      if (!keytype) {\n        return Promise.reject(new Error(\"unsupported key type\"));\n      }\n\n      props = clone(props || {});\n      props.kty = kty;\n\n      var self = this,\n          promise = keytype.generate(size);\n      return promise.then(function(jwk) {\n        jwk = merge(props, jwk, {\n          kty: kty\n        });\n        return self.add(jwk);\n      });\n    }\n  });\n  /**\n   * @method JWK.KeyStore#add\n   * @description\n   * Adds a Key to this KeyStore. If {jwk} is a string, it is first\n   * parsed into a plain JSON object. If {jwk} is already an instance\n   * of JWK.Key, its (public) JSON representation is first obtained\n   * then applied to a new JWK.Key object within this KeyStore.\n   *\n   * @param {String|Object} jwk The JSON Web Key (JWK)\n   * @param {String} [form] The format of a String key to expect\n   * @param {Object} [extras] extra jwk fields inserted when importing from a non json string (eg \"pem\")\n   * @returns {Promise} The promise for the added key\n   */\n  Object.defineProperty(this, \"add\", {\n    value: function(jwk, form, extras) {\n      extras = extras || {};\n\n      var factors;\n      if (Buffer.isBuffer(jwk) || typeof jwk === \"string\") {\n        // form can be 'json', 'pkcs8', 'spki', 'pkix', 'x509', 'pem'\n        form = (form || \"json\").toLowerCase();\n        if (\"json\" === form) {\n          jwk = JSON.parse(jwk.toString(\"utf8\"));\n        } else {\n          try {\n            if (\"pem\" === form) {\n              // convert *first* PEM -> DER\n              factors = fromPEM(jwk);\n            } else {\n              factors = {\n                body: jwk.toString(\"binary\"),\n                form: form\n              };\n            }\n            jwk = importFrom(registry, factors);\n            if (!jwk) {\n              throw new Error(\"no importer for key\");\n            }\n            Object.keys(extras).forEach(function(field){\n              jwk[field] = extras[field];\n            });\n          } catch (err) {\n            return Promise.reject(err);\n          }\n        }\n      } else if (JWKStore.isKey(jwk)) {\n        // assume a complete duplicate is desired\n        jwk = jwk.toJSON(true);\n      } else {\n        jwk = clone(jwk);\n      }\n\n      var keytype = registry.get(jwk.kty);\n      if (!keytype) {\n        return Promise.reject(new Error(\"unsupported key type\"));\n      }\n\n      var self = this,\n          promise = keytype.prepare(jwk);\n      return promise.then(function(cfg) {\n        return new JWK.BaseKey(jwk.kty, self, jwk, cfg);\n      }).then(function(jwk) {\n        var kid = jwk.kid || \"\";\n        var keys = keysets[kid] = keysets[kid] || [];\n        keys.push(jwk);\n\n        return jwk;\n      });\n    }\n  });\n  /**\n   * @method JWK.KeyStore#remove\n   * @description\n   * Removes a Key from this KeyStore.\n   *\n   * **NOTE:** The removed Key's {keystore} property is not changed.\n   *\n   * @param {JWK.Key} jwk The key to remove.\n   */\n  Object.defineProperty(this, \"remove\", {\n    value: function(jwk) {\n      if (!jwk) {\n        return;\n      }\n\n      var keys = keysets[jwk.kid];\n      if (!keys) {\n        return;\n      }\n\n      var pos = keys.indexOf(jwk);\n      if (pos === -1) {\n        return;\n      }\n\n      keys.splice(pos, 1);\n      if (!keys.length) {\n        delete keysets[jwk.kid];\n      }\n    }\n  });\n\n  /**\n   * @method JWK.KeyStore#all\n   * @description\n   * Retrieves all of the contained Keys that optinally match all of the\n   * given properties.\n   *\n   * If {props} are specified, this method only returns Keys which exactly\n   * match the given properties. The properties can be any of the\n   * following:\n   *\n   * + **alg**: The algorithm for the Key.\n   * + **use**: The usage for the Key.\n   * + **kid**: The identifier for the Key.\n   *\n   * If no properties are given, this method returns all of the Keys for this\n   * KeyStore.\n   *\n   * @param {Object} [props] The properties to match against\n   * @param {Boolean} [local = false] `true` if only the Keys\n   *        directly contained by this KeyStore should be returned, or\n   *        `false` if it should return all Keys of this KeyStore and\n   *        its ancestors.\n   * @returns {JWK.Key[]} The list of matching Keys, or an empty array if no\n   *          matches are found.\n   */\n  Object.defineProperty(this, \"all\", {\n    value: function(props, local) {\n      props = props || {};\n\n      // workaround for issues/109\n      if (props.kid !== undefined && props.kid !== null && typeof props.kid !== \"string\") {\n        props.kid = String(props.kid);\n      }\n\n      var candidates = [];\n      var matches = function(key) {\n        // match on 'kty'\n        if (props.kty &&\n            key.kty &&\n            props.kty !== key.kty) {\n          return false;\n        }\n        // match on 'use'\n        if (props.use &&\n            key.use &&\n            props.use !== key.use) {\n          return false;\n        }\n        // match on 'alg'\n        if (props.alg) {\n          if (props.alg !== \"dir\" &&\n              key.alg &&\n              props.alg !== key.alg) {\n            return false;\n          }\n          return key.supports(props.alg);\n        }\n        //TODO: match on 'key_ops'\n\n        return true;\n      };\n      Object.keys(keysets).forEach(function(id) {\n        if (props.kid && props.kid !== id) {\n          return;\n        }\n\n        var keys = keysets[id].filter(matches);\n        if (keys.length) {\n          candidates = candidates.concat(keys);\n        }\n      });\n\n      if (!local && parent) {\n        candidates = candidates.concat(parent.all(props));\n      }\n\n      return candidates;\n    }\n  });\n  /**\n   * @method JWK.KeyStore#get\n   * @description\n   * Retrieves the contained Key matching the given {kid}, and optionally\n   * all of the given properties.  This method equivalent to calling\n   * {@link JWK.Store#all}, then returning the first Key whose\n   * \"kid\" is {kid}. If {kid} is undefined, then the first Key that\n   * is returned from `all()` is returned.\n   *\n   * @param {String} [kid] The key identifier to match against.\n   * @param {Object} [props] The properties to match against.\n   * @param {Boolean} [local = false] `true` if only the Keys\n   *        directly contained by this KeyStore should be returned, or\n   *        `false` if it should return all Keys of this KeyStore and\n   *        its ancestors.\n   * @returns {JWK.Key} The Key matching {kid} and {props}, or `null`\n   *          if no match is found.\n   */\n  Object.defineProperty(this, \"get\", {\n    value: function(kid, props, local) {\n      // reconcile arguments\n      if (typeof kid === \"boolean\") {\n        local = kid;\n        props = kid = null;\n      } else if (typeof kid === \"object\") {\n        local = props;\n        props = kid;\n        kid = null;\n      }\n\n      // fixup props\n      props = props || {};\n      if (kid) {\n        props.kid = kid;\n      }\n\n      // workaround for issues/109\n      if (props.kid !== undefined && props.kid !== null && typeof props.kid !== \"string\") {\n       props.kid = String(props.kid);\n      }\n\n      var candidates = this.all(props, true);\n      if (!candidates.length && parent && !local) {\n        candidates = parent.get(props, local);\n      }\n      return candidates[0] || null;\n    }\n  });\n\n  /**\n   * @method JWK.KeyStore#temp\n   * @description\n   * Creates a temporary KeyStore based on this KeyStore.\n   *\n   * @returns {JWK.KeyStore} The temporary KeyStore.\n   */\n  Object.defineProperty(this, \"temp\", {\n    value: function() {\n      return new JWKStore(registry, this);\n    }\n  });\n\n  /**\n   * @method JWK.KeyStore#toJSON\n   * @description\n   * Generates a JSON representation of this KeyStore, which conforms\n   * to a JWK Set from {I-D.ietf-jose-json-web-key}.\n   *\n   * @param {Boolean} [isPrivate = false] `true` if the private fields\n   *        of stored keys are to be included.\n   * @returns {Object} The JSON representation of this KeyStore.\n   */\n  Object.defineProperty(this, \"toJSON\", {\n    value: function(isPrivate) {\n      var keys = [];\n\n      Object.keys(keysets).forEach(function(kid) {\n        var items = keysets[kid].map(function(k) {\n          return k.toJSON(isPrivate);\n        });\n        keys = keys.concat(items);\n      });\n\n      return {\n        keys: keys\n      };\n    }\n  });\n};\n\n/**\n * Determines if the given object is an instance of JWK.KeyStore.\n *\n * @param {Object} obj The object to test\n * @returns {Boolean} `true` if {obj} is an instance of JWK.KeyStore,\n *          and `false` otherwise.\n */\nJWKStore.isKeyStore = function(obj) {\n  if (!obj) {\n    return false;\n  }\n\n  if (\"object\" !== typeof obj) {\n    return false;\n  }\n\n  if (\"function\" !== typeof obj.get ||\n      \"function\" !== typeof obj.all ||\n      \"function\" !== typeof obj.generate ||\n      \"function\" !== typeof obj.add ||\n      \"function\" !== typeof obj.remove) {\n    return false;\n  }\n\n  return true;\n};\n\n/**\n * Creates a new empty KeyStore.\n *\n * @returns {JWK.KeyStore} The empty KeyStore.\n */\nJWKStore.createKeyStore = function() {\n  return new JWKStore(GLOBAL_REGISTRY);\n};\n\n/**\n * Coerces the given object into a KeyStore. This method uses the following\n * algorithm to coerce {ks}:\n *\n * 1. if {ks} is an instance of JWK.KeyStore, it is returned directly\n * 2. if {ks} is a string, it is parsed into a JSON value\n * 3. if {ks} is an array, it creates a new JWK.KeyStore and calls {@link\n *    JWK.KeyStore#add} for each element in the {ks} array.\n * 4. if {ks} is a JSON object, it creates a new JWK.KeyStore and calls {@link\n *    JWK.KeyStore#add} for each element in the \"keys\" property.\n *\n * @param {Object|String} ks The value to coerce into a\n *        KeyStore\n * @returns {Promise(JWK.KeyStore)} A promise for the coerced KeyStore.\n */\nJWKStore.asKeyStore = function(ks) {\n  if (JWKStore.isKeyStore(ks)) {\n    return Promise.resolve(ks);\n  }\n\n  var store = JWKStore.createKeyStore(),\n      keys;\n\n  if (typeof ks === \"string\") {\n    ks = JSON.parse(ks);\n  }\n\n  if (Array.isArray(ks)) {\n    keys = ks;\n  } else if (\"keys\" in ks) {\n    keys = ks.keys;\n  } else {\n    return Promise.reject(new Error(\"invalid keystore\"));\n  }\n\n  keys = keys.map(function(k) {\n    return store.add(k);\n  });\n\n  var promise = Promise.all(keys);\n  promise = promise.then(function() {\n    return store;\n  });\n\n  return promise;\n};\n\n\n/**\n * Determines if the given object is a JWK.Key instance.\n *\n * @param {Object} obj The object to test\n * @returns `true` if {obj} is a JWK.Key\n */\nJWKStore.isKey = function(obj) {\n  if (!obj) {\n    return false;\n  }\n\n  if (\"object\" !== typeof obj) {\n    return false;\n  }\n\n  if (!JWKStore.isKeyStore(obj.keystore)) {\n    return false;\n  }\n\n  if (\"string\" !== typeof obj.kty ||\n      \"number\" !== typeof obj.length ||\n      \"function\" !== typeof obj.algorithms ||\n      \"function\" !== typeof obj.supports ||\n      \"function\" !== typeof obj.encrypt ||\n      \"function\" !== typeof obj.decrypt ||\n      \"function\" !== typeof obj.wrap ||\n      \"function\" !== typeof obj.unwrap ||\n      \"function\" !== typeof obj.sign ||\n      \"function\" !== typeof obj.verify) {\n    return false;\n  }\n\n  return true;\n};\n\n/**\n * Creates a new key with the given properties.  This method is a convenience\n * to calling `JWK.createKeyStore()` then `generate()` on the returned keystore.\n *\n * @param {String} kty The type of generated key\n * @param {String|Number} [size] The size of the generated key\n * @param {Object} [props] Additional properties to apply to the generated\n *        key.\n * @returns {Promise} The promise for the generated Key\n * @throws {Error} If {kty} is not supported\n * @see JWKStore#generate\n */\nJWKStore.createKey = function(kty, size, props) {\n  var ks = JWKStore.createKeyStore();\n  return ks.generate(kty, size, props);\n}\n\n/**\n * Coerces the given object into a Key. If {key} is an instance of JWK.Key,\n * it is returned directly. Otherwise, this method first creates a new\n * JWK.KeyStore and calls {@link JWK.KeyStore#add} on this new KeyStore.\n *\n * @param {Object|String} key The value to coerce into a Key\n * @param {String} [form] The format of a String Key to expect\n * @param {Object} [extras] extra jwk fields inserted when importing from a non json string (eg \"pem\")\n * @returns {Promise(JWK.Key)} A promise for the coerced Key.\n */\nJWKStore.asKey = function(key, form, extras) {\n  if (JWKStore.isKey(key)) {\n    return Promise.resolve(key);\n  }\n\n  var ks = JWKStore.createKeyStore();\n  key = ks.add(key, form, extras);\n\n  return key;\n};\n\nmodule.exports = {\n  KeyRegistry: JWKRegistry,\n  KeyStore: JWKStore,\n  registry: GLOBAL_REGISTRY\n};\n","/*!\n * jwk/octkey.js - Symmetric Octet Key Representation\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar util = require(\"../util\");\n\nvar JWK = {\n  BaseKey: require(\"./basekey.js\"),\n  helpers: require(\"./helpers.js\")\n};\n\nvar SIG_ALGS = [\n  \"HS256\",\n  \"HS384\",\n  \"HS512\"\n];\nvar ENC_ALGS = [\n  \"A128GCM\",\n  \"A192GCM\",\n  \"A256GCM\",\n  \"A128CBC-HS256\",\n  \"A192CBC-HS384\",\n  \"A256CBC-HS512\",\n  \"A128CBC+HS256\",\n  \"A192CBC+HS384\",\n  \"A256CBC+HS512\"\n];\nvar WRAP_ALGS = [\n  \"A128KW\",\n  \"A192KW\",\n  \"A256KW\",\n  \"A128GCMKW\",\n  \"A192GCMKW\",\n  \"A256GCMKW\",\n  \"PBES2-HS256+A128KW\",\n  \"PBES2-HS384+A192KW\",\n  \"PBES2-HS512+A256KW\",\n  \"dir\"\n];\n\nfunction adjustDecryptProps(alg, props) {\n  if (\"iv\" in props) {\n    props.iv = Buffer.isBuffer(props.iv) ?\n               props.iv :\n               util.base64url.decode(props.iv || \"\");\n  }\n  if (\"adata\" in props) {\n    props.adata = Buffer.isBuffer(props.adata) ?\n                  props.adata :\n                  Buffer.from(props.adata || \"\", \"utf8\");\n  }\n  if (\"mac\" in props) {\n    props.mac = Buffer.isBuffer(props.mac) ?\n                props.mac :\n                util.base64url.decode(props.mac || \"\");\n  }\n  if (\"tag\" in props) {\n    props.tag = Buffer.isBuffer(props.tag) ?\n                props.tag :\n                util.base64url.decode(props.tag || \"\");\n  }\n\n  return props;\n}\nfunction adjustEncryptProps(alg, props) {\n  if (\"iv\" in props) {\n    props.iv = Buffer.isBuffer(props.iv) ?\n               props.iv :\n               util.base64url.decode(props.iv || \"\");\n  }\n  if (\"adata\" in props) {\n    props.adata = Buffer.isBuffer(props.adata) ?\n                  props.adata :\n                  Buffer.from(props.adata || \"\", \"utf8\");\n  }\n\n  return props;\n}\n\nvar JWKOctetCfg = {\n  publicKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n    ]);\n\n    var pk;\n    pk = JWK.helpers.unpackProps(props, fields);\n\n    return pk;\n  },\n  privateKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n      {name: \"k\", type: \"binary\"}\n    ]);\n\n    var pk;\n    pk = JWK.helpers.unpackProps(props, fields);\n    if (pk && pk.k) {\n      pk.length = pk.k.length * 8;\n    } else {\n      pk = undefined;\n    }\n\n    return pk;\n  },\n\n  thumbprint: function(json) {\n    if (json.private) {\n      json = json.private;\n    }\n    var fields;\n    fields = {\n      k: json.k || \"\",\n      kty: \"oct\"\n    };\n    return fields;\n  },\n  algorithms: function(keys, mode) {\n    var len = keys.private && (keys.private.k.length * 8);\n    var mins = [256, 384, 512];\n\n    if (!len) {\n      return [];\n    }\n    switch (mode) {\n      case \"encrypt\":\n      case \"decrypt\":\n        return ENC_ALGS.filter(function(a) {\n          return (a === (\"A\" + (len / 2) + \"CBC-HS\" + len)) ||\n                 (a === (\"A\" + (len / 2) + \"CBC+HS\" + len)) ||\n                 (a === (\"A\" + len + \"GCM\"));\n        });\n      case \"sign\":\n      case \"verify\":\n        // TODO: allow for HS{less-than-keysize}\n        return SIG_ALGS.filter(function(a) {\n          var result = false;\n          mins.forEach(function(m) {\n            if (m > len) { return; }\n            result = result | (a === (\"HS\" + m));\n          });\n          return result;\n        });\n      case \"wrap\":\n      case \"unwrap\":\n        return WRAP_ALGS.filter(function(a) {\n          return (a === (\"A\" + len + \"KW\")) ||\n                 (a === (\"A\" + len + \"GCMKW\")) ||\n                 (a.indexOf(\"PBES2-\") === 0) ||\n                 (a === \"dir\");\n        });\n    }\n\n    return [];\n  },\n  encryptKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  },\n  encryptProps: adjustEncryptProps,\n\n  decryptKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  },\n  decryptProps: adjustDecryptProps,\n\n  wrapKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  },\n  wrapProps: adjustEncryptProps,\n\n  unwrapKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  },\n  unwrapProps: adjustDecryptProps,\n\n  signKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  },\n  verifyKey: function(alg, keys) {\n    return keys.private && keys.private.k;\n  }\n};\n\n// Factory\nvar JWKOctetFactory = {\n  kty: \"oct\",\n  prepare: function(props) {\n    // TODO: validate key properties\n    var cfg = JWKOctetCfg;\n    var p = Promise.resolve(props);\n    p = p.then(function(json) {\n      return JWK.helpers.thumbprint(cfg, json);\n    });\n    p = p.then(function(hash) {\n      var prints = {};\n      prints[JWK.helpers.INTERNALS.THUMBPRINT_HASH] = hash;\n      props[JWK.helpers.INTERNALS.THUMBPRINT_KEY] = prints;\n      return cfg;\n    });\n    return p;\n  },\n  generate: function(size) {\n    // TODO: validate key sizes\n    var key = util.randomBytes(size / 8);\n\n    return Promise.resolve({\n      k: key\n    });\n  }\n};\n\n// public API\nmodule.exports = Object.freeze({\n  config: JWKOctetCfg,\n  factory: JWKOctetFactory\n});\n\n// registration\n(function(REGISTRY) {\n  REGISTRY.register(JWKOctetFactory);\n})(require(\"./keystore\").registry);\n","/*!\n * jwk/rsa.js - RSA Key Representation\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    rsau = require(\"../algorithms/rsa-util\"),\n    nodeCrypto = require(\"../algorithms/helpers\").nodeCrypto;\n\nvar JWK = {\n  BaseKey: require(\"./basekey.js\"),\n  helpers: require(\"./helpers.js\")\n};\n\nvar SIG_ALGS = [\n  \"RS256\",\n  \"RS384\",\n  \"RS512\",\n  \"PS256\",\n  \"PS384\",\n  \"PS512\"\n];\nvar WRAP_ALGS = [\n  \"RSA-OAEP\",\n  \"RSA-OAEP-256\",\n  \"RSA1_5\"\n];\n\nvar JWKRsaCfg = {\n  publicKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n      {name: \"n\", type: \"binary\"},\n      {name: \"e\", type: \"binary\"}\n    ]);\n    var pk;\n    pk = JWK.helpers.unpackProps(props, fields);\n    if (pk && pk.n && pk.e) {\n      pk.length = pk.n.length * 8;\n    } else {\n      delete pk.e;\n      delete pk.n;\n    }\n\n    return pk;\n  },\n  privateKey: function(props) {\n    var fields = JWK.helpers.COMMON_PROPS.concat([\n      {name: \"n\", type: \"binary\"},\n      {name: \"e\", type: \"binary\"},\n      {name: \"d\", type: \"binary\"},\n      {name: \"p\", type: \"binary\"},\n      {name: \"q\", type: \"binary\"},\n      {name: \"dp\", type: \"binary\"},\n      {name: \"dq\", type: \"binary\"},\n      {name: \"qi\", type: \"binary\"}\n    ]);\n\n    var pk;\n    pk = JWK.helpers.unpackProps(props, fields);\n    if (pk && pk.d && pk.n && pk.e && pk.p && pk.q && pk.dp && pk.dq && pk.qi) {\n      pk.length = pk.d.length * 8;\n    } else {\n      pk = undefined;\n    }\n\n    return pk;\n  },\n  thumbprint: function(json) {\n    if (json.public) {\n      json = json.public;\n    }\n    var fields = {\n      e: json.e,\n      kty: \"RSA\",\n      n: json.n\n    };\n    return fields;\n  },\n  algorithms: function(keys, mode) {\n    switch (mode) {\n    case \"encrypt\":\n    case \"decrypt\":\n      return [];\n    case \"wrap\":\n      return (keys.public && WRAP_ALGS.slice()) || [];\n    case \"unwrap\":\n      return (keys.private && WRAP_ALGS.slice()) || [];\n    case \"sign\":\n      return (keys.private && SIG_ALGS.slice()) || [];\n    case \"verify\":\n      return (keys.public && SIG_ALGS.slice()) || [];\n    }\n\n    return [];\n  },\n\n  wrapKey: function(alg, keys) {\n    return keys.public;\n  },\n  unwrapKey: function(alg, keys) {\n    return keys.private;\n  },\n\n  signKey: function(alg, keys) {\n    return keys.private;\n  },\n  verifyKey: function(alg, keys) {\n    return keys.public;\n  },\n\n  convertToPEM: function(key, isPrivate) {\n    var k = rsau.convertToForge(key, !isPrivate);\n    if (!isPrivate) {\n      return forge.pki.publicKeyToPem(k);\n    }\n    return forge.pki.privateKeyToPem(k);\n  }\n};\n\nfunction convertBNtoBuffer(bn) {\n  bn = bn.toString(16);\n  if (bn.length % 2) {\n    bn = \"0\" + bn;\n  }\n  return Buffer.from(bn, \"hex\");\n}\n\n// Adapted from digitalbaazar/node-forge/js/rsa.js\nvar validators = {\n  oid: \"1.2.840.113549.1.1.1\",\n  privateKey: {\n    name: \"RSAPrivateKey\",\n    tagClass: forge.asn1.Class.UNIVERSAL,\n    type: forge.asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [\n      {\n        // Version (INTEGER)\n        name: \"RSAPrivateKey.version\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"version\"\n      },\n      {\n        // modulus (n)\n        name: \"RSAPrivateKey.modulus\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"n\"\n      },\n      {\n        // publicExponent (e)\n        name: \"RSAPrivateKey.publicExponent\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"e\"\n      },\n      {\n        // privateExponent (d)\n        name: \"RSAPrivateKey.privateExponent\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"d\"\n      },\n      {\n        // prime1 (p)\n        name: \"RSAPrivateKey.prime1\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"p\"\n      },\n      {\n        // prime2 (q)\n        name: \"RSAPrivateKey.prime2\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"q\"\n      },\n      {\n        // exponent1 (d mod (p-1))\n        name: \"RSAPrivateKey.exponent1\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"dp\"\n      },\n      {\n        // exponent2 (d mod (q-1))\n        name: \"RSAPrivateKey.exponent2\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"dq\"\n      },\n      {\n        // coefficient ((inverse of q) mod p)\n        name: \"RSAPrivateKey.coefficient\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"qi\"\n      }\n    ]\n  },\n  publicKey: {\n    // RSAPublicKey\n    name: \"RSAPublicKey\",\n    tagClass: forge.asn1.Class.UNIVERSAL,\n    type: forge.asn1.Type.SEQUENCE,\n    constructed: true,\n    value: [\n      {\n        // modulus (n)\n        name: \"RSAPublicKey.modulus\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"n\"\n      },\n      {\n        // publicExponent (e)\n        name: \"RSAPublicKey.exponent\",\n        tagClass: forge.asn1.Class.UNIVERSAL,\n        type: forge.asn1.Type.INTEGER,\n        constructed: false,\n        capture: \"e\"\n      }\n    ]\n  }\n};\n\n// Factory\nvar JWKRsaFactory = {\n  kty: \"RSA\",\n  validators: validators,\n  prepare: function(props) {\n    // TODO: validate key properties\n    var cfg = JWKRsaCfg;\n    var p = Promise.resolve(props);\n    p = p.then(function(json) {\n      return JWK.helpers.thumbprint(cfg, json);\n    });\n    p = p.then(function(hash) {\n      var prints = {};\n      prints[JWK.helpers.INTERNALS.THUMBPRINT_HASH] = hash;\n      props[JWK.helpers.INTERNALS.THUMBPRINT_KEY] = prints;\n      return cfg;\n    });\n    return p;\n  },\n  generate: function(size) {\n    // TODO: validate key sizes\n    var promise;\n\n    if (nodeCrypto) {\n      promise = new Promise(function (resolve, reject) {\n        forge.pki.rsa.generateKeyPair({\n          bits: size,\n          e: 0x010001\n        }, function (err, key) {\n          if (err) return reject(err);\n          resolve(key.privateKey);\n        });\n      });\n    } else {\n      var key = forge.pki.rsa.generateKeyPair({\n        bits: size,\n        e: 0x010001\n      });\n      promise = Promise.resolve(key.privateKey);\n    }\n\n    return promise.then(function (key) {\n\n      // convert to JSON-ish\n      var result = {};\n      [\n        \"e\",\n        \"n\",\n        \"d\",\n        \"p\",\n        \"q\",\n        {incoming: \"dP\", outgoing: \"dp\"},\n        {incoming: \"dQ\", outgoing: \"dq\"},\n        {incoming: \"qInv\", outgoing: \"qi\"}\n      ].forEach(function(f) {\n        var incoming,\n            outgoing;\n\n        if (\"string\" === typeof f) {\n          incoming = outgoing = f;\n        } else {\n          incoming = f.incoming;\n          outgoing = f.outgoing;\n        }\n\n        if (incoming in key) {\n          result[outgoing] = convertBNtoBuffer(key[incoming]);\n        }\n      });\n\n      return result;\n    });\n  },\n  import: function(input) {\n    if (validators.oid !== input.keyOid) {\n      return null;\n    }\n\n    if (!input.parsed) {\n      // coerce capture.keyValue to DER\n      if (\"string\" === typeof input.keyValue) {\n        input.keyValue = forge.asn1.fromDer(input.keyValue);\n      } else if (Array.isArray(input.keyValue)) {\n        input.keyValue = input.keyValue[0];\n      }\n      // capture key factors\n      var validator = (\"private\" === input.type) ?\n                      validators.privateKey :\n                      validators.publicKey;\n      var capture = {},\n          errors = [];\n      if (!forge.asn1.validate(input.keyValue, validator, capture, errors)) {\n        return null;\n      }\n      input = capture;\n    }\n\n    // convert factors to Buffers\n    var output = {\n      kty: \"RSA\"\n    };\n    [\"n\", \"e\", \"d\", \"p\", \"q\", \"dp\", \"dq\", \"qi\"].forEach(function(f) {\n      if (!(f in input)) {\n        return;\n      }\n      var b = Buffer.from(input[f], \"binary\");\n      // remove leading zero padding if any\n      if (0 === b[0]) {\n        b = b.slice(1);\n      }\n      output[f] = b;\n    });\n    return output;\n  }\n};\n\n// public API\nmodule.exports = Object.freeze({\n  config: JWKRsaCfg,\n  factory: JWKRsaFactory\n});\n\n// registration\n(function(REGISTRY) {\n  REGISTRY.register(JWKRsaFactory);\n})(require(\"./keystore\").registry);\n","/*!\n * jws/defaults.js - Defaults for JWSs\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\n/**\n * @description\n * The default options for {@link JWS.createSign}.\n *\n * @property {Boolean} compact Determines if the output is the Compact\n *           serialization (`true`) or the JSON serialization (**`false`**,\n *           the default).\n * @property {String|String[]} protect The names of the headers to integrity\n *           protect.  The value `\"\"` means that none of header parameters\n *           are integrity protected, while `\"*\"` (the default) means that all\n *           headers parameter sare integrity protected.\n */\nvar JWSDefaults = {\n    compact: false,\n    protect: \"*\"\n};\n\nmodule.exports = JWSDefaults;\n","/*!\n * jws/helpers.js - JWS Internal Helper Functions\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nmodule.exports = {\n  slice: function(input, start) {\n    return Array.prototype.slice.call(input, start || 0);\n  }\n};\n","/*!\n * jws/index.js - JSON Web Signature (JWS) Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar JWS = {\n  createSign: require(\"./sign\").createSign,\n  createVerify: require(\"./verify\").createVerify\n};\n\nmodule.exports = JWS;\n","/*!\n * jws/sign.js - Sign to JWS\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar merge = require(\"../util/merge\"),\n    util = require(\"../util\"),\n    JWK = require(\"../jwk\"),\n    slice = require(\"./helpers\").slice;\n\nvar clone = require(\"lodash/clone\");\nvar uniq = require(\"lodash/uniq\");\n\nvar DEFAULTS = require(\"./defaults\");\n\n/**\n * @class JWS.Signer\n * @classdesc Generator of signed content.\n *\n * @description\n * **NOTE:** this class cannot be instantiated directly. Instead call {@link\n * JWS.createSign}.\n */\nvar JWSSigner = function(cfg, signatories) {\n  var finalized = false,\n      format = cfg.format || \"general\",\n      content = Buffer.alloc(0);\n\n  /**\n  * @member {Boolean} JWS.Signer#compact\n  * @description\n  * Indicates whether the outuput of this signature generator is using\n  * the Compact serialization (`true`) or the JSON serialization\n  * (`false`).\n  */\n  Object.defineProperty(this, \"compact\", {\n    get: function() {\n      return \"compact\" === format;\n    },\n    enumerable: true\n  });\n  Object.defineProperty(this, \"format\", {\n    get: function() {\n      return format;\n    },\n    enumerable: true\n  });\n\n  /**\n  * @method JWS.Signer#update\n  * @description\n  * Updates the signing content for this signature content. The content\n  * is appended to the end of any other content already applied.\n  *\n  * If {data} is a Buffer, {encoding} is ignored. Otherwise, {data} is\n  * converted to a Buffer internally to {encoding}.\n  *\n  * @param {Buffer|String} data The data to sign.\n  * @param {String} [encoding=\"binary\"] The encoding of {data}.\n  * @returns {JWS.Signer} This signature generator.\n  * @throws {Error} If a signature has already been generated.\n  */\n  Object.defineProperty(this, \"update\", {\n    value: function(data, encoding) {\n      if (finalized) {\n        throw new Error(\"already final\");\n      }\n      if (data != null) {\n        data = util.asBuffer(data, encoding);\n        if (content.length) {\n          content = Buffer.concat([content, data],\n                      content.length + data.length);\n        } else {\n          content = data;\n        }\n      }\n\n      return this;\n    }\n  });\n  /**\n  * @method JWS.Signer#final\n  * @description\n  * Finishes the signature operation.\n  *\n  * The returned Promise, when fulfilled, is the JSON Web Signature (JWS)\n  * object, either in the Compact (if {@link JWS.Signer#format} is\n  * `\"compact\"`), the flattened JSON (if {@link JWS.Signer#format} is\n  * \"flattened\"), or the general JSON serialization.\n  *\n  * @param {Buffer|String} [data] The final content to apply.\n  * @param {String} [encoding=\"binary\"] The encoding of the final content\n  *        (if any).\n  * @returns {Promise} The promise for the signatures\n  * @throws {Error} If a signature has already been generated.\n  */\n  Object.defineProperty(this, \"final\", {\n    value: function(data, encoding) {\n      if (finalized) {\n        return Promise.reject(new Error(\"already final\"));\n      }\n\n      // last-minute data\n      this.update(data, encoding);\n\n      // mark as done...ish\n      finalized = true;\n      var promise;\n\n      // map signatory promises to just signatories\n      promise = Promise.all(signatories);\n      promise = promise.then(function(sigs) {\n        // prepare content\n        content = util.base64url.encode(content);\n\n        sigs = sigs.map(function(s) {\n          // prepare protected\n          var protect = {},\n              lenProtect = 0,\n              unprotect = clone(s.header),\n              lenUnprotect = Object.keys(unprotect).length;\n          s.protected.forEach(function(h) {\n            if (!(h in unprotect)) {\n              return;\n            }\n            protect[h] = unprotect[h];\n            lenProtect++;\n            delete unprotect[h];\n            lenUnprotect--;\n          });\n          if (lenProtect > 0) {\n            protect = JSON.stringify(protect);\n            protect = util.base64url.encode(protect);\n          } else {\n            protect = \"\";\n          }\n\n          // signit!\n          var data = Buffer.from(protect + \".\" + content, \"ascii\");\n          s = s.key.sign(s.header.alg, data, s.header);\n          s = s.then(function(result) {\n            var sig = {};\n            if (0 < lenProtect) {\n              sig.protected = protect;\n            }\n            if (0 < lenUnprotect) {\n              sig.header = unprotect;\n            }\n            sig.signature = util.base64url.encode(result.mac);\n            return sig;\n          });\n          return s;\n        });\n        sigs = [Promise.resolve(content)].concat(sigs);\n        return Promise.all(sigs);\n      });\n      promise = promise.then(function(results) {\n        var content = results[0];\n        return {\n          payload: content,\n          signatures: results.slice(1)\n        };\n      });\n      switch (format) {\n        case \"compact\":\n          promise = promise.then(function(jws) {\n            var compact = [\n              jws.signatures[0].protected,\n              jws.payload,\n              jws.signatures[0].signature\n            ];\n            compact = compact.join(\".\");\n            return compact;\n          });\n          break;\n        case \"flattened\":\n          promise = promise.then(function(jws) {\n            var flattened = {};\n            flattened.payload = jws.payload;\n\n            var sig = jws.signatures[0];\n            if (sig.protected) {\n              flattened.protected = sig.protected;\n            }\n            if (sig.header) {\n              flattened.header = sig.header;\n            }\n            flattened.signature = sig.signature;\n\n            return flattened;\n          });\n          break;\n      }\n\n      return promise;\n    }\n  });\n};\n\n\n/**\n * @description\n * Creates a new JWS.Signer with the given options and signatories.\n *\n * @param {Object} [opts] The signing options\n * @param {Boolean} [opts.compact] Use compact serialization?\n * @param {String} [opts.format] The serialization format to use (\"compact\",\n *                 \"flattened\", \"general\")\n * @param {Object} [opts.fields] Additional header fields\n * @param {JWK.Key[]|Object[]} [signs] Signatories, either as an array of\n *        JWK.Key instances; or an array of objects, each with the following\n *        properties\n * @param {JWK.Key} signs.key Key used to sign content\n * @param {Object} [signs.header] Per-signatory header fields\n * @param {String} [signs.reference] Reference field to identify the key\n * @param {String[]|String} [signs.protect] List of fields to integrity\n *        protect (\"*\" to protect all fields)\n * @returns {JWS.Signer} The signature generator.\n * @throws {Error} If Compact serialization is requested but there are\n *         multiple signatories\n */\nfunction createSign(opts, signs) {\n  // fixup signatories\n  var options = opts,\n      signStart = 1,\n      signList = signs;\n\n  if (arguments.length === 0) {\n    throw new Error(\"at least one signatory must be provided\");\n  }\n  if (arguments.length === 1) {\n    signList = opts;\n    signStart = 0;\n    options = {};\n  } else if (JWK.isKey(opts) ||\n            (opts && \"kty\" in opts) ||\n            (opts && \"key\" in opts &&\n            (JWK.isKey(opts.key) || \"kty\" in opts.key))) {\n    signList = opts;\n    signStart = 0;\n    options = {};\n  } else {\n    options = clone(opts);\n  }\n  if (!Array.isArray(signList)) {\n    signList = slice(arguments, signStart);\n  }\n\n  // fixup options\n  options = merge(clone(DEFAULTS), options);\n\n  // setup header fields\n  var allFields = options.fields || {};\n  // setup serialization format\n  var format = options.format;\n  if (!format) {\n    format = options.compact ? \"compact\" : \"general\";\n  }\n  if ((\"compact\" === format || \"flattened\" === format) && 1 < signList.length) {\n    throw new Error(\"too many signatories for compact or flattened JSON serialization\");\n  }\n\n  // note protected fields (globally)\n  // protected fields are per signature\n  var protectAll = (\"*\" === options.protect);\n  if (options.compact) {\n    protectAll = true;\n  }\n\n  signList = signList.map(function(s, idx) {\n    var p;\n\n    // resolve a key\n    if (s && \"kty\" in s) {\n      p = JWK.asKey(s);\n      p = p.then(function(k) {\n        return {\n          key: k\n        };\n      });\n    } else if (s) {\n      p = JWK.asKey(s.key);\n      p = p.then(function(k) {\n        return {\n          header: s.header,\n          reference: s.reference,\n          protect: s.protect,\n          key: k\n        };\n      });\n    } else {\n      p = Promise.reject(new Error(\"missing key for signatory \" + idx));\n    }\n\n    // resolve the complete signatory\n    p = p.then(function(signatory) {\n      var key = signatory.key;\n\n      // make sure there is a header\n      var header = signatory.header || {};\n      header = merge(merge({}, allFields), header);\n      signatory.header = header;\n\n      // ensure an algorithm\n      if (!header.alg) {\n        header.alg = key.algorithms(JWK.MODE_SIGN)[0] || \"\";\n      }\n\n      // determine the key reference\n      var ref = signatory.reference;\n      delete signatory.reference;\n      if (undefined === ref) {\n        // header already contains the key reference\n        ref = [\"kid\", \"jku\", \"x5c\", \"x5t\", \"x5u\"].some(function(k) {\n          return (k in header);\n        });\n        ref = !ref ? \"kid\" : null;\n      } else if (\"boolean\" === typeof ref) {\n        // explicit (positive | negative) request for key reference\n        ref = ref ? \"kid\" : null;\n      }\n      var jwk;\n      if (ref) {\n        jwk = key.toJSON();\n        if (\"jwk\" === ref) {\n          if (\"oct\" === key.kty) {\n            return Promise.reject(new Error(\"cannot embed key\"));\n          }\n          header.jwk = jwk;\n        } else if (ref in jwk) {\n          header[ref] = jwk[ref];\n        }\n      }\n\n      // determine protected fields\n      var protect = signatory.protect;\n      if (protectAll || \"*\" === protect) {\n        protect = Object.keys(header);\n      } else if (\"string\" === protect) {\n        protect = [protect];\n      } else if (Array.isArray(protect)) {\n        protect = protect.concat();\n      } else if (!protect) {\n        protect = [];\n      } else {\n        return Promise.reject(new Error(\"protect must be a list of fields\"));\n      }\n      protect = uniq(protect);\n      signatory.protected = protect;\n\n      // freeze signatory\n      signatory = Object.freeze(signatory);\n      return signatory;\n    });\n\n    return p;\n  });\n\n  var cfg = {\n    format: format\n  };\n  return new JWSSigner(cfg,\n                       signList);\n}\n\nmodule.exports = {\n  signer: JWSSigner,\n  createSign: createSign\n};\n","/*!\n * jws/verify.js - Verifies from a JWS\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar clone = require(\"lodash/clone\"),\n    merge = require(\"../util/merge\"),\n    base64url = require(\"../util/base64url\"),\n    AlgConfig = require(\"../util/algconfig\"),\n    JWK = require(\"../jwk\");\n\nvar DEFAULT_OPTIONS = {\n  algorithms: \"*\",\n  allowEmbeddedKey: false\n};\n\n/**\n * @class JWS.Verifier\n * @classdesc Parser of signed content.\n *\n * @description\n * **NOTE:** this class cannot be instantiated directly. Instead call {@link\n * JWS.createVerify}.\n */\nvar JWSVerifier = function(ks, globalOpts) {\n  var assumedKey,\n      keystore;\n\n  if (JWK.isKey(ks)) {\n    assumedKey = ks;\n    keystore = assumedKey.keystore;\n  } else if (JWK.isKeyStore(ks)) {\n    keystore = ks;\n  } else {\n    keystore = JWK.createKeyStore();\n  }\n\n  globalOpts = merge(DEFAULT_OPTIONS, globalOpts);\n\n  Object.defineProperty(this, \"defaultKey\", {\n    value: assumedKey || undefined,\n    enumerable: true\n  });\n  Object.defineProperty(this, \"keystore\", {\n    value: keystore,\n    enumerable: true\n  });\n\n  Object.defineProperty(this, \"verify\", {\n    value: function(input, opts) {\n      opts = merge({}, globalOpts, opts || {});\n      var extraHandlers = opts.handlers || {};\n      var handlerKeys = Object.keys(extraHandlers);\n      var algSpec = new AlgConfig(opts.algorithms);\n\n      if (\"string\" === typeof input) {\n        input = input.split(\".\");\n        input = {\n          payload: input[1],\n          signatures: [\n            {\n              protected: input[0],\n              signature: input[2]\n            }\n          ]\n        };\n      } else if (!input || \"object\" !== typeof input) {\n        throw new Error(\"invalid input\");\n      }\n\n      // fixup \"flattened JSON\" to look like \"general JSON\"\n      if (input.signature) {\n        input.signatures = [\n          {\n            protected: input.protected || undefined,\n            header: input.header || undefined,\n            signature: input.signature\n          }\n        ];\n      }\n\n      // ensure signatories exists\n      var sigList = input.signatures || [{}];\n\n      // combine fields and decode signature per signatory\n      sigList = sigList.map(function(s) {\n        var header = clone(s.header || {});\n        var protect = s.protected ?\n                      JSON.parse(base64url.decode(s.protected, \"utf8\")) :\n                      {};\n        header = merge(header, protect);\n        var signature = base64url.decode(s.signature);\n\n        // process allowed algorithims\n        if (!algSpec.match(header.alg)) {\n          return Promise.reject(new Error(\"Algorithm not allowed: \" + header.alg));\n        }\n\n        // process \"crit\" first\n        var crit = protect.crit;\n        if (crit) {\n          if (!Array.isArray(crit)) {\n            return Promise.reject(new Error(\"Invalid 'crit' header\"));\n          }\n          for (var idx = 0; crit.length > idx; idx++) {\n            if (-1 === handlerKeys.indexOf(crit[idx])) {\n              return Promise.reject(new Error(\n                  \"Critical extension is not supported: \" + crit[idx]\n              ));\n            }\n          }\n        }\n        protect = Object.keys(protect);\n\n        return Promise.resolve({\n          protected: protect,\n          aad: s.protected || \"\",\n          header: header,\n          signature: signature\n        });\n      });\n\n      var promise = Promise.all(sigList);\n      promise = promise.then(function(sigList) {\n        return new Promise(function(resolve, reject) {\n          var processSig = function() {\n            var sig = sigList.shift();\n            if (!sig) {\n              reject(new Error(\"no key found\"));\n              return;\n            }\n\n            sig = merge({}, sig, {\n              payload: input.payload\n            });\n            var p = Promise.resolve(sig);\n            // find the key\n            p = p.then(function(sig) {\n              var algKey;\n              // TODO: resolve jku, x5c, x5u\n              if (opts.allowEmbeddedKey && sig.header.jwk) {\n                algKey = JWK.asKey(sig.header.jwk);\n              } else if (opts.allowEmbeddedKey && sig.header.x5c) {\n                algKey = sig.header.x5c[0];\n                algKey = Buffer.from(algKey, \"base64\");\n                // TODO: callback to validate chain\n                algKey = JWK.asKey(algKey, \"pkix\");\n              } else {\n                algKey = Promise.resolve(assumedKey || keystore.get({\n                  use: \"sig\",\n                  alg: sig.header.alg,\n                  kid: sig.header.kid\n                }));\n              }\n              return algKey.then(function(k) {\n                if (!k) {\n                  return Promise.reject(new Error(\"key does not match\"));\n                }\n                sig.key = k;\n                return sig;\n              });\n            });\n\n            // process any prepare-verify handlers\n            p = p.then(function(sig) {\n              var processing = [];\n              handlerKeys.forEach(function(h) {\n                h = extraHandlers[h];\n                var p;\n                if (\"function\" === typeof h) {\n                  p = h(sig);\n                } else if (\"object\" === typeof h && \"function\" === typeof h.prepare) {\n                  p = h.prepare(sig);\n                }\n                if (p) {\n                  processing.push(Promise.resolve(p));\n                }\n              });\n              return Promise.all(processing).then(function() {\n                // don't actually care about individual handler results\n                // assume {sig} is updated\n                return sig;\n              });\n            });\n\n            // prepare verify inputs\n            p = p.then(function(sig) {\n              var aad = sig.aad || \"\",\n                  payload = sig.payload || \"\";\n              var content = Buffer.alloc(1 + aad.length + payload.length),\n                  pos = 0;\n              content.write(aad, pos, \"ascii\");\n              pos += aad.length;\n              content.write(\".\", pos, \"ascii\");\n              pos++;\n\n              if (Buffer.isBuffer(payload)) {\n                payload.copy(content, pos);\n              } else {\n                content.write(payload, pos, \"binary\");\n              }\n              sig.content = content;\n              return sig;\n            });\n\n            p = p.then(function(sig) {\n              return sig.key.verify(sig.header.alg,\n                                    sig.content,\n                                    sig.signature);\n            });\n\n            p = p.then(function(result) {\n              var payload = sig.payload;\n              payload = base64url.decode(payload);\n              return {\n                protected: sig.protected,\n                header: sig.header,\n                payload: payload,\n                signature: result.mac,\n                key: sig.key\n              };\n            });\n\n            // process any post-verify handlers\n            p = p.then(function(jws) {\n              var processing = [];\n              handlerKeys.forEach(function(h) {\n                h = extraHandlers[h];\n                var p;\n                if (\"object\" === typeof h && \"function\" === typeof h.complete) {\n                  p = h.complete(jws);\n                }\n                if (p) {\n                  processing.push(Promise.resolve(p));\n                }\n              });\n              return Promise.all(processing).then(function() {\n                // don't actually care about individual handler results\n                // assume {jws} is updated\n                return jws;\n              });\n            });\n            p.then(resolve, processSig);\n          };\n          processSig();\n        });\n      });\n      return promise;\n    }\n  });\n};\n\n/**\n * @description\n * Creates a new JWS.Verifier with the given Key or KeyStore.\n *\n * @param {JWK.Key|JWK.KeyStore} ks The Key or KeyStore to use for verification.\n * @returns {JWS.Verifier} The new Verifier.\n */\nfunction createVerify(ks, opts) {\n  var vfy = new JWSVerifier(ks, opts);\n\n  return vfy;\n}\n\nmodule.exports = {\n  verifier: JWSVerifier,\n  createVerify: createVerify\n};\n","/*!\n * parse/compact.js - JOSE Compact Serialization Parser\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar jose = {\n  JWE: require(\"../jwe\"),\n  JWS: require(\"../jws\"),\n  util: require(\"../util\")\n};\n\nfunction parseCompact(input) {\n  var parts = input.split(\".\");\n\n  var type,\n      op;\n  if (3 === parts.length) {\n    // JWS\n    type = \"JWS\";\n    op = function(ks, opts) {\n      return jose.JWS.createVerify(ks).\n             verify(input, opts);\n    };\n  } else if (5 === parts.length) {\n    // JWE\n    type = \"JWE\";\n    op = function(ks, opts) {\n      return jose.JWE.createDecrypt(ks).\n             decrypt(input, opts);\n    };\n  } else {\n    throw new TypeError(\"invalid jose serialization\");\n  }\n\n  // parse header\n  var header;\n  header = jose.util.base64url.decode(parts[0], \"utf8\");\n  header = JSON.parse(header);\n  return {\n    type: type,\n    format: \"compact\",\n    input: input,\n    header: header,\n    perform: op\n  };\n}\n\nmodule.exports = parseCompact;\n","/*!\n * parse/index.js - JOSE Parser Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar compact = require(\"./compact\"),\n    json = require(\"./json\");\n\nvar parse = module.exports = function(input) {\n  if (Buffer.isBuffer(input)) {\n    // assume buffer holds a Compact Serialization string\n    return compact(input.toString(\"ascii\"));\n  } else if (\"string\" === typeof input) {\n    return compact(input);\n  } else if (input) {\n    return json(input);\n  } else {\n    throw new TypeError(\"invalid input\");\n  }\n};\n\nparse.compact = compact;\nparse.json = json;\n","/*!\n * parse/compact.js - JOSE JSON Serialization Parser\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar merge = require(\"../util/merge\");\n\nvar jose = {\n  JWE: require(\"../jwe\"),\n  JWS: require(\"../jws\"),\n  util: require(\"../util\")\n};\n\nfunction parseJSON(input) {\n  var type,\n      op,\n      headers;\n\n  if (\"signatures\" in input || \"signature\" in input) {\n    // JWS\n    type = \"JWS\";\n    op = function(ks, opts) {\n      return jose.JWS.createVerify(ks).\n             verify(input, opts);\n    };\n    // headers can be (signatures[].protected, signatures[].header, signature.protected, signature.header)\n    headers = input.signatures ||\n              [ {\n                protected: input.protected,\n                header: input.header,\n                signature: input.signature\n              }];\n    headers = headers.map(function(sig) {\n      var all = {};\n      if (sig.header) {\n        all = merge(all, sig.header);\n      }\n\n      var prot;\n      if (sig.protected) {\n        prot = sig.protected;\n        prot = jose.util.base64url.decode(prot, \"utf8\");\n        prot = JSON.parse(prot);\n        all = merge(all, prot);\n      }\n\n      return all;\n    });\n  } else if (\"ciphertext\" in input) {\n    // JWE\n    type = \"JWE\";\n    op = function(ks, opts) {\n      return jose.JWE.createDecrypt(ks).\n             decrypt(input, opts);\n    };\n    // headers can be (protected, unprotected, recipients[].header)\n    var root = {};\n    if (input.protected) {\n      root.protected = input.protected;\n      root.protected = jose.util.base64url.decode(root.protected, \"utf8\");\n      root.protected = JSON.parse(root.protected);\n    }\n    if (input.unprotected) {\n      root.unprotected = input.unprotected;\n    }\n\n    headers = input.recipients || [{}];\n    headers = headers.map(function(rcpt) {\n      var all = {};\n      if (rcpt.header) {\n        all = merge(all, rcpt.header);\n      }\n      if (root.unprotected) {\n        all = merge(all, root.unprotected);\n      }\n      if (root.protected) {\n        all = merge(all, root.protected);\n      }\n\n      return all;\n    });\n  }\n\n  return {\n    type: type,\n    format: \"json\",\n    input: input,\n    all: headers,\n    perform: op\n  };\n}\n\nmodule.exports = parseJSON;\n","/*!\n * util/algconfig.js - Functions for managing algorithm set options\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nfunction quoteRE(str) {\n  return str.replace(/[.?*+^$[\\]\\\\(){}|-]/g, \"\\\\$&\");\n}\n\nfunction makeRE(prefix, wildcard, suffix) {\n  var parts = [];\n\n  parts.push(\"^\");\n  if (prefix) {\n    prefix = quoteRE(prefix);\n    parts.push(prefix);\n  }\n  if (wildcard) {\n    parts.push((prefix || suffix) ? \".*\" : \".+\");\n  }\n  if (suffix) {\n    suffix = quoteRE(suffix);\n    parts.push(suffix);\n  }\n  parts.push(\"$\");\n\n  return parts.join(\"\");\n}\n\nvar AlgConfig = function(algspec) {\n  if (!algspec) {\n    algspec = [];\n  } else if (\"string\" === typeof algspec) {\n    algspec = algspec.split(\" \");\n  }\n\n  var specAllowed = [], specDisallowed = [];\n  var ptnAllowed = [], ptnDisallowed = [];\n  var ptn = /^(!)?([^*]*)(\\*?)([^*]*)$/, fmt;\n  algspec.forEach(function (a) {\n    if (!a) { return; }\n\n    ptn.lastIndex = 0;\n    var parts = ptn.exec(a);\n    if (!parts) { return; }\n\n    fmt = \"(\" + makeRE(parts[2], parts[3], parts[4]) + \")\";\n    if (!parts[1]) {\n      // allowed pattern\n      ptnAllowed.push(fmt);\n      specAllowed.push(parts[0]);\n    } else {\n      // disallowed pattern\n      ptnDisallowed.push(fmt);\n      specDisallowed.push(parts[0]);\n    }\n  });\n\n  ptnAllowed = (ptnAllowed.length) ?\n            new RegExp(ptnAllowed.join(\"|\")) :\n            null;\n  ptnDisallowed = (ptnDisallowed.length) ?\n               new RegExp(ptnDisallowed.join(\"|\")) :\n               null;\n  if (!specAllowed.length) {\n    specAllowed = [\"*\"];\n  }\n\n  Object.defineProperty(this, \"spec\", {\n    value: specAllowed.join(\" \") + \" \" + specDisallowed.join(\" \"),\n    enumerable: true\n  });\n  Object.defineProperty(this, \"match\", {\n    value: function(alg) {\n      var result = Boolean(alg);\n\n      if (result && ptnAllowed) {\n        ptnAllowed.lastIndex = 0;\n        result = ptnAllowed.test(alg);\n      }\n      if (result && ptnDisallowed) {\n        ptnDisallowed.lastIndex = 0;\n        result = !ptnDisallowed.test(alg);\n      }\n\n      return result;\n    }\n  });\n}\n\nmodule.exports = AlgConfig;\n","/*!\n * util/base64url.js - Implementation of web-safe Base64 Encoder/Decoder\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar impl = require(\"base64url\");\n\n/**\n * @namespace base64url\n * @description\n * Provides methods to encode and decode data according to the\n * base64url alphabet.\n */\nvar base64url = {\n  /**\n   * @function\n   * Encodes the input to base64url.\n   *\n   * If {input} is a Buffer, then {encoding} is ignored. Otherwise,\n   * {encoding} can be one of \"binary\", \"base64\", \"hex\", \"utf8\".\n   *\n   * @param {Buffer|String} input The data to encode.\n   * @param {String} [encoding = binary] The input encoding format.\n   * @returns {String} the base64url encoding of {input}.\n   */\n  encode: function encode(buffer, encoding) {\n    if (buffer instanceof ArrayBuffer) {\n      buffer = new Uint8Array(buffer);\n    }\n\n    if (!Buffer.isBuffer(buffer)) {\n      buffer = Buffer.from(buffer, encoding);\n    }\n\n    return impl.encode(buffer);\n  },\n  /**\n   * @function\n   * Decodes the input from base64url.\n   *\n   * @param {String} input The data to decode.\n   * @returns {Buffer|String} the base64url decoding of {input}.\n   */\n  decode: impl.toBuffer\n};\n\nmodule.exports = base64url;\n","/*!\n * util/databuffer.js - Forge-compatible Buffer based on Node.js Buffers\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\"),\n    base64url = require(\"./base64url.js\");\n\n/**\n *\n */\nfunction DataBuffer(b, options) {\n  options = options || {};\n\n  // treat (views of) (Array)Buffers special\n  // NOTE: default implementation creates copies, but efficiently\n  //       wherever possible\n  if (Buffer.isBuffer(b)) {\n    this.data = b;\n  } else if (forge.util.isArrayBuffer(b)) {\n    b = new Uint8Array(b);\n    this.data = Buffer.from(b);\n  } else if (forge.util.isArrayBufferView(b)) {\n    b = new Uint8Array(b.buffer, b.byteOffset, b.byteLength);\n    this.data = Buffer.from(b);\n  }\n\n  if (this.data) {\n    this.write = this.data.length;\n    b = undefined;\n  }\n\n  // setup growth rate\n  this.growSize = options.growSize || DataBuffer.DEFAULT_GROW_SIZE;\n\n  // initialize pointers and data\n  this.write = this.write || 0;\n  this.read = this.read || 0;\n  if (b) {\n    this.putBytes(b);\n  } else if (!this.data) {\n    this.accommodate(0);\n  }\n\n  // massage read/write pointers\n  options.readOffset = (\"readOffset\" in options) ?\n                       options.readOffset :\n                       this.read;\n  this.write = (\"writeOffset\" in options) ?\n               options.writeOffset :\n               this.write;\n  this.read = Math.min(options.readOffset, this.write);\n}\nDataBuffer.DEFAULT_GROW_SIZE = 16;\n\nDataBuffer.prototype.length = function() {\n  return this.write - this.read;\n};\nDataBuffer.prototype.available = function() {\n  return this.data.length - this.write;\n};\nDataBuffer.prototype.isEmpty = function() {\n  return this.length() <= 0;\n};\n\nDataBuffer.prototype.accommodate = function(length) {\n  if (!this.data) {\n    // initializes a new buffer\n    length = Math.max(this.write + length, this.growSize);\n\n    this.data = Buffer.alloc(length);\n  } else if (this.available() < length) {\n    length = Math.max(length, this.growSize);\n\n    // create a new empty buffer, and copy current one into it\n    var src = this.data;\n    var dst = Buffer.alloc(src.length + length);\n    src.copy(dst, 0);\n\n    // set data as the new buffer\n    this.data = dst;\n  }\n  // ensure the rest is 0\n  this.data.fill(0, this.write);\n\n  return this;\n};\nDataBuffer.prototype.clear = function() {\n  this.read = this.write = 0;\n  this.data = Buffer.alloc(0);\n  return this;\n};\nDataBuffer.prototype.truncate = function(count) {\n  // chop off <count> bytes from the end\n  this.write = this.read + Math.max(0, this.length() - count);\n  // ensure the remainder is 0\n  this.data.fill(0, this.write);\n  return this;\n};\nDataBuffer.prototype.compact = function() {\n  if (this.read > 0) {\n    if (this.write === this.read) {\n      this.read = this.write = 0;\n    } else {\n      this.data.copy(this.data, 0, this.read, this.write);\n      this.write = this.write - this.read;\n      this.read = 0;\n    }\n    // ensure remainder is 0\n    this.data.fill(0, this.write);\n  }\n  return this;\n};\nDataBuffer.prototype.copy = function() {\n  return new DataBuffer(this, {\n    readOffset: this.read,\n    writeOffset: this.write,\n    growSize: this.growSize\n  });\n};\n\nDataBuffer.prototype.equals = function(test) {\n  if (!DataBuffer.isBuffer(test)) {\n    return false;\n  }\n\n  if (test.length() !== this.length()) {\n    return false;\n  }\n\n  var rval = true,\n      delta = this.read - test.read;\n  // constant time\n  for (var idx = test.read; test.write > idx; idx++) {\n    rval = rval && (this.data[idx + delta] === test.data[idx]);\n  }\n  return rval;\n};\nDataBuffer.prototype.at = function(idx) {\n  return this.data[this.read + idx];\n};\nDataBuffer.prototype.setAt = function(idx, b) {\n  this.data[this.read + idx] = b;\n  return this;\n};\nDataBuffer.prototype.last = function() {\n  return this.data[this.write - 1];\n};\nDataBuffer.prototype.bytes = function(count) {\n  var rval;\n  if (undefined === count) {\n    count = this.length();\n  } else if (count) {\n    count = Math.min(count, this.length());\n  }\n\n  if (0 === count) {\n    rval = \"\";\n  } else {\n    var begin = this.read,\n        end = begin + count,\n        data = this.data.slice(begin, end);\n    rval = String.fromCharCode.apply(null, data);\n  }\n\n  return rval;\n};\nDataBuffer.prototype.buffer = function(count) {\n  var rval;\n  if (undefined === count) {\n    count = this.length();\n  } else if (count) {\n    count = Math.min(count, this.length());\n  }\n\n  if (0 === count) {\n    rval = new ArrayBuffer(0);\n  } else {\n    var begin = this.read,\n        end = begin + count,\n        data = this.data.slice(begin, end);\n    rval = new Uint8Array(end - begin);\n    rval.set(data);\n  }\n\n  return rval;\n};\nDataBuffer.prototype.native = function(count) {\n  var rval;\n  if (\"undefined\" === typeof count) {\n    count = this.length();\n  } else if (count) {\n    count = Math.min(count, this.length());\n  }\n\n  if (0 === count) {\n    rval = Buffer.alloc(0);\n  } else {\n    var begin = this.read,\n        end = begin + count;\n    rval = this.data.slice(begin, end);\n  }\n\n  return rval;\n};\n\nDataBuffer.prototype.toHex = function() {\n  return this.toString(\"hex\");\n};\nDataBuffer.prototype.toString = function(encoding) {\n  // short circuit empty string\n  if (0 === this.length()) {\n    return \"\";\n  }\n\n  var view = this.data.slice(this.read, this.write);\n  encoding = encoding || \"utf8\";\n  // special cases, then built-in support\n  switch (encoding) {\n    case \"raw\":\n      return view.toString(\"binary\");\n    case \"base64url\":\n      return base64url.encode(view);\n    case \"utf16\":\n      return view.toString(\"ucs2\");\n    default:\n      return view.toString(encoding);\n  }\n};\n\nDataBuffer.prototype.fillWithByte = function(b, n) {\n  if (!n) {\n    n = this.available();\n  }\n  this.accommodate(n);\n  this.data.fill(b, this.write, this.write + n);\n  this.write += n;\n\n  return this;\n};\n\nDataBuffer.prototype.getBuffer = function(count) {\n  var rval = this.buffer(count);\n  this.read += rval.byteLength;\n\n  return rval;\n};\nDataBuffer.prototype.putBuffer = function(bytes) {\n  return this.putBytes(bytes);\n};\n\nDataBuffer.prototype.getBytes = function(count) {\n  var rval = this.bytes(count);\n  this.read += rval.length;\n  return rval;\n};\nDataBuffer.prototype.putBytes = function(bytes, encoding) {\n  if (\"string\" === typeof bytes) {\n    // fixup encoding\n    encoding = encoding || \"binary\";\n    switch (encoding) {\n      case \"utf16\":\n        // treat as UCS-2/UTF-16BE\n        encoding = \"ucs-2\";\n        break;\n      case \"raw\":\n        encoding = \"binary\";\n        break;\n      case \"base64url\":\n        // NOTE: this returns a Buffer\n        bytes = base64url.decode(bytes);\n        break;\n    }\n\n    // replace bytes with decoded Buffer (if not already)\n    if (!Buffer.isBuffer(bytes)) {\n      bytes = Buffer.from(bytes, encoding);\n    }\n  }\n\n  var src, dst;\n  if (bytes instanceof DataBuffer) {\n    // be slightly more efficient\n    var orig = bytes;\n    bytes = orig.data.slice(orig.read, orig.write);\n    orig.read = orig.write;\n  } else if (bytes instanceof forge.util.ByteStringBuffer) {\n    bytes = bytes.getBytes();\n  }\n\n  // process array\n  if (Buffer.isBuffer(bytes)) {\n    src = bytes;\n  } else if (Array.isArray(bytes)) {\n    src = Buffer.from(bytes);\n  } else if (forge.util.isArrayBuffer(bytes)) {\n    src = new Uint8Array(bytes);\n    src = Buffer.from(src);\n  } else if (forge.util.isArrayBufferView(bytes)) {\n    src = (bytes instanceof Uint8Array) ?\n              bytes :\n              new Uint8Array(bytes.buffer,\n                             bytes.byteOffset,\n                             bytes.byteLength);\n    src = Buffer.from(src);\n  } else {\n    throw new TypeError(\"invalid source type\");\n  }\n\n  this.accommodate(src.length);\n  dst = this.data;\n  src.copy(dst, this.write);\n  this.write += src.length;\n\n  return this;\n};\n\nDataBuffer.prototype.getNative = function(count) {\n  var rval = this.native(count);\n  this.read += rval.length;\n  return rval;\n};\nDataBuffer.prototype.putNative = DataBuffer.prototype.putBuffer;\n\nDataBuffer.prototype.getByte = function() {\n  var b = this.data[this.read];\n  this.read = Math.min(this.read + 1, this.write);\n  return b;\n};\nDataBuffer.prototype.putByte = function(b) {\n  this.accommodate(1);\n  this.data[this.write] = b & 0xff;\n  this.write++;\n\n  return this;\n};\n\nDataBuffer.prototype.getInt16 = function() {\n  var n = (this.data[this.read] << 8) ^\n          (this.data[this.read + 1]);\n  this.read = Math.min(this.read + 2, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt16 = function(n) {\n  this.accommodate(2);\n  this.data[this.write] = (n >>> 8) & 0xff;\n  this.data[this.write + 1] = n & 0xff;\n  this.write += 2;\n  return this;\n};\n\nDataBuffer.prototype.getInt24 = function() {\n  var n = (this.data[this.read] << 16) ^\n          (this.data[this.read + 1] << 8) ^\n          this.data[this.read + 2];\n  this.read = Math.min(this.read + 3, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt24 = function(n) {\n  this.accommodate(3);\n  this.data[this.write] = (n >>> 16) & 0xff;\n  this.data[this.write + 1] = (n >>> 8) & 0xff;\n  this.data[this.write + 2] = n & 0xff;\n  this.write += 3;\n  return this;\n};\n\nDataBuffer.prototype.getInt32 = function() {\n  var n = (this.data[this.read] << 24) ^\n          (this.data[this.read + 1] << 16) ^\n          (this.data[this.read + 2] << 8) ^\n          this.data[this.read + 3];\n  this.read = Math.min(this.read + 4, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt32 = function(n) {\n  this.accommodate(4);\n  this.data[this.write] = (n >>> 24) & 0xff;\n  this.data[this.write + 1] = (n >>> 16) & 0xff;\n  this.data[this.write + 2] = (n >>> 8) & 0xff;\n  this.data[this.write + 3] = n & 0xff;\n  this.write += 4;\n  return this;\n};\n\nDataBuffer.prototype.getInt16Le = function() {\n  var n = (this.data[this.read + 1] << 8) ^\n          this.data[this.read];\n  this.read = Math.min(this.read + 2, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt16Le = function(n) {\n  this.accommodate(2);\n  this.data[this.write + 1] = (n >>> 8) & 0xff;\n  this.data[this.write] = n & 0xff;\n  this.write += 2;\n  return this;\n};\n\nDataBuffer.prototype.getInt24Le = function() {\n  var n = (this.data[this.read + 2] << 16) ^\n          (this.data[this.read + 1] << 8) ^\n          this.data[this.read];\n  this.read = Math.min(this.read + 3, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt24Le = function(n) {\n  this.accommodate(3);\n  this.data[this.write + 2] = (n >>> 16) & 0xff;\n  this.data[this.write + 1] = (n >>> 8) & 0xff;\n  this.data[this.write] = n & 0xff;\n  this.write += 3;\n  return this;\n};\nDataBuffer.prototype.getInt32Le = function() {\n  var n = (this.data[this.read + 3] << 24) ^\n          (this.data[this.read + 2] << 16) ^\n          (this.data[this.read + 1] << 8) ^\n          this.data[this.read];\n  this.read = Math.min(this.read + 4, this.write);\n  return n;\n};\nDataBuffer.prototype.putInt32Le = function(n) {\n  this.accommodate(4);\n  this.data[this.write + 3] = (n >>> 24) & 0xff;\n  this.data[this.write + 2] = (n >>> 16) & 0xff;\n  this.data[this.write + 1] = (n >>> 8) & 0xff;\n  this.data[this.write] = n & 0xff;\n  this.write += 4;\n  return this;\n};\n\nDataBuffer.prototype.getInt = function(bits) {\n  var rval = 0;\n  do {\n    rval = (rval << 8) | this.getByte();\n    bits -= 8;\n  } while (bits > 0);\n  return rval;\n};\nDataBuffer.prototype.putInt = function(n, bits) {\n  this.accommodate(Math.ceil(bits / 8));\n  do {\n    bits -= 8;\n    this.putByte((n >> bits) & 0xff);\n  } while (bits > 0);\n  return this;\n};\n\nDataBuffer.prototype.putSignedInt = function(n, bits) {\n  if (n < 0) {\n    n += 2 << (bits - 1);\n  }\n  return this.putInt(n, bits);\n};\n\nDataBuffer.prototype.putString = function(str) {\n  return this.putBytes(str, \"utf16\");\n};\n\nDataBuffer.isBuffer = function(test) {\n  return (test instanceof DataBuffer);\n};\nDataBuffer.asBuffer = function(orig) {\n  return DataBuffer.isBuffer(orig) ?\n         orig :\n         orig ?\n         new DataBuffer(orig) :\n         new DataBuffer();\n};\n\nmodule.exports = DataBuffer;\n","/*!\n * util/index.js - Utilities Entry Point\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar forge = require(\"../deps/forge.js\");\n\nvar util;\n\nfunction asBuffer(input, encoding) {\n  if (Buffer.isBuffer(input)) {\n    return input;\n  }\n\n  if (\"string\" === typeof input) {\n    encoding = encoding || \"binary\";\n    if (\"base64url\" === encoding) {\n      return util.base64url.decode(input);\n    }\n    return Buffer.from(input, encoding);\n  }\n\n  // assume input is an Array, ArrayBuffer, or ArrayBufferView\n  if (forge.util.isArrayBufferView(input)) {\n    input = (input instanceof Uint8Array) ?\n            input :\n            new Uint8Array(input.buffer, input.byteOffset, input.byteOffset + input.byteLength);\n  } else if (forge.util.isArrayBuffer(input)) {\n    input = new Uint8Array(input);\n  }\n\n  var output;\n  output = Buffer.from(input);\n\n  return output;\n}\n\nfunction randomBytes(len) {\n  return Buffer.from(forge.random.getBytes(len), \"binary\");\n}\n\nutil = {\n  base64url: require(\"./base64url.js\"),\n  utf8: require(\"./utf8.js\"),\n  asBuffer: asBuffer,\n  randomBytes: randomBytes\n};\nmodule.exports = util;\n","/*!\n * util/utf8.js - Implementation of UTF-8 Encoder/Decoder\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar partialRight = require(\"lodash/partialRight\");\nvar merge = require(\"lodash/merge\");\n\nvar typedArrayCtors = (function() {\n  var ctors = [];\n  if (\"undefined\" !== typeof Uint8ClampedArray) {\n    ctors.push(Uint8ClampedArray);\n  }\n  if (\"undefined\" !== typeof Uint8Array) {\n    ctors.push(Uint8Array);\n  }\n  if (\"undefined\" !== typeof Uint16Array) {\n    ctors.push(Uint16Array);\n  }\n  if (\"undefined\" !== typeof Uint32Array) {\n    ctors.push(Uint32Array);\n  }\n  if (\"undefined\" !== typeof Float32Array) {\n    ctors.push(Float32Array);\n  }\n  if (\"undefined\" !== typeof Float64Array) {\n    ctors.push(Float64Array);\n  }\n  return ctors;\n})();\n\nfunction findTypedArrayFor(ta) {\n  var ctor;\n  for (var idx = 0; !ctor && typedArrayCtors.length > idx; idx++) {\n    if (ta instanceof typedArrayCtors[idx]) {\n      ctor = typedArrayCtors[idx];\n    }\n  }\n  return ctor;\n}\n\nfunction mergeBuffer(a, b) {\n  // TODO: should this be a copy, or the reference itself?\n  if (Buffer.isBuffer(b)) {\n    b = Buffer.from(b);\n  } else {\n    var Ctor = findTypedArrayFor(b);\n    b = Ctor ?\n        new Ctor(b, b.byteOffset, b.byteLength) :\n        undefined;\n  }\n\n  // TODO: QUESTION: create a merged <whatever-a-is>??\n  // for now, a is b\n  a = b;\n\n  return b;\n}\n\nmodule.exports = partialRight(merge, mergeBuffer);\n","/*!\n * util/utf8.js - Implementation of UTF-8 Encoder/Decoder\n *\n * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.\n */\n\"use strict\";\n\nvar utf8 = exports;\n\nutf8.encode = function(input) {\n  var output = encodeURIComponent(input || \"\");\n  output = output.replace(/%([0-9a-fA-F]{2})/g, function(m, code) {\n    code = parseInt(code, 16);\n    return String.fromCharCode(code);\n  });\n\n  return output;\n};\nutf8.decode = function(input) {\n  var output = (input || \"\").replace(/[\\u0080-\\u00ff]/g, function(m) {\n    var code = (0x100 | m.charCodeAt(0)).toString(16).substring(1);\n    return \"%\" + code;\n  });\n  output = decodeURIComponent(output);\n\n  return output;\n};\n","// Top level file is just a mixin of submodules & constants\n'use strict';\n\nconst { Deflate, deflate, deflateRaw, gzip } = require('./lib/deflate');\n\nconst { Inflate, inflate, inflateRaw, ungzip } = require('./lib/inflate');\n\nconst constants = require('./lib/zlib/constants');\n\nmodule.exports.Deflate = Deflate;\nmodule.exports.deflate = deflate;\nmodule.exports.deflateRaw = deflateRaw;\nmodule.exports.gzip = gzip;\nmodule.exports.Inflate = Inflate;\nmodule.exports.inflate = inflate;\nmodule.exports.inflateRaw = inflateRaw;\nmodule.exports.ungzip = ungzip;\nmodule.exports.constants = constants;\n","'use strict';\n\n\nconst zlib_deflate = require('./zlib/deflate');\nconst utils        = require('./utils/common');\nconst strings      = require('./utils/strings');\nconst msg          = require('./zlib/messages');\nconst ZStream      = require('./zlib/zstream');\n\nconst toString = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH, Z_SYNC_FLUSH, Z_FULL_FLUSH, Z_FINISH,\n  Z_OK, Z_STREAM_END,\n  Z_DEFAULT_COMPRESSION,\n  Z_DEFAULT_STRATEGY,\n  Z_DEFLATED\n} = require('./zlib/constants');\n\n/* ===========================================================================*/\n\n\n/**\n * class Deflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[deflate]],\n * [[deflateRaw]] and [[gzip]].\n **/\n\n/* internal\n * Deflate.chunks -> Array\n *\n * Chunks of output data, if [[Deflate#onData]] not overridden.\n **/\n\n/**\n * Deflate.result -> Uint8Array\n *\n * Compressed result, generated by default [[Deflate#onData]]\n * and [[Deflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Deflate#push]] with `Z_FINISH` / `true` param).\n **/\n\n/**\n * Deflate.err -> Number\n *\n * Error code after deflate finished. 0 (Z_OK) on success.\n * You will not need it in real life, because deflate errors\n * are possible only on wrong options or bad `onData` / `onEnd`\n * custom handlers.\n **/\n\n/**\n * Deflate.msg -> String\n *\n * Error message, if [[Deflate.err]] != 0\n **/\n\n\n/**\n * new Deflate(options)\n * - options (Object): zlib deflate options.\n *\n * Creates new deflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `level`\n * - `windowBits`\n * - `memLevel`\n * - `strategy`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw deflate\n * - `gzip` (Boolean) - create gzip wrapper\n * - `header` (Object) - custom header for gzip\n *   - `text` (Boolean) - true if compressed data believed to be text\n *   - `time` (Number) - modification time, unix timestamp\n *   - `os` (Number) - operation system code\n *   - `extra` (Array) - array of bytes with extra data (max 65536)\n *   - `name` (String) - file name (binary string)\n *   - `comment` (String) - comment (binary string)\n *   - `hcrc` (Boolean) - true if header crc should be added\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n *   , chunk1 = new Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = new Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * const deflate = new pako.Deflate({ level: 3});\n *\n * deflate.push(chunk1, false);\n * deflate.push(chunk2, true);  // true -> last chunk\n *\n * if (deflate.err) { throw new Error(deflate.err); }\n *\n * console.log(deflate.result);\n * ```\n **/\nfunction Deflate(options) {\n  this.options = utils.assign({\n    level: Z_DEFAULT_COMPRESSION,\n    method: Z_DEFLATED,\n    chunkSize: 16384,\n    windowBits: 15,\n    memLevel: 8,\n    strategy: Z_DEFAULT_STRATEGY\n  }, options || {});\n\n  let opt = this.options;\n\n  if (opt.raw && (opt.windowBits > 0)) {\n    opt.windowBits = -opt.windowBits;\n  }\n\n  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {\n    opt.windowBits += 16;\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm = new ZStream();\n  this.strm.avail_out = 0;\n\n  let status = zlib_deflate.deflateInit2(\n    this.strm,\n    opt.level,\n    opt.method,\n    opt.windowBits,\n    opt.memLevel,\n    opt.strategy\n  );\n\n  if (status !== Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  if (opt.header) {\n    zlib_deflate.deflateSetHeader(this.strm, opt.header);\n  }\n\n  if (opt.dictionary) {\n    let dict;\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      // If we need to compress text, change encoding to utf8.\n      dict = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      dict = new Uint8Array(opt.dictionary);\n    } else {\n      dict = opt.dictionary;\n    }\n\n    status = zlib_deflate.deflateSetDictionary(this.strm, dict);\n\n    if (status !== Z_OK) {\n      throw new Error(msg[status]);\n    }\n\n    this._dict_set = true;\n  }\n}\n\n/**\n * Deflate#push(data[, flush_mode]) -> Boolean\n * - data (Uint8Array|ArrayBuffer|String): input data. Strings will be\n *   converted to utf8 byte sequence.\n * - flush_mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with\n * new compressed chunks. Returns `true` on success. The last data block must\n * have `flush_mode` Z_FINISH (or `true`). That will flush internal pending\n * buffers and call [[Deflate#onEnd]].\n *\n * On fail call [[Deflate#onEnd]] with error code and return false.\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nDeflate.prototype.push = function (data, flush_mode) {\n  const strm = this.strm;\n  const chunkSize = this.options.chunkSize;\n  let status, _flush_mode;\n\n  if (this.ended) { return false; }\n\n  if (flush_mode === ~~flush_mode) _flush_mode = flush_mode;\n  else _flush_mode = flush_mode === true ? Z_FINISH : Z_NO_FLUSH;\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // If we need to compress text, change encoding to utf8.\n    strm.input = strings.string2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  for (;;) {\n    if (strm.avail_out === 0) {\n      strm.output = new Uint8Array(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    // Make sure avail_out > 6 to avoid repeating markers\n    if ((_flush_mode === Z_SYNC_FLUSH || _flush_mode === Z_FULL_FLUSH) && strm.avail_out <= 6) {\n      this.onData(strm.output.subarray(0, strm.next_out));\n      strm.avail_out = 0;\n      continue;\n    }\n\n    status = zlib_deflate.deflate(strm, _flush_mode);\n\n    // Ended => flush and finish\n    if (status === Z_STREAM_END) {\n      if (strm.next_out > 0) {\n        this.onData(strm.output.subarray(0, strm.next_out));\n      }\n      status = zlib_deflate.deflateEnd(this.strm);\n      this.onEnd(status);\n      this.ended = true;\n      return status === Z_OK;\n    }\n\n    // Flush if out buffer full\n    if (strm.avail_out === 0) {\n      this.onData(strm.output);\n      continue;\n    }\n\n    // Flush if requested and has data\n    if (_flush_mode > 0 && strm.next_out > 0) {\n      this.onData(strm.output.subarray(0, strm.next_out));\n      strm.avail_out = 0;\n      continue;\n    }\n\n    if (strm.avail_in === 0) break;\n  }\n\n  return true;\n};\n\n\n/**\n * Deflate#onData(chunk) -> Void\n * - chunk (Uint8Array): output data.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nDeflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Deflate#onEnd(status) -> Void\n * - status (Number): deflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called once after you tell deflate that the input stream is\n * complete (Z_FINISH). By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nDeflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK) {\n    this.result = utils.flattenChunks(this.chunks);\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * deflate(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * Compress `data` with deflate algorithm and `options`.\n *\n * Supported options are:\n *\n * - level\n * - windowBits\n * - memLevel\n * - strategy\n * - dictionary\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n * const data = new Uint8Array([1,2,3,4,5,6,7,8,9]);\n *\n * console.log(pako.deflate(data));\n * ```\n **/\nfunction deflate(input, options) {\n  const deflator = new Deflate(options);\n\n  deflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (deflator.err) { throw deflator.msg || msg[deflator.err]; }\n\n  return deflator.result;\n}\n\n\n/**\n * deflateRaw(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction deflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return deflate(input, options);\n}\n\n\n/**\n * gzip(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but create gzip wrapper instead of\n * deflate one.\n **/\nfunction gzip(input, options) {\n  options = options || {};\n  options.gzip = true;\n  return deflate(input, options);\n}\n\n\nmodule.exports.Deflate = Deflate;\nmodule.exports.deflate = deflate;\nmodule.exports.deflateRaw = deflateRaw;\nmodule.exports.gzip = gzip;\nmodule.exports.constants = require('./zlib/constants');\n","'use strict';\n\n\nconst zlib_inflate = require('./zlib/inflate');\nconst utils        = require('./utils/common');\nconst strings      = require('./utils/strings');\nconst msg          = require('./zlib/messages');\nconst ZStream      = require('./zlib/zstream');\nconst GZheader     = require('./zlib/gzheader');\n\nconst toString = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH, Z_FINISH,\n  Z_OK, Z_STREAM_END, Z_NEED_DICT, Z_STREAM_ERROR, Z_DATA_ERROR, Z_MEM_ERROR\n} = require('./zlib/constants');\n\n/* ===========================================================================*/\n\n\n/**\n * class Inflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[inflate]]\n * and [[inflateRaw]].\n **/\n\n/* internal\n * inflate.chunks -> Array\n *\n * Chunks of output data, if [[Inflate#onData]] not overridden.\n **/\n\n/**\n * Inflate.result -> Uint8Array|String\n *\n * Uncompressed result, generated by default [[Inflate#onData]]\n * and [[Inflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Inflate#push]] with `Z_FINISH` / `true` param).\n **/\n\n/**\n * Inflate.err -> Number\n *\n * Error code after inflate finished. 0 (Z_OK) on success.\n * Should be checked if broken data possible.\n **/\n\n/**\n * Inflate.msg -> String\n *\n * Error message, if [[Inflate.err]] != 0\n **/\n\n\n/**\n * new Inflate(options)\n * - options (Object): zlib inflate options.\n *\n * Creates new inflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `windowBits`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw inflate\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n * By default, when no options set, autodetect deflate/gzip data format via\n * wrapper header.\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n * const chunk1 = new Uint8Array([1,2,3,4,5,6,7,8,9])\n * const chunk2 = new Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * const inflate = new pako.Inflate({ level: 3});\n *\n * inflate.push(chunk1, false);\n * inflate.push(chunk2, true);  // true -> last chunk\n *\n * if (inflate.err) { throw new Error(inflate.err); }\n *\n * console.log(inflate.result);\n * ```\n **/\nfunction Inflate(options) {\n  this.options = utils.assign({\n    chunkSize: 1024 * 64,\n    windowBits: 15,\n    to: ''\n  }, options || {});\n\n  const opt = this.options;\n\n  // Force window size for `raw` data, if not set directly,\n  // because we have no header for autodetect.\n  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {\n    opt.windowBits = -opt.windowBits;\n    if (opt.windowBits === 0) { opt.windowBits = -15; }\n  }\n\n  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate\n  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&\n      !(options && options.windowBits)) {\n    opt.windowBits += 32;\n  }\n\n  // Gzip header has no info about windows size, we can do autodetect only\n  // for deflate. So, if window size not set, force it to max when gzip possible\n  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {\n    // bit 3 (16) -> gzipped data\n    // bit 4 (32) -> autodetect gzip/deflate\n    if ((opt.windowBits & 15) === 0) {\n      opt.windowBits |= 15;\n    }\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm   = new ZStream();\n  this.strm.avail_out = 0;\n\n  let status  = zlib_inflate.inflateInit2(\n    this.strm,\n    opt.windowBits\n  );\n\n  if (status !== Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  this.header = new GZheader();\n\n  zlib_inflate.inflateGetHeader(this.strm, this.header);\n\n  // Setup dictionary\n  if (opt.dictionary) {\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      opt.dictionary = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      opt.dictionary = new Uint8Array(opt.dictionary);\n    }\n    if (opt.raw) { //In raw mode we need to set the dictionary early\n      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);\n      if (status !== Z_OK) {\n        throw new Error(msg[status]);\n      }\n    }\n  }\n}\n\n/**\n * Inflate#push(data[, flush_mode]) -> Boolean\n * - data (Uint8Array|ArrayBuffer): input data\n * - flush_mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE\n *   flush modes. See constants. Skipped or `false` means Z_NO_FLUSH,\n *   `true` means Z_FINISH.\n *\n * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with\n * new output chunks. Returns `true` on success. If end of stream detected,\n * [[Inflate#onEnd]] will be called.\n *\n * `flush_mode` is not needed for normal operation, because end of stream\n * detected automatically. You may try to use it for advanced things, but\n * this functionality was not tested.\n *\n * On fail call [[Inflate#onEnd]] with error code and return false.\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nInflate.prototype.push = function (data, flush_mode) {\n  const strm = this.strm;\n  const chunkSize = this.options.chunkSize;\n  const dictionary = this.options.dictionary;\n  let status, _flush_mode, last_avail_out;\n\n  if (this.ended) return false;\n\n  if (flush_mode === ~~flush_mode) _flush_mode = flush_mode;\n  else _flush_mode = flush_mode === true ? Z_FINISH : Z_NO_FLUSH;\n\n  // Convert data if needed\n  if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  for (;;) {\n    if (strm.avail_out === 0) {\n      strm.output = new Uint8Array(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    status = zlib_inflate.inflate(strm, _flush_mode);\n\n    if (status === Z_NEED_DICT && dictionary) {\n      status = zlib_inflate.inflateSetDictionary(strm, dictionary);\n\n      if (status === Z_OK) {\n        status = zlib_inflate.inflate(strm, _flush_mode);\n      } else if (status === Z_DATA_ERROR) {\n        // Replace code with more verbose\n        status = Z_NEED_DICT;\n      }\n    }\n\n    // Skip snyc markers if more data follows and not raw mode\n    while (strm.avail_in > 0 &&\n           status === Z_STREAM_END &&\n           strm.state.wrap > 0 &&\n           data[strm.next_in] !== 0)\n    {\n      zlib_inflate.inflateReset(strm);\n      status = zlib_inflate.inflate(strm, _flush_mode);\n    }\n\n    switch (status) {\n      case Z_STREAM_ERROR:\n      case Z_DATA_ERROR:\n      case Z_NEED_DICT:\n      case Z_MEM_ERROR:\n        this.onEnd(status);\n        this.ended = true;\n        return false;\n    }\n\n    // Remember real `avail_out` value, because we may patch out buffer content\n    // to align utf8 strings boundaries.\n    last_avail_out = strm.avail_out;\n\n    if (strm.next_out) {\n      if (strm.avail_out === 0 || status === Z_STREAM_END) {\n\n        if (this.options.to === 'string') {\n\n          let next_out_utf8 = strings.utf8border(strm.output, strm.next_out);\n\n          let tail = strm.next_out - next_out_utf8;\n          let utf8str = strings.buf2string(strm.output, next_out_utf8);\n\n          // move tail & realign counters\n          strm.next_out = tail;\n          strm.avail_out = chunkSize - tail;\n          if (tail) strm.output.set(strm.output.subarray(next_out_utf8, next_out_utf8 + tail), 0);\n\n          this.onData(utf8str);\n\n        } else {\n          this.onData(strm.output.length === strm.next_out ? strm.output : strm.output.subarray(0, strm.next_out));\n        }\n      }\n    }\n\n    // Must repeat iteration if out buffer is full\n    if (status === Z_OK && last_avail_out === 0) continue;\n\n    // Finalize if end of stream reached.\n    if (status === Z_STREAM_END) {\n      status = zlib_inflate.inflateEnd(this.strm);\n      this.onEnd(status);\n      this.ended = true;\n      return true;\n    }\n\n    if (strm.avail_in === 0) break;\n  }\n\n  return true;\n};\n\n\n/**\n * Inflate#onData(chunk) -> Void\n * - chunk (Uint8Array|String): output data. When string output requested,\n *   each chunk will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nInflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Inflate#onEnd(status) -> Void\n * - status (Number): inflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called either after you tell inflate that the input stream is\n * complete (Z_FINISH). By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nInflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK) {\n    if (this.options.to === 'string') {\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * inflate(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Decompress `data` with inflate/ungzip and `options`. Autodetect\n * format via wrapper header by default. That's why we don't provide\n * separate `ungzip` method.\n *\n * Supported options are:\n *\n * - windowBits\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako');\n * const input = pako.deflate(new Uint8Array([1,2,3,4,5,6,7,8,9]));\n * let output;\n *\n * try {\n *   output = pako.inflate(input);\n * } catch (err) {\n *   console.log(err);\n * }\n * ```\n **/\nfunction inflate(input, options) {\n  const inflator = new Inflate(options);\n\n  inflator.push(input);\n\n  // That will never happens, if you don't cheat with options :)\n  if (inflator.err) throw inflator.msg || msg[inflator.err];\n\n  return inflator.result;\n}\n\n\n/**\n * inflateRaw(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * The same as [[inflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction inflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return inflate(input, options);\n}\n\n\n/**\n * ungzip(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Just shortcut to [[inflate]], because it autodetects format\n * by header.content. Done for convenience.\n **/\n\n\nmodule.exports.Inflate = Inflate;\nmodule.exports.inflate = inflate;\nmodule.exports.inflateRaw = inflateRaw;\nmodule.exports.ungzip = inflate;\nmodule.exports.constants = require('./zlib/constants');\n","'use strict';\n\n\nconst _has = (obj, key) => {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n};\n\nmodule.exports.assign = function (obj /*from1, from2, from3, ...*/) {\n  const sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    const source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (const p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// Join array of chunks to single array.\nmodule.exports.flattenChunks = (chunks) => {\n  // calculate data length\n  let len = 0;\n\n  for (let i = 0, l = chunks.length; i < l; i++) {\n    len += chunks[i].length;\n  }\n\n  // join chunks\n  const result = new Uint8Array(len);\n\n  for (let i = 0, pos = 0, l = chunks.length; i < l; i++) {\n    let chunk = chunks[i];\n    result.set(chunk, pos);\n    pos += chunk.length;\n  }\n\n  return result;\n};\n","// String encode/decode helpers\n'use strict';\n\n\n// Quick check if we can use fast array to bin string conversion\n//\n// - apply(Array) can fail on Android 2.2\n// - apply(Uint8Array) can fail on iOS 5.1 Safari\n//\nlet STR_APPLY_UIA_OK = true;\n\ntry { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }\n\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nconst _utf8len = new Uint8Array(256);\nfor (let q = 0; q < 256; q++) {\n  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);\n}\n_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start\n\n\n// convert string to array (typed, when possible)\nmodule.exports.string2buf = (str) => {\n  if (typeof TextEncoder === 'function' && TextEncoder.prototype.encode) {\n    return new TextEncoder().encode(str);\n  }\n\n  let buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n  // count binary size\n  for (m_pos = 0; m_pos < str_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n  }\n\n  // allocate buffer\n  buf = new Uint8Array(buf_len);\n\n  // convert\n  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    if (c < 0x80) {\n      /* one byte */\n      buf[i++] = c;\n    } else if (c < 0x800) {\n      /* two bytes */\n      buf[i++] = 0xC0 | (c >>> 6);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else if (c < 0x10000) {\n      /* three bytes */\n      buf[i++] = 0xE0 | (c >>> 12);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else {\n      /* four bytes */\n      buf[i++] = 0xf0 | (c >>> 18);\n      buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    }\n  }\n\n  return buf;\n};\n\n// Helper\nconst buf2binstring = (buf, len) => {\n  // On Chrome, the arguments in a function call that are allowed is `65534`.\n  // If the length of the buffer is smaller than that, we can use this optimization,\n  // otherwise we will take a slower path.\n  if (len < 65534) {\n    if (buf.subarray && STR_APPLY_UIA_OK) {\n      return String.fromCharCode.apply(null, buf.length === len ? buf : buf.subarray(0, len));\n    }\n  }\n\n  let result = '';\n  for (let i = 0; i < len; i++) {\n    result += String.fromCharCode(buf[i]);\n  }\n  return result;\n};\n\n\n// convert array to string\nmodule.exports.buf2string = (buf, max) => {\n  const len = max || buf.length;\n\n  if (typeof TextDecoder === 'function' && TextDecoder.prototype.decode) {\n    return new TextDecoder().decode(buf.subarray(0, max));\n  }\n\n  let i, out;\n\n  // Reserve max possible length (2 words per char)\n  // NB: by unknown reasons, Array is significantly faster for\n  //     String.fromCharCode.apply than Uint16Array.\n  const utf16buf = new Array(len * 2);\n\n  for (out = 0, i = 0; i < len;) {\n    let c = buf[i++];\n    // quick process ascii\n    if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n    let c_len = _utf8len[c];\n    // skip 5 & 6 byte codes\n    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }\n\n    // apply mask on first byte\n    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n    // join the rest\n    while (c_len > 1 && i < len) {\n      c = (c << 6) | (buf[i++] & 0x3f);\n      c_len--;\n    }\n\n    // terminated by end of string?\n    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n    if (c < 0x10000) {\n      utf16buf[out++] = c;\n    } else {\n      c -= 0x10000;\n      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n      utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n    }\n  }\n\n  return buf2binstring(utf16buf, out);\n};\n\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nmodule.exports.utf8border = (buf, max) => {\n\n  max = max || buf.length;\n  if (max > buf.length) { max = buf.length; }\n\n  // go back from last position, until start of sequence found\n  let pos = max - 1;\n  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n  // Very small and broken sequence,\n  // return max, because we should return something anyway.\n  if (pos < 0) { return max; }\n\n  // If we came to start of buffer - that means buffer is too small,\n  // return max too.\n  if (pos === 0) { return max; }\n\n  return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n","'use strict';\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst adler32 = (adler, buf, len, pos) => {\n  let s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n};\n\n\nmodule.exports = adler32;\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  Z_MEM_ERROR:       -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n","'use strict';\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nconst makeTable = () => {\n  let c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n};\n\n// Create table on load. Just 255 signed longs. Not a problem.\nconst crcTable = new Uint32Array(makeTable());\n\n\nconst crc32 = (crc, buf, len, pos) => {\n  const t = crcTable;\n  const end = pos + len;\n\n  crc ^= -1;\n\n  for (let i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n};\n\n\nmodule.exports = crc32;\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst { _tr_init, _tr_stored_block, _tr_flush_block, _tr_tally, _tr_align } = require('./trees');\nconst adler32 = require('./adler32');\nconst crc32   = require('./crc32');\nconst msg     = require('./messages');\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH, Z_PARTIAL_FLUSH, Z_FULL_FLUSH, Z_FINISH, Z_BLOCK,\n  Z_OK, Z_STREAM_END, Z_STREAM_ERROR, Z_DATA_ERROR, Z_BUF_ERROR,\n  Z_DEFAULT_COMPRESSION,\n  Z_FILTERED, Z_HUFFMAN_ONLY, Z_RLE, Z_FIXED, Z_DEFAULT_STRATEGY,\n  Z_UNKNOWN,\n  Z_DEFLATED\n} = require('./constants');\n\n/*============================================================================*/\n\n\nconst MAX_MEM_LEVEL = 9;\n/* Maximum value for memLevel in deflateInit2 */\nconst MAX_WBITS = 15;\n/* 32K LZ77 window */\nconst DEF_MEM_LEVEL = 8;\n\n\nconst LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\nconst LITERALS      = 256;\n/* number of literal bytes 0..255 */\nconst L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\nconst D_CODES       = 30;\n/* number of distance codes */\nconst BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\nconst HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\nconst MAX_BITS  = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nconst MIN_MATCH = 3;\nconst MAX_MATCH = 258;\nconst MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);\n\nconst PRESET_DICT = 0x20;\n\nconst INIT_STATE    =  42;    /* zlib header -> BUSY_STATE */\n//#ifdef GZIP\nconst GZIP_STATE    =  57;    /* gzip header -> BUSY_STATE | EXTRA_STATE */\n//#endif\nconst EXTRA_STATE   =  69;    /* gzip extra block -> NAME_STATE */\nconst NAME_STATE    =  73;    /* gzip file name -> COMMENT_STATE */\nconst COMMENT_STATE =  91;    /* gzip comment -> HCRC_STATE */\nconst HCRC_STATE    = 103;    /* gzip header CRC -> BUSY_STATE */\nconst BUSY_STATE    = 113;    /* deflate -> FINISH_STATE */\nconst FINISH_STATE  = 666;    /* stream complete */\n\nconst BS_NEED_MORE      = 1; /* block not completed, need more input or more output */\nconst BS_BLOCK_DONE     = 2; /* block flush performed */\nconst BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */\nconst BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */\n\nconst OS_CODE = 0x03; // Unix :) . Don't detect, use this default.\n\nconst err = (strm, errorCode) => {\n  strm.msg = msg[errorCode];\n  return errorCode;\n};\n\nconst rank = (f) => {\n  return ((f) * 2) - ((f) > 4 ? 9 : 0);\n};\n\nconst zero = (buf) => {\n  let len = buf.length; while (--len >= 0) { buf[len] = 0; }\n};\n\n/* ===========================================================================\n * Slide the hash table when sliding the window down (could be avoided with 32\n * bit values at the expense of memory usage). We slide even when level == 0 to\n * keep the hash table consistent if we switch back to level > 0 later.\n */\nconst slide_hash = (s) => {\n  let n, m;\n  let p;\n  let wsize = s.w_size;\n\n  n = s.hash_size;\n  p = n;\n  do {\n    m = s.head[--p];\n    s.head[p] = (m >= wsize ? m - wsize : 0);\n  } while (--n);\n  n = wsize;\n//#ifndef FASTEST\n  p = n;\n  do {\n    m = s.prev[--p];\n    s.prev[p] = (m >= wsize ? m - wsize : 0);\n    /* If n is not on any hash chain, prev[n] is garbage but\n     * its value will never be used.\n     */\n  } while (--n);\n//#endif\n};\n\n/* eslint-disable new-cap */\nlet HASH_ZLIB = (s, prev, data) => ((prev << s.hash_shift) ^ data) & s.hash_mask;\n// This hash causes less collisions, https://github.com/nodeca/pako/issues/135\n// But breaks binary compatibility\n//let HASH_FAST = (s, prev, data) => ((prev << 8) + (prev >> 8) + (data << 4)) & s.hash_mask;\nlet HASH = HASH_ZLIB;\n\n\n/* =========================================================================\n * Flush as much pending output as possible. All deflate() output, except for\n * some deflate_stored() output, goes through this function so some\n * applications may wish to modify it to avoid allocating a large\n * strm->next_out buffer and copying into it. (See also read_buf()).\n */\nconst flush_pending = (strm) => {\n  const s = strm.state;\n\n  //_tr_flush_bits(s);\n  let len = s.pending;\n  if (len > strm.avail_out) {\n    len = strm.avail_out;\n  }\n  if (len === 0) { return; }\n\n  strm.output.set(s.pending_buf.subarray(s.pending_out, s.pending_out + len), strm.next_out);\n  strm.next_out  += len;\n  s.pending_out  += len;\n  strm.total_out += len;\n  strm.avail_out -= len;\n  s.pending      -= len;\n  if (s.pending === 0) {\n    s.pending_out = 0;\n  }\n};\n\n\nconst flush_block_only = (s, last) => {\n  _tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);\n  s.block_start = s.strstart;\n  flush_pending(s.strm);\n};\n\n\nconst put_byte = (s, b) => {\n  s.pending_buf[s.pending++] = b;\n};\n\n\n/* =========================================================================\n * Put a short in the pending buffer. The 16-bit value is put in MSB order.\n * IN assertion: the stream state is correct and there is enough room in\n * pending_buf.\n */\nconst putShortMSB = (s, b) => {\n\n  //  put_byte(s, (Byte)(b >> 8));\n//  put_byte(s, (Byte)(b & 0xff));\n  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;\n  s.pending_buf[s.pending++] = b & 0xff;\n};\n\n\n/* ===========================================================================\n * Read a new buffer from the current input stream, update the adler32\n * and total number of bytes read.  All deflate() input goes through\n * this function so some applications may wish to modify it to avoid\n * allocating a large strm->input buffer and copying from it.\n * (See also flush_pending()).\n */\nconst read_buf = (strm, buf, start, size) => {\n\n  let len = strm.avail_in;\n\n  if (len > size) { len = size; }\n  if (len === 0) { return 0; }\n\n  strm.avail_in -= len;\n\n  // zmemcpy(buf, strm->next_in, len);\n  buf.set(strm.input.subarray(strm.next_in, strm.next_in + len), start);\n  if (strm.state.wrap === 1) {\n    strm.adler = adler32(strm.adler, buf, len, start);\n  }\n\n  else if (strm.state.wrap === 2) {\n    strm.adler = crc32(strm.adler, buf, len, start);\n  }\n\n  strm.next_in += len;\n  strm.total_in += len;\n\n  return len;\n};\n\n\n/* ===========================================================================\n * Set match_start to the longest match starting at the given string and\n * return its length. Matches shorter or equal to prev_length are discarded,\n * in which case the result is equal to prev_length and match_start is\n * garbage.\n * IN assertions: cur_match is the head of the hash chain for the current\n *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n * OUT assertion: the match length is not greater than s->lookahead.\n */\nconst longest_match = (s, cur_match) => {\n\n  let chain_length = s.max_chain_length;      /* max hash chain length */\n  let scan = s.strstart; /* current string */\n  let match;                       /* matched string */\n  let len;                           /* length of current match */\n  let best_len = s.prev_length;              /* best match length so far */\n  let nice_match = s.nice_match;             /* stop if match long enough */\n  const limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?\n      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;\n\n  const _win = s.window; // shortcut\n\n  const wmask = s.w_mask;\n  const prev  = s.prev;\n\n  /* Stop when cur_match becomes <= limit. To simplify the code,\n   * we prevent matches with the string of window index 0.\n   */\n\n  const strend = s.strstart + MAX_MATCH;\n  let scan_end1  = _win[scan + best_len - 1];\n  let scan_end   = _win[scan + best_len];\n\n  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.\n   * It is easy to get rid of this optimization if necessary.\n   */\n  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, \"Code too clever\");\n\n  /* Do not waste too much time if we already have a good match: */\n  if (s.prev_length >= s.good_match) {\n    chain_length >>= 2;\n  }\n  /* Do not look for matches beyond the end of the input. This is necessary\n   * to make deflate deterministic.\n   */\n  if (nice_match > s.lookahead) { nice_match = s.lookahead; }\n\n  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, \"need lookahead\");\n\n  do {\n    // Assert(cur_match < s->strstart, \"no future\");\n    match = cur_match;\n\n    /* Skip to next match if the match length cannot increase\n     * or if the match length is less than 2.  Note that the checks below\n     * for insufficient lookahead only occur occasionally for performance\n     * reasons.  Therefore uninitialized memory will be accessed, and\n     * conditional jumps will be made that depend on those values.\n     * However the length of the match is limited to the lookahead, so\n     * the output of deflate is not affected by the uninitialized values.\n     */\n\n    if (_win[match + best_len]     !== scan_end  ||\n        _win[match + best_len - 1] !== scan_end1 ||\n        _win[match]                !== _win[scan] ||\n        _win[++match]              !== _win[scan + 1]) {\n      continue;\n    }\n\n    /* The check at best_len-1 can be removed because it will be made\n     * again later. (This heuristic is not always a win.)\n     * It is not necessary to compare scan[2] and match[2] since they\n     * are always equal when the other bytes match, given that\n     * the hash keys are equal and that HASH_BITS >= 8.\n     */\n    scan += 2;\n    match++;\n    // Assert(*scan == *match, \"match[2]?\");\n\n    /* We check for insufficient lookahead only every 8th comparison;\n     * the 256th check will be made at strstart+258.\n     */\n    do {\n      /*jshint noempty:false*/\n    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             scan < strend);\n\n    // Assert(scan <= s->window+(unsigned)(s->window_size-1), \"wild scan\");\n\n    len = MAX_MATCH - (strend - scan);\n    scan = strend - MAX_MATCH;\n\n    if (len > best_len) {\n      s.match_start = cur_match;\n      best_len = len;\n      if (len >= nice_match) {\n        break;\n      }\n      scan_end1  = _win[scan + best_len - 1];\n      scan_end   = _win[scan + best_len];\n    }\n  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);\n\n  if (best_len <= s.lookahead) {\n    return best_len;\n  }\n  return s.lookahead;\n};\n\n\n/* ===========================================================================\n * Fill the window when the lookahead becomes insufficient.\n * Updates strstart and lookahead.\n *\n * IN assertion: lookahead < MIN_LOOKAHEAD\n * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD\n *    At least one byte has been read, or avail_in == 0; reads are\n *    performed for at least two bytes (required for the zip translate_eol\n *    option -- not supported here).\n */\nconst fill_window = (s) => {\n\n  const _w_size = s.w_size;\n  let n, more, str;\n\n  //Assert(s->lookahead < MIN_LOOKAHEAD, \"already enough lookahead\");\n\n  do {\n    more = s.window_size - s.lookahead - s.strstart;\n\n    // JS ints have 32 bit, block below not needed\n    /* Deal with !@#$% 64K limit: */\n    //if (sizeof(int) <= 2) {\n    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {\n    //        more = wsize;\n    //\n    //  } else if (more == (unsigned)(-1)) {\n    //        /* Very unlikely, but possible on 16 bit machine if\n    //         * strstart == 0 && lookahead == 1 (input done a byte at time)\n    //         */\n    //        more--;\n    //    }\n    //}\n\n\n    /* If the window is almost full and there is insufficient lookahead,\n     * move the upper half to the lower one to make room in the upper half.\n     */\n    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {\n\n      s.window.set(s.window.subarray(_w_size, _w_size + _w_size - more), 0);\n      s.match_start -= _w_size;\n      s.strstart -= _w_size;\n      /* we now have strstart >= MAX_DIST */\n      s.block_start -= _w_size;\n      if (s.insert > s.strstart) {\n        s.insert = s.strstart;\n      }\n      slide_hash(s);\n      more += _w_size;\n    }\n    if (s.strm.avail_in === 0) {\n      break;\n    }\n\n    /* If there was no sliding:\n     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&\n     *    more == window_size - lookahead - strstart\n     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)\n     * => more >= window_size - 2*WSIZE + 2\n     * In the BIG_MEM or MMAP case (not yet supported),\n     *   window_size == input_size + MIN_LOOKAHEAD  &&\n     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.\n     * Otherwise, window_size == 2*WSIZE so more >= 2.\n     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.\n     */\n    //Assert(more >= 2, \"more < 2\");\n    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);\n    s.lookahead += n;\n\n    /* Initialize the hash value now that we have some input: */\n    if (s.lookahead + s.insert >= MIN_MATCH) {\n      str = s.strstart - s.insert;\n      s.ins_h = s.window[str];\n\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */\n      s.ins_h = HASH(s, s.ins_h, s.window[str + 1]);\n//#if MIN_MATCH != 3\n//        Call update_hash() MIN_MATCH-3 more times\n//#endif\n      while (s.insert) {\n        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n        s.ins_h = HASH(s, s.ins_h, s.window[str + MIN_MATCH - 1]);\n\n        s.prev[str & s.w_mask] = s.head[s.ins_h];\n        s.head[s.ins_h] = str;\n        str++;\n        s.insert--;\n        if (s.lookahead + s.insert < MIN_MATCH) {\n          break;\n        }\n      }\n    }\n    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,\n     * but this is not important since only literal bytes will be emitted.\n     */\n\n  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);\n\n  /* If the WIN_INIT bytes after the end of the current data have never been\n   * written, then zero those bytes in order to avoid memory check reports of\n   * the use of uninitialized (or uninitialised as Julian writes) bytes by\n   * the longest match routines.  Update the high water mark for the next\n   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match\n   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.\n   */\n//  if (s.high_water < s.window_size) {\n//    const curr = s.strstart + s.lookahead;\n//    let init = 0;\n//\n//    if (s.high_water < curr) {\n//      /* Previous high water mark below current data -- zero WIN_INIT\n//       * bytes or up to end of window, whichever is less.\n//       */\n//      init = s.window_size - curr;\n//      if (init > WIN_INIT)\n//        init = WIN_INIT;\n//      zmemzero(s->window + curr, (unsigned)init);\n//      s->high_water = curr + init;\n//    }\n//    else if (s->high_water < (ulg)curr + WIN_INIT) {\n//      /* High water mark at or above current data, but below current data\n//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up\n//       * to end of window, whichever is less.\n//       */\n//      init = (ulg)curr + WIN_INIT - s->high_water;\n//      if (init > s->window_size - s->high_water)\n//        init = s->window_size - s->high_water;\n//      zmemzero(s->window + s->high_water, (unsigned)init);\n//      s->high_water += init;\n//    }\n//  }\n//\n//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,\n//    \"not enough room for search\");\n};\n\n/* ===========================================================================\n * Copy without compression as much as possible from the input stream, return\n * the current block state.\n *\n * In case deflateParams() is used to later switch to a non-zero compression\n * level, s->matches (otherwise unused when storing) keeps track of the number\n * of hash table slides to perform. If s->matches is 1, then one hash table\n * slide will be done when switching. If s->matches is 2, the maximum value\n * allowed here, then the hash table will be cleared, since two or more slides\n * is the same as a clear.\n *\n * deflate_stored() is written to minimize the number of times an input byte is\n * copied. It is most efficient with large input and output buffers, which\n * maximizes the opportunites to have a single copy from next_in to next_out.\n */\nconst deflate_stored = (s, flush) => {\n\n  /* Smallest worthy block size when not flushing or finishing. By default\n   * this is 32K. This can be as small as 507 bytes for memLevel == 1. For\n   * large input and output buffers, the stored block size will be larger.\n   */\n  let min_block = s.pending_buf_size - 5 > s.w_size ? s.w_size : s.pending_buf_size - 5;\n\n  /* Copy as many min_block or larger stored blocks directly to next_out as\n   * possible. If flushing, copy the remaining available input to next_out as\n   * stored blocks, if there is enough space.\n   */\n  let len, left, have, last = 0;\n  let used = s.strm.avail_in;\n  do {\n    /* Set len to the maximum size block that we can copy directly with the\n     * available input data and output space. Set left to how much of that\n     * would be copied from what's left in the window.\n     */\n    len = 65535/* MAX_STORED */;     /* maximum deflate stored block length */\n    have = (s.bi_valid + 42) >> 3;     /* number of header bytes */\n    if (s.strm.avail_out < have) {         /* need room for header */\n      break;\n    }\n      /* maximum stored block length that will fit in avail_out: */\n    have = s.strm.avail_out - have;\n    left = s.strstart - s.block_start;  /* bytes left in window */\n    if (len > left + s.strm.avail_in) {\n      len = left + s.strm.avail_in;   /* limit len to the input */\n    }\n    if (len > have) {\n      len = have;             /* limit len to the output */\n    }\n\n    /* If the stored block would be less than min_block in length, or if\n     * unable to copy all of the available input when flushing, then try\n     * copying to the window and the pending buffer instead. Also don't\n     * write an empty block when flushing -- deflate() does that.\n     */\n    if (len < min_block && ((len === 0 && flush !== Z_FINISH) ||\n                        flush === Z_NO_FLUSH ||\n                        len !== left + s.strm.avail_in)) {\n      break;\n    }\n\n    /* Make a dummy stored block in pending to get the header bytes,\n     * including any pending bits. This also updates the debugging counts.\n     */\n    last = flush === Z_FINISH && len === left + s.strm.avail_in ? 1 : 0;\n    _tr_stored_block(s, 0, 0, last);\n\n    /* Replace the lengths in the dummy stored block with len. */\n    s.pending_buf[s.pending - 4] = len;\n    s.pending_buf[s.pending - 3] = len >> 8;\n    s.pending_buf[s.pending - 2] = ~len;\n    s.pending_buf[s.pending - 1] = ~len >> 8;\n\n    /* Write the stored block header bytes. */\n    flush_pending(s.strm);\n\n//#ifdef ZLIB_DEBUG\n//    /* Update debugging counts for the data about to be copied. */\n//    s->compressed_len += len << 3;\n//    s->bits_sent += len << 3;\n//#endif\n\n    /* Copy uncompressed bytes from the window to next_out. */\n    if (left) {\n      if (left > len) {\n        left = len;\n      }\n      //zmemcpy(s->strm->next_out, s->window + s->block_start, left);\n      s.strm.output.set(s.window.subarray(s.block_start, s.block_start + left), s.strm.next_out);\n      s.strm.next_out += left;\n      s.strm.avail_out -= left;\n      s.strm.total_out += left;\n      s.block_start += left;\n      len -= left;\n    }\n\n    /* Copy uncompressed bytes directly from next_in to next_out, updating\n     * the check value.\n     */\n    if (len) {\n      read_buf(s.strm, s.strm.output, s.strm.next_out, len);\n      s.strm.next_out += len;\n      s.strm.avail_out -= len;\n      s.strm.total_out += len;\n    }\n  } while (last === 0);\n\n  /* Update the sliding window with the last s->w_size bytes of the copied\n   * data, or append all of the copied data to the existing window if less\n   * than s->w_size bytes were copied. Also update the number of bytes to\n   * insert in the hash tables, in the event that deflateParams() switches to\n   * a non-zero compression level.\n   */\n  used -= s.strm.avail_in;    /* number of input bytes directly copied */\n  if (used) {\n    /* If any input was used, then no unused input remains in the window,\n     * therefore s->block_start == s->strstart.\n     */\n    if (used >= s.w_size) {  /* supplant the previous history */\n      s.matches = 2;     /* clear hash */\n      //zmemcpy(s->window, s->strm->next_in - s->w_size, s->w_size);\n      s.window.set(s.strm.input.subarray(s.strm.next_in - s.w_size, s.strm.next_in), 0);\n      s.strstart = s.w_size;\n      s.insert = s.strstart;\n    }\n    else {\n      if (s.window_size - s.strstart <= used) {\n        /* Slide the window down. */\n        s.strstart -= s.w_size;\n        //zmemcpy(s->window, s->window + s->w_size, s->strstart);\n        s.window.set(s.window.subarray(s.w_size, s.w_size + s.strstart), 0);\n        if (s.matches < 2) {\n          s.matches++;   /* add a pending slide_hash() */\n        }\n        if (s.insert > s.strstart) {\n          s.insert = s.strstart;\n        }\n      }\n      //zmemcpy(s->window + s->strstart, s->strm->next_in - used, used);\n      s.window.set(s.strm.input.subarray(s.strm.next_in - used, s.strm.next_in), s.strstart);\n      s.strstart += used;\n      s.insert += used > s.w_size - s.insert ? s.w_size - s.insert : used;\n    }\n    s.block_start = s.strstart;\n  }\n  if (s.high_water < s.strstart) {\n    s.high_water = s.strstart;\n  }\n\n  /* If the last block was written to next_out, then done. */\n  if (last) {\n    return BS_FINISH_DONE;\n  }\n\n  /* If flushing and all input has been consumed, then done. */\n  if (flush !== Z_NO_FLUSH && flush !== Z_FINISH &&\n    s.strm.avail_in === 0 && s.strstart === s.block_start) {\n    return BS_BLOCK_DONE;\n  }\n\n  /* Fill the window with any remaining input. */\n  have = s.window_size - s.strstart;\n  if (s.strm.avail_in > have && s.block_start >= s.w_size) {\n    /* Slide the window down. */\n    s.block_start -= s.w_size;\n    s.strstart -= s.w_size;\n    //zmemcpy(s->window, s->window + s->w_size, s->strstart);\n    s.window.set(s.window.subarray(s.w_size, s.w_size + s.strstart), 0);\n    if (s.matches < 2) {\n      s.matches++;       /* add a pending slide_hash() */\n    }\n    have += s.w_size;      /* more space now */\n    if (s.insert > s.strstart) {\n      s.insert = s.strstart;\n    }\n  }\n  if (have > s.strm.avail_in) {\n    have = s.strm.avail_in;\n  }\n  if (have) {\n    read_buf(s.strm, s.window, s.strstart, have);\n    s.strstart += have;\n    s.insert += have > s.w_size - s.insert ? s.w_size - s.insert : have;\n  }\n  if (s.high_water < s.strstart) {\n    s.high_water = s.strstart;\n  }\n\n  /* There was not enough avail_out to write a complete worthy or flushed\n   * stored block to next_out. Write a stored block to pending instead, if we\n   * have enough input for a worthy block, or if flushing and there is enough\n   * room for the remaining input as a stored block in the pending buffer.\n   */\n  have = (s.bi_valid + 42) >> 3;     /* number of header bytes */\n    /* maximum stored block length that will fit in pending: */\n  have = s.pending_buf_size - have > 65535/* MAX_STORED */ ? 65535/* MAX_STORED */ : s.pending_buf_size - have;\n  min_block = have > s.w_size ? s.w_size : have;\n  left = s.strstart - s.block_start;\n  if (left >= min_block ||\n     ((left || flush === Z_FINISH) && flush !== Z_NO_FLUSH &&\n     s.strm.avail_in === 0 && left <= have)) {\n    len = left > have ? have : left;\n    last = flush === Z_FINISH && s.strm.avail_in === 0 &&\n         len === left ? 1 : 0;\n    _tr_stored_block(s, s.block_start, len, last);\n    s.block_start += len;\n    flush_pending(s.strm);\n  }\n\n  /* We've done all we can with the available input and output. */\n  return last ? BS_FINISH_STARTED : BS_NEED_MORE;\n};\n\n\n/* ===========================================================================\n * Compress as much as possible from the input stream, return the current\n * block state.\n * This function does not perform lazy evaluation of matches and inserts\n * new strings in the dictionary only for unmatched strings or for short\n * matches. It is used only for the fast compression options.\n */\nconst deflate_fast = (s, flush) => {\n\n  let hash_head;        /* head of the hash chain */\n  let bflush;           /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) {\n        break; /* flush the current block */\n      }\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     * At this point we have always match_length < MIN_MATCH\n     */\n    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n    }\n    if (s.match_length >= MIN_MATCH) {\n      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only\n\n      /*** _tr_tally_dist(s, s.strstart - s.match_start,\n                     s.match_length - MIN_MATCH, bflush); ***/\n      bflush = _tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n\n      /* Insert new strings in the hash table only if the match length\n       * is not too large. This saves time but degrades compression.\n       */\n      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {\n        s.match_length--; /* string at strstart already in table */\n        do {\n          s.strstart++;\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n          /* strstart never exceeds WSIZE-MAX_MATCH, so there are\n           * always MIN_MATCH bytes ahead.\n           */\n        } while (--s.match_length !== 0);\n        s.strstart++;\n      } else\n      {\n        s.strstart += s.match_length;\n        s.match_length = 0;\n        s.ins_h = s.window[s.strstart];\n        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */\n        s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + 1]);\n\n//#if MIN_MATCH != 3\n//                Call UPDATE_HASH() MIN_MATCH-3 more times\n//#endif\n        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not\n         * matter since it will be recomputed at next deflate call.\n         */\n      }\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s.window[s.strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* ===========================================================================\n * Same as above, but achieves better compression. We use a lazy\n * evaluation for matches: a match is finally adopted only if there is\n * no better match at the next window position.\n */\nconst deflate_slow = (s, flush) => {\n\n  let hash_head;          /* head of hash chain */\n  let bflush;              /* set if current block must be flushed */\n\n  let max_insert;\n\n  /* Process the input block. */\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     */\n    s.prev_length = s.match_length;\n    s.prev_match = s.match_start;\n    s.match_length = MIN_MATCH - 1;\n\n    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&\n        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n\n      if (s.match_length <= 5 &&\n         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {\n\n        /* If prev_match is also MIN_MATCH, match_start is garbage\n         * but we will ignore the current match anyway.\n         */\n        s.match_length = MIN_MATCH - 1;\n      }\n    }\n    /* If there was a match at the previous step and the current\n     * match is not better, output the previous match:\n     */\n    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {\n      max_insert = s.strstart + s.lookahead - MIN_MATCH;\n      /* Do not insert strings in hash table beyond this. */\n\n      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);\n\n      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,\n                     s.prev_length - MIN_MATCH, bflush);***/\n      bflush = _tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);\n      /* Insert in hash table all strings up to the end of the match.\n       * strstart-1 and strstart are already inserted. If there is not\n       * enough lookahead, the last two strings are not inserted in\n       * the hash table.\n       */\n      s.lookahead -= s.prev_length - 1;\n      s.prev_length -= 2;\n      do {\n        if (++s.strstart <= max_insert) {\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n        }\n      } while (--s.prev_length !== 0);\n      s.match_available = 0;\n      s.match_length = MIN_MATCH - 1;\n      s.strstart++;\n\n      if (bflush) {\n        /*** FLUSH_BLOCK(s, 0); ***/\n        flush_block_only(s, false);\n        if (s.strm.avail_out === 0) {\n          return BS_NEED_MORE;\n        }\n        /***/\n      }\n\n    } else if (s.match_available) {\n      /* If there was no match at the previous position, output a\n       * single literal. If there was a match but the current match\n       * is longer, truncate the previous match to a single literal.\n       */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart - 1]);\n\n      if (bflush) {\n        /*** FLUSH_BLOCK_ONLY(s, 0) ***/\n        flush_block_only(s, false);\n        /***/\n      }\n      s.strstart++;\n      s.lookahead--;\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n    } else {\n      /* There is no previous match to compare with, wait for\n       * the next step to decide.\n       */\n      s.match_available = 1;\n      s.strstart++;\n      s.lookahead--;\n    }\n  }\n  //Assert (flush != Z_NO_FLUSH, \"no flush?\");\n  if (s.match_available) {\n    //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n    bflush = _tr_tally(s, 0, s.window[s.strstart - 1]);\n\n    s.match_available = 0;\n  }\n  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_BLOCK_DONE;\n};\n\n\n/* ===========================================================================\n * For Z_RLE, simply look for runs of bytes, generate matches only of distance\n * one.  Do not maintain a hash table.  (It will be regenerated if this run of\n * deflate switches away from Z_RLE.)\n */\nconst deflate_rle = (s, flush) => {\n\n  let bflush;            /* set if current block must be flushed */\n  let prev;              /* byte at distance one to match */\n  let scan, strend;      /* scan goes up to strend for length of run */\n\n  const _win = s.window;\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the longest run, plus one for the unrolled loop.\n     */\n    if (s.lookahead <= MAX_MATCH) {\n      fill_window(s);\n      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* See how many times the previous byte repeats */\n    s.match_length = 0;\n    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {\n      scan = s.strstart - 1;\n      prev = _win[scan];\n      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {\n        strend = s.strstart + MAX_MATCH;\n        do {\n          /*jshint noempty:false*/\n        } while (prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 scan < strend);\n        s.match_length = MAX_MATCH - (strend - scan);\n        if (s.match_length > s.lookahead) {\n          s.match_length = s.lookahead;\n        }\n      }\n      //Assert(scan <= s->window+(uInt)(s->window_size-1), \"wild scan\");\n    }\n\n    /* Emit match if have run of MIN_MATCH or longer, else emit literal */\n    if (s.match_length >= MIN_MATCH) {\n      //check_match(s, s.strstart, s.strstart - 1, s.match_length);\n\n      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/\n      bflush = _tr_tally(s, 1, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n      s.strstart += s.match_length;\n      s.match_length = 0;\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* ===========================================================================\n * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.\n * (It will be regenerated if this run of deflate switches away from Huffman.)\n */\nconst deflate_huff = (s, flush) => {\n\n  let bflush;             /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we have a literal to write. */\n    if (s.lookahead === 0) {\n      fill_window(s);\n      if (s.lookahead === 0) {\n        if (flush === Z_NO_FLUSH) {\n          return BS_NEED_MORE;\n        }\n        break;      /* flush the current block */\n      }\n    }\n\n    /* Output a literal byte */\n    s.match_length = 0;\n    //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n    bflush = _tr_tally(s, 0, s.window[s.strstart]);\n    s.lookahead--;\n    s.strstart++;\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* Values for max_lazy_match, good_match and max_chain_length, depending on\n * the desired pack level (0..9). The values given below have been tuned to\n * exclude worst case performance for pathological files. Better values may be\n * found for specific files.\n */\nfunction Config(good_length, max_lazy, nice_length, max_chain, func) {\n\n  this.good_length = good_length;\n  this.max_lazy = max_lazy;\n  this.nice_length = nice_length;\n  this.max_chain = max_chain;\n  this.func = func;\n}\n\nconst configuration_table = [\n  /*      good lazy nice chain */\n  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */\n  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */\n  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */\n  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */\n\n  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */\n  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */\n  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */\n  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */\n  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */\n  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */\n];\n\n\n/* ===========================================================================\n * Initialize the \"longest match\" routines for a new zlib stream\n */\nconst lm_init = (s) => {\n\n  s.window_size = 2 * s.w_size;\n\n  /*** CLEAR_HASH(s); ***/\n  zero(s.head); // Fill with NIL (= 0);\n\n  /* Set the default configuration parameters:\n   */\n  s.max_lazy_match = configuration_table[s.level].max_lazy;\n  s.good_match = configuration_table[s.level].good_length;\n  s.nice_match = configuration_table[s.level].nice_length;\n  s.max_chain_length = configuration_table[s.level].max_chain;\n\n  s.strstart = 0;\n  s.block_start = 0;\n  s.lookahead = 0;\n  s.insert = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  s.ins_h = 0;\n};\n\n\nfunction DeflateState() {\n  this.strm = null;            /* pointer back to this zlib stream */\n  this.status = 0;            /* as the name implies */\n  this.pending_buf = null;      /* output still pending */\n  this.pending_buf_size = 0;  /* size of pending_buf */\n  this.pending_out = 0;       /* next pending byte to output to the stream */\n  this.pending = 0;           /* nb of bytes in the pending buffer */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.gzhead = null;         /* gzip header information to write */\n  this.gzindex = 0;           /* where in extra, name, or comment */\n  this.method = Z_DEFLATED; /* can only be DEFLATED */\n  this.last_flush = -1;   /* value of flush param for previous deflate call */\n\n  this.w_size = 0;  /* LZ77 window size (32K by default) */\n  this.w_bits = 0;  /* log2(w_size)  (8..16) */\n  this.w_mask = 0;  /* w_size - 1 */\n\n  this.window = null;\n  /* Sliding window. Input bytes are read into the second half of the window,\n   * and move to the first half later to keep a dictionary of at least wSize\n   * bytes. With this organization, matches are limited to a distance of\n   * wSize-MAX_MATCH bytes, but this ensures that IO is always\n   * performed with a length multiple of the block size.\n   */\n\n  this.window_size = 0;\n  /* Actual size of window: 2*wSize, except when the user input buffer\n   * is directly used as sliding window.\n   */\n\n  this.prev = null;\n  /* Link to older string with same hash index. To limit the size of this\n   * array to 64K, this link is maintained only for the last 32K strings.\n   * An index in this array is thus a window index modulo 32K.\n   */\n\n  this.head = null;   /* Heads of the hash chains or NIL. */\n\n  this.ins_h = 0;       /* hash index of string to be inserted */\n  this.hash_size = 0;   /* number of elements in hash table */\n  this.hash_bits = 0;   /* log2(hash_size) */\n  this.hash_mask = 0;   /* hash_size-1 */\n\n  this.hash_shift = 0;\n  /* Number of bits by which ins_h must be shifted at each input\n   * step. It must be such that after MIN_MATCH steps, the oldest\n   * byte no longer takes part in the hash key, that is:\n   *   hash_shift * MIN_MATCH >= hash_bits\n   */\n\n  this.block_start = 0;\n  /* Window position at the beginning of the current output block. Gets\n   * negative when the window is moved backwards.\n   */\n\n  this.match_length = 0;      /* length of best match */\n  this.prev_match = 0;        /* previous match */\n  this.match_available = 0;   /* set if previous match exists */\n  this.strstart = 0;          /* start of string to insert */\n  this.match_start = 0;       /* start of matching string */\n  this.lookahead = 0;         /* number of valid bytes ahead in window */\n\n  this.prev_length = 0;\n  /* Length of the best match at previous step. Matches not greater than this\n   * are discarded. This is used in the lazy match evaluation.\n   */\n\n  this.max_chain_length = 0;\n  /* To speed up deflation, hash chains are never searched beyond this\n   * length.  A higher limit improves compression ratio but degrades the\n   * speed.\n   */\n\n  this.max_lazy_match = 0;\n  /* Attempt to find a better match only when the current match is strictly\n   * smaller than this value. This mechanism is used only for compression\n   * levels >= 4.\n   */\n  // That's alias to max_lazy_match, don't use directly\n  //this.max_insert_length = 0;\n  /* Insert new strings in the hash table only if the match length is not\n   * greater than this length. This saves time but degrades compression.\n   * max_insert_length is used only for compression levels <= 3.\n   */\n\n  this.level = 0;     /* compression level (1..9) */\n  this.strategy = 0;  /* favor or force Huffman coding*/\n\n  this.good_match = 0;\n  /* Use a faster search when the previous match is longer than this */\n\n  this.nice_match = 0; /* Stop searching when current match exceeds this */\n\n              /* used by trees.c: */\n\n  /* Didn't use ct_data typedef below to suppress compiler warning */\n\n  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */\n  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */\n  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */\n\n  // Use flat array of DOUBLE size, with interleaved fata,\n  // because JS does not support effective\n  this.dyn_ltree  = new Uint16Array(HEAP_SIZE * 2);\n  this.dyn_dtree  = new Uint16Array((2 * D_CODES + 1) * 2);\n  this.bl_tree    = new Uint16Array((2 * BL_CODES + 1) * 2);\n  zero(this.dyn_ltree);\n  zero(this.dyn_dtree);\n  zero(this.bl_tree);\n\n  this.l_desc   = null;         /* desc. for literal tree */\n  this.d_desc   = null;         /* desc. for distance tree */\n  this.bl_desc  = null;         /* desc. for bit length tree */\n\n  //ush bl_count[MAX_BITS+1];\n  this.bl_count = new Uint16Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */\n  this.heap = new Uint16Array(2 * L_CODES + 1);  /* heap used to build the Huffman trees */\n  zero(this.heap);\n\n  this.heap_len = 0;               /* number of elements in the heap */\n  this.heap_max = 0;               /* element of largest frequency */\n  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.\n   * The same heap array is used to build all trees.\n   */\n\n  this.depth = new Uint16Array(2 * L_CODES + 1); //uch depth[2*L_CODES+1];\n  zero(this.depth);\n  /* Depth of each subtree used as tie breaker for trees of equal frequency\n   */\n\n  this.sym_buf = 0;        /* buffer for distances and literals/lengths */\n\n  this.lit_bufsize = 0;\n  /* Size of match buffer for literals/lengths.  There are 4 reasons for\n   * limiting lit_bufsize to 64K:\n   *   - frequencies can be kept in 16 bit counters\n   *   - if compression is not successful for the first block, all input\n   *     data is still in the window so we can still emit a stored block even\n   *     when input comes from standard input.  (This can also be done for\n   *     all blocks if lit_bufsize is not greater than 32K.)\n   *   - if compression is not successful for a file smaller than 64K, we can\n   *     even emit a stored file instead of a stored block (saving 5 bytes).\n   *     This is applicable only for zip (not gzip or zlib).\n   *   - creating new Huffman trees less frequently may not provide fast\n   *     adaptation to changes in the input data statistics. (Take for\n   *     example a binary file with poorly compressible code followed by\n   *     a highly compressible string table.) Smaller buffer sizes give\n   *     fast adaptation but have of course the overhead of transmitting\n   *     trees more frequently.\n   *   - I can't count above 4\n   */\n\n  this.sym_next = 0;      /* running index in sym_buf */\n  this.sym_end = 0;       /* symbol table full when sym_next reaches this */\n\n  this.opt_len = 0;       /* bit length of current block with optimal trees */\n  this.static_len = 0;    /* bit length of current block with static trees */\n  this.matches = 0;       /* number of string matches in current block */\n  this.insert = 0;        /* bytes at end of window left to insert */\n\n\n  this.bi_buf = 0;\n  /* Output buffer. bits are inserted starting at the bottom (least\n   * significant bits).\n   */\n  this.bi_valid = 0;\n  /* Number of valid bits in bi_buf.  All bits above the last valid bit\n   * are always zero.\n   */\n\n  // Used for window memory init. We safely ignore it for JS. That makes\n  // sense only for pointers and memory check tools.\n  //this.high_water = 0;\n  /* High water mark offset in window for initialized bytes -- bytes above\n   * this are set to zero in order to avoid memory check warnings when\n   * longest match routines access bytes past the input.  This is then\n   * updated to the new high water mark.\n   */\n}\n\n\n/* =========================================================================\n * Check for a valid deflate stream state. Return 0 if ok, 1 if not.\n */\nconst deflateStateCheck = (strm) => {\n\n  if (!strm) {\n    return 1;\n  }\n  const s = strm.state;\n  if (!s || s.strm !== strm || (s.status !== INIT_STATE &&\n//#ifdef GZIP\n                                s.status !== GZIP_STATE &&\n//#endif\n                                s.status !== EXTRA_STATE &&\n                                s.status !== NAME_STATE &&\n                                s.status !== COMMENT_STATE &&\n                                s.status !== HCRC_STATE &&\n                                s.status !== BUSY_STATE &&\n                                s.status !== FINISH_STATE)) {\n    return 1;\n  }\n  return 0;\n};\n\n\nconst deflateResetKeep = (strm) => {\n\n  if (deflateStateCheck(strm)) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.total_in = strm.total_out = 0;\n  strm.data_type = Z_UNKNOWN;\n\n  const s = strm.state;\n  s.pending = 0;\n  s.pending_out = 0;\n\n  if (s.wrap < 0) {\n    s.wrap = -s.wrap;\n    /* was made negative by deflate(..., Z_FINISH); */\n  }\n  s.status =\n//#ifdef GZIP\n    s.wrap === 2 ? GZIP_STATE :\n//#endif\n    s.wrap ? INIT_STATE : BUSY_STATE;\n  strm.adler = (s.wrap === 2) ?\n    0  // crc32(0, Z_NULL, 0)\n  :\n    1; // adler32(0, Z_NULL, 0)\n  s.last_flush = -2;\n  _tr_init(s);\n  return Z_OK;\n};\n\n\nconst deflateReset = (strm) => {\n\n  const ret = deflateResetKeep(strm);\n  if (ret === Z_OK) {\n    lm_init(strm.state);\n  }\n  return ret;\n};\n\n\nconst deflateSetHeader = (strm, head) => {\n\n  if (deflateStateCheck(strm) || strm.state.wrap !== 2) {\n    return Z_STREAM_ERROR;\n  }\n  strm.state.gzhead = head;\n  return Z_OK;\n};\n\n\nconst deflateInit2 = (strm, level, method, windowBits, memLevel, strategy) => {\n\n  if (!strm) { // === Z_NULL\n    return Z_STREAM_ERROR;\n  }\n  let wrap = 1;\n\n  if (level === Z_DEFAULT_COMPRESSION) {\n    level = 6;\n  }\n\n  if (windowBits < 0) { /* suppress zlib wrapper */\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n\n  else if (windowBits > 15) {\n    wrap = 2;           /* write gzip wrapper instead */\n    windowBits -= 16;\n  }\n\n\n  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||\n    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||\n    strategy < 0 || strategy > Z_FIXED || (windowBits === 8 && wrap !== 1)) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n\n  if (windowBits === 8) {\n    windowBits = 9;\n  }\n  /* until 256-byte window bug fixed */\n\n  const s = new DeflateState();\n\n  strm.state = s;\n  s.strm = strm;\n  s.status = INIT_STATE;     /* to pass state test in deflateReset() */\n\n  s.wrap = wrap;\n  s.gzhead = null;\n  s.w_bits = windowBits;\n  s.w_size = 1 << s.w_bits;\n  s.w_mask = s.w_size - 1;\n\n  s.hash_bits = memLevel + 7;\n  s.hash_size = 1 << s.hash_bits;\n  s.hash_mask = s.hash_size - 1;\n  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);\n\n  s.window = new Uint8Array(s.w_size * 2);\n  s.head = new Uint16Array(s.hash_size);\n  s.prev = new Uint16Array(s.w_size);\n\n  // Don't need mem init magic for JS.\n  //s.high_water = 0;  /* nothing written to s->window yet */\n\n  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */\n\n  /* We overlay pending_buf and sym_buf. This works since the average size\n   * for length/distance pairs over any compressed block is assured to be 31\n   * bits or less.\n   *\n   * Analysis: The longest fixed codes are a length code of 8 bits plus 5\n   * extra bits, for lengths 131 to 257. The longest fixed distance codes are\n   * 5 bits plus 13 extra bits, for distances 16385 to 32768. The longest\n   * possible fixed-codes length/distance pair is then 31 bits total.\n   *\n   * sym_buf starts one-fourth of the way into pending_buf. So there are\n   * three bytes in sym_buf for every four bytes in pending_buf. Each symbol\n   * in sym_buf is three bytes -- two for the distance and one for the\n   * literal/length. As each symbol is consumed, the pointer to the next\n   * sym_buf value to read moves forward three bytes. From that symbol, up to\n   * 31 bits are written to pending_buf. The closest the written pending_buf\n   * bits gets to the next sym_buf symbol to read is just before the last\n   * code is written. At that time, 31*(n-2) bits have been written, just\n   * after 24*(n-2) bits have been consumed from sym_buf. sym_buf starts at\n   * 8*n bits into pending_buf. (Note that the symbol buffer fills when n-1\n   * symbols are written.) The closest the writing gets to what is unread is\n   * then n+14 bits. Here n is lit_bufsize, which is 16384 by default, and\n   * can range from 128 to 32768.\n   *\n   * Therefore, at a minimum, there are 142 bits of space between what is\n   * written and what is read in the overlain buffers, so the symbols cannot\n   * be overwritten by the compressed data. That space is actually 139 bits,\n   * due to the three-bit fixed-code block header.\n   *\n   * That covers the case where either Z_FIXED is specified, forcing fixed\n   * codes, or when the use of fixed codes is chosen, because that choice\n   * results in a smaller compressed block than dynamic codes. That latter\n   * condition then assures that the above analysis also covers all dynamic\n   * blocks. A dynamic-code block will only be chosen to be emitted if it has\n   * fewer bits than a fixed-code block would for the same set of symbols.\n   * Therefore its average symbol length is assured to be less than 31. So\n   * the compressed data for a dynamic block also cannot overwrite the\n   * symbols from which it is being constructed.\n   */\n\n  s.pending_buf_size = s.lit_bufsize * 4;\n  s.pending_buf = new Uint8Array(s.pending_buf_size);\n\n  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)\n  //s->sym_buf = s->pending_buf + s->lit_bufsize;\n  s.sym_buf = s.lit_bufsize;\n\n  //s->sym_end = (s->lit_bufsize - 1) * 3;\n  s.sym_end = (s.lit_bufsize - 1) * 3;\n  /* We avoid equality with lit_bufsize*3 because of wraparound at 64K\n   * on 16 bit machines and because stored blocks are restricted to\n   * 64K-1 bytes.\n   */\n\n  s.level = level;\n  s.strategy = strategy;\n  s.method = method;\n\n  return deflateReset(strm);\n};\n\nconst deflateInit = (strm, level) => {\n\n  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);\n};\n\n\n/* ========================================================================= */\nconst deflate = (strm, flush) => {\n\n  if (deflateStateCheck(strm) || flush > Z_BLOCK || flush < 0) {\n    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;\n  }\n\n  const s = strm.state;\n\n  if (!strm.output ||\n      (strm.avail_in !== 0 && !strm.input) ||\n      (s.status === FINISH_STATE && flush !== Z_FINISH)) {\n    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);\n  }\n\n  const old_flush = s.last_flush;\n  s.last_flush = flush;\n\n  /* Flush as much pending output as possible */\n  if (s.pending !== 0) {\n    flush_pending(strm);\n    if (strm.avail_out === 0) {\n      /* Since avail_out is 0, deflate will be called again with\n       * more output space, but possibly with both pending and\n       * avail_in equal to zero. There won't be anything to do,\n       * but this is not an error situation so make sure we\n       * return OK instead of BUF_ERROR at next call of deflate:\n       */\n      s.last_flush = -1;\n      return Z_OK;\n    }\n\n    /* Make sure there is something to do and avoid duplicate consecutive\n     * flushes. For repeated and useless calls with Z_FINISH, we keep\n     * returning Z_STREAM_END instead of Z_BUF_ERROR.\n     */\n  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&\n    flush !== Z_FINISH) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* User must not provide more input after the first FINISH: */\n  if (s.status === FINISH_STATE && strm.avail_in !== 0) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* Write the header */\n  if (s.status === INIT_STATE && s.wrap === 0) {\n    s.status = BUSY_STATE;\n  }\n  if (s.status === INIT_STATE) {\n    /* zlib header */\n    let header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;\n    let level_flags = -1;\n\n    if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {\n      level_flags = 0;\n    } else if (s.level < 6) {\n      level_flags = 1;\n    } else if (s.level === 6) {\n      level_flags = 2;\n    } else {\n      level_flags = 3;\n    }\n    header |= (level_flags << 6);\n    if (s.strstart !== 0) { header |= PRESET_DICT; }\n    header += 31 - (header % 31);\n\n    putShortMSB(s, header);\n\n    /* Save the adler32 of the preset dictionary: */\n    if (s.strstart !== 0) {\n      putShortMSB(s, strm.adler >>> 16);\n      putShortMSB(s, strm.adler & 0xffff);\n    }\n    strm.adler = 1; // adler32(0L, Z_NULL, 0);\n    s.status = BUSY_STATE;\n\n    /* Compression must start with an empty pending buffer */\n    flush_pending(strm);\n    if (s.pending !== 0) {\n      s.last_flush = -1;\n      return Z_OK;\n    }\n  }\n//#ifdef GZIP\n  if (s.status === GZIP_STATE) {\n    /* gzip header */\n    strm.adler = 0;  //crc32(0L, Z_NULL, 0);\n    put_byte(s, 31);\n    put_byte(s, 139);\n    put_byte(s, 8);\n    if (!s.gzhead) { // s->gzhead == Z_NULL\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, s.level === 9 ? 2 :\n                  (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                   4 : 0));\n      put_byte(s, OS_CODE);\n      s.status = BUSY_STATE;\n\n      /* Compression must start with an empty pending buffer */\n      flush_pending(strm);\n      if (s.pending !== 0) {\n        s.last_flush = -1;\n        return Z_OK;\n      }\n    }\n    else {\n      put_byte(s, (s.gzhead.text ? 1 : 0) +\n                  (s.gzhead.hcrc ? 2 : 0) +\n                  (!s.gzhead.extra ? 0 : 4) +\n                  (!s.gzhead.name ? 0 : 8) +\n                  (!s.gzhead.comment ? 0 : 16)\n      );\n      put_byte(s, s.gzhead.time & 0xff);\n      put_byte(s, (s.gzhead.time >> 8) & 0xff);\n      put_byte(s, (s.gzhead.time >> 16) & 0xff);\n      put_byte(s, (s.gzhead.time >> 24) & 0xff);\n      put_byte(s, s.level === 9 ? 2 :\n                  (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                   4 : 0));\n      put_byte(s, s.gzhead.os & 0xff);\n      if (s.gzhead.extra && s.gzhead.extra.length) {\n        put_byte(s, s.gzhead.extra.length & 0xff);\n        put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);\n      }\n      if (s.gzhead.hcrc) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);\n      }\n      s.gzindex = 0;\n      s.status = EXTRA_STATE;\n    }\n  }\n  if (s.status === EXTRA_STATE) {\n    if (s.gzhead.extra/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let left = (s.gzhead.extra.length & 0xffff) - s.gzindex;\n      while (s.pending + left > s.pending_buf_size) {\n        let copy = s.pending_buf_size - s.pending;\n        // zmemcpy(s.pending_buf + s.pending,\n        //    s.gzhead.extra + s.gzindex, copy);\n        s.pending_buf.set(s.gzhead.extra.subarray(s.gzindex, s.gzindex + copy), s.pending);\n        s.pending = s.pending_buf_size;\n        //--- HCRC_UPDATE(beg) ---//\n        if (s.gzhead.hcrc && s.pending > beg) {\n          strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n        }\n        //---//\n        s.gzindex += copy;\n        flush_pending(strm);\n        if (s.pending !== 0) {\n          s.last_flush = -1;\n          return Z_OK;\n        }\n        beg = 0;\n        left -= copy;\n      }\n      // JS specific: s.gzhead.extra may be TypedArray or Array for backward compatibility\n      //              TypedArray.slice and TypedArray.from don't exist in IE10-IE11\n      let gzhead_extra = new Uint8Array(s.gzhead.extra);\n      // zmemcpy(s->pending_buf + s->pending,\n      //     s->gzhead->extra + s->gzindex, left);\n      s.pending_buf.set(gzhead_extra.subarray(s.gzindex, s.gzindex + left), s.pending);\n      s.pending += left;\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n      s.gzindex = 0;\n    }\n    s.status = NAME_STATE;\n  }\n  if (s.status === NAME_STATE) {\n    if (s.gzhead.name/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let val;\n      do {\n        if (s.pending === s.pending_buf_size) {\n          //--- HCRC_UPDATE(beg) ---//\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          //---//\n          flush_pending(strm);\n          if (s.pending !== 0) {\n            s.last_flush = -1;\n            return Z_OK;\n          }\n          beg = 0;\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.name.length) {\n          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n      s.gzindex = 0;\n    }\n    s.status = COMMENT_STATE;\n  }\n  if (s.status === COMMENT_STATE) {\n    if (s.gzhead.comment/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let val;\n      do {\n        if (s.pending === s.pending_buf_size) {\n          //--- HCRC_UPDATE(beg) ---//\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          //---//\n          flush_pending(strm);\n          if (s.pending !== 0) {\n            s.last_flush = -1;\n            return Z_OK;\n          }\n          beg = 0;\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.comment.length) {\n          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n    }\n    s.status = HCRC_STATE;\n  }\n  if (s.status === HCRC_STATE) {\n    if (s.gzhead.hcrc) {\n      if (s.pending + 2 > s.pending_buf_size) {\n        flush_pending(strm);\n        if (s.pending !== 0) {\n          s.last_flush = -1;\n          return Z_OK;\n        }\n      }\n      put_byte(s, strm.adler & 0xff);\n      put_byte(s, (strm.adler >> 8) & 0xff);\n      strm.adler = 0; //crc32(0L, Z_NULL, 0);\n    }\n    s.status = BUSY_STATE;\n\n    /* Compression must start with an empty pending buffer */\n    flush_pending(strm);\n    if (s.pending !== 0) {\n      s.last_flush = -1;\n      return Z_OK;\n    }\n  }\n//#endif\n\n  /* Start a new block or continue the current one.\n   */\n  if (strm.avail_in !== 0 || s.lookahead !== 0 ||\n    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {\n    let bstate = s.level === 0 ? deflate_stored(s, flush) :\n                 s.strategy === Z_HUFFMAN_ONLY ? deflate_huff(s, flush) :\n                 s.strategy === Z_RLE ? deflate_rle(s, flush) :\n                 configuration_table[s.level].func(s, flush);\n\n    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {\n      s.status = FINISH_STATE;\n    }\n    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {\n      if (strm.avail_out === 0) {\n        s.last_flush = -1;\n        /* avoid BUF_ERROR next call, see above */\n      }\n      return Z_OK;\n      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call\n       * of deflate should use the same flush parameter to make sure\n       * that the flush is complete. So we don't have to output an\n       * empty block here, this will be done at next call. This also\n       * ensures that for a very small output buffer, we emit at most\n       * one empty block.\n       */\n    }\n    if (bstate === BS_BLOCK_DONE) {\n      if (flush === Z_PARTIAL_FLUSH) {\n        _tr_align(s);\n      }\n      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */\n\n        _tr_stored_block(s, 0, 0, false);\n        /* For a full flush, this empty block will be recognized\n         * as a special marker by inflate_sync().\n         */\n        if (flush === Z_FULL_FLUSH) {\n          /*** CLEAR_HASH(s); ***/             /* forget history */\n          zero(s.head); // Fill with NIL (= 0);\n\n          if (s.lookahead === 0) {\n            s.strstart = 0;\n            s.block_start = 0;\n            s.insert = 0;\n          }\n        }\n      }\n      flush_pending(strm);\n      if (strm.avail_out === 0) {\n        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */\n        return Z_OK;\n      }\n    }\n  }\n\n  if (flush !== Z_FINISH) { return Z_OK; }\n  if (s.wrap <= 0) { return Z_STREAM_END; }\n\n  /* Write the trailer */\n  if (s.wrap === 2) {\n    put_byte(s, strm.adler & 0xff);\n    put_byte(s, (strm.adler >> 8) & 0xff);\n    put_byte(s, (strm.adler >> 16) & 0xff);\n    put_byte(s, (strm.adler >> 24) & 0xff);\n    put_byte(s, strm.total_in & 0xff);\n    put_byte(s, (strm.total_in >> 8) & 0xff);\n    put_byte(s, (strm.total_in >> 16) & 0xff);\n    put_byte(s, (strm.total_in >> 24) & 0xff);\n  }\n  else\n  {\n    putShortMSB(s, strm.adler >>> 16);\n    putShortMSB(s, strm.adler & 0xffff);\n  }\n\n  flush_pending(strm);\n  /* If avail_out is zero, the application will call deflate again\n   * to flush the rest.\n   */\n  if (s.wrap > 0) { s.wrap = -s.wrap; }\n  /* write the trailer only once! */\n  return s.pending !== 0 ? Z_OK : Z_STREAM_END;\n};\n\n\nconst deflateEnd = (strm) => {\n\n  if (deflateStateCheck(strm)) {\n    return Z_STREAM_ERROR;\n  }\n\n  const status = strm.state.status;\n\n  strm.state = null;\n\n  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;\n};\n\n\n/* =========================================================================\n * Initializes the compression dictionary from the given byte\n * sequence without producing any compressed output.\n */\nconst deflateSetDictionary = (strm, dictionary) => {\n\n  let dictLength = dictionary.length;\n\n  if (deflateStateCheck(strm)) {\n    return Z_STREAM_ERROR;\n  }\n\n  const s = strm.state;\n  const wrap = s.wrap;\n\n  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* when using zlib wrappers, compute Adler-32 for provided dictionary */\n  if (wrap === 1) {\n    /* adler32(strm->adler, dictionary, dictLength); */\n    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);\n  }\n\n  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */\n\n  /* if dictionary would fill window, just replace the history */\n  if (dictLength >= s.w_size) {\n    if (wrap === 0) {            /* already empty otherwise */\n      /*** CLEAR_HASH(s); ***/\n      zero(s.head); // Fill with NIL (= 0);\n      s.strstart = 0;\n      s.block_start = 0;\n      s.insert = 0;\n    }\n    /* use the tail */\n    // dictionary = dictionary.slice(dictLength - s.w_size);\n    let tmpDict = new Uint8Array(s.w_size);\n    tmpDict.set(dictionary.subarray(dictLength - s.w_size, dictLength), 0);\n    dictionary = tmpDict;\n    dictLength = s.w_size;\n  }\n  /* insert dictionary into window and hash */\n  const avail = strm.avail_in;\n  const next = strm.next_in;\n  const input = strm.input;\n  strm.avail_in = dictLength;\n  strm.next_in = 0;\n  strm.input = dictionary;\n  fill_window(s);\n  while (s.lookahead >= MIN_MATCH) {\n    let str = s.strstart;\n    let n = s.lookahead - (MIN_MATCH - 1);\n    do {\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n      s.ins_h = HASH(s, s.ins_h, s.window[str + MIN_MATCH - 1]);\n\n      s.prev[str & s.w_mask] = s.head[s.ins_h];\n\n      s.head[s.ins_h] = str;\n      str++;\n    } while (--n);\n    s.strstart = str;\n    s.lookahead = MIN_MATCH - 1;\n    fill_window(s);\n  }\n  s.strstart += s.lookahead;\n  s.block_start = s.strstart;\n  s.insert = s.lookahead;\n  s.lookahead = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  strm.next_in = next;\n  strm.input = input;\n  strm.avail_in = avail;\n  s.wrap = wrap;\n  return Z_OK;\n};\n\n\nmodule.exports.deflateInit = deflateInit;\nmodule.exports.deflateInit2 = deflateInit2;\nmodule.exports.deflateReset = deflateReset;\nmodule.exports.deflateResetKeep = deflateResetKeep;\nmodule.exports.deflateSetHeader = deflateSetHeader;\nmodule.exports.deflate = deflate;\nmodule.exports.deflateEnd = deflateEnd;\nmodule.exports.deflateSetDictionary = deflateSetDictionary;\nmodule.exports.deflateInfo = 'pako deflate (from Nodeca project)';\n\n/* Not implemented\nmodule.exports.deflateBound = deflateBound;\nmodule.exports.deflateCopy = deflateCopy;\nmodule.exports.deflateGetDictionary = deflateGetDictionary;\nmodule.exports.deflateParams = deflateParams;\nmodule.exports.deflatePending = deflatePending;\nmodule.exports.deflatePrime = deflatePrime;\nmodule.exports.deflateTune = deflateTune;\n*/\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction GZheader() {\n  /* true if compressed data believed to be text */\n  this.text       = 0;\n  /* modification time */\n  this.time       = 0;\n  /* extra flags (not used when writing a gzip file) */\n  this.xflags     = 0;\n  /* operating system */\n  this.os         = 0;\n  /* pointer to extra field or Z_NULL if none */\n  this.extra      = null;\n  /* extra field length (valid if extra != Z_NULL) */\n  this.extra_len  = 0; // Actually, we don't need it in JS,\n                       // but leave for few code modifications\n\n  //\n  // Setup limits is not necessary because in js we should not preallocate memory\n  // for inflate use constant limit in 65536 bytes\n  //\n\n  /* space at extra (only when reading header) */\n  // this.extra_max  = 0;\n  /* pointer to zero-terminated file name or Z_NULL */\n  this.name       = '';\n  /* space at name (only when reading header) */\n  // this.name_max   = 0;\n  /* pointer to zero-terminated comment or Z_NULL */\n  this.comment    = '';\n  /* space at comment (only when reading header) */\n  // this.comm_max   = 0;\n  /* true if there was or will be a header crc */\n  this.hcrc       = 0;\n  /* true when done reading gzip header (not used when writing a gzip file) */\n  this.done       = false;\n}\n\nmodule.exports = GZheader;\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nconst BAD = 16209;       /* got a data error -- remain here until reset */\nconst TYPE = 16191;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nmodule.exports = function inflate_fast(strm, start) {\n  let _in;                    /* local strm.input */\n  let last;                   /* have enough input while in < last */\n  let _out;                   /* local strm.output */\n  let beg;                    /* inflate()'s initial strm.output */\n  let end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  let dmax;                   /* maximum distance from zlib header */\n//#endif\n  let wsize;                  /* window size or zero if not using window */\n  let whave;                  /* valid bytes in the window */\n  let wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  let s_window;               /* allocated sliding window, if wsize != 0 */\n  let hold;                   /* local strm.hold */\n  let bits;                   /* local strm.bits */\n  let lcode;                  /* local strm.lencode */\n  let dcode;                  /* local strm.distcode */\n  let lmask;                  /* mask for first level of length codes */\n  let dmask;                  /* mask for first level of distance codes */\n  let here;                   /* retrieved table entry */\n  let op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  let len;                    /* match length, unused bytes */\n  let dist;                   /* match distance */\n  let from;                   /* where to copy match from */\n  let from_source;\n\n\n  let input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  const state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst adler32       = require('./adler32');\nconst crc32         = require('./crc32');\nconst inflate_fast  = require('./inffast');\nconst inflate_table = require('./inftrees');\n\nconst CODES = 0;\nconst LENS = 1;\nconst DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_FINISH, Z_BLOCK, Z_TREES,\n  Z_OK, Z_STREAM_END, Z_NEED_DICT, Z_STREAM_ERROR, Z_DATA_ERROR, Z_MEM_ERROR, Z_BUF_ERROR,\n  Z_DEFLATED\n} = require('./constants');\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nconst    HEAD = 16180;       /* i: waiting for magic header */\nconst    FLAGS = 16181;      /* i: waiting for method and flags (gzip) */\nconst    TIME = 16182;       /* i: waiting for modification time (gzip) */\nconst    OS = 16183;         /* i: waiting for extra flags and operating system (gzip) */\nconst    EXLEN = 16184;      /* i: waiting for extra length (gzip) */\nconst    EXTRA = 16185;      /* i: waiting for extra bytes (gzip) */\nconst    NAME = 16186;       /* i: waiting for end of file name (gzip) */\nconst    COMMENT = 16187;    /* i: waiting for end of comment (gzip) */\nconst    HCRC = 16188;       /* i: waiting for header crc (gzip) */\nconst    DICTID = 16189;    /* i: waiting for dictionary check value */\nconst    DICT = 16190;      /* waiting for inflateSetDictionary() call */\nconst        TYPE = 16191;      /* i: waiting for type bits, including last-flag bit */\nconst        TYPEDO = 16192;    /* i: same, but skip check to exit inflate on new block */\nconst        STORED = 16193;    /* i: waiting for stored size (length and complement) */\nconst        COPY_ = 16194;     /* i/o: same as COPY below, but only first time in */\nconst        COPY = 16195;      /* i/o: waiting for input or output to copy stored block */\nconst        TABLE = 16196;     /* i: waiting for dynamic block table lengths */\nconst        LENLENS = 16197;   /* i: waiting for code length code lengths */\nconst        CODELENS = 16198;  /* i: waiting for length/lit and distance code lengths */\nconst            LEN_ = 16199;      /* i: same as LEN below, but only first time in */\nconst            LEN = 16200;       /* i: waiting for length/lit/eob code */\nconst            LENEXT = 16201;    /* i: waiting for length extra bits */\nconst            DIST = 16202;      /* i: waiting for distance code */\nconst            DISTEXT = 16203;   /* i: waiting for distance extra bits */\nconst            MATCH = 16204;     /* o: waiting for output space to copy string */\nconst            LIT = 16205;       /* o: waiting for output space to write literal */\nconst    CHECK = 16206;     /* i: waiting for 32-bit check value */\nconst    LENGTH = 16207;    /* i: waiting for 32-bit length (gzip) */\nconst    DONE = 16208;      /* finished check, done -- remain here until reset */\nconst    BAD = 16209;       /* got a data error -- remain here until reset */\nconst    MEM = 16210;       /* got an inflate() memory error -- remain here until reset */\nconst    SYNC = 16211;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nconst ENOUGH_LENS = 852;\nconst ENOUGH_DISTS = 592;\n//const ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nconst MAX_WBITS = 15;\n/* 32K LZ77 window */\nconst DEF_WBITS = MAX_WBITS;\n\n\nconst zswap32 = (q) => {\n\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n};\n\n\nfunction InflateState() {\n  this.strm = null;           /* pointer back to this zlib stream */\n  this.mode = 0;              /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip,\n                                 bit 2 true to validate check value */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib), or\n                                 -1 if raw or no header yet */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new Uint16Array(320); /* temporary storage for code lengths */\n  this.work = new Uint16Array(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new Int32Array(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\n\nconst inflateStateCheck = (strm) => {\n\n  if (!strm) {\n    return 1;\n  }\n  const state = strm.state;\n  if (!state || state.strm !== strm ||\n    state.mode < HEAD || state.mode > SYNC) {\n    return 1;\n  }\n  return 0;\n};\n\n\nconst inflateResetKeep = (strm) => {\n\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR; }\n  const state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.flags = -1;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new Int32Array(ENOUGH_LENS);\n  state.distcode = state.distdyn = new Int32Array(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n};\n\n\nconst inflateReset = (strm) => {\n\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR; }\n  const state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n};\n\n\nconst inflateReset2 = (strm, windowBits) => {\n  let wrap;\n\n  /* get the state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR; }\n  const state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 5;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n};\n\n\nconst inflateInit2 = (strm, windowBits) => {\n\n  if (!strm) { return Z_STREAM_ERROR; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  const state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.strm = strm;\n  state.window = null/*Z_NULL*/;\n  state.mode = HEAD;     /* to pass state test in inflateReset2() */\n  const ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n};\n\n\nconst inflateInit = (strm) => {\n\n  return inflateInit2(strm, DEF_WBITS);\n};\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nlet virgin = true;\n\nlet lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\n\nconst fixedtables = (state) => {\n\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    lenfix = new Int32Array(512);\n    distfix = new Int32Array(32);\n\n    /* literal/length table */\n    let sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n};\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nconst updatewindow = (strm, src, end, copy) => {\n\n  let dist;\n  const state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new Uint8Array(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    state.window.set(src.subarray(end - state.wsize, end), 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    state.window.set(src.subarray(end - copy, end - copy + dist), state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      state.window.set(src.subarray(end - copy, end), 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n};\n\n\nconst inflate = (strm, flush) => {\n\n  let state;\n  let input, output;          // input/output buffers\n  let next;                   /* next input INDEX */\n  let put;                    /* next output INDEX */\n  let have, left;             /* available input and output */\n  let hold;                   /* bit buffer */\n  let bits;                   /* bits in bit buffer */\n  let _in, _out;              /* save starting available input and output */\n  let copy;                   /* number of stored or match bytes to copy */\n  let from;                   /* where to copy match bytes from */\n  let from_source;\n  let here = 0;               /* current decoding table entry */\n  let here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //let last;                   /* parent table entry */\n  let last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  let len;                    /* length to copy for repeats, bits to drop */\n  let ret;                    /* return code */\n  const hbuf = new Uint8Array(4);    /* buffer for gzip header crc calculation */\n  let opts;\n\n  let n; // temporary variable for NEED_BITS\n\n  const order = /* permutation of code lengths */\n    new Uint8Array([ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ]);\n\n\n  if (inflateStateCheck(strm) || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          if (state.wbits === 0) {\n            state.wbits = 15;\n          }\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        if (len > 15 || len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n\n        // !!! pako patch. Force use `options.windowBits` if passed.\n        // Required to always use max window size by default.\n        state.dmax = 1 << state.wbits;\n        //state.dmax = 1 << len;\n\n        state.flags = 0;               /* indicate zlib header */\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Uint8Array(state.head.extra_len);\n              }\n              state.head.extra.set(\n                input.subarray(\n                  next,\n                  // extra field is limited to 65536 bytes\n                  // - no need for additional size check\n                  next + copy\n                ),\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if ((state.flags & 0x0200) && (state.wrap & 4)) {\n              state.check = crc32(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if ((state.wrap & 4) && hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          output.set(input.subarray(next, next + copy), put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inflate_fast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if ((state.wrap & 4) && _out) {\n            strm.adler = state.check =\n                /*UPDATE_CHECK(state.check, put - _out, _out);*/\n                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.wrap & 4) && (state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if ((state.wrap & 4) && hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {\n      state.mode = MEM;\n      return Z_MEM_ERROR;\n    }\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if ((state.wrap & 4) && _out) {\n    strm.adler = state.check = /*UPDATE_CHECK(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n};\n\n\nconst inflateEnd = (strm) => {\n\n  if (inflateStateCheck(strm)) {\n    return Z_STREAM_ERROR;\n  }\n\n  let state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK;\n};\n\n\nconst inflateGetHeader = (strm, head) => {\n\n  /* check state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR; }\n  const state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK;\n};\n\n\nconst inflateSetDictionary = (strm, dictionary) => {\n  const dictLength = dictionary.length;\n\n  let state;\n  let dictid;\n  let ret;\n\n  /* check state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK;\n};\n\n\nmodule.exports.inflateReset = inflateReset;\nmodule.exports.inflateReset2 = inflateReset2;\nmodule.exports.inflateResetKeep = inflateResetKeep;\nmodule.exports.inflateInit = inflateInit;\nmodule.exports.inflateInit2 = inflateInit2;\nmodule.exports.inflate = inflate;\nmodule.exports.inflateEnd = inflateEnd;\nmodule.exports.inflateGetHeader = inflateGetHeader;\nmodule.exports.inflateSetDictionary = inflateSetDictionary;\nmodule.exports.inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nmodule.exports.inflateCodesUsed = inflateCodesUsed;\nmodule.exports.inflateCopy = inflateCopy;\nmodule.exports.inflateGetDictionary = inflateGetDictionary;\nmodule.exports.inflateMark = inflateMark;\nmodule.exports.inflatePrime = inflatePrime;\nmodule.exports.inflateSync = inflateSync;\nmodule.exports.inflateSyncPoint = inflateSyncPoint;\nmodule.exports.inflateUndermine = inflateUndermine;\nmodule.exports.inflateValidate = inflateValidate;\n*/\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst MAXBITS = 15;\nconst ENOUGH_LENS = 852;\nconst ENOUGH_DISTS = 592;\n//const ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nconst CODES = 0;\nconst LENS = 1;\nconst DISTS = 2;\n\nconst lbase = new Uint16Array([ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n]);\n\nconst lext = new Uint8Array([ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n]);\n\nconst dbase = new Uint16Array([ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n]);\n\nconst dext = new Uint8Array([ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n]);\n\nconst inflate_table = (type, lens, lens_index, codes, table, table_index, work, opts) =>\n{\n  const bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  let len = 0;               /* a code's length in bits */\n  let sym = 0;               /* index of code symbols */\n  let min = 0, max = 0;          /* minimum and maximum code lengths */\n  let root = 0;              /* number of index bits for root table */\n  let curr = 0;              /* number of index bits for current table */\n  let drop = 0;              /* code bits to drop for sub-table */\n  let left = 0;                   /* number of prefix codes available */\n  let used = 0;              /* code entries in table used */\n  let huff = 0;              /* Huffman code */\n  let incr;              /* for incrementing code, index */\n  let fill;              /* index for replicating entries */\n  let low;               /* low bits for current root entry */\n  let mask;              /* mask for low root bits */\n  let next;             /* next available space in table */\n  let base = null;     /* base value table to use */\n//  let shoextra;    /* extra bits table to use */\n  let match;                  /* use base and extra for symbol >= match */\n  const count = new Uint16Array(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  const offs = new Uint16Array(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  let extra = null;\n\n  let here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES) {\n    base = extra = work;    /* dummy value--not used */\n    match = 20;\n\n  } else if (type === LENS) {\n    base = lbase;\n    extra = lext;\n    match = 257;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    match = 0;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS && used > ENOUGH_LENS) ||\n    (type === DISTS && used > ENOUGH_DISTS)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] + 1 < match) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] >= match) {\n      here_op = extra[work[sym] - match];\n      here_val = base[work[sym] - match];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS && used > ENOUGH_LENS) ||\n        (type === DISTS && used > ENOUGH_DISTS)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\nmodule.exports = inflate_table;\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n/* eslint-disable space-unary-ops */\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n//const Z_FILTERED          = 1;\n//const Z_HUFFMAN_ONLY      = 2;\n//const Z_RLE               = 3;\nconst Z_FIXED               = 4;\n//const Z_DEFAULT_STRATEGY  = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\nconst Z_BINARY              = 0;\nconst Z_TEXT                = 1;\n//const Z_ASCII             = 1; // = Z_TEXT\nconst Z_UNKNOWN             = 2;\n\n/*============================================================================*/\n\n\nfunction zero(buf) { let len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n// From zutil.h\n\nconst STORED_BLOCK = 0;\nconst STATIC_TREES = 1;\nconst DYN_TREES    = 2;\n/* The three kinds of block type */\n\nconst MIN_MATCH    = 3;\nconst MAX_MATCH    = 258;\n/* The minimum and maximum match lengths */\n\n// From deflate.h\n/* ===========================================================================\n * Internal compression state.\n */\n\nconst LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\n\nconst LITERALS      = 256;\n/* number of literal bytes 0..255 */\n\nconst L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\n\nconst D_CODES       = 30;\n/* number of distance codes */\n\nconst BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\n\nconst HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\n\nconst MAX_BITS      = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nconst Buf_size      = 16;\n/* size of bit buffer in bi_buf */\n\n\n/* ===========================================================================\n * Constants\n */\n\nconst MAX_BL_BITS = 7;\n/* Bit length codes must not exceed MAX_BL_BITS bits */\n\nconst END_BLOCK   = 256;\n/* end of block literal code */\n\nconst REP_3_6     = 16;\n/* repeat previous bit length 3-6 times (2 bits of repeat count) */\n\nconst REPZ_3_10   = 17;\n/* repeat a zero length 3-10 times  (3 bits of repeat count) */\n\nconst REPZ_11_138 = 18;\n/* repeat a zero length 11-138 times  (7 bits of repeat count) */\n\n/* eslint-disable comma-spacing,array-bracket-spacing */\nconst extra_lbits =   /* extra bits for each length code */\n  new Uint8Array([0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0]);\n\nconst extra_dbits =   /* extra bits for each distance code */\n  new Uint8Array([0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13]);\n\nconst extra_blbits =  /* extra bits for each bit length code */\n  new Uint8Array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7]);\n\nconst bl_order =\n  new Uint8Array([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]);\n/* eslint-enable comma-spacing,array-bracket-spacing */\n\n/* The lengths of the bit length codes are sent in order of decreasing\n * probability, to avoid transmitting the lengths for unused bit length codes.\n */\n\n/* ===========================================================================\n * Local data. These are initialized only once.\n */\n\n// We pre-fill arrays with 0 to avoid uninitialized gaps\n\nconst DIST_CODE_LEN = 512; /* see definition of array dist_code below */\n\n// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1\nconst static_ltree  = new Array((L_CODES + 2) * 2);\nzero(static_ltree);\n/* The static literal tree. Since the bit lengths are imposed, there is no\n * need for the L_CODES extra codes used during heap construction. However\n * The codes 286 and 287 are needed to build a canonical tree (see _tr_init\n * below).\n */\n\nconst static_dtree  = new Array(D_CODES * 2);\nzero(static_dtree);\n/* The static distance tree. (Actually a trivial tree since all codes use\n * 5 bits.)\n */\n\nconst _dist_code    = new Array(DIST_CODE_LEN);\nzero(_dist_code);\n/* Distance codes. The first 256 values correspond to the distances\n * 3 .. 258, the last 256 values correspond to the top 8 bits of\n * the 15 bit distances.\n */\n\nconst _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);\nzero(_length_code);\n/* length code for each normalized match length (0 == MIN_MATCH) */\n\nconst base_length   = new Array(LENGTH_CODES);\nzero(base_length);\n/* First normalized length for each code (0 = MIN_MATCH) */\n\nconst base_dist     = new Array(D_CODES);\nzero(base_dist);\n/* First normalized distance for each code (0 = distance of 1) */\n\n\nfunction StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {\n\n  this.static_tree  = static_tree;  /* static tree or NULL */\n  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */\n  this.extra_base   = extra_base;   /* base index for extra_bits */\n  this.elems        = elems;        /* max number of elements in the tree */\n  this.max_length   = max_length;   /* max bit length for the codes */\n\n  // show if `static_tree` has data or dummy - needed for monomorphic objects\n  this.has_stree    = static_tree && static_tree.length;\n}\n\n\nlet static_l_desc;\nlet static_d_desc;\nlet static_bl_desc;\n\n\nfunction TreeDesc(dyn_tree, stat_desc) {\n  this.dyn_tree = dyn_tree;     /* the dynamic tree */\n  this.max_code = 0;            /* largest code with non zero frequency */\n  this.stat_desc = stat_desc;   /* the corresponding static tree */\n}\n\n\n\nconst d_code = (dist) => {\n\n  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];\n};\n\n\n/* ===========================================================================\n * Output a short LSB first on the stream.\n * IN assertion: there is enough room in pendingBuf.\n */\nconst put_short = (s, w) => {\n//    put_byte(s, (uch)((w) & 0xff));\n//    put_byte(s, (uch)((ush)(w) >> 8));\n  s.pending_buf[s.pending++] = (w) & 0xff;\n  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;\n};\n\n\n/* ===========================================================================\n * Send a value on a given number of bits.\n * IN assertion: length <= 16 and value fits in length bits.\n */\nconst send_bits = (s, value, length) => {\n\n  if (s.bi_valid > (Buf_size - length)) {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    put_short(s, s.bi_buf);\n    s.bi_buf = value >> (Buf_size - s.bi_valid);\n    s.bi_valid += length - Buf_size;\n  } else {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    s.bi_valid += length;\n  }\n};\n\n\nconst send_code = (s, c, tree) => {\n\n  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);\n};\n\n\n/* ===========================================================================\n * Reverse the first len bits of a code, using straightforward code (a faster\n * method would use a table)\n * IN assertion: 1 <= len <= 15\n */\nconst bi_reverse = (code, len) => {\n\n  let res = 0;\n  do {\n    res |= code & 1;\n    code >>>= 1;\n    res <<= 1;\n  } while (--len > 0);\n  return res >>> 1;\n};\n\n\n/* ===========================================================================\n * Flush the bit buffer, keeping at most 7 bits in it.\n */\nconst bi_flush = (s) => {\n\n  if (s.bi_valid === 16) {\n    put_short(s, s.bi_buf);\n    s.bi_buf = 0;\n    s.bi_valid = 0;\n\n  } else if (s.bi_valid >= 8) {\n    s.pending_buf[s.pending++] = s.bi_buf & 0xff;\n    s.bi_buf >>= 8;\n    s.bi_valid -= 8;\n  }\n};\n\n\n/* ===========================================================================\n * Compute the optimal bit lengths for a tree and update the total bit length\n * for the current block.\n * IN assertion: the fields freq and dad are set, heap[heap_max] and\n *    above are the tree nodes sorted by increasing frequency.\n * OUT assertions: the field len is set to the optimal bit length, the\n *     array bl_count contains the frequencies for each bit length.\n *     The length opt_len is updated; static_len is also updated if stree is\n *     not null.\n */\nconst gen_bitlen = (s, desc) => {\n//    deflate_state *s;\n//    tree_desc *desc;    /* the tree descriptor */\n\n  const tree            = desc.dyn_tree;\n  const max_code        = desc.max_code;\n  const stree           = desc.stat_desc.static_tree;\n  const has_stree       = desc.stat_desc.has_stree;\n  const extra           = desc.stat_desc.extra_bits;\n  const base            = desc.stat_desc.extra_base;\n  const max_length      = desc.stat_desc.max_length;\n  let h;              /* heap index */\n  let n, m;           /* iterate over the tree elements */\n  let bits;           /* bit length */\n  let xbits;          /* extra bits */\n  let f;              /* frequency */\n  let overflow = 0;   /* number of elements with bit length too large */\n\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    s.bl_count[bits] = 0;\n  }\n\n  /* In a first pass, compute the optimal bit lengths (which may\n   * overflow in the case of the bit length tree).\n   */\n  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */\n\n  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {\n    n = s.heap[h];\n    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;\n    if (bits > max_length) {\n      bits = max_length;\n      overflow++;\n    }\n    tree[n * 2 + 1]/*.Len*/ = bits;\n    /* We overwrite tree[n].Dad which is no longer needed */\n\n    if (n > max_code) { continue; } /* not a leaf node */\n\n    s.bl_count[bits]++;\n    xbits = 0;\n    if (n >= base) {\n      xbits = extra[n - base];\n    }\n    f = tree[n * 2]/*.Freq*/;\n    s.opt_len += f * (bits + xbits);\n    if (has_stree) {\n      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);\n    }\n  }\n  if (overflow === 0) { return; }\n\n  // Tracev((stderr,\"\\nbit length overflow\\n\"));\n  /* This happens for example on obj2 and pic of the Calgary corpus */\n\n  /* Find the first bit length which could increase: */\n  do {\n    bits = max_length - 1;\n    while (s.bl_count[bits] === 0) { bits--; }\n    s.bl_count[bits]--;      /* move one leaf down the tree */\n    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */\n    s.bl_count[max_length]--;\n    /* The brother of the overflow item also moves one step up,\n     * but this does not affect bl_count[max_length]\n     */\n    overflow -= 2;\n  } while (overflow > 0);\n\n  /* Now recompute all bit lengths, scanning in increasing frequency.\n   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n   * lengths instead of fixing only the wrong ones. This idea is taken\n   * from 'ar' written by Haruhiko Okumura.)\n   */\n  for (bits = max_length; bits !== 0; bits--) {\n    n = s.bl_count[bits];\n    while (n !== 0) {\n      m = s.heap[--h];\n      if (m > max_code) { continue; }\n      if (tree[m * 2 + 1]/*.Len*/ !== bits) {\n        // Tracev((stderr,\"code %d bits %d->%d\\n\", m, tree[m].Len, bits));\n        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;\n        tree[m * 2 + 1]/*.Len*/ = bits;\n      }\n      n--;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Generate the codes for a given tree and bit counts (which need not be\n * optimal).\n * IN assertion: the array bl_count contains the bit length statistics for\n * the given tree and the field len is set for all tree elements.\n * OUT assertion: the field code is set for all tree elements of non\n *     zero code length.\n */\nconst gen_codes = (tree, max_code, bl_count) => {\n//    ct_data *tree;             /* the tree to decorate */\n//    int max_code;              /* largest code with non zero frequency */\n//    ushf *bl_count;            /* number of codes at each bit length */\n\n  const next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */\n  let code = 0;              /* running code value */\n  let bits;                  /* bit index */\n  let n;                     /* code index */\n\n  /* The distribution counts are first used to generate the code values\n   * without bit reversal.\n   */\n  for (bits = 1; bits <= MAX_BITS; bits++) {\n    code = (code + bl_count[bits - 1]) << 1;\n    next_code[bits] = code;\n  }\n  /* Check that the bit counts in bl_count are consistent. The last code\n   * must be all ones.\n   */\n  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,\n  //        \"inconsistent bit counts\");\n  //Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n  for (n = 0;  n <= max_code; n++) {\n    let len = tree[n * 2 + 1]/*.Len*/;\n    if (len === 0) { continue; }\n    /* Now reverse the bits */\n    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);\n\n    //Tracecv(tree != static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \",\n    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));\n  }\n};\n\n\n/* ===========================================================================\n * Initialize the various 'constant' tables.\n */\nconst tr_static_init = () => {\n\n  let n;        /* iterates over tree elements */\n  let bits;     /* bit counter */\n  let length;   /* length value */\n  let code;     /* code value */\n  let dist;     /* distance index */\n  const bl_count = new Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  // do check in _tr_init()\n  //if (static_init_done) return;\n\n  /* For some embedded targets, global variables are not initialized: */\n/*#ifdef NO_INIT_GLOBAL_POINTERS\n  static_l_desc.static_tree = static_ltree;\n  static_l_desc.extra_bits = extra_lbits;\n  static_d_desc.static_tree = static_dtree;\n  static_d_desc.extra_bits = extra_dbits;\n  static_bl_desc.extra_bits = extra_blbits;\n#endif*/\n\n  /* Initialize the mapping length (0..255) -> length code (0..28) */\n  length = 0;\n  for (code = 0; code < LENGTH_CODES - 1; code++) {\n    base_length[code] = length;\n    for (n = 0; n < (1 << extra_lbits[code]); n++) {\n      _length_code[length++] = code;\n    }\n  }\n  //Assert (length == 256, \"tr_static_init: length != 256\");\n  /* Note that the length 255 (match length 258) can be represented\n   * in two different ways: code 284 + 5 bits or code 285, so we\n   * overwrite length_code[255] to use the best encoding:\n   */\n  _length_code[length - 1] = code;\n\n  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */\n  dist = 0;\n  for (code = 0; code < 16; code++) {\n    base_dist[code] = dist;\n    for (n = 0; n < (1 << extra_dbits[code]); n++) {\n      _dist_code[dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: dist != 256\");\n  dist >>= 7; /* from now on, all distances are divided by 128 */\n  for (; code < D_CODES; code++) {\n    base_dist[code] = dist << 7;\n    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n      _dist_code[256 + dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: 256+dist != 512\");\n\n  /* Construct the codes of the static literal tree */\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    bl_count[bits] = 0;\n  }\n\n  n = 0;\n  while (n <= 143) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  while (n <= 255) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 9;\n    n++;\n    bl_count[9]++;\n  }\n  while (n <= 279) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 7;\n    n++;\n    bl_count[7]++;\n  }\n  while (n <= 287) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  /* Codes 286 and 287 do not exist, but we must include them in the\n   * tree construction to get a canonical Huffman tree (longest code\n   * all ones)\n   */\n  gen_codes(static_ltree, L_CODES + 1, bl_count);\n\n  /* The static distance tree is trivial: */\n  for (n = 0; n < D_CODES; n++) {\n    static_dtree[n * 2 + 1]/*.Len*/ = 5;\n    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);\n  }\n\n  // Now data ready and we can init static trees\n  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);\n  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);\n  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);\n\n  //static_init_done = true;\n};\n\n\n/* ===========================================================================\n * Initialize a new block.\n */\nconst init_block = (s) => {\n\n  let n; /* iterates over tree elements */\n\n  /* Initialize the trees. */\n  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }\n\n  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;\n  s.opt_len = s.static_len = 0;\n  s.sym_next = s.matches = 0;\n};\n\n\n/* ===========================================================================\n * Flush the bit buffer and align the output on a byte boundary\n */\nconst bi_windup = (s) =>\n{\n  if (s.bi_valid > 8) {\n    put_short(s, s.bi_buf);\n  } else if (s.bi_valid > 0) {\n    //put_byte(s, (Byte)s->bi_buf);\n    s.pending_buf[s.pending++] = s.bi_buf;\n  }\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n};\n\n/* ===========================================================================\n * Compares to subtrees, using the tree depth as tie breaker when\n * the subtrees have equal frequency. This minimizes the worst case length.\n */\nconst smaller = (tree, n, m, depth) => {\n\n  const _n2 = n * 2;\n  const _m2 = m * 2;\n  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||\n         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));\n};\n\n/* ===========================================================================\n * Restore the heap property by moving down the tree starting at node k,\n * exchanging a node with the smallest of its two sons if necessary, stopping\n * when the heap property is re-established (each father smaller than its\n * two sons).\n */\nconst pqdownheap = (s, tree, k) => {\n//    deflate_state *s;\n//    ct_data *tree;  /* the tree to restore */\n//    int k;               /* node to move down */\n\n  const v = s.heap[k];\n  let j = k << 1;  /* left son of k */\n  while (j <= s.heap_len) {\n    /* Set j to the smallest of the two sons: */\n    if (j < s.heap_len &&\n      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {\n      j++;\n    }\n    /* Exit if v is smaller than both sons */\n    if (smaller(tree, v, s.heap[j], s.depth)) { break; }\n\n    /* Exchange v with the smallest son */\n    s.heap[k] = s.heap[j];\n    k = j;\n\n    /* And continue down the tree, setting j to the left son of k */\n    j <<= 1;\n  }\n  s.heap[k] = v;\n};\n\n\n// inlined manually\n// const SMALLEST = 1;\n\n/* ===========================================================================\n * Send the block data compressed using the given Huffman trees\n */\nconst compress_block = (s, ltree, dtree) => {\n//    deflate_state *s;\n//    const ct_data *ltree; /* literal tree */\n//    const ct_data *dtree; /* distance tree */\n\n  let dist;           /* distance of matched string */\n  let lc;             /* match length or unmatched char (if dist == 0) */\n  let sx = 0;         /* running index in sym_buf */\n  let code;           /* the code to send */\n  let extra;          /* number of extra bits to send */\n\n  if (s.sym_next !== 0) {\n    do {\n      dist = s.pending_buf[s.sym_buf + sx++] & 0xff;\n      dist += (s.pending_buf[s.sym_buf + sx++] & 0xff) << 8;\n      lc = s.pending_buf[s.sym_buf + sx++];\n      if (dist === 0) {\n        send_code(s, lc, ltree); /* send a literal byte */\n        //Tracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n      } else {\n        /* Here, lc is the match length - MIN_MATCH */\n        code = _length_code[lc];\n        send_code(s, code + LITERALS + 1, ltree); /* send the length code */\n        extra = extra_lbits[code];\n        if (extra !== 0) {\n          lc -= base_length[code];\n          send_bits(s, lc, extra);       /* send the extra length bits */\n        }\n        dist--; /* dist is now the match distance - 1 */\n        code = d_code(dist);\n        //Assert (code < D_CODES, \"bad d_code\");\n\n        send_code(s, code, dtree);       /* send the distance code */\n        extra = extra_dbits[code];\n        if (extra !== 0) {\n          dist -= base_dist[code];\n          send_bits(s, dist, extra);   /* send the extra distance bits */\n        }\n      } /* literal or match pair ? */\n\n      /* Check that the overlay between pending_buf and sym_buf is ok: */\n      //Assert(s->pending < s->lit_bufsize + sx, \"pendingBuf overflow\");\n\n    } while (sx < s.sym_next);\n  }\n\n  send_code(s, END_BLOCK, ltree);\n};\n\n\n/* ===========================================================================\n * Construct one Huffman tree and assigns the code bit strings and lengths.\n * Update the total bit length for the current block.\n * IN assertion: the field freq is set for all tree elements.\n * OUT assertions: the fields len and code are set to the optimal bit length\n *     and corresponding code. The length opt_len is updated; static_len is\n *     also updated if stree is not null. The field max_code is set.\n */\nconst build_tree = (s, desc) => {\n//    deflate_state *s;\n//    tree_desc *desc; /* the tree descriptor */\n\n  const tree     = desc.dyn_tree;\n  const stree    = desc.stat_desc.static_tree;\n  const has_stree = desc.stat_desc.has_stree;\n  const elems    = desc.stat_desc.elems;\n  let n, m;          /* iterate over heap elements */\n  let max_code = -1; /* largest code with non zero frequency */\n  let node;          /* new node being created */\n\n  /* Construct the initial heap, with least frequent element in\n   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n   * heap[0] is not used.\n   */\n  s.heap_len = 0;\n  s.heap_max = HEAP_SIZE;\n\n  for (n = 0; n < elems; n++) {\n    if (tree[n * 2]/*.Freq*/ !== 0) {\n      s.heap[++s.heap_len] = max_code = n;\n      s.depth[n] = 0;\n\n    } else {\n      tree[n * 2 + 1]/*.Len*/ = 0;\n    }\n  }\n\n  /* The pkzip format requires that at least one distance code exists,\n   * and that at least one bit should be sent even if there is only one\n   * possible code. So to avoid special checks later on we force at least\n   * two codes of non zero frequency.\n   */\n  while (s.heap_len < 2) {\n    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);\n    tree[node * 2]/*.Freq*/ = 1;\n    s.depth[node] = 0;\n    s.opt_len--;\n\n    if (has_stree) {\n      s.static_len -= stree[node * 2 + 1]/*.Len*/;\n    }\n    /* node is 0 or 1 so it does not have extra bits */\n  }\n  desc.max_code = max_code;\n\n  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n   * establish sub-heaps of increasing lengths:\n   */\n  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }\n\n  /* Construct the Huffman tree by repeatedly combining the least two\n   * frequent nodes.\n   */\n  node = elems;              /* next internal node of the tree */\n  do {\n    //pqremove(s, tree, n);  /* n = node of least frequency */\n    /*** pqremove ***/\n    n = s.heap[1/*SMALLEST*/];\n    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n    /***/\n\n    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */\n\n    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */\n    s.heap[--s.heap_max] = m;\n\n    /* Create a new node father of n and m */\n    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;\n    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;\n    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;\n\n    /* and insert the new node in the heap */\n    s.heap[1/*SMALLEST*/] = node++;\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n\n  } while (s.heap_len >= 2);\n\n  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];\n\n  /* At this point, the fields freq and dad are set. We can now\n   * generate the bit lengths.\n   */\n  gen_bitlen(s, desc);\n\n  /* The field len is now set, we can generate the bit codes */\n  gen_codes(tree, max_code, s.bl_count);\n};\n\n\n/* ===========================================================================\n * Scan a literal or distance tree to determine the frequencies of the codes\n * in the bit length tree.\n */\nconst scan_tree = (s, tree, max_code) => {\n//    deflate_state *s;\n//    ct_data *tree;   /* the tree to be scanned */\n//    int max_code;    /* and its largest code of non zero frequency */\n\n  let n;                     /* iterates over all tree elements */\n  let prevlen = -1;          /* last emitted length */\n  let curlen;                /* length of current code */\n\n  let nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  let count = 0;             /* repeat count of the current code */\n  let max_count = 7;         /* max repeat count */\n  let min_count = 4;         /* min repeat count */\n\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      s.bl_tree[curlen * 2]/*.Freq*/ += count;\n\n    } else if (curlen !== 0) {\n\n      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }\n      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;\n\n    } else if (count <= 10) {\n      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;\n\n    } else {\n      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;\n    }\n\n    count = 0;\n    prevlen = curlen;\n\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Send a literal or distance tree in compressed form, using the codes in\n * bl_tree.\n */\nconst send_tree = (s, tree, max_code) => {\n//    deflate_state *s;\n//    ct_data *tree; /* the tree to be scanned */\n//    int max_code;       /* and its largest code of non zero frequency */\n\n  let n;                     /* iterates over all tree elements */\n  let prevlen = -1;          /* last emitted length */\n  let curlen;                /* length of current code */\n\n  let nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  let count = 0;             /* repeat count of the current code */\n  let max_count = 7;         /* max repeat count */\n  let min_count = 4;         /* min repeat count */\n\n  /* tree[max_code+1].Len = -1; */  /* guard already set */\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);\n\n    } else if (curlen !== 0) {\n      if (curlen !== prevlen) {\n        send_code(s, curlen, s.bl_tree);\n        count--;\n      }\n      //Assert(count >= 3 && count <= 6, \" 3_6?\");\n      send_code(s, REP_3_6, s.bl_tree);\n      send_bits(s, count - 3, 2);\n\n    } else if (count <= 10) {\n      send_code(s, REPZ_3_10, s.bl_tree);\n      send_bits(s, count - 3, 3);\n\n    } else {\n      send_code(s, REPZ_11_138, s.bl_tree);\n      send_bits(s, count - 11, 7);\n    }\n\n    count = 0;\n    prevlen = curlen;\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Construct the Huffman tree for the bit lengths and return the index in\n * bl_order of the last bit length code to send.\n */\nconst build_bl_tree = (s) => {\n\n  let max_blindex;  /* index of last bit length code of non zero freq */\n\n  /* Determine the bit length frequencies for literal and distance trees */\n  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);\n  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);\n\n  /* Build the bit length tree: */\n  build_tree(s, s.bl_desc);\n  /* opt_len now includes the length of the tree representations, except\n   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n   */\n\n  /* Determine the number of bit length codes to send. The pkzip format\n   * requires that at least 4 bit length codes be sent. (appnote.txt says\n   * 3 but the actual value used is 4.)\n   */\n  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {\n    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {\n      break;\n    }\n  }\n  /* Update opt_len to include the bit length tree and counts */\n  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n  //Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n  //        s->opt_len, s->static_len));\n\n  return max_blindex;\n};\n\n\n/* ===========================================================================\n * Send the header for a block using dynamic Huffman trees: the counts, the\n * lengths of the bit length codes, the literal tree and the distance tree.\n * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n */\nconst send_all_trees = (s, lcodes, dcodes, blcodes) => {\n//    deflate_state *s;\n//    int lcodes, dcodes, blcodes; /* number of codes for each tree */\n\n  let rank;                    /* index in bl_order */\n\n  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,\n  //        \"too many codes\");\n  //Tracev((stderr, \"\\nbl counts: \"));\n  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */\n  send_bits(s, dcodes - 1,   5);\n  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */\n  for (rank = 0; rank < blcodes; rank++) {\n    //Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);\n  }\n  //Tracev((stderr, \"\\nbl tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */\n  //Tracev((stderr, \"\\nlit tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */\n  //Tracev((stderr, \"\\ndist tree: sent %ld\", s->bits_sent));\n};\n\n\n/* ===========================================================================\n * Check if the data type is TEXT or BINARY, using the following algorithm:\n * - TEXT if the two conditions below are satisfied:\n *    a) There are no non-portable control characters belonging to the\n *       \"block list\" (0..6, 14..25, 28..31).\n *    b) There is at least one printable character belonging to the\n *       \"allow list\" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).\n * - BINARY otherwise.\n * - The following partially-portable control characters form a\n *   \"gray list\" that is ignored in this detection algorithm:\n *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).\n * IN assertion: the fields Freq of dyn_ltree are set.\n */\nconst detect_data_type = (s) => {\n  /* block_mask is the bit mask of block-listed bytes\n   * set bits 0..6, 14..25, and 28..31\n   * 0xf3ffc07f = binary 11110011111111111100000001111111\n   */\n  let block_mask = 0xf3ffc07f;\n  let n;\n\n  /* Check for non-textual (\"block-listed\") bytes. */\n  for (n = 0; n <= 31; n++, block_mask >>>= 1) {\n    if ((block_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {\n      return Z_BINARY;\n    }\n  }\n\n  /* Check for textual (\"allow-listed\") bytes. */\n  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||\n      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {\n    return Z_TEXT;\n  }\n  for (n = 32; n < LITERALS; n++) {\n    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {\n      return Z_TEXT;\n    }\n  }\n\n  /* There are no \"block-listed\" or \"allow-listed\" bytes:\n   * this stream either is empty or has tolerated (\"gray-listed\") bytes only.\n   */\n  return Z_BINARY;\n};\n\n\nlet static_init_done = false;\n\n/* ===========================================================================\n * Initialize the tree data structures for a new zlib stream.\n */\nconst _tr_init = (s) =>\n{\n\n  if (!static_init_done) {\n    tr_static_init();\n    static_init_done = true;\n  }\n\n  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);\n  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);\n  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);\n\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n\n  /* Initialize the first block of the first file: */\n  init_block(s);\n};\n\n\n/* ===========================================================================\n * Send a stored block\n */\nconst _tr_stored_block = (s, buf, stored_len, last) => {\n//DeflateState *s;\n//charf *buf;       /* input block */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n\n  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */\n  bi_windup(s);        /* align on byte boundary */\n  put_short(s, stored_len);\n  put_short(s, ~stored_len);\n  if (stored_len) {\n    s.pending_buf.set(s.window.subarray(buf, buf + stored_len), s.pending);\n  }\n  s.pending += stored_len;\n};\n\n\n/* ===========================================================================\n * Send one empty static block to give enough lookahead for inflate.\n * This takes 10 bits, of which 7 may remain in the bit buffer.\n */\nconst _tr_align = (s) => {\n  send_bits(s, STATIC_TREES << 1, 3);\n  send_code(s, END_BLOCK, static_ltree);\n  bi_flush(s);\n};\n\n\n/* ===========================================================================\n * Determine the best encoding for the current block: dynamic trees, static\n * trees or store, and write out the encoded block.\n */\nconst _tr_flush_block = (s, buf, stored_len, last) => {\n//DeflateState *s;\n//charf *buf;       /* input block, or NULL if too old */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n\n  let opt_lenb, static_lenb;  /* opt_len and static_len in bytes */\n  let max_blindex = 0;        /* index of last bit length code of non zero freq */\n\n  /* Build the Huffman trees unless a stored block is forced */\n  if (s.level > 0) {\n\n    /* Check if the file is binary or text */\n    if (s.strm.data_type === Z_UNKNOWN) {\n      s.strm.data_type = detect_data_type(s);\n    }\n\n    /* Construct the literal and distance trees */\n    build_tree(s, s.l_desc);\n    // Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n\n    build_tree(s, s.d_desc);\n    // Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n    /* At this point, opt_len and static_len are the total bit lengths of\n     * the compressed block data, excluding the tree representations.\n     */\n\n    /* Build the bit length tree for the above two trees, and get the index\n     * in bl_order of the last bit length code to send.\n     */\n    max_blindex = build_bl_tree(s);\n\n    /* Determine the best encoding. Compute the block lengths in bytes. */\n    opt_lenb = (s.opt_len + 3 + 7) >>> 3;\n    static_lenb = (s.static_len + 3 + 7) >>> 3;\n\n    // Tracev((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u \",\n    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,\n    //        s->sym_next / 3));\n\n    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }\n\n  } else {\n    // Assert(buf != (char*)0, \"lost buf\");\n    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */\n  }\n\n  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {\n    /* 4: two words for the lengths */\n\n    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.\n     * Otherwise we can't have processed more than WSIZE input bytes since\n     * the last block flush, because compression would have been\n     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n     * transform a block into a stored block.\n     */\n    _tr_stored_block(s, buf, stored_len, last);\n\n  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {\n\n    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);\n    compress_block(s, static_ltree, static_dtree);\n\n  } else {\n    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);\n    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);\n    compress_block(s, s.dyn_ltree, s.dyn_dtree);\n  }\n  // Assert (s->compressed_len == s->bits_sent, \"bad compressed size\");\n  /* The above check is made mod 2^32, for files larger than 512 MB\n   * and uLong implemented on 32 bits.\n   */\n  init_block(s);\n\n  if (last) {\n    bi_windup(s);\n  }\n  // Tracev((stderr,\"\\ncomprlen %lu(%lu) \", s->compressed_len>>3,\n  //       s->compressed_len-7*last));\n};\n\n/* ===========================================================================\n * Save the match info and tally the frequency counts. Return true if\n * the current block must be flushed.\n */\nconst _tr_tally = (s, dist, lc) => {\n//    deflate_state *s;\n//    unsigned dist;  /* distance of matched string */\n//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */\n\n  s.pending_buf[s.sym_buf + s.sym_next++] = dist;\n  s.pending_buf[s.sym_buf + s.sym_next++] = dist >> 8;\n  s.pending_buf[s.sym_buf + s.sym_next++] = lc;\n  if (dist === 0) {\n    /* lc is the unmatched char */\n    s.dyn_ltree[lc * 2]/*.Freq*/++;\n  } else {\n    s.matches++;\n    /* Here, lc is the match length - MIN_MATCH */\n    dist--;             /* dist = match distance - 1 */\n    //Assert((ush)dist < (ush)MAX_DIST(s) &&\n    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&\n    //       (ush)d_code(dist) < (ush)D_CODES,  \"_tr_tally: bad match\");\n\n    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;\n    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;\n  }\n\n  return (s.sym_next === s.sym_end);\n};\n\nmodule.exports._tr_init  = _tr_init;\nmodule.exports._tr_stored_block = _tr_stored_block;\nmodule.exports._tr_flush_block  = _tr_flush_block;\nmodule.exports._tr_tally = _tr_tally;\nmodule.exports._tr_align = _tr_align;\n","'use strict';\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nmodule.exports = ZStream;\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function get() {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function get() {\n    return _parse.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function get() {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function get() {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function get() {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function get() {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function get() {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function get() {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function get() {\n    return _version.default;\n  }\n});\n\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\n\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\n\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\n\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\n\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\n\nvar _version = _interopRequireDefault(require(\"./version.js\"));\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\n\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\n/*\n * Browser-compatible JavaScript MD5\n *\n * Modification of JavaScript MD5\n * https://github.com/blueimp/JavaScript-MD5\n *\n * Copyright 2011, Sebastian Tschan\n * https://blueimp.net\n *\n * Licensed under the MIT license:\n * https://opensource.org/licenses/MIT\n *\n * Based on\n * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message\n * Digest Algorithm, as defined in RFC 1321.\n * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n * Distributed under the BSD License\n * See http://pajhome.org.uk/crypt/md5 for more info.\n */\nfunction md5(bytes) {\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = new Uint8Array(msg.length);\n\n    for (let i = 0; i < msg.length; ++i) {\n      bytes[i] = msg.charCodeAt(i);\n    }\n  }\n\n  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));\n}\n/*\n * Convert an array of little-endian words to an array of bytes\n */\n\n\nfunction md5ToHexEncodedArray(input) {\n  const output = [];\n  const length32 = input.length * 32;\n  const hexTab = '0123456789abcdef';\n\n  for (let i = 0; i < length32; i += 8) {\n    const x = input[i >> 5] >>> i % 32 & 0xff;\n    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);\n    output.push(hex);\n  }\n\n  return output;\n}\n/**\n * Calculate output length with padding and bit length\n */\n\n\nfunction getOutputLength(inputLength8) {\n  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;\n}\n/*\n * Calculate the MD5 of an array of little-endian words, and a bit length.\n */\n\n\nfunction wordsToMd5(x, len) {\n  /* append padding */\n  x[len >> 5] |= 0x80 << len % 32;\n  x[getOutputLength(len) - 1] = len;\n  let a = 1732584193;\n  let b = -271733879;\n  let c = -1732584194;\n  let d = 271733878;\n\n  for (let i = 0; i < x.length; i += 16) {\n    const olda = a;\n    const oldb = b;\n    const oldc = c;\n    const oldd = d;\n    a = md5ff(a, b, c, d, x[i], 7, -680876936);\n    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);\n    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);\n    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);\n    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);\n    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);\n    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);\n    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);\n    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);\n    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);\n    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);\n    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);\n    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);\n    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);\n    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);\n    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);\n    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);\n    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);\n    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);\n    b = md5gg(b, c, d, a, x[i], 20, -373897302);\n    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);\n    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);\n    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);\n    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);\n    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);\n    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);\n    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);\n    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);\n    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);\n    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);\n    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);\n    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);\n    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);\n    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);\n    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);\n    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);\n    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);\n    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);\n    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);\n    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);\n    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);\n    d = md5hh(d, a, b, c, x[i], 11, -358537222);\n    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);\n    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);\n    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);\n    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);\n    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);\n    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);\n    a = md5ii(a, b, c, d, x[i], 6, -198630844);\n    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);\n    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);\n    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);\n    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);\n    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);\n    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);\n    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);\n    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);\n    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);\n    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);\n    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);\n    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);\n    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);\n    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);\n    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);\n    a = safeAdd(a, olda);\n    b = safeAdd(b, oldb);\n    c = safeAdd(c, oldc);\n    d = safeAdd(d, oldd);\n  }\n\n  return [a, b, c, d];\n}\n/*\n * Convert an array bytes to an array of little-endian words\n * Characters >255 have their high-byte silently ignored.\n */\n\n\nfunction bytesToWords(input) {\n  if (input.length === 0) {\n    return [];\n  }\n\n  const length8 = input.length * 8;\n  const output = new Uint32Array(getOutputLength(length8));\n\n  for (let i = 0; i < length8; i += 8) {\n    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;\n  }\n\n  return output;\n}\n/*\n * Add integers, wrapping at 2^32. This uses 16-bit operations internally\n * to work around bugs in some JS interpreters.\n */\n\n\nfunction safeAdd(x, y) {\n  const lsw = (x & 0xffff) + (y & 0xffff);\n  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n  return msw << 16 | lsw & 0xffff;\n}\n/*\n * Bitwise rotate a 32-bit number to the left.\n */\n\n\nfunction bitRotateLeft(num, cnt) {\n  return num << cnt | num >>> 32 - cnt;\n}\n/*\n * These functions implement the four basic operations the algorithm uses.\n */\n\n\nfunction md5cmn(q, a, b, x, s, t) {\n  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);\n}\n\nfunction md5ff(a, b, c, d, x, s, t) {\n  return md5cmn(b & c | ~b & d, a, b, x, s, t);\n}\n\nfunction md5gg(a, b, c, d, x, s, t) {\n  return md5cmn(b & d | c & ~d, a, b, x, s, t);\n}\n\nfunction md5hh(a, b, c, d, x, s, t) {\n  return md5cmn(b ^ c ^ d, a, b, x, s, t);\n}\n\nfunction md5ii(a, b, c, d, x, s, t) {\n  return md5cmn(c ^ (b | ~d), a, b, x, s, t);\n}\n\nvar _default = md5;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nconst randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\nvar _default = {\n  randomUUID\n};\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = '00000000-0000-0000-0000-000000000000';\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  let v;\n  const arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\n\nvar _default = parse;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\n\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\n// Adapted from Chris Veness' SHA1 code at\n// http://www.movable-type.co.uk/scripts/sha1.html\nfunction f(s, x, y, z) {\n  switch (s) {\n    case 0:\n      return x & y ^ ~x & z;\n\n    case 1:\n      return x ^ y ^ z;\n\n    case 2:\n      return x & y ^ x & z ^ y & z;\n\n    case 3:\n      return x ^ y ^ z;\n  }\n}\n\nfunction ROTL(x, n) {\n  return x << n | x >>> 32 - n;\n}\n\nfunction sha1(bytes) {\n  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];\n  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = [];\n\n    for (let i = 0; i < msg.length; ++i) {\n      bytes.push(msg.charCodeAt(i));\n    }\n  } else if (!Array.isArray(bytes)) {\n    // Convert Array-like to Array\n    bytes = Array.prototype.slice.call(bytes);\n  }\n\n  bytes.push(0x80);\n  const l = bytes.length / 4 + 2;\n  const N = Math.ceil(l / 16);\n  const M = new Array(N);\n\n  for (let i = 0; i < N; ++i) {\n    const arr = new Uint32Array(16);\n\n    for (let j = 0; j < 16; ++j) {\n      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];\n    }\n\n    M[i] = arr;\n  }\n\n  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);\n  M[N - 1][14] = Math.floor(M[N - 1][14]);\n  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;\n\n  for (let i = 0; i < N; ++i) {\n    const W = new Uint32Array(80);\n\n    for (let t = 0; t < 16; ++t) {\n      W[t] = M[i][t];\n    }\n\n    for (let t = 16; t < 80; ++t) {\n      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);\n    }\n\n    let a = H[0];\n    let b = H[1];\n    let c = H[2];\n    let d = H[3];\n    let e = H[4];\n\n    for (let t = 0; t < 80; ++t) {\n      const s = Math.floor(t / 20);\n      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;\n      e = d;\n      d = c;\n      c = ROTL(b, 30) >>> 0;\n      b = a;\n      a = T;\n    }\n\n    H[0] = H[0] + a >>> 0;\n    H[1] = H[1] + b >>> 0;\n    H[2] = H[2] + c >>> 0;\n    H[3] = H[3] + d >>> 0;\n    H[4] = H[4] + e >>> 0;\n  }\n\n  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];\n}\n\nvar _default = sha1;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nexports.unsafeStringify = unsafeStringify;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\n\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];\n}\n\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\nvar _default = stringify;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\n\nvar _stringify = require(\"./stringify.js\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\nlet _nodeId;\n\nlet _clockseq; // Previous uuid creation time\n\n\nlet _lastMSecs = 0;\nlet _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node || _nodeId;\n  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\n\nvar _default = v1;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\n\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = v3;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.URL = exports.DNS = void 0;\nexports.default = v35;\n\nvar _stringify = require(\"./stringify.js\");\n\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n\n  return bytes;\n}\n\nconst DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nexports.DNS = DNS;\nconst URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nexports.URL = URL;\n\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n\n    if (buf) {\n      offset = offset || 0;\n\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n\n      return buf;\n    }\n\n    return (0, _stringify.unsafeStringify)(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _native = _interopRequireDefault(require(\"./native.js\"));\n\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\n\nvar _stringify = require(\"./stringify.js\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n\n  options = options || {};\n\n  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0, _stringify.unsafeStringify)(rnds);\n}\n\nvar _default = v4;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\n\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = v5;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\n\nvar _default = validate;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  return parseInt(uuid.slice(14, 15), 16);\n}\n\nvar _default = version;\nexports.default = _default;","\n    var doc = {\"kind\":\"Document\",\"definitions\":[{\"kind\":\"OperationDefinition\",\"operation\":\"query\",\"name\":{\"kind\":\"Name\",\"value\":\"GetElectionLogEntries\"},\"variableDefinitions\":[{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"electionUniqueId\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]},{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"after\"}},\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}},\"directives\":[]},{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"types\"}},\"type\":{\"kind\":\"ListType\",\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}}},\"directives\":[]}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"election\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"uniqueId\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"electionUniqueId\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"logEntries\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"after\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"after\"}}},{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"types\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"types\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"id\"},\"arguments\":[],\"directives\":[]},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"},\"arguments\":[],\"directives\":[]},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"arguments\":[],\"directives\":[]},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"chainedHash\"},\"arguments\":[],\"directives\":[]}]}}]}}]}}],\"loc\":{\"start\":0,\"end\":260}};\n    doc.loc.source = {\"body\":\"query GetElectionLogEntries(\\n  $electionUniqueId: String!\\n  $after: String\\n  $types: [String!]\\n) {\\n  election(uniqueId: $electionUniqueId) {\\n    logEntries(after: $after, types: $types) {\\n      id\\n      messageId\\n      signedData\\n      chainedHash\\n    }\\n  }\\n}\\n\",\"name\":\"GraphQL request\",\"locationOffset\":{\"line\":1,\"column\":1}};\n  \n\n    var names = {};\n    function unique(defs) {\n      return defs.filter(\n        function(def) {\n          if (def.kind !== 'FragmentDefinition') return true;\n          var name = def.name.value\n          if (names[name]) {\n            return false;\n          } else {\n            names[name] = true;\n            return true;\n          }\n        }\n      )\n    }\n  \n\n    // Collect any fragment/type references from a node, adding them to the refs Set\n    function collectFragmentReferences(node, refs) {\n      if (node.kind === \"FragmentSpread\") {\n        refs.add(node.name.value);\n      } else if (node.kind === \"VariableDefinition\") {\n        var type = node.type;\n        if (type.kind === \"NamedType\") {\n          refs.add(type.name.value);\n        }\n      }\n\n      if (node.selectionSet) {\n        node.selectionSet.selections.forEach(function(selection) {\n          collectFragmentReferences(selection, refs);\n        });\n      }\n\n      if (node.variableDefinitions) {\n        node.variableDefinitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n\n      if (node.definitions) {\n        node.definitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n    }\n\n    var definitionRefs = {};\n    (function extractReferences() {\n      doc.definitions.forEach(function(def) {\n        if (def.name) {\n          var refs = new Set();\n          collectFragmentReferences(def, refs);\n          definitionRefs[def.name.value] = refs;\n        }\n      });\n    })();\n\n    function findOperation(doc, name) {\n      for (var i = 0; i < doc.definitions.length; i++) {\n        var element = doc.definitions[i];\n        if (element.name && element.name.value == name) {\n          return element;\n        }\n      }\n    }\n\n    function oneQuery(doc, operationName) {\n      // Copy the DocumentNode, but clear out the definitions\n      var newDoc = {\n        kind: doc.kind,\n        definitions: [findOperation(doc, operationName)]\n      };\n      if (doc.hasOwnProperty(\"loc\")) {\n        newDoc.loc = doc.loc;\n      }\n\n      // Now, for the operation we're running, find any fragments referenced by\n      // it or the fragments it references\n      var opRefs = definitionRefs[operationName] || new Set();\n      var allRefs = new Set();\n      var newRefs = new Set();\n\n      // IE 11 doesn't support \"new Set(iterable)\", so we add the members of opRefs to newRefs one by one\n      opRefs.forEach(function(refName) {\n        newRefs.add(refName);\n      });\n\n      while (newRefs.size > 0) {\n        var prevRefs = newRefs;\n        newRefs = new Set();\n\n        prevRefs.forEach(function(refName) {\n          if (!allRefs.has(refName)) {\n            allRefs.add(refName);\n            var childRefs = definitionRefs[refName] || new Set();\n            childRefs.forEach(function(childRef) {\n              newRefs.add(childRef);\n            });\n          }\n        });\n      }\n\n      allRefs.forEach(function(refName) {\n        var op = findOperation(doc, refName);\n        if (op) {\n          newDoc.definitions.push(op);\n        }\n      });\n\n      return newDoc;\n    }\n    \n    module.exports = doc;\n    \n        module.exports[\"GetElectionLogEntries\"] = oneQuery(doc, \"GetElectionLogEntries\");\n        \n","\n    var doc = {\"kind\":\"Document\",\"definitions\":[{\"kind\":\"OperationDefinition\",\"operation\":\"query\",\"name\":{\"kind\":\"Name\",\"value\":\"GetLogEntry\"},\"variableDefinitions\":[{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"electionUniqueId\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]},{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"contentHash\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"logEntry\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"electionUniqueId\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"electionUniqueId\"}}},{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"contentHash\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"contentHash\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"},\"arguments\":[],\"directives\":[]},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"arguments\":[],\"directives\":[]},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"contentHash\"},\"arguments\":[],\"directives\":[]}]}}]}}],\"loc\":{\"start\":0,\"end\":199}};\n    doc.loc.source = {\"body\":\"query GetLogEntry($electionUniqueId: String!, $contentHash: String!) {\\n  logEntry(electionUniqueId: $electionUniqueId, contentHash: $contentHash) {\\n    messageId\\n    signedData\\n    contentHash\\n  }\\n}\\n\",\"name\":\"GraphQL request\",\"locationOffset\":{\"line\":1,\"column\":1}};\n  \n\n    var names = {};\n    function unique(defs) {\n      return defs.filter(\n        function(def) {\n          if (def.kind !== 'FragmentDefinition') return true;\n          var name = def.name.value\n          if (names[name]) {\n            return false;\n          } else {\n            names[name] = true;\n            return true;\n          }\n        }\n      )\n    }\n  \n\n    // Collect any fragment/type references from a node, adding them to the refs Set\n    function collectFragmentReferences(node, refs) {\n      if (node.kind === \"FragmentSpread\") {\n        refs.add(node.name.value);\n      } else if (node.kind === \"VariableDefinition\") {\n        var type = node.type;\n        if (type.kind === \"NamedType\") {\n          refs.add(type.name.value);\n        }\n      }\n\n      if (node.selectionSet) {\n        node.selectionSet.selections.forEach(function(selection) {\n          collectFragmentReferences(selection, refs);\n        });\n      }\n\n      if (node.variableDefinitions) {\n        node.variableDefinitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n\n      if (node.definitions) {\n        node.definitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n    }\n\n    var definitionRefs = {};\n    (function extractReferences() {\n      doc.definitions.forEach(function(def) {\n        if (def.name) {\n          var refs = new Set();\n          collectFragmentReferences(def, refs);\n          definitionRefs[def.name.value] = refs;\n        }\n      });\n    })();\n\n    function findOperation(doc, name) {\n      for (var i = 0; i < doc.definitions.length; i++) {\n        var element = doc.definitions[i];\n        if (element.name && element.name.value == name) {\n          return element;\n        }\n      }\n    }\n\n    function oneQuery(doc, operationName) {\n      // Copy the DocumentNode, but clear out the definitions\n      var newDoc = {\n        kind: doc.kind,\n        definitions: [findOperation(doc, operationName)]\n      };\n      if (doc.hasOwnProperty(\"loc\")) {\n        newDoc.loc = doc.loc;\n      }\n\n      // Now, for the operation we're running, find any fragments referenced by\n      // it or the fragments it references\n      var opRefs = definitionRefs[operationName] || new Set();\n      var allRefs = new Set();\n      var newRefs = new Set();\n\n      // IE 11 doesn't support \"new Set(iterable)\", so we add the members of opRefs to newRefs one by one\n      opRefs.forEach(function(refName) {\n        newRefs.add(refName);\n      });\n\n      while (newRefs.size > 0) {\n        var prevRefs = newRefs;\n        newRefs = new Set();\n\n        prevRefs.forEach(function(refName) {\n          if (!allRefs.has(refName)) {\n            allRefs.add(refName);\n            var childRefs = definitionRefs[refName] || new Set();\n            childRefs.forEach(function(childRef) {\n              newRefs.add(childRef);\n            });\n          }\n        });\n      }\n\n      allRefs.forEach(function(refName) {\n        var op = findOperation(doc, refName);\n        if (op) {\n          newDoc.definitions.push(op);\n        }\n      });\n\n      return newDoc;\n    }\n    \n    module.exports = doc;\n    \n        module.exports[\"GetLogEntry\"] = oneQuery(doc, \"GetLogEntry\");\n        \n","\n    var doc = {\"kind\":\"Document\",\"definitions\":[{\"kind\":\"OperationDefinition\",\"operation\":\"query\",\"name\":{\"kind\":\"Name\",\"value\":\"GetPendingMessageByMessageId\"},\"variableDefinitions\":[{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"pendingMessage\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"status\"},\"arguments\":[],\"directives\":[]}]}}]}}],\"loc\":{\"start\":0,\"end\":117}};\n    doc.loc.source = {\"body\":\"query GetPendingMessageByMessageId($messageId: String!) {\\n  pendingMessage(messageId: $messageId) {\\n    status\\n  }\\n}\\n\",\"name\":\"GraphQL request\",\"locationOffset\":{\"line\":1,\"column\":1}};\n  \n\n    var names = {};\n    function unique(defs) {\n      return defs.filter(\n        function(def) {\n          if (def.kind !== 'FragmentDefinition') return true;\n          var name = def.name.value\n          if (names[name]) {\n            return false;\n          } else {\n            names[name] = true;\n            return true;\n          }\n        }\n      )\n    }\n  \n\n    // Collect any fragment/type references from a node, adding them to the refs Set\n    function collectFragmentReferences(node, refs) {\n      if (node.kind === \"FragmentSpread\") {\n        refs.add(node.name.value);\n      } else if (node.kind === \"VariableDefinition\") {\n        var type = node.type;\n        if (type.kind === \"NamedType\") {\n          refs.add(type.name.value);\n        }\n      }\n\n      if (node.selectionSet) {\n        node.selectionSet.selections.forEach(function(selection) {\n          collectFragmentReferences(selection, refs);\n        });\n      }\n\n      if (node.variableDefinitions) {\n        node.variableDefinitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n\n      if (node.definitions) {\n        node.definitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n    }\n\n    var definitionRefs = {};\n    (function extractReferences() {\n      doc.definitions.forEach(function(def) {\n        if (def.name) {\n          var refs = new Set();\n          collectFragmentReferences(def, refs);\n          definitionRefs[def.name.value] = refs;\n        }\n      });\n    })();\n\n    function findOperation(doc, name) {\n      for (var i = 0; i < doc.definitions.length; i++) {\n        var element = doc.definitions[i];\n        if (element.name && element.name.value == name) {\n          return element;\n        }\n      }\n    }\n\n    function oneQuery(doc, operationName) {\n      // Copy the DocumentNode, but clear out the definitions\n      var newDoc = {\n        kind: doc.kind,\n        definitions: [findOperation(doc, operationName)]\n      };\n      if (doc.hasOwnProperty(\"loc\")) {\n        newDoc.loc = doc.loc;\n      }\n\n      // Now, for the operation we're running, find any fragments referenced by\n      // it or the fragments it references\n      var opRefs = definitionRefs[operationName] || new Set();\n      var allRefs = new Set();\n      var newRefs = new Set();\n\n      // IE 11 doesn't support \"new Set(iterable)\", so we add the members of opRefs to newRefs one by one\n      opRefs.forEach(function(refName) {\n        newRefs.add(refName);\n      });\n\n      while (newRefs.size > 0) {\n        var prevRefs = newRefs;\n        newRefs = new Set();\n\n        prevRefs.forEach(function(refName) {\n          if (!allRefs.has(refName)) {\n            allRefs.add(refName);\n            var childRefs = definitionRefs[refName] || new Set();\n            childRefs.forEach(function(childRef) {\n              newRefs.add(childRef);\n            });\n          }\n        });\n      }\n\n      allRefs.forEach(function(refName) {\n        var op = findOperation(doc, refName);\n        if (op) {\n          newDoc.definitions.push(op);\n        }\n      });\n\n      return newDoc;\n    }\n    \n    module.exports = doc;\n    \n        module.exports[\"GetPendingMessageByMessageId\"] = oneQuery(doc, \"GetPendingMessageByMessageId\");\n        \n","\n    var doc = {\"kind\":\"Document\",\"definitions\":[{\"kind\":\"OperationDefinition\",\"operation\":\"mutation\",\"name\":{\"kind\":\"Name\",\"value\":\"ProcessKeyCeremonyStep\"},\"variableDefinitions\":[{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]},{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"processKeyCeremonyStep\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}}},{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"pendingMessage\"},\"arguments\":[],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"arguments\":[],\"directives\":[]}]}},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"error\"},\"arguments\":[],\"directives\":[]}]}}]}}],\"loc\":{\"start\":0,\"end\":212}};\n    doc.loc.source = {\"body\":\"mutation ProcessKeyCeremonyStep($messageId: String!, $signedData: String!) {\\n  processKeyCeremonyStep(messageId: $messageId, signedData: $signedData) {\\n    pendingMessage {\\n      signedData\\n    }\\n    error\\n  }\\n}\\n\",\"name\":\"GraphQL request\",\"locationOffset\":{\"line\":1,\"column\":1}};\n  \n\n    var names = {};\n    function unique(defs) {\n      return defs.filter(\n        function(def) {\n          if (def.kind !== 'FragmentDefinition') return true;\n          var name = def.name.value\n          if (names[name]) {\n            return false;\n          } else {\n            names[name] = true;\n            return true;\n          }\n        }\n      )\n    }\n  \n\n    // Collect any fragment/type references from a node, adding them to the refs Set\n    function collectFragmentReferences(node, refs) {\n      if (node.kind === \"FragmentSpread\") {\n        refs.add(node.name.value);\n      } else if (node.kind === \"VariableDefinition\") {\n        var type = node.type;\n        if (type.kind === \"NamedType\") {\n          refs.add(type.name.value);\n        }\n      }\n\n      if (node.selectionSet) {\n        node.selectionSet.selections.forEach(function(selection) {\n          collectFragmentReferences(selection, refs);\n        });\n      }\n\n      if (node.variableDefinitions) {\n        node.variableDefinitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n\n      if (node.definitions) {\n        node.definitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n    }\n\n    var definitionRefs = {};\n    (function extractReferences() {\n      doc.definitions.forEach(function(def) {\n        if (def.name) {\n          var refs = new Set();\n          collectFragmentReferences(def, refs);\n          definitionRefs[def.name.value] = refs;\n        }\n      });\n    })();\n\n    function findOperation(doc, name) {\n      for (var i = 0; i < doc.definitions.length; i++) {\n        var element = doc.definitions[i];\n        if (element.name && element.name.value == name) {\n          return element;\n        }\n      }\n    }\n\n    function oneQuery(doc, operationName) {\n      // Copy the DocumentNode, but clear out the definitions\n      var newDoc = {\n        kind: doc.kind,\n        definitions: [findOperation(doc, operationName)]\n      };\n      if (doc.hasOwnProperty(\"loc\")) {\n        newDoc.loc = doc.loc;\n      }\n\n      // Now, for the operation we're running, find any fragments referenced by\n      // it or the fragments it references\n      var opRefs = definitionRefs[operationName] || new Set();\n      var allRefs = new Set();\n      var newRefs = new Set();\n\n      // IE 11 doesn't support \"new Set(iterable)\", so we add the members of opRefs to newRefs one by one\n      opRefs.forEach(function(refName) {\n        newRefs.add(refName);\n      });\n\n      while (newRefs.size > 0) {\n        var prevRefs = newRefs;\n        newRefs = new Set();\n\n        prevRefs.forEach(function(refName) {\n          if (!allRefs.has(refName)) {\n            allRefs.add(refName);\n            var childRefs = definitionRefs[refName] || new Set();\n            childRefs.forEach(function(childRef) {\n              newRefs.add(childRef);\n            });\n          }\n        });\n      }\n\n      allRefs.forEach(function(refName) {\n        var op = findOperation(doc, refName);\n        if (op) {\n          newDoc.definitions.push(op);\n        }\n      });\n\n      return newDoc;\n    }\n    \n    module.exports = doc;\n    \n        module.exports[\"ProcessKeyCeremonyStep\"] = oneQuery(doc, \"ProcessKeyCeremonyStep\");\n        \n","\n    var doc = {\"kind\":\"Document\",\"definitions\":[{\"kind\":\"OperationDefinition\",\"operation\":\"mutation\",\"name\":{\"kind\":\"Name\",\"value\":\"ProcessTallyStep\"},\"variableDefinitions\":[{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]},{\"kind\":\"VariableDefinition\",\"variable\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"}},\"type\":{\"kind\":\"NonNullType\",\"type\":{\"kind\":\"NamedType\",\"name\":{\"kind\":\"Name\",\"value\":\"String\"}}},\"directives\":[]}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"processTallyStep\"},\"arguments\":[{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"messageId\"}}},{\"kind\":\"Argument\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"value\":{\"kind\":\"Variable\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"}}}],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"pendingMessage\"},\"arguments\":[],\"directives\":[],\"selectionSet\":{\"kind\":\"SelectionSet\",\"selections\":[{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"signedData\"},\"arguments\":[],\"directives\":[]}]}},{\"kind\":\"Field\",\"name\":{\"kind\":\"Name\",\"value\":\"error\"},\"arguments\":[],\"directives\":[]}]}}]}}],\"loc\":{\"start\":0,\"end\":200}};\n    doc.loc.source = {\"body\":\"mutation ProcessTallyStep($messageId: String!, $signedData: String!) {\\n  processTallyStep(messageId: $messageId, signedData: $signedData) {\\n    pendingMessage {\\n      signedData\\n    }\\n    error\\n  }\\n}\\n\",\"name\":\"GraphQL request\",\"locationOffset\":{\"line\":1,\"column\":1}};\n  \n\n    var names = {};\n    function unique(defs) {\n      return defs.filter(\n        function(def) {\n          if (def.kind !== 'FragmentDefinition') return true;\n          var name = def.name.value\n          if (names[name]) {\n            return false;\n          } else {\n            names[name] = true;\n            return true;\n          }\n        }\n      )\n    }\n  \n\n    // Collect any fragment/type references from a node, adding them to the refs Set\n    function collectFragmentReferences(node, refs) {\n      if (node.kind === \"FragmentSpread\") {\n        refs.add(node.name.value);\n      } else if (node.kind === \"VariableDefinition\") {\n        var type = node.type;\n        if (type.kind === \"NamedType\") {\n          refs.add(type.name.value);\n        }\n      }\n\n      if (node.selectionSet) {\n        node.selectionSet.selections.forEach(function(selection) {\n          collectFragmentReferences(selection, refs);\n        });\n      }\n\n      if (node.variableDefinitions) {\n        node.variableDefinitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n\n      if (node.definitions) {\n        node.definitions.forEach(function(def) {\n          collectFragmentReferences(def, refs);\n        });\n      }\n    }\n\n    var definitionRefs = {};\n    (function extractReferences() {\n      doc.definitions.forEach(function(def) {\n        if (def.name) {\n          var refs = new Set();\n          collectFragmentReferences(def, refs);\n          definitionRefs[def.name.value] = refs;\n        }\n      });\n    })();\n\n    function findOperation(doc, name) {\n      for (var i = 0; i < doc.definitions.length; i++) {\n        var element = doc.definitions[i];\n        if (element.name && element.name.value == name) {\n          return element;\n        }\n      }\n    }\n\n    function oneQuery(doc, operationName) {\n      // Copy the DocumentNode, but clear out the definitions\n      var newDoc = {\n        kind: doc.kind,\n        definitions: [findOperation(doc, operationName)]\n      };\n      if (doc.hasOwnProperty(\"loc\")) {\n        newDoc.loc = doc.loc;\n      }\n\n      // Now, for the operation we're running, find any fragments referenced by\n      // it or the fragments it references\n      var opRefs = definitionRefs[operationName] || new Set();\n      var allRefs = new Set();\n      var newRefs = new Set();\n\n      // IE 11 doesn't support \"new Set(iterable)\", so we add the members of opRefs to newRefs one by one\n      opRefs.forEach(function(refName) {\n        newRefs.add(refName);\n      });\n\n      while (newRefs.size > 0) {\n        var prevRefs = newRefs;\n        newRefs = new Set();\n\n        prevRefs.forEach(function(refName) {\n          if (!allRefs.has(refName)) {\n            allRefs.add(refName);\n            var childRefs = definitionRefs[refName] || new Set();\n            childRefs.forEach(function(childRef) {\n              newRefs.add(childRef);\n            });\n          }\n        });\n      }\n\n      allRefs.forEach(function(refName) {\n        var op = findOperation(doc, refName);\n        if (op) {\n          newDoc.definitions.push(op);\n        }\n      });\n\n      return newDoc;\n    }\n    \n    module.exports = doc;\n    \n        module.exports[\"ProcessTallyStep\"] = oneQuery(doc, \"ProcessTallyStep\");\n        \n","/* (ignored) */","/* (ignored) */","// GENERATED FILE. DO NOT EDIT.\nvar Long = (function(exports) {\n  \"use strict\";\n  \n  Object.defineProperty(exports, \"__esModule\", {\n    value: true\n  });\n  exports.default = void 0;\n  \n  /**\n   * @license\n   * Copyright 2009 The Closure Library Authors\n   * Copyright 2020 Daniel Wirtz / The long.js Authors.\n   *\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\n   * you may not use this file except in compliance with the License.\n   * You may obtain a copy of the License at\n   *\n   *     http://www.apache.org/licenses/LICENSE-2.0\n   *\n   * Unless required by applicable law or agreed to in writing, software\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   * See the License for the specific language governing permissions and\n   * limitations under the License.\n   *\n   * SPDX-License-Identifier: Apache-2.0\n   */\n  // WebAssembly optimizations to do native i64 multiplication and divide\n  var wasm = null;\n  \n  try {\n    wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n  } catch (e) {// no wasm support :(\n  }\n  /**\n   * Constructs a 64 bit two's-complement integer, given its low and high 32 bit values as *signed* integers.\n   *  See the from* functions below for more convenient ways of constructing Longs.\n   * @exports Long\n   * @class A Long class for representing a 64 bit two's-complement integer value.\n   * @param {number} low The low (signed) 32 bits of the long\n   * @param {number} high The high (signed) 32 bits of the long\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @constructor\n   */\n  \n  \n  function Long(low, high, unsigned) {\n    /**\n     * The low 32 bits as a signed value.\n     * @type {number}\n     */\n    this.low = low | 0;\n    /**\n     * The high 32 bits as a signed value.\n     * @type {number}\n     */\n  \n    this.high = high | 0;\n    /**\n     * Whether unsigned or not.\n     * @type {boolean}\n     */\n  \n    this.unsigned = !!unsigned;\n  } // The internal representation of a long is the two given signed, 32-bit values.\n  // We use 32-bit pieces because these are the size of integers on which\n  // Javascript performs bit-operations.  For operations like addition and\n  // multiplication, we split each number into 16 bit pieces, which can easily be\n  // multiplied within Javascript's floating-point representation without overflow\n  // or change in sign.\n  //\n  // In the algorithms below, we frequently reduce the negative case to the\n  // positive case by negating the input(s) and then post-processing the result.\n  // Note that we must ALWAYS check specially whether those values are MIN_VALUE\n  // (-2^63) because -MIN_VALUE == MIN_VALUE (since 2^63 cannot be represented as\n  // a positive number, it overflows back into a negative).  Not handling this\n  // case would often result in infinite recursion.\n  //\n  // Common constant values ZERO, ONE, NEG_ONE, etc. are defined below the from*\n  // methods on which they depend.\n  \n  /**\n   * An indicator used to reliably determine if an object is a Long or not.\n   * @type {boolean}\n   * @const\n   * @private\n   */\n  \n  \n  Long.prototype.__isLong__;\n  Object.defineProperty(Long.prototype, \"__isLong__\", {\n    value: true\n  });\n  /**\n   * @function\n   * @param {*} obj Object\n   * @returns {boolean}\n   * @inner\n   */\n  \n  function isLong(obj) {\n    return (obj && obj[\"__isLong__\"]) === true;\n  }\n  /**\n   * @function\n   * @param {*} value number\n   * @returns {number}\n   * @inner\n   */\n  \n  \n  function ctz32(value) {\n    var c = Math.clz32(value & -value);\n    return value ? 31 - c : c;\n  }\n  /**\n   * Tests if the specified object is a Long.\n   * @function\n   * @param {*} obj Object\n   * @returns {boolean}\n   */\n  \n  \n  Long.isLong = isLong;\n  /**\n   * A cache of the Long representations of small integer values.\n   * @type {!Object}\n   * @inner\n   */\n  \n  var INT_CACHE = {};\n  /**\n   * A cache of the Long representations of small unsigned integer values.\n   * @type {!Object}\n   * @inner\n   */\n  \n  var UINT_CACHE = {};\n  /**\n   * @param {number} value\n   * @param {boolean=} unsigned\n   * @returns {!Long}\n   * @inner\n   */\n  \n  function fromInt(value, unsigned) {\n    var obj, cachedObj, cache;\n  \n    if (unsigned) {\n      value >>>= 0;\n  \n      if (cache = 0 <= value && value < 256) {\n        cachedObj = UINT_CACHE[value];\n        if (cachedObj) return cachedObj;\n      }\n  \n      obj = fromBits(value, 0, true);\n      if (cache) UINT_CACHE[value] = obj;\n      return obj;\n    } else {\n      value |= 0;\n  \n      if (cache = -128 <= value && value < 128) {\n        cachedObj = INT_CACHE[value];\n        if (cachedObj) return cachedObj;\n      }\n  \n      obj = fromBits(value, value < 0 ? -1 : 0, false);\n      if (cache) INT_CACHE[value] = obj;\n      return obj;\n    }\n  }\n  /**\n   * Returns a Long representing the given 32 bit integer value.\n   * @function\n   * @param {number} value The 32 bit integer in question\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {!Long} The corresponding Long value\n   */\n  \n  \n  Long.fromInt = fromInt;\n  /**\n   * @param {number} value\n   * @param {boolean=} unsigned\n   * @returns {!Long}\n   * @inner\n   */\n  \n  function fromNumber(value, unsigned) {\n    if (isNaN(value)) return unsigned ? UZERO : ZERO;\n  \n    if (unsigned) {\n      if (value < 0) return UZERO;\n      if (value >= TWO_PWR_64_DBL) return MAX_UNSIGNED_VALUE;\n    } else {\n      if (value <= -TWO_PWR_63_DBL) return MIN_VALUE;\n      if (value + 1 >= TWO_PWR_63_DBL) return MAX_VALUE;\n    }\n  \n    if (value < 0) return fromNumber(-value, unsigned).neg();\n    return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);\n  }\n  /**\n   * Returns a Long representing the given value, provided that it is a finite number. Otherwise, zero is returned.\n   * @function\n   * @param {number} value The number in question\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {!Long} The corresponding Long value\n   */\n  \n  \n  Long.fromNumber = fromNumber;\n  /**\n   * @param {number} lowBits\n   * @param {number} highBits\n   * @param {boolean=} unsigned\n   * @returns {!Long}\n   * @inner\n   */\n  \n  function fromBits(lowBits, highBits, unsigned) {\n    return new Long(lowBits, highBits, unsigned);\n  }\n  /**\n   * Returns a Long representing the 64 bit integer that comes by concatenating the given low and high bits. Each is\n   *  assumed to use 32 bits.\n   * @function\n   * @param {number} lowBits The low 32 bits\n   * @param {number} highBits The high 32 bits\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {!Long} The corresponding Long value\n   */\n  \n  \n  Long.fromBits = fromBits;\n  /**\n   * @function\n   * @param {number} base\n   * @param {number} exponent\n   * @returns {number}\n   * @inner\n   */\n  \n  var pow_dbl = Math.pow; // Used 4 times (4*8 to 15+4)\n  \n  /**\n   * @param {string} str\n   * @param {(boolean|number)=} unsigned\n   * @param {number=} radix\n   * @returns {!Long}\n   * @inner\n   */\n  \n  function fromString(str, unsigned, radix) {\n    if (str.length === 0) throw Error('empty string');\n  \n    if (typeof unsigned === 'number') {\n      // For goog.math.long compatibility\n      radix = unsigned;\n      unsigned = false;\n    } else {\n      unsigned = !!unsigned;\n    }\n  \n    if (str === \"NaN\" || str === \"Infinity\" || str === \"+Infinity\" || str === \"-Infinity\") return unsigned ? UZERO : ZERO;\n    radix = radix || 10;\n    if (radix < 2 || 36 < radix) throw RangeError('radix');\n    var p;\n    if ((p = str.indexOf('-')) > 0) throw Error('interior hyphen');else if (p === 0) {\n      return fromString(str.substring(1), unsigned, radix).neg();\n    } // Do several (8) digits each time through the loop, so as to\n    // minimize the calls to the very expensive emulated div.\n  \n    var radixToPower = fromNumber(pow_dbl(radix, 8));\n    var result = ZERO;\n  \n    for (var i = 0; i < str.length; i += 8) {\n      var size = Math.min(8, str.length - i),\n          value = parseInt(str.substring(i, i + size), radix);\n  \n      if (size < 8) {\n        var power = fromNumber(pow_dbl(radix, size));\n        result = result.mul(power).add(fromNumber(value));\n      } else {\n        result = result.mul(radixToPower);\n        result = result.add(fromNumber(value));\n      }\n    }\n  \n    result.unsigned = unsigned;\n    return result;\n  }\n  /**\n   * Returns a Long representation of the given string, written using the specified radix.\n   * @function\n   * @param {string} str The textual representation of the Long\n   * @param {(boolean|number)=} unsigned Whether unsigned or not, defaults to signed\n   * @param {number=} radix The radix in which the text is written (2-36), defaults to 10\n   * @returns {!Long} The corresponding Long value\n   */\n  \n  \n  Long.fromString = fromString;\n  /**\n   * @function\n   * @param {!Long|number|string|!{low: number, high: number, unsigned: boolean}} val\n   * @param {boolean=} unsigned\n   * @returns {!Long}\n   * @inner\n   */\n  \n  function fromValue(val, unsigned) {\n    if (typeof val === 'number') return fromNumber(val, unsigned);\n    if (typeof val === 'string') return fromString(val, unsigned); // Throws for non-objects, converts non-instanceof Long:\n  \n    return fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);\n  }\n  /**\n   * Converts the specified value to a Long using the appropriate from* function for its type.\n   * @function\n   * @param {!Long|number|string|!{low: number, high: number, unsigned: boolean}} val Value\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {!Long}\n   */\n  \n  \n  Long.fromValue = fromValue; // NOTE: the compiler should inline these constant values below and then remove these variables, so there should be\n  // no runtime penalty for these.\n  \n  /**\n   * @type {number}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_16_DBL = 1 << 16;\n  /**\n   * @type {number}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_24_DBL = 1 << 24;\n  /**\n   * @type {number}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\n  /**\n   * @type {number}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;\n  /**\n   * @type {number}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;\n  /**\n   * @type {!Long}\n   * @const\n   * @inner\n   */\n  \n  var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var ZERO = fromInt(0);\n  /**\n   * Signed zero.\n   * @type {!Long}\n   */\n  \n  Long.ZERO = ZERO;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var UZERO = fromInt(0, true);\n  /**\n   * Unsigned zero.\n   * @type {!Long}\n   */\n  \n  Long.UZERO = UZERO;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var ONE = fromInt(1);\n  /**\n   * Signed one.\n   * @type {!Long}\n   */\n  \n  Long.ONE = ONE;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var UONE = fromInt(1, true);\n  /**\n   * Unsigned one.\n   * @type {!Long}\n   */\n  \n  Long.UONE = UONE;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var NEG_ONE = fromInt(-1);\n  /**\n   * Signed negative one.\n   * @type {!Long}\n   */\n  \n  Long.NEG_ONE = NEG_ONE;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var MAX_VALUE = fromBits(0xFFFFFFFF | 0, 0x7FFFFFFF | 0, false);\n  /**\n   * Maximum signed value.\n   * @type {!Long}\n   */\n  \n  Long.MAX_VALUE = MAX_VALUE;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var MAX_UNSIGNED_VALUE = fromBits(0xFFFFFFFF | 0, 0xFFFFFFFF | 0, true);\n  /**\n   * Maximum unsigned value.\n   * @type {!Long}\n   */\n  \n  Long.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;\n  /**\n   * @type {!Long}\n   * @inner\n   */\n  \n  var MIN_VALUE = fromBits(0, 0x80000000 | 0, false);\n  /**\n   * Minimum signed value.\n   * @type {!Long}\n   */\n  \n  Long.MIN_VALUE = MIN_VALUE;\n  /**\n   * @alias Long.prototype\n   * @inner\n   */\n  \n  var LongPrototype = Long.prototype;\n  /**\n   * Converts the Long to a 32 bit integer, assuming it is a 32 bit integer.\n   * @this {!Long}\n   * @returns {number}\n   */\n  \n  LongPrototype.toInt = function toInt() {\n    return this.unsigned ? this.low >>> 0 : this.low;\n  };\n  /**\n   * Converts the Long to a the nearest floating-point representation of this value (double, 53 bit mantissa).\n   * @this {!Long}\n   * @returns {number}\n   */\n  \n  \n  LongPrototype.toNumber = function toNumber() {\n    if (this.unsigned) return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);\n    return this.high * TWO_PWR_32_DBL + (this.low >>> 0);\n  };\n  /**\n   * Converts the Long to a string written in the specified radix.\n   * @this {!Long}\n   * @param {number=} radix Radix (2-36), defaults to 10\n   * @returns {string}\n   * @override\n   * @throws {RangeError} If `radix` is out of range\n   */\n  \n  \n  LongPrototype.toString = function toString(radix) {\n    radix = radix || 10;\n    if (radix < 2 || 36 < radix) throw RangeError('radix');\n    if (this.isZero()) return '0';\n  \n    if (this.isNegative()) {\n      // Unsigned Longs are never negative\n      if (this.eq(MIN_VALUE)) {\n        // We need to change the Long value before it can be negated, so we remove\n        // the bottom-most digit in this base and then recurse to do the rest.\n        var radixLong = fromNumber(radix),\n            div = this.div(radixLong),\n            rem1 = div.mul(radixLong).sub(this);\n        return div.toString(radix) + rem1.toInt().toString(radix);\n      } else return '-' + this.neg().toString(radix);\n    } // Do several (6) digits each time through the loop, so as to\n    // minimize the calls to the very expensive emulated div.\n  \n  \n    var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned),\n        rem = this;\n    var result = '';\n  \n    while (true) {\n      var remDiv = rem.div(radixToPower),\n          intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0,\n          digits = intval.toString(radix);\n      rem = remDiv;\n      if (rem.isZero()) return digits + result;else {\n        while (digits.length < 6) digits = '0' + digits;\n  \n        result = '' + digits + result;\n      }\n    }\n  };\n  /**\n   * Gets the high 32 bits as a signed integer.\n   * @this {!Long}\n   * @returns {number} Signed high bits\n   */\n  \n  \n  LongPrototype.getHighBits = function getHighBits() {\n    return this.high;\n  };\n  /**\n   * Gets the high 32 bits as an unsigned integer.\n   * @this {!Long}\n   * @returns {number} Unsigned high bits\n   */\n  \n  \n  LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {\n    return this.high >>> 0;\n  };\n  /**\n   * Gets the low 32 bits as a signed integer.\n   * @this {!Long}\n   * @returns {number} Signed low bits\n   */\n  \n  \n  LongPrototype.getLowBits = function getLowBits() {\n    return this.low;\n  };\n  /**\n   * Gets the low 32 bits as an unsigned integer.\n   * @this {!Long}\n   * @returns {number} Unsigned low bits\n   */\n  \n  \n  LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {\n    return this.low >>> 0;\n  };\n  /**\n   * Gets the number of bits needed to represent the absolute value of this Long.\n   * @this {!Long}\n   * @returns {number}\n   */\n  \n  \n  LongPrototype.getNumBitsAbs = function getNumBitsAbs() {\n    if (this.isNegative()) // Unsigned Longs are never negative\n      return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();\n    var val = this.high != 0 ? this.high : this.low;\n  \n    for (var bit = 31; bit > 0; bit--) if ((val & 1 << bit) != 0) break;\n  \n    return this.high != 0 ? bit + 33 : bit + 1;\n  };\n  /**\n   * Tests if this Long's value equals zero.\n   * @this {!Long}\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.isZero = function isZero() {\n    return this.high === 0 && this.low === 0;\n  };\n  /**\n   * Tests if this Long's value equals zero. This is an alias of {@link Long#isZero}.\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.eqz = LongPrototype.isZero;\n  /**\n   * Tests if this Long's value is negative.\n   * @this {!Long}\n   * @returns {boolean}\n   */\n  \n  LongPrototype.isNegative = function isNegative() {\n    return !this.unsigned && this.high < 0;\n  };\n  /**\n   * Tests if this Long's value is positive or zero.\n   * @this {!Long}\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.isPositive = function isPositive() {\n    return this.unsigned || this.high >= 0;\n  };\n  /**\n   * Tests if this Long's value is odd.\n   * @this {!Long}\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.isOdd = function isOdd() {\n    return (this.low & 1) === 1;\n  };\n  /**\n   * Tests if this Long's value is even.\n   * @this {!Long}\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.isEven = function isEven() {\n    return (this.low & 1) === 0;\n  };\n  /**\n   * Tests if this Long's value equals the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.equals = function equals(other) {\n    if (!isLong(other)) other = fromValue(other);\n    if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1) return false;\n    return this.high === other.high && this.low === other.low;\n  };\n  /**\n   * Tests if this Long's value equals the specified's. This is an alias of {@link Long#equals}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.eq = LongPrototype.equals;\n  /**\n   * Tests if this Long's value differs from the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.notEquals = function notEquals(other) {\n    return !this.eq(\n    /* validates */\n    other);\n  };\n  /**\n   * Tests if this Long's value differs from the specified's. This is an alias of {@link Long#notEquals}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.neq = LongPrototype.notEquals;\n  /**\n   * Tests if this Long's value differs from the specified's. This is an alias of {@link Long#notEquals}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.ne = LongPrototype.notEquals;\n  /**\n   * Tests if this Long's value is less than the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.lessThan = function lessThan(other) {\n    return this.comp(\n    /* validates */\n    other) < 0;\n  };\n  /**\n   * Tests if this Long's value is less than the specified's. This is an alias of {@link Long#lessThan}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.lt = LongPrototype.lessThan;\n  /**\n   * Tests if this Long's value is less than or equal the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {\n    return this.comp(\n    /* validates */\n    other) <= 0;\n  };\n  /**\n   * Tests if this Long's value is less than or equal the specified's. This is an alias of {@link Long#lessThanOrEqual}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.lte = LongPrototype.lessThanOrEqual;\n  /**\n   * Tests if this Long's value is less than or equal the specified's. This is an alias of {@link Long#lessThanOrEqual}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.le = LongPrototype.lessThanOrEqual;\n  /**\n   * Tests if this Long's value is greater than the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.greaterThan = function greaterThan(other) {\n    return this.comp(\n    /* validates */\n    other) > 0;\n  };\n  /**\n   * Tests if this Long's value is greater than the specified's. This is an alias of {@link Long#greaterThan}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.gt = LongPrototype.greaterThan;\n  /**\n   * Tests if this Long's value is greater than or equal the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {\n    return this.comp(\n    /* validates */\n    other) >= 0;\n  };\n  /**\n   * Tests if this Long's value is greater than or equal the specified's. This is an alias of {@link Long#greaterThanOrEqual}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  \n  LongPrototype.gte = LongPrototype.greaterThanOrEqual;\n  /**\n   * Tests if this Long's value is greater than or equal the specified's. This is an alias of {@link Long#greaterThanOrEqual}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {boolean}\n   */\n  \n  LongPrototype.ge = LongPrototype.greaterThanOrEqual;\n  /**\n   * Compares this Long's value with the specified's.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other value\n   * @returns {number} 0 if they are the same, 1 if the this is greater and -1\n   *  if the given one is greater\n   */\n  \n  LongPrototype.compare = function compare(other) {\n    if (!isLong(other)) other = fromValue(other);\n    if (this.eq(other)) return 0;\n    var thisNeg = this.isNegative(),\n        otherNeg = other.isNegative();\n    if (thisNeg && !otherNeg) return -1;\n    if (!thisNeg && otherNeg) return 1; // At this point the sign bits are the same\n  \n    if (!this.unsigned) return this.sub(other).isNegative() ? -1 : 1; // Both are positive if at least one is unsigned\n  \n    return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;\n  };\n  /**\n   * Compares this Long's value with the specified's. This is an alias of {@link Long#compare}.\n   * @function\n   * @param {!Long|number|string} other Other value\n   * @returns {number} 0 if they are the same, 1 if the this is greater and -1\n   *  if the given one is greater\n   */\n  \n  \n  LongPrototype.comp = LongPrototype.compare;\n  /**\n   * Negates this Long's value.\n   * @this {!Long}\n   * @returns {!Long} Negated Long\n   */\n  \n  LongPrototype.negate = function negate() {\n    if (!this.unsigned && this.eq(MIN_VALUE)) return MIN_VALUE;\n    return this.not().add(ONE);\n  };\n  /**\n   * Negates this Long's value. This is an alias of {@link Long#negate}.\n   * @function\n   * @returns {!Long} Negated Long\n   */\n  \n  \n  LongPrototype.neg = LongPrototype.negate;\n  /**\n   * Returns the sum of this and the specified Long.\n   * @this {!Long}\n   * @param {!Long|number|string} addend Addend\n   * @returns {!Long} Sum\n   */\n  \n  LongPrototype.add = function add(addend) {\n    if (!isLong(addend)) addend = fromValue(addend); // Divide each number into 4 chunks of 16 bits, and then sum the chunks.\n  \n    var a48 = this.high >>> 16;\n    var a32 = this.high & 0xFFFF;\n    var a16 = this.low >>> 16;\n    var a00 = this.low & 0xFFFF;\n    var b48 = addend.high >>> 16;\n    var b32 = addend.high & 0xFFFF;\n    var b16 = addend.low >>> 16;\n    var b00 = addend.low & 0xFFFF;\n    var c48 = 0,\n        c32 = 0,\n        c16 = 0,\n        c00 = 0;\n    c00 += a00 + b00;\n    c16 += c00 >>> 16;\n    c00 &= 0xFFFF;\n    c16 += a16 + b16;\n    c32 += c16 >>> 16;\n    c16 &= 0xFFFF;\n    c32 += a32 + b32;\n    c48 += c32 >>> 16;\n    c32 &= 0xFFFF;\n    c48 += a48 + b48;\n    c48 &= 0xFFFF;\n    return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);\n  };\n  /**\n   * Returns the difference of this and the specified Long.\n   * @this {!Long}\n   * @param {!Long|number|string} subtrahend Subtrahend\n   * @returns {!Long} Difference\n   */\n  \n  \n  LongPrototype.subtract = function subtract(subtrahend) {\n    if (!isLong(subtrahend)) subtrahend = fromValue(subtrahend);\n    return this.add(subtrahend.neg());\n  };\n  /**\n   * Returns the difference of this and the specified Long. This is an alias of {@link Long#subtract}.\n   * @function\n   * @param {!Long|number|string} subtrahend Subtrahend\n   * @returns {!Long} Difference\n   */\n  \n  \n  LongPrototype.sub = LongPrototype.subtract;\n  /**\n   * Returns the product of this and the specified Long.\n   * @this {!Long}\n   * @param {!Long|number|string} multiplier Multiplier\n   * @returns {!Long} Product\n   */\n  \n  LongPrototype.multiply = function multiply(multiplier) {\n    if (this.isZero()) return this;\n    if (!isLong(multiplier)) multiplier = fromValue(multiplier); // use wasm support if present\n  \n    if (wasm) {\n      var low = wasm[\"mul\"](this.low, this.high, multiplier.low, multiplier.high);\n      return fromBits(low, wasm[\"get_high\"](), this.unsigned);\n    }\n  \n    if (multiplier.isZero()) return this.unsigned ? UZERO : ZERO;\n    if (this.eq(MIN_VALUE)) return multiplier.isOdd() ? MIN_VALUE : ZERO;\n    if (multiplier.eq(MIN_VALUE)) return this.isOdd() ? MIN_VALUE : ZERO;\n  \n    if (this.isNegative()) {\n      if (multiplier.isNegative()) return this.neg().mul(multiplier.neg());else return this.neg().mul(multiplier).neg();\n    } else if (multiplier.isNegative()) return this.mul(multiplier.neg()).neg(); // If both longs are small, use float multiplication\n  \n  \n    if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24)) return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned); // Divide each long into 4 chunks of 16 bits, and then add up 4x4 products.\n    // We can skip products that would overflow.\n  \n    var a48 = this.high >>> 16;\n    var a32 = this.high & 0xFFFF;\n    var a16 = this.low >>> 16;\n    var a00 = this.low & 0xFFFF;\n    var b48 = multiplier.high >>> 16;\n    var b32 = multiplier.high & 0xFFFF;\n    var b16 = multiplier.low >>> 16;\n    var b00 = multiplier.low & 0xFFFF;\n    var c48 = 0,\n        c32 = 0,\n        c16 = 0,\n        c00 = 0;\n    c00 += a00 * b00;\n    c16 += c00 >>> 16;\n    c00 &= 0xFFFF;\n    c16 += a16 * b00;\n    c32 += c16 >>> 16;\n    c16 &= 0xFFFF;\n    c16 += a00 * b16;\n    c32 += c16 >>> 16;\n    c16 &= 0xFFFF;\n    c32 += a32 * b00;\n    c48 += c32 >>> 16;\n    c32 &= 0xFFFF;\n    c32 += a16 * b16;\n    c48 += c32 >>> 16;\n    c32 &= 0xFFFF;\n    c32 += a00 * b32;\n    c48 += c32 >>> 16;\n    c32 &= 0xFFFF;\n    c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;\n    c48 &= 0xFFFF;\n    return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);\n  };\n  /**\n   * Returns the product of this and the specified Long. This is an alias of {@link Long#multiply}.\n   * @function\n   * @param {!Long|number|string} multiplier Multiplier\n   * @returns {!Long} Product\n   */\n  \n  \n  LongPrototype.mul = LongPrototype.multiply;\n  /**\n   * Returns this Long divided by the specified. The result is signed if this Long is signed or\n   *  unsigned if this Long is unsigned.\n   * @this {!Long}\n   * @param {!Long|number|string} divisor Divisor\n   * @returns {!Long} Quotient\n   */\n  \n  LongPrototype.divide = function divide(divisor) {\n    if (!isLong(divisor)) divisor = fromValue(divisor);\n    if (divisor.isZero()) throw Error('division by zero'); // use wasm support if present\n  \n    if (wasm) {\n      // guard against signed division overflow: the largest\n      // negative number / -1 would be 1 larger than the largest\n      // positive number, due to two's complement.\n      if (!this.unsigned && this.high === -0x80000000 && divisor.low === -1 && divisor.high === -1) {\n        // be consistent with non-wasm code path\n        return this;\n      }\n  \n      var low = (this.unsigned ? wasm[\"div_u\"] : wasm[\"div_s\"])(this.low, this.high, divisor.low, divisor.high);\n      return fromBits(low, wasm[\"get_high\"](), this.unsigned);\n    }\n  \n    if (this.isZero()) return this.unsigned ? UZERO : ZERO;\n    var approx, rem, res;\n  \n    if (!this.unsigned) {\n      // This section is only relevant for signed longs and is derived from the\n      // closure library as a whole.\n      if (this.eq(MIN_VALUE)) {\n        if (divisor.eq(ONE) || divisor.eq(NEG_ONE)) return MIN_VALUE; // recall that -MIN_VALUE == MIN_VALUE\n        else if (divisor.eq(MIN_VALUE)) return ONE;else {\n          // At this point, we have |other| >= 2, so |this/other| < |MIN_VALUE|.\n          var halfThis = this.shr(1);\n          approx = halfThis.div(divisor).shl(1);\n  \n          if (approx.eq(ZERO)) {\n            return divisor.isNegative() ? ONE : NEG_ONE;\n          } else {\n            rem = this.sub(divisor.mul(approx));\n            res = approx.add(rem.div(divisor));\n            return res;\n          }\n        }\n      } else if (divisor.eq(MIN_VALUE)) return this.unsigned ? UZERO : ZERO;\n  \n      if (this.isNegative()) {\n        if (divisor.isNegative()) return this.neg().div(divisor.neg());\n        return this.neg().div(divisor).neg();\n      } else if (divisor.isNegative()) return this.div(divisor.neg()).neg();\n  \n      res = ZERO;\n    } else {\n      // The algorithm below has not been made for unsigned longs. It's therefore\n      // required to take special care of the MSB prior to running it.\n      if (!divisor.unsigned) divisor = divisor.toUnsigned();\n      if (divisor.gt(this)) return UZERO;\n      if (divisor.gt(this.shru(1))) // 15 >>> 1 = 7 ; with divisor = 8 ; true\n        return UONE;\n      res = UZERO;\n    } // Repeat the following until the remainder is less than other:  find a\n    // floating-point that approximates remainder / other *from below*, add this\n    // into the result, and subtract it from the remainder.  It is critical that\n    // the approximate value is less than or equal to the real value so that the\n    // remainder never becomes negative.\n  \n  \n    rem = this;\n  \n    while (rem.gte(divisor)) {\n      // Approximate the result of division. This may be a little greater or\n      // smaller than the actual value.\n      approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber())); // We will tweak the approximate result by changing it in the 48-th digit or\n      // the smallest non-fractional digit, whichever is larger.\n  \n      var log2 = Math.ceil(Math.log(approx) / Math.LN2),\n          delta = log2 <= 48 ? 1 : pow_dbl(2, log2 - 48),\n          // Decrease the approximation until it is smaller than the remainder.  Note\n      // that if it is too large, the product overflows and is negative.\n      approxRes = fromNumber(approx),\n          approxRem = approxRes.mul(divisor);\n  \n      while (approxRem.isNegative() || approxRem.gt(rem)) {\n        approx -= delta;\n        approxRes = fromNumber(approx, this.unsigned);\n        approxRem = approxRes.mul(divisor);\n      } // We know the answer can't be zero... and actually, zero would cause\n      // infinite recursion since we would make no progress.\n  \n  \n      if (approxRes.isZero()) approxRes = ONE;\n      res = res.add(approxRes);\n      rem = rem.sub(approxRem);\n    }\n  \n    return res;\n  };\n  /**\n   * Returns this Long divided by the specified. This is an alias of {@link Long#divide}.\n   * @function\n   * @param {!Long|number|string} divisor Divisor\n   * @returns {!Long} Quotient\n   */\n  \n  \n  LongPrototype.div = LongPrototype.divide;\n  /**\n   * Returns this Long modulo the specified.\n   * @this {!Long}\n   * @param {!Long|number|string} divisor Divisor\n   * @returns {!Long} Remainder\n   */\n  \n  LongPrototype.modulo = function modulo(divisor) {\n    if (!isLong(divisor)) divisor = fromValue(divisor); // use wasm support if present\n  \n    if (wasm) {\n      var low = (this.unsigned ? wasm[\"rem_u\"] : wasm[\"rem_s\"])(this.low, this.high, divisor.low, divisor.high);\n      return fromBits(low, wasm[\"get_high\"](), this.unsigned);\n    }\n  \n    return this.sub(this.div(divisor).mul(divisor));\n  };\n  /**\n   * Returns this Long modulo the specified. This is an alias of {@link Long#modulo}.\n   * @function\n   * @param {!Long|number|string} divisor Divisor\n   * @returns {!Long} Remainder\n   */\n  \n  \n  LongPrototype.mod = LongPrototype.modulo;\n  /**\n   * Returns this Long modulo the specified. This is an alias of {@link Long#modulo}.\n   * @function\n   * @param {!Long|number|string} divisor Divisor\n   * @returns {!Long} Remainder\n   */\n  \n  LongPrototype.rem = LongPrototype.modulo;\n  /**\n   * Returns the bitwise NOT of this Long.\n   * @this {!Long}\n   * @returns {!Long}\n   */\n  \n  LongPrototype.not = function not() {\n    return fromBits(~this.low, ~this.high, this.unsigned);\n  };\n  /**\n   * Returns count leading zeros of this Long.\n   * @this {!Long}\n   * @returns {!number}\n   */\n  \n  \n  LongPrototype.countLeadingZeros = function countLeadingZeros() {\n    return this.high ? Math.clz32(this.high) : Math.clz32(this.low) + 32;\n  };\n  /**\n   * Returns count leading zeros. This is an alias of {@link Long#countLeadingZeros}.\n   * @function\n   * @param {!Long}\n   * @returns {!number}\n   */\n  \n  \n  LongPrototype.clz = LongPrototype.countLeadingZeros;\n  /**\n   * Returns count trailing zeros of this Long.\n   * @this {!Long}\n   * @returns {!number}\n   */\n  \n  LongPrototype.countTrailingZeros = function countTrailingZeros() {\n    return this.low ? ctz32(this.low) : ctz32(this.high) + 32;\n  };\n  /**\n   * Returns count trailing zeros. This is an alias of {@link Long#countTrailingZeros}.\n   * @function\n   * @param {!Long}\n   * @returns {!number}\n   */\n  \n  \n  LongPrototype.ctz = LongPrototype.countTrailingZeros;\n  /**\n   * Returns the bitwise AND of this Long and the specified.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other Long\n   * @returns {!Long}\n   */\n  \n  LongPrototype.and = function and(other) {\n    if (!isLong(other)) other = fromValue(other);\n    return fromBits(this.low & other.low, this.high & other.high, this.unsigned);\n  };\n  /**\n   * Returns the bitwise OR of this Long and the specified.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other Long\n   * @returns {!Long}\n   */\n  \n  \n  LongPrototype.or = function or(other) {\n    if (!isLong(other)) other = fromValue(other);\n    return fromBits(this.low | other.low, this.high | other.high, this.unsigned);\n  };\n  /**\n   * Returns the bitwise XOR of this Long and the given one.\n   * @this {!Long}\n   * @param {!Long|number|string} other Other Long\n   * @returns {!Long}\n   */\n  \n  \n  LongPrototype.xor = function xor(other) {\n    if (!isLong(other)) other = fromValue(other);\n    return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits shifted to the left by the given amount.\n   * @this {!Long}\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  \n  LongPrototype.shiftLeft = function shiftLeft(numBits) {\n    if (isLong(numBits)) numBits = numBits.toInt();\n    if ((numBits &= 63) === 0) return this;else if (numBits < 32) return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);else return fromBits(0, this.low << numBits - 32, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits shifted to the left by the given amount. This is an alias of {@link Long#shiftLeft}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  \n  LongPrototype.shl = LongPrototype.shiftLeft;\n  /**\n   * Returns this Long with bits arithmetically shifted to the right by the given amount.\n   * @this {!Long}\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  LongPrototype.shiftRight = function shiftRight(numBits) {\n    if (isLong(numBits)) numBits = numBits.toInt();\n    if ((numBits &= 63) === 0) return this;else if (numBits < 32) return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);else return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits arithmetically shifted to the right by the given amount. This is an alias of {@link Long#shiftRight}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  \n  LongPrototype.shr = LongPrototype.shiftRight;\n  /**\n   * Returns this Long with bits logically shifted to the right by the given amount.\n   * @this {!Long}\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {\n    if (isLong(numBits)) numBits = numBits.toInt();\n    if ((numBits &= 63) === 0) return this;\n    if (numBits < 32) return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >>> numBits, this.unsigned);\n    if (numBits === 32) return fromBits(this.high, 0, this.unsigned);\n    return fromBits(this.high >>> numBits - 32, 0, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits logically shifted to the right by the given amount. This is an alias of {@link Long#shiftRightUnsigned}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  \n  LongPrototype.shru = LongPrototype.shiftRightUnsigned;\n  /**\n   * Returns this Long with bits logically shifted to the right by the given amount. This is an alias of {@link Long#shiftRightUnsigned}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Shifted Long\n   */\n  \n  LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;\n  /**\n   * Returns this Long with bits rotated to the left by the given amount.\n   * @this {!Long}\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Rotated Long\n   */\n  \n  LongPrototype.rotateLeft = function rotateLeft(numBits) {\n    var b;\n    if (isLong(numBits)) numBits = numBits.toInt();\n    if ((numBits &= 63) === 0) return this;\n    if (numBits === 32) return fromBits(this.high, this.low, this.unsigned);\n  \n    if (numBits < 32) {\n      b = 32 - numBits;\n      return fromBits(this.low << numBits | this.high >>> b, this.high << numBits | this.low >>> b, this.unsigned);\n    }\n  \n    numBits -= 32;\n    b = 32 - numBits;\n    return fromBits(this.high << numBits | this.low >>> b, this.low << numBits | this.high >>> b, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits rotated to the left by the given amount. This is an alias of {@link Long#rotateLeft}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Rotated Long\n   */\n  \n  \n  LongPrototype.rotl = LongPrototype.rotateLeft;\n  /**\n   * Returns this Long with bits rotated to the right by the given amount.\n   * @this {!Long}\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Rotated Long\n   */\n  \n  LongPrototype.rotateRight = function rotateRight(numBits) {\n    var b;\n    if (isLong(numBits)) numBits = numBits.toInt();\n    if ((numBits &= 63) === 0) return this;\n    if (numBits === 32) return fromBits(this.high, this.low, this.unsigned);\n  \n    if (numBits < 32) {\n      b = 32 - numBits;\n      return fromBits(this.high << b | this.low >>> numBits, this.low << b | this.high >>> numBits, this.unsigned);\n    }\n  \n    numBits -= 32;\n    b = 32 - numBits;\n    return fromBits(this.low << b | this.high >>> numBits, this.high << b | this.low >>> numBits, this.unsigned);\n  };\n  /**\n   * Returns this Long with bits rotated to the right by the given amount. This is an alias of {@link Long#rotateRight}.\n   * @function\n   * @param {number|!Long} numBits Number of bits\n   * @returns {!Long} Rotated Long\n   */\n  \n  \n  LongPrototype.rotr = LongPrototype.rotateRight;\n  /**\n   * Converts this Long to signed.\n   * @this {!Long}\n   * @returns {!Long} Signed long\n   */\n  \n  LongPrototype.toSigned = function toSigned() {\n    if (!this.unsigned) return this;\n    return fromBits(this.low, this.high, false);\n  };\n  /**\n   * Converts this Long to unsigned.\n   * @this {!Long}\n   * @returns {!Long} Unsigned long\n   */\n  \n  \n  LongPrototype.toUnsigned = function toUnsigned() {\n    if (this.unsigned) return this;\n    return fromBits(this.low, this.high, true);\n  };\n  /**\n   * Converts this Long to its byte representation.\n   * @param {boolean=} le Whether little or big endian, defaults to big endian\n   * @this {!Long}\n   * @returns {!Array.<number>} Byte representation\n   */\n  \n  \n  LongPrototype.toBytes = function toBytes(le) {\n    return le ? this.toBytesLE() : this.toBytesBE();\n  };\n  /**\n   * Converts this Long to its little endian byte representation.\n   * @this {!Long}\n   * @returns {!Array.<number>} Little endian byte representation\n   */\n  \n  \n  LongPrototype.toBytesLE = function toBytesLE() {\n    var hi = this.high,\n        lo = this.low;\n    return [lo & 0xff, lo >>> 8 & 0xff, lo >>> 16 & 0xff, lo >>> 24, hi & 0xff, hi >>> 8 & 0xff, hi >>> 16 & 0xff, hi >>> 24];\n  };\n  /**\n   * Converts this Long to its big endian byte representation.\n   * @this {!Long}\n   * @returns {!Array.<number>} Big endian byte representation\n   */\n  \n  \n  LongPrototype.toBytesBE = function toBytesBE() {\n    var hi = this.high,\n        lo = this.low;\n    return [hi >>> 24, hi >>> 16 & 0xff, hi >>> 8 & 0xff, hi & 0xff, lo >>> 24, lo >>> 16 & 0xff, lo >>> 8 & 0xff, lo & 0xff];\n  };\n  /**\n   * Creates a Long from its byte representation.\n   * @param {!Array.<number>} bytes Byte representation\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @param {boolean=} le Whether little or big endian, defaults to big endian\n   * @returns {Long} The corresponding Long value\n   */\n  \n  \n  Long.fromBytes = function fromBytes(bytes, unsigned, le) {\n    return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);\n  };\n  /**\n   * Creates a Long from its little endian byte representation.\n   * @param {!Array.<number>} bytes Little endian byte representation\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {Long} The corresponding Long value\n   */\n  \n  \n  Long.fromBytesLE = function fromBytesLE(bytes, unsigned) {\n    return new Long(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);\n  };\n  /**\n   * Creates a Long from its big endian byte representation.\n   * @param {!Array.<number>} bytes Big endian byte representation\n   * @param {boolean=} unsigned Whether unsigned or not, defaults to signed\n   * @returns {Long} The corresponding Long value\n   */\n  \n  \n  Long.fromBytesBE = function fromBytesBE(bytes, unsigned) {\n    return new Long(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);\n  };\n  \n  var _default = Long;\n  exports.default = _default;\n  return \"default\" in exports ? exports.default : exports;\n})({});\nif (typeof define === 'function' && define.amd) define([], function() { return Long; });\nelse if (typeof module === 'object' && typeof exports === 'object') module.exports = Long;\n","import type { DocumentNode } from \"graphql\";\nimport { wrap } from \"optimism\";\n\nimport type { StoreObject, Reference } from \"../../utilities/index.js\";\nimport { getFragmentQueryDocument } from \"../../utilities/index.js\";\nimport type { DataProxy } from \"./types/DataProxy.js\";\nimport type { Cache } from \"./types/Cache.js\";\n\nexport type Transaction<T> = (c: ApolloCache<T>) => void;\n\nexport abstract class ApolloCache<TSerialized> implements DataProxy {\n  public readonly assumeImmutableResults: boolean = false;\n\n  // required to implement\n  // core API\n  public abstract read<TData = any, TVariables = any>(\n    query: Cache.ReadOptions<TVariables, TData>\n  ): TData | null;\n  public abstract write<TData = any, TVariables = any>(\n    write: Cache.WriteOptions<TData, TVariables>\n  ): Reference | undefined;\n  public abstract diff<T>(query: Cache.DiffOptions): Cache.DiffResult<T>;\n  public abstract watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>\n  ): () => void;\n\n  // Empty the cache and restart all current watches (unless\n  // options.discardWatches is true).\n  public abstract reset(options?: Cache.ResetOptions): Promise<void>;\n\n  // Remove whole objects from the cache by passing just options.id, or\n  // specific fields by passing options.field and/or options.args. If no\n  // options.args are provided, all fields matching options.field (even\n  // those with arguments) will be removed. Returns true iff any data was\n  // removed from the cache.\n  public abstract evict(options: Cache.EvictOptions): boolean;\n\n  // initializer / offline / ssr API\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public abstract restore(\n    serializedState: TSerialized\n  ): ApolloCache<TSerialized>;\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public abstract extract(optimistic?: boolean): TSerialized;\n\n  // Optimistic API\n\n  public abstract removeOptimistic(id: string): void;\n\n  // Transactional API\n\n  // The batch method is intended to replace/subsume both performTransaction\n  // and recordOptimisticTransaction, but performTransaction came first, so we\n  // provide a default batch implementation that's just another way of calling\n  // performTransaction. Subclasses of ApolloCache (such as InMemoryCache) can\n  // override the batch method to do more interesting things with its options.\n  public batch<U>(options: Cache.BatchOptions<this, U>): U {\n    const optimisticId =\n      typeof options.optimistic === \"string\" ? options.optimistic\n      : options.optimistic === false ? null\n      : void 0;\n    let updateResult: U;\n    this.performTransaction(\n      () => (updateResult = options.update(this)),\n      optimisticId\n    );\n    return updateResult!;\n  }\n\n  public abstract performTransaction(\n    transaction: Transaction<TSerialized>,\n    // Although subclasses may implement recordOptimisticTransaction\n    // however they choose, the default implementation simply calls\n    // performTransaction with a string as the second argument, allowing\n    // performTransaction to handle both optimistic and non-optimistic\n    // (broadcast-batching) transactions. Passing null for optimisticId is\n    // also allowed, and indicates that performTransaction should apply\n    // the transaction non-optimistically (ignoring optimistic data).\n    optimisticId?: string | null\n  ): void;\n\n  public recordOptimisticTransaction(\n    transaction: Transaction<TSerialized>,\n    optimisticId: string\n  ) {\n    this.performTransaction(transaction, optimisticId);\n  }\n\n  // Optional API\n\n  // Called once per input document, allowing the cache to make static changes\n  // to the query, such as adding __typename fields.\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  // Called before each ApolloLink request, allowing the cache to make dynamic\n  // changes to the query, such as filling in missing fragment definitions.\n  public transformForLink(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  public identify(object: StoreObject | Reference): string | undefined {\n    return;\n  }\n\n  public gc(): string[] {\n    return [];\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(\n    options: Cache.ModifyOptions<Entity>\n  ): boolean {\n    return false;\n  }\n\n  // DataProxy API\n  public readQuery<QueryType, TVariables = any>(\n    options: Cache.ReadQueryOptions<QueryType, TVariables>,\n    optimistic = !!options.optimistic\n  ): QueryType | null {\n    return this.read({\n      ...options,\n      rootId: options.id || \"ROOT_QUERY\",\n      optimistic,\n    });\n  }\n\n  // Make sure we compute the same (===) fragment query document every\n  // time we receive the same fragment in readFragment.\n  private getFragmentDoc = wrap(getFragmentQueryDocument);\n\n  public readFragment<FragmentType, TVariables = any>(\n    options: Cache.ReadFragmentOptions<FragmentType, TVariables>,\n    optimistic = !!options.optimistic\n  ): FragmentType | null {\n    return this.read({\n      ...options,\n      query: this.getFragmentDoc(options.fragment, options.fragmentName),\n      rootId: options.id,\n      optimistic,\n    });\n  }\n\n  public writeQuery<TData = any, TVariables = any>({\n    id,\n    data,\n    ...options\n  }: Cache.WriteQueryOptions<TData, TVariables>): Reference | undefined {\n    return this.write(\n      Object.assign(options, {\n        dataId: id || \"ROOT_QUERY\",\n        result: data,\n      })\n    );\n  }\n\n  public writeFragment<TData = any, TVariables = any>({\n    id,\n    data,\n    fragment,\n    fragmentName,\n    ...options\n  }: Cache.WriteFragmentOptions<TData, TVariables>): Reference | undefined {\n    return this.write(\n      Object.assign(options, {\n        query: this.getFragmentDoc(fragment, fragmentName),\n        dataId: id,\n        result: data,\n      })\n    );\n  }\n\n  public updateQuery<TData = any, TVariables = any>(\n    options: Cache.UpdateQueryOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readQuery<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeQuery<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n\n  public updateFragment<TData = any, TVariables = any>(\n    options: Cache.UpdateFragmentOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readFragment<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeFragment<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n}\n","import type { DocumentNode, FieldNode } from \"graphql\";\n\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n  isReference,\n  AsStoreObject,\n} from \"../../../utilities/index.js\";\n\nimport type { StorageType } from \"../../inmemory/policies.js\";\n\n// The Readonly<T> type only really works for object types, since it marks\n// all of the object's properties as readonly, but there are many cases when\n// a generic type parameter like TExisting might be a string or some other\n// primitive type, in which case we need to avoid wrapping it with Readonly.\n// SafeReadonly<string> collapses to just string, which makes string\n// assignable to SafeReadonly<any>, whereas string is not assignable to\n// Readonly<any>, somewhat surprisingly.\nexport type SafeReadonly<T> = T extends object ? Readonly<T> : T;\n\nexport type MissingTree =\n  | string\n  | {\n      readonly [key: string]: MissingTree;\n    };\n\nexport class MissingFieldError extends Error {\n  constructor(\n    public readonly message: string,\n    public readonly path: MissingTree | Array<string | number>,\n    public readonly query: DocumentNode,\n    public readonly variables?: Record<string, any>\n  ) {\n    // 'Error' breaks prototype chain here\n    super(message);\n\n    if (Array.isArray(this.path)) {\n      this.missing = this.message;\n      for (let i = this.path.length - 1; i >= 0; --i) {\n        this.missing = { [this.path[i]]: this.missing };\n      }\n    } else {\n      this.missing = this.path;\n    }\n\n    // We're not using `Object.setPrototypeOf` here as it isn't fully supported\n    // on Android (see issue #3236).\n    (this as any).__proto__ = MissingFieldError.prototype;\n  }\n\n  public readonly missing: MissingTree;\n}\n\nexport interface FieldSpecifier {\n  typename?: string;\n  fieldName: string;\n  field?: FieldNode;\n  args?: Record<string, any>;\n  variables?: Record<string, any>;\n}\n\nexport interface ReadFieldOptions extends FieldSpecifier {\n  from?: StoreObject | Reference;\n}\n\nexport interface ReadFieldFunction {\n  <V = StoreValue>(options: ReadFieldOptions): SafeReadonly<V> | undefined;\n  <V = StoreValue>(\n    fieldName: string,\n    from?: StoreObject | Reference\n  ): SafeReadonly<V> | undefined;\n}\n\nexport type ToReferenceFunction = (\n  objOrIdOrRef: StoreObject | string | Reference,\n  mergeIntoStore?: boolean\n) => Reference | undefined;\n\nexport type CanReadFunction = (value: StoreValue) => boolean;\n\ndeclare const _deleteModifier: unique symbol;\nexport interface DeleteModifier {\n  [_deleteModifier]: true;\n}\ndeclare const _invalidateModifier: unique symbol;\nexport interface InvalidateModifier {\n  [_invalidateModifier]: true;\n}\n\nexport type ModifierDetails = {\n  DELETE: DeleteModifier;\n  INVALIDATE: InvalidateModifier;\n  fieldName: string;\n  storeFieldName: string;\n  readField: ReadFieldFunction;\n  canRead: CanReadFunction;\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n  storage: StorageType;\n};\n\nexport type Modifier<T> = (\n  value: T,\n  details: ModifierDetails\n) => T | DeleteModifier | InvalidateModifier;\n\ntype StoreObjectValueMaybeReference<StoreVal> =\n  StoreVal extends Array<Record<string, any>> ?\n    StoreVal extends Array<infer Item> ?\n      Item extends Record<string, any> ?\n        ReadonlyArray<AsStoreObject<Item> | Reference>\n      : never\n    : never\n  : StoreVal extends Record<string, any> ? AsStoreObject<StoreVal> | Reference\n  : StoreVal;\n\nexport type AllFieldsModifier<Entity extends Record<string, any>> = Modifier<\n  Entity[keyof Entity] extends infer Value ?\n    StoreObjectValueMaybeReference<Exclude<Value, undefined>>\n  : never\n>;\n\nexport type Modifiers<T extends Record<string, any> = Record<string, unknown>> =\n  Partial<{\n    [FieldName in keyof T]: Modifier<\n      StoreObjectValueMaybeReference<Exclude<T[FieldName], undefined>>\n    >;\n  }>;\n","import { invariant } from \"../../utilities/globals/index.js\";\nimport type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\n\nimport type {\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  isReference,\n  makeReference,\n  DeepMerger,\n  maybeDeepFreeze,\n  canUseWeakMap,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\nimport type { NormalizedCache, NormalizedCacheObject } from \"./types.js\";\nimport { hasOwn, fieldNameFromStoreName } from \"./helpers.js\";\nimport type { Policies, StorageType } from \"./policies.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  SafeReadonly,\n  Modifier,\n  Modifiers,\n  ReadFieldOptions,\n  ToReferenceFunction,\n  CanReadFunction,\n  InvalidateModifier,\n  DeleteModifier,\n  ModifierDetails,\n} from \"../core/types/common.js\";\n\nconst DELETE: DeleteModifier = Object.create(null);\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE: InvalidateModifier = Object.create(null);\n\nexport abstract class EntityStore implements NormalizedCache {\n  protected data: NormalizedCacheObject = Object.create(null);\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (\n      fieldName === \"__typename\" &&\n      hasOwn.call(this.policies.rootTypenamesById, dataId)\n    ) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(\n    dataId: string,\n    dependOnExistence?: boolean\n  ): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  }\n\n  public merge(older: string | StoreObject, newer: StoreObject | string): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\" ? this.lookup((dataId = older)) : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\" ? this.lookup((dataId = newer)) : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(typeof dataId === \"string\", \"store.merge expects a string ID\");\n\n    const merged: StoreObject = new DeepMerger(storeObjectReconciler).merge(\n      existing,\n      incoming\n    );\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = Object.create(null);\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach((storeFieldName) => {\n          if (\n            !existing ||\n            existing[storeFieldName] !== merged[storeFieldName]\n          ) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (\n              fieldName !== storeFieldName &&\n              !this.policies.hasKeyArgs(merged.__typename, fieldName)\n            ) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (\n          fieldsToDirty.__typename &&\n          !(existing && existing.__typename) &&\n          // Since we return default root __typename strings\n          // automatically from store.get, we don't need to dirty the\n          // ROOT_QUERY.__typename field if merged.__typename is equal\n          // to the default string (usually \"Query\").\n          this.policies.rootTypenamesById[dataId] === merged.__typename\n        ) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach((fieldName) =>\n          this.group.dirty(dataId as string, fieldName)\n        );\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers<Record<string, any>>\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = Object.create(null);\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference\n        ) =>\n          this.policies.readField<V>(\n            typeof fieldNameOrOptions === \"string\" ?\n              {\n                fieldName: fieldNameOrOptions,\n                from: from || makeReference(dataId),\n              }\n            : fieldNameOrOptions,\n            { store: this }\n          ),\n      } satisfies Partial<ModifierDetails>;\n\n      Object.keys(storeObject).forEach((storeFieldName) => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> | undefined =\n          typeof fields === \"function\" ? fields : (\n            fields[storeFieldName] || fields[fieldName]\n          );\n        if (modify) {\n          let newValue =\n            modify === delModifier ? DELETE : (\n              modify(maybeDeepFreeze(fieldValue), {\n                ...sharedDetails,\n                fieldName,\n                storeFieldName,\n                storage: this.getStorage(dataId, storeFieldName),\n              })\n            );\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n\n              if (__DEV__) {\n                const checkReference = (ref: Reference) => {\n                  if (this.lookup(ref.__ref) === undefined) {\n                    invariant.warn(\n                      \"cache.modify: You are trying to write a Reference that is not part of the store: %o\\n\" +\n                        \"Please make sure to set the `mergeIntoStore` parameter to `true` when creating a Reference that is not part of the store yet:\\n\" +\n                        \"`toReference(object, true)`\",\n                      ref\n                    );\n                    return true;\n                  }\n                };\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  let seenReference: boolean = false;\n                  let someNonReference: unknown;\n                  for (const value of newValue) {\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        const [id] = this.policies.identify(value);\n                        // check if object could even be referenced, otherwise we are not interested in it for this warning\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n                    if (seenReference && someNonReference !== undefined) {\n                      invariant.warn(\n                        \"cache.modify: Writing an array with a mix of both References and Objects will not result in the Objects being normalized correctly.\\n\" +\n                          \"Please convert the object instance %o to a Reference before writing it to the cache by calling `toReference(object, true)`.\",\n                        someNonReference\n                      );\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName =\n        fieldName && args ?\n          this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(\n        dataId,\n        storeFieldName ?\n          {\n            [storeFieldName]: delModifier,\n          }\n        : delModifier\n      );\n    }\n    return false;\n  }\n\n  public evict(options: Cache.EvictOptions, limit: EntityStore): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach((id) => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach((dataId) => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach((dataId) => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = Object.create(null);\n\n  public retain(rootId: string): number {\n    return (this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1);\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach((id) => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach((id) => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = Object.create(null);\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = (this.refs[dataId] = Object.create(null));\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach((obj) => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach((key) => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string\n  ) =>\n    maybeDeepFreeze(\n      isReference(objectOrReference) ?\n        this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n    ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = (objOrRef) => {\n    return isReference(objOrRef) ?\n        this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (objOrIdOrRef, mergeIntoStore) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker!: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\"\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nexport namespace EntityStore {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  export class Root extends EntityStore {\n    constructor({\n      policies,\n      resultCaching = true,\n      seed,\n    }: {\n      policies: Policies;\n      resultCaching?: boolean;\n      seed?: NormalizedCacheObject;\n    }) {\n      super(policies, new CacheGroup(resultCaching));\n      if (seed) this.replace(seed);\n    }\n\n    public readonly stump = new Stump(this);\n\n    public addLayer(\n      layerId: string,\n      replay: (layer: EntityStore) => any\n    ): Layer {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    }\n\n    public removeLayer(): Root {\n      // Never remove the root layer.\n      return this;\n    }\n\n    public readonly storageTrie = new Trie<StorageType>(canUseWeakMap);\n    public getStorage(): StorageType {\n      return this.storageTrie.lookupArray(arguments);\n    }\n  }\n}\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(layerId: string, replay: (layer: EntityStore) => any): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach((dataId) => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach((storeFieldName) => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach((storeFieldName) => {\n              if (\n                !equal(\n                  ownStoreObject[storeFieldName],\n                  parentStoreObject[storeFieldName]\n                )\n              ) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ?\n        {\n          ...fromParent,\n          ...super.findChildRefIds(dataId),\n        }\n      : fromParent;\n  }\n\n  public getStorage(): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage.apply(\n      p,\n      // @ts-expect-error\n      arguments\n    );\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: EntityStore.Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group)\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge(older: string | StoreObject, newer: string | StoreObject) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string | number\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}\n","import type {\n  DocumentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n} from \"graphql\";\n\nimport type { NormalizedCache, InMemoryCacheConfig } from \"./types.js\";\n\nimport type { KeyFieldsContext } from \"./policies.js\";\nimport type { FragmentRegistryAPI } from \"./fragmentRegistry.js\";\n\nimport type {\n  Reference,\n  StoreValue,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction,\n} from \"../../utilities/index.js\";\nimport {\n  isReference,\n  isField,\n  DeepMerger,\n  resultKeyNameFromField,\n  shouldInclude,\n  isNonNullObject,\n  compact,\n  createFragmentMap,\n  getFragmentDefinitions,\n  isArray,\n} from \"../../utilities/index.js\";\n\nexport const { hasOwnProperty: hasOwn } = Object.prototype;\n\nexport function isNullish(value: any): value is null | undefined {\n  return value === null || value === void 0;\n}\n\nexport { isArray };\n\nexport function defaultDataIdFromObject(\n  { __typename, id, _id }: Readonly<StoreObject>,\n  context?: KeyFieldsContext\n): string | undefined {\n  if (typeof __typename === \"string\") {\n    if (context) {\n      context.keyObject =\n        !isNullish(id) ? { id }\n        : !isNullish(_id) ? { _id }\n        : void 0;\n    }\n\n    // If there is no object.id, fall back to object._id.\n    if (isNullish(id) && !isNullish(_id)) {\n      id = _id;\n    }\n\n    if (!isNullish(id)) {\n      return `${__typename}:${\n        typeof id === \"number\" || typeof id === \"string\" ?\n          id\n        : JSON.stringify(id)\n      }`;\n    }\n  }\n}\n\nconst defaultConfig = {\n  dataIdFromObject: defaultDataIdFromObject,\n  addTypename: true,\n  resultCaching: true,\n  // Thanks to the shouldCanonizeResults helper, this should be the only line\n  // you have to change to reenable canonization by default in the future.\n  canonizeResults: false,\n};\n\nexport function normalizeConfig(config: InMemoryCacheConfig) {\n  return compact(defaultConfig, config);\n}\n\nexport function shouldCanonizeResults(\n  config: Pick<InMemoryCacheConfig, \"canonizeResults\">\n): boolean {\n  const value = config.canonizeResults;\n  return value === void 0 ? defaultConfig.canonizeResults : value;\n}\n\nexport function getTypenameFromStoreObject(\n  store: NormalizedCache,\n  objectOrReference: StoreObject | Reference\n): string | undefined {\n  return isReference(objectOrReference) ?\n      (store.get(objectOrReference.__ref, \"__typename\") as string)\n    : objectOrReference && objectOrReference.__typename;\n}\n\nexport const TypeOrFieldNameRegExp = /^[_a-z][_0-9a-z]*/i;\n\nexport function fieldNameFromStoreName(storeFieldName: string): string {\n  const match = storeFieldName.match(TypeOrFieldNameRegExp);\n  return match ? match[0] : storeFieldName;\n}\n\nexport function selectionSetMatchesResult(\n  selectionSet: SelectionSetNode,\n  result: Record<string, any>,\n  variables?: Record<string, any>\n): boolean {\n  if (isNonNullObject(result)) {\n    return isArray(result) ?\n        result.every((item) =>\n          selectionSetMatchesResult(selectionSet, item, variables)\n        )\n      : selectionSet.selections.every((field) => {\n          if (isField(field) && shouldInclude(field, variables)) {\n            const key = resultKeyNameFromField(field);\n            return (\n              hasOwn.call(result, key) &&\n              (!field.selectionSet ||\n                selectionSetMatchesResult(\n                  field.selectionSet,\n                  result[key],\n                  variables\n                ))\n            );\n          }\n          // If the selection has been skipped with @skip(true) or\n          // @include(false), it should not count against the matching. If\n          // the selection is not a field, it must be a fragment (inline or\n          // named). We will determine if selectionSetMatchesResult for that\n          // fragment when we get to it, so for now we return true.\n          return true;\n        });\n  }\n  return false;\n}\n\nexport function storeValueIsStoreObject(\n  value: StoreValue\n): value is StoreObject {\n  return isNonNullObject(value) && !isReference(value) && !isArray(value);\n}\n\nexport function makeProcessedFieldsMerger() {\n  return new DeepMerger();\n}\n\nexport function extractFragmentContext(\n  document: DocumentNode,\n  fragments?: FragmentRegistryAPI\n): {\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n} {\n  // FragmentMap consisting only of fragments defined directly in document, not\n  // including other fragments registered in the FragmentRegistry.\n  const fragmentMap = createFragmentMap(getFragmentDefinitions(document));\n  return {\n    fragmentMap,\n    lookupFragment(name) {\n      let def: FragmentDefinitionNode | null = fragmentMap[name];\n      if (!def && fragments) {\n        def = fragments.lookup(name);\n      }\n      return def || null;\n    },\n  };\n}\n","import { invariant } from \"../../utilities/globals/index.js\";\n\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport \"./fixPolyfills.js\";\n\nimport type { DocumentNode } from \"graphql\";\nimport type { OptimisticWrapperFunction } from \"optimism\";\nimport { wrap } from \"optimism\";\nimport { equal } from \"@wry/equality\";\n\nimport { ApolloCache } from \"../core/cache.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport type { StoreObject, Reference } from \"../../utilities/index.js\";\nimport {\n  addTypenameToDocument,\n  isReference,\n  DocumentTransform,\n} from \"../../utilities/index.js\";\nimport type { InMemoryCacheConfig, NormalizedCacheObject } from \"./types.js\";\nimport { StoreReader } from \"./readFromStore.js\";\nimport { StoreWriter } from \"./writeToStore.js\";\nimport { EntityStore, supportsResultCaching } from \"./entityStore.js\";\nimport { makeVar, forgetCache, recallCache } from \"./reactiveVars.js\";\nimport { Policies } from \"./policies.js\";\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \"./helpers.js\";\nimport { canonicalStringify } from \"./object-canon.js\";\nimport type { OperationVariables } from \"../../core/index.js\";\n\ntype BroadcastOptions = Pick<\n  Cache.BatchOptions<InMemoryCache>,\n  \"optimistic\" | \"onWatchUpdated\"\n>;\n\nexport class InMemoryCache extends ApolloCache<NormalizedCacheObject> {\n  private data!: EntityStore;\n  private optimisticData!: EntityStore;\n\n  protected config: InMemoryCacheConfig;\n  private watches = new Set<Cache.WatchOptions>();\n  private addTypename: boolean;\n\n  private storeReader!: StoreReader;\n  private storeWriter!: StoreWriter;\n  private addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n\n  private maybeBroadcastWatch!: OptimisticWrapperFunction<\n    [Cache.WatchOptions, BroadcastOptions?],\n    any,\n    [Cache.WatchOptions]\n  >;\n\n  // Override the default value, since InMemoryCache result objects are frozen\n  // in development and expected to remain logically immutable in production.\n  public readonly assumeImmutableResults = true;\n\n  // Dynamically imported code can augment existing typePolicies or\n  // possibleTypes by calling cache.policies.addTypePolicies or\n  // cache.policies.addPossibletypes.\n  public readonly policies: Policies;\n\n  public readonly makeVar = makeVar;\n\n  constructor(config: InMemoryCacheConfig = {}) {\n    super();\n    this.config = normalizeConfig(config);\n    this.addTypename = !!this.config.addTypename;\n\n    this.policies = new Policies({\n      cache: this,\n      dataIdFromObject: this.config.dataIdFromObject,\n      possibleTypes: this.config.possibleTypes,\n      typePolicies: this.config.typePolicies,\n    });\n\n    this.init();\n  }\n\n  private init() {\n    // Passing { resultCaching: false } in the InMemoryCache constructor options\n    // will completely disable dependency tracking, which will improve memory\n    // usage but worsen the performance of repeated reads.\n    const rootStore = (this.data = new EntityStore.Root({\n      policies: this.policies,\n      resultCaching: this.config.resultCaching,\n    }));\n\n    // When no optimistic writes are currently active, cache.optimisticData ===\n    // cache.data, so there are no additional layers on top of the actual data.\n    // When an optimistic update happens, this.optimisticData will become a\n    // linked list of EntityStore Layer objects that terminates with the\n    // original this.data cache object.\n    this.optimisticData = rootStore.stump;\n\n    this.resetResultCache();\n  }\n\n  private resetResultCache(resetResultIdentities?: boolean) {\n    const previousReader = this.storeReader;\n    const { fragments } = this.config;\n\n    // The StoreWriter is mostly stateless and so doesn't really need to be\n    // reset, but it does need to have its writer.storeReader reference updated,\n    // so it's simpler to update this.storeWriter as well.\n    this.storeWriter = new StoreWriter(\n      this,\n      (this.storeReader = new StoreReader({\n        cache: this,\n        addTypename: this.addTypename,\n        resultCacheMaxSize: this.config.resultCacheMaxSize,\n        canonizeResults: shouldCanonizeResults(this.config),\n        canon:\n          resetResultIdentities ? void 0 : (\n            previousReader && previousReader.canon\n          ),\n        fragments,\n      })),\n      fragments\n    );\n\n    this.maybeBroadcastWatch = wrap(\n      (c: Cache.WatchOptions, options?: BroadcastOptions) => {\n        return this.broadcastWatch(c, options);\n      },\n      {\n        max: this.config.resultCacheMaxSize,\n        makeCacheKey: (c: Cache.WatchOptions) => {\n          // Return a cache key (thus enabling result caching) only if we're\n          // currently using a data store that can track cache dependencies.\n          const store = c.optimistic ? this.optimisticData : this.data;\n          if (supportsResultCaching(store)) {\n            const { optimistic, id, variables } = c;\n            return store.makeCacheKey(\n              c.query,\n              // Different watches can have the same query, optimistic\n              // status, rootId, and variables, but if their callbacks are\n              // different, the (identical) result needs to be delivered to\n              // each distinct callback. The easiest way to achieve that\n              // separation is to include c.callback in the cache key for\n              // maybeBroadcastWatch calls. See issue #5733.\n              c.callback,\n              canonicalStringify({ optimistic, id, variables })\n            );\n          }\n        },\n      }\n    );\n\n    // Since we have thrown away all the cached functions that depend on the\n    // CacheGroup dependencies maintained by EntityStore, we should also reset\n    // all CacheGroup dependency information.\n    new Set([this.data.group, this.optimisticData.group]).forEach((group) =>\n      group.resetCaching()\n    );\n  }\n\n  public restore(data: NormalizedCacheObject): this {\n    this.init();\n    // Since calling this.init() discards/replaces the entire StoreReader, along\n    // with the result caches it maintains, this.data.replace(data) won't have\n    // to bother deleting the old data.\n    if (data) this.data.replace(data);\n    return this;\n  }\n\n  public extract(optimistic: boolean = false): NormalizedCacheObject {\n    return (optimistic ? this.optimisticData : this.data).extract();\n  }\n\n  public read<T>(options: Cache.ReadOptions): T | null {\n    const {\n      // Since read returns data or null, without any additional metadata\n      // about whether/where there might have been missing fields, the\n      // default behavior cannot be returnPartialData = true (like it is\n      // for the diff method), since defaulting to true would violate the\n      // integrity of the T in the return type. However, partial data may\n      // be useful in some cases, so returnPartialData:true may be\n      // specified explicitly.\n      returnPartialData = false,\n    } = options;\n    try {\n      return (\n        this.storeReader.diffQueryAgainstStore<T>({\n          ...options,\n          store: options.optimistic ? this.optimisticData : this.data,\n          config: this.config,\n          returnPartialData,\n        }).result || null\n      );\n    } catch (e) {\n      if (e instanceof MissingFieldError) {\n        // Swallow MissingFieldError and return null, so callers do not need to\n        // worry about catching \"normal\" exceptions resulting from incomplete\n        // cache data. Unexpected errors will be re-thrown. If you need more\n        // information about which fields were missing, use cache.diff instead,\n        // and examine diffResult.missing.\n        return null;\n      }\n      throw e;\n    }\n  }\n\n  public write(options: Cache.WriteOptions): Reference | undefined {\n    try {\n      ++this.txCount;\n      return this.storeWriter.writeToStore(this.data, options);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(\n    options: Cache.ModifyOptions<Entity>\n  ): boolean {\n    if (hasOwn.call(options, \"id\") && !options.id) {\n      // To my knowledge, TypeScript does not currently provide a way to\n      // enforce that an optional property?:type must *not* be undefined\n      // when present. That ability would be useful here, because we want\n      // options.id to default to ROOT_QUERY only when no options.id was\n      // provided. If the caller attempts to pass options.id with a\n      // falsy/undefined value (perhaps because cache.identify failed), we\n      // should not assume the goal was to modify the ROOT_QUERY object.\n      // We could throw, but it seems natural to return false to indicate\n      // that nothing was modified.\n      return false;\n    }\n    const store =\n      (\n        options.optimistic // Defaults to false.\n      ) ?\n        this.optimisticData\n      : this.data;\n    try {\n      ++this.txCount;\n      return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public diff<TData, TVariables extends OperationVariables = any>(\n    options: Cache.DiffOptions<TData, TVariables>\n  ): Cache.DiffResult<TData> {\n    return this.storeReader.diffQueryAgainstStore({\n      ...options,\n      store: options.optimistic ? this.optimisticData : this.data,\n      rootId: options.id || \"ROOT_QUERY\",\n      config: this.config,\n    });\n  }\n\n  public watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>\n  ): () => void {\n    if (!this.watches.size) {\n      // In case we previously called forgetCache(this) because\n      // this.watches became empty (see below), reattach this cache to any\n      // reactive variables on which it previously depended. It might seem\n      // paradoxical that we're able to recall something we supposedly\n      // forgot, but the point of calling forgetCache(this) is to silence\n      // useless broadcasts while this.watches is empty, and to allow the\n      // cache to be garbage collected. If, however, we manage to call\n      // recallCache(this) here, this cache object must not have been\n      // garbage collected yet, and should resume receiving updates from\n      // reactive variables, now that it has a watcher to notify.\n      recallCache(this);\n    }\n    this.watches.add(watch);\n    if (watch.immediate) {\n      this.maybeBroadcastWatch(watch);\n    }\n    return () => {\n      // Once we remove the last watch from this.watches, cache.broadcastWatches\n      // no longer does anything, so we preemptively tell the reactive variable\n      // system to exclude this cache from future broadcasts.\n      if (this.watches.delete(watch) && !this.watches.size) {\n        forgetCache(this);\n      }\n      // Remove this watch from the LRU cache managed by the\n      // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n      // leaks involving the closure of watch.callback.\n      this.maybeBroadcastWatch.forget(watch);\n    };\n  }\n\n  public gc(options?: {\n    // If true, also free non-essential result cache memory by bulk-releasing\n    // this.{store{Reader,Writer},maybeBroadcastWatch}. Defaults to false.\n    resetResultCache?: boolean;\n    // If resetResultCache is true, this.storeReader.canon will be preserved by\n    // default, but can also be discarded by passing resetResultIdentities:true.\n    // Defaults to false.\n    resetResultIdentities?: boolean;\n  }) {\n    canonicalStringify.reset();\n    const ids = this.optimisticData.gc();\n    if (options && !this.txCount) {\n      if (options.resetResultCache) {\n        this.resetResultCache(options.resetResultIdentities);\n      } else if (options.resetResultIdentities) {\n        this.storeReader.resetCanon();\n      }\n    }\n    return ids;\n  }\n\n  // Call this method to ensure the given root ID remains in the cache after\n  // garbage collection, along with its transitive child entities. Note that\n  // the cache automatically retains all directly written entities. By default,\n  // the retainment persists after optimistic updates are removed. Pass true\n  // for the optimistic argument if you would prefer for the retainment to be\n  // discarded when the top-most optimistic layer is removed. Returns the\n  // resulting (non-negative) retainment count.\n  public retain(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).retain(rootId);\n  }\n\n  // Call this method to undo the effect of the retain method, above. Once the\n  // retainment count falls to zero, the given ID will no longer be preserved\n  // during garbage collection, though it may still be preserved by other safe\n  // entities that refer to it. Returns the resulting (non-negative) retainment\n  // count, in case that's useful.\n  public release(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).release(rootId);\n  }\n\n  // Returns the canonical ID for a given StoreObject, obeying typePolicies\n  // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n  // the object must contain a __typename and any primary key fields required\n  // to identify entities of that type. If you pass a query result object, be\n  // sure that none of the primary key fields have been renamed by aliasing.\n  // If you pass a Reference object, its __ref ID string will be returned.\n  public identify(object: StoreObject | Reference): string | undefined {\n    if (isReference(object)) return object.__ref;\n    try {\n      return this.policies.identify(object)[0];\n    } catch (e) {\n      invariant.warn(e);\n    }\n  }\n\n  public evict(options: Cache.EvictOptions): boolean {\n    if (!options.id) {\n      if (hasOwn.call(options, \"id\")) {\n        // See comment in modify method about why we return false when\n        // options.id exists but is falsy/undefined.\n        return false;\n      }\n      options = { ...options, id: \"ROOT_QUERY\" };\n    }\n    try {\n      // It's unlikely that the eviction will end up invoking any other\n      // cache update operations while it's running, but {in,de}crementing\n      // this.txCount still seems like a good idea, for uniformity with\n      // the other update methods.\n      ++this.txCount;\n      // Pass this.data as a limit on the depth of the eviction, so evictions\n      // during optimistic updates (when this.data is temporarily set equal to\n      // this.optimisticData) do not escape their optimistic Layer.\n      return this.optimisticData.evict(options, this.data);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public reset(options?: Cache.ResetOptions): Promise<void> {\n    this.init();\n\n    canonicalStringify.reset();\n\n    if (options && options.discardWatches) {\n      // Similar to what happens in the unsubscribe function returned by\n      // cache.watch, applied to all current watches.\n      this.watches.forEach((watch) => this.maybeBroadcastWatch.forget(watch));\n      this.watches.clear();\n      forgetCache(this);\n    } else {\n      // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n      // this.broadcastWatches() triggers a broadcast to every current watcher\n      // (letting them know their data is now missing). This default behavior is\n      // convenient because it means the watches do not have to be manually\n      // reestablished after resetting the cache. To prevent this broadcast and\n      // cancel all watches, pass true for options.discardWatches.\n      this.broadcastWatches();\n    }\n\n    return Promise.resolve();\n  }\n\n  public removeOptimistic(idToRemove: string) {\n    const newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n    if (newOptimisticData !== this.optimisticData) {\n      this.optimisticData = newOptimisticData;\n      this.broadcastWatches();\n    }\n  }\n\n  private txCount = 0;\n\n  public batch<TUpdateResult>(\n    options: Cache.BatchOptions<InMemoryCache, TUpdateResult>\n  ): TUpdateResult {\n    const {\n      update,\n      optimistic = true,\n      removeOptimistic,\n      onWatchUpdated,\n    } = options;\n\n    let updateResult: TUpdateResult;\n    const perform = (layer?: EntityStore): TUpdateResult => {\n      const { data, optimisticData } = this;\n      ++this.txCount;\n      if (layer) {\n        this.data = this.optimisticData = layer;\n      }\n      try {\n        return (updateResult = update(this));\n      } finally {\n        --this.txCount;\n        this.data = data;\n        this.optimisticData = optimisticData;\n      }\n    };\n\n    const alreadyDirty = new Set<Cache.WatchOptions>();\n\n    if (onWatchUpdated && !this.txCount) {\n      // If an options.onWatchUpdated callback is provided, we want to call it\n      // with only the Cache.WatchOptions objects affected by options.update,\n      // but there might be dirty watchers already waiting to be broadcast that\n      // have nothing to do with the update. To prevent including those watchers\n      // in the post-update broadcast, we perform this initial broadcast to\n      // collect the dirty watchers, so we can re-dirty them later, after the\n      // post-update broadcast, allowing them to receive their pending\n      // broadcasts the next time broadcastWatches is called, just as they would\n      // if we never called cache.batch.\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch) {\n          alreadyDirty.add(watch);\n          return false;\n        },\n      });\n    }\n\n    if (typeof optimistic === \"string\") {\n      // Note that there can be multiple layers with the same optimistic ID.\n      // When removeOptimistic(id) is called for that id, all matching layers\n      // will be removed, and the remaining layers will be reapplied.\n      this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n    } else if (optimistic === false) {\n      // Ensure both this.data and this.optimisticData refer to the root\n      // (non-optimistic) layer of the cache during the update. Note that\n      // this.data could be a Layer if we are currently executing an optimistic\n      // update function, but otherwise will always be an EntityStore.Root\n      // instance.\n      perform(this.data);\n    } else {\n      // Otherwise, leave this.data and this.optimisticData unchanged and run\n      // the update with broadcast batching.\n      perform();\n    }\n\n    if (typeof removeOptimistic === \"string\") {\n      this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n    }\n\n    // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n    // takes the else branch and calls this.broadcastWatches(options), which\n    // does nothing when this.txCount > 0.\n    if (onWatchUpdated && alreadyDirty.size) {\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch, diff) {\n          const result = onWatchUpdated.call(this, watch, diff);\n          if (result !== false) {\n            // Since onWatchUpdated did not return false, this diff is\n            // about to be broadcast to watch.callback, so we don't need\n            // to re-dirty it with the other alreadyDirty watches below.\n            alreadyDirty.delete(watch);\n          }\n          return result;\n        },\n      });\n      // Silently re-dirty any watches that were already dirty before the update\n      // was performed, and were not broadcast just now.\n      if (alreadyDirty.size) {\n        alreadyDirty.forEach((watch) => this.maybeBroadcastWatch.dirty(watch));\n      }\n    } else {\n      // If alreadyDirty is empty or we don't have an onWatchUpdated\n      // function, we don't need to go to the trouble of wrapping\n      // options.onWatchUpdated.\n      this.broadcastWatches(options);\n    }\n\n    return updateResult!;\n  }\n\n  public performTransaction(\n    update: (cache: InMemoryCache) => any,\n    optimisticId?: string | null\n  ) {\n    return this.batch({\n      update,\n      optimistic: optimisticId || optimisticId !== null,\n    });\n  }\n\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n  }\n\n  protected broadcastWatches(options?: BroadcastOptions) {\n    if (!this.txCount) {\n      this.watches.forEach((c) => this.maybeBroadcastWatch(c, options));\n    }\n  }\n\n  private addFragmentsToDocument(document: DocumentNode) {\n    const { fragments } = this.config;\n    return fragments ? fragments.transform(document) : document;\n  }\n\n  private addTypenameToDocument(document: DocumentNode) {\n    if (this.addTypename) {\n      return this.addTypenameTransform.transformDocument(document);\n    }\n    return document;\n  }\n\n  // This method is wrapped by maybeBroadcastWatch, which is called by\n  // broadcastWatches, so that we compute and broadcast results only when\n  // the data that would be broadcast might have changed. It would be\n  // simpler to check for changes after recomputing a result but before\n  // broadcasting it, but this wrapping approach allows us to skip both\n  // the recomputation and the broadcast, in most cases.\n  private broadcastWatch(c: Cache.WatchOptions, options?: BroadcastOptions) {\n    const { lastDiff } = c;\n\n    // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n    // currently requires no additional properties, so we can use c (a\n    // WatchOptions object) as DiffOptions, without having to allocate a new\n    // object, and without having to enumerate the relevant properties (query,\n    // variables, etc.) explicitly. There will be some additional properties\n    // (lastDiff, callback, etc.), but cache.diff ignores them.\n    const diff = this.diff<any>(c);\n\n    if (options) {\n      if (c.optimistic && typeof options.optimistic === \"string\") {\n        diff.fromOptimisticTransaction = true;\n      }\n\n      if (\n        options.onWatchUpdated &&\n        options.onWatchUpdated.call(this, c, diff, lastDiff) === false\n      ) {\n        // Returning false from the onWatchUpdated callback will prevent\n        // calling c.callback(diff) for this watcher.\n        return;\n      }\n    }\n\n    if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n      c.callback((c.lastDiff = diff), lastDiff);\n    }\n  }\n}\n","import { invariant } from \"../../utilities/globals/index.js\";\n\nimport {\n  argumentsObjectFromField,\n  DeepMerger,\n  isNonEmptyArray,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\n\nimport { hasOwn, isArray } from \"./helpers.js\";\nimport type {\n  KeySpecifier,\n  KeyFieldsFunction,\n  KeyArgsFunction,\n} from \"./policies.js\";\n\n// Mapping from JSON-encoded KeySpecifier strings to associated information.\nconst specifierInfoCache: Record<\n  string,\n  {\n    paths?: string[][];\n    keyFieldsFn?: KeyFieldsFunction;\n    keyArgsFn?: KeyArgsFunction;\n  }\n> = Object.create(null);\n\nfunction lookupSpecifierInfo(spec: KeySpecifier) {\n  // It's safe to encode KeySpecifier arrays with JSON.stringify, since they're\n  // just arrays of strings or nested KeySpecifier arrays, and the order of the\n  // array elements is important (and suitably preserved by JSON.stringify).\n  const cacheKey = JSON.stringify(spec);\n  return (\n    specifierInfoCache[cacheKey] ||\n    (specifierInfoCache[cacheKey] = Object.create(null))\n  );\n}\n\nexport function keyFieldsFnFromSpecifier(\n  specifier: KeySpecifier\n): KeyFieldsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return (\n    info.keyFieldsFn ||\n    (info.keyFieldsFn = (object, context) => {\n      const extract: typeof extractKey = (from, key) =>\n        context.readField(key, from);\n\n      const keyObject = (context.keyObject = collectSpecifierPaths(\n        specifier,\n        (schemaKeyPath) => {\n          let extracted = extractKeyPath(\n            context.storeObject,\n            schemaKeyPath,\n            // Using context.readField to extract paths from context.storeObject\n            // allows the extraction to see through Reference objects and respect\n            // custom read functions.\n            extract\n          );\n\n          if (\n            extracted === void 0 &&\n            object !== context.storeObject &&\n            hasOwn.call(object, schemaKeyPath[0])\n          ) {\n            // If context.storeObject fails to provide a value for the requested\n            // path, fall back to the raw result object, if it has a top-level key\n            // matching the first key in the path (schemaKeyPath[0]). This allows\n            // key fields included in the written data to be saved in the cache\n            // even if they are not selected explicitly in context.selectionSet.\n            // Not being mentioned by context.selectionSet is convenient here,\n            // since it means these extra fields cannot be affected by field\n            // aliasing, which is why we can use extractKey instead of\n            // context.readField for this extraction.\n            extracted = extractKeyPath(object, schemaKeyPath, extractKey);\n          }\n\n          invariant(\n            extracted !== void 0,\n            `Missing field '%s' while extracting keyFields from %s`,\n            schemaKeyPath.join(\".\"),\n            object\n          );\n\n          return extracted;\n        }\n      ));\n\n      return `${context.typename}:${JSON.stringify(keyObject)}`;\n    })\n  );\n}\n\n// The keyArgs extraction process is roughly analogous to keyFields extraction,\n// but there are no aliases involved, missing fields are tolerated (by merely\n// omitting them from the key), and drawing from field.directives or variables\n// is allowed (in addition to drawing from the field's arguments object).\n// Concretely, these differences mean passing a different key path extractor\n// function to collectSpecifierPaths, reusing the shared extractKeyPath helper\n// wherever possible.\nexport function keyArgsFnFromSpecifier(\n  specifier: KeySpecifier\n): KeyArgsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return (\n    info.keyArgsFn ||\n    (info.keyArgsFn = (args, { field, variables, fieldName }) => {\n      const collected = collectSpecifierPaths(specifier, (keyPath) => {\n        const firstKey = keyPath[0];\n        const firstChar = firstKey.charAt(0);\n\n        if (firstChar === \"@\") {\n          if (field && isNonEmptyArray(field.directives)) {\n            const directiveName = firstKey.slice(1);\n            // If the directive appears multiple times, only the first\n            // occurrence's arguments will be used. TODO Allow repetition?\n            // TODO Cache this work somehow, a la aliasMap?\n            const d = field.directives.find(\n              (d) => d.name.value === directiveName\n            );\n            // Fortunately argumentsObjectFromField works for DirectiveNode!\n            const directiveArgs = d && argumentsObjectFromField(d, variables);\n            // For directives without arguments (d defined, but directiveArgs ===\n            // null), the presence or absence of the directive still counts as\n            // part of the field key, so we return null in those cases. If no\n            // directive with this name was found for this field (d undefined and\n            // thus directiveArgs undefined), we return undefined, which causes\n            // this value to be omitted from the key object returned by\n            // collectSpecifierPaths.\n            return (\n              directiveArgs &&\n              extractKeyPath(\n                directiveArgs,\n                // If keyPath.length === 1, this code calls extractKeyPath with an\n                // empty path, which works because it uses directiveArgs as the\n                // extracted value.\n                keyPath.slice(1)\n              )\n            );\n          }\n          // If the key started with @ but there was no corresponding directive,\n          // we want to omit this value from the key object, not fall through to\n          // treating @whatever as a normal argument name.\n          return;\n        }\n\n        if (firstChar === \"$\") {\n          const variableName = firstKey.slice(1);\n          if (variables && hasOwn.call(variables, variableName)) {\n            const varKeyPath = keyPath.slice(0);\n            varKeyPath[0] = variableName;\n            return extractKeyPath(variables, varKeyPath);\n          }\n          // If the key started with $ but there was no corresponding variable, we\n          // want to omit this value from the key object, not fall through to\n          // treating $whatever as a normal argument name.\n          return;\n        }\n\n        if (args) {\n          return extractKeyPath(args, keyPath);\n        }\n      });\n\n      const suffix = JSON.stringify(collected);\n\n      // If no arguments were passed to this field, and it didn't have any other\n      // field key contributions from directives or variables, hide the empty\n      // :{} suffix from the field key. However, a field passed no arguments can\n      // still end up with a non-empty :{...} suffix if its key configuration\n      // refers to directives or variables.\n      if (args || suffix !== \"{}\") {\n        fieldName += \":\" + suffix;\n      }\n\n      return fieldName;\n    })\n  );\n}\n\nexport function collectSpecifierPaths(\n  specifier: KeySpecifier,\n  extractor: (path: string[]) => any\n): Record<string, any> {\n  // For each path specified by specifier, invoke the extractor, and repeatedly\n  // merge the results together, with appropriate ancestor context.\n  const merger = new DeepMerger();\n  return getSpecifierPaths(specifier).reduce((collected, path) => {\n    let toMerge = extractor(path);\n    if (toMerge !== void 0) {\n      // This path is not expected to contain array indexes, so the toMerge\n      // reconstruction will not contain arrays. TODO Fix this?\n      for (let i = path.length - 1; i >= 0; --i) {\n        toMerge = { [path[i]]: toMerge };\n      }\n      collected = merger.merge(collected, toMerge);\n    }\n    return collected;\n  }, Object.create(null));\n}\n\nexport function getSpecifierPaths(spec: KeySpecifier): string[][] {\n  const info = lookupSpecifierInfo(spec);\n\n  if (!info.paths) {\n    const paths: string[][] = (info.paths = []);\n    const currentPath: string[] = [];\n\n    spec.forEach((s, i) => {\n      if (isArray(s)) {\n        getSpecifierPaths(s).forEach((p) => paths.push(currentPath.concat(p)));\n        currentPath.length = 0;\n      } else {\n        currentPath.push(s);\n        if (!isArray(spec[i + 1])) {\n          paths.push(currentPath.slice(0));\n          currentPath.length = 0;\n        }\n      }\n    });\n  }\n\n  return info.paths!;\n}\n\nfunction extractKey<TObj extends Record<string, any>, TKey extends string>(\n  object: TObj,\n  key: TKey\n): TObj[TKey] | undefined {\n  return object[key];\n}\n\nexport function extractKeyPath(\n  object: Record<string, any>,\n  path: string[],\n  extract?: typeof extractKey\n): any {\n  // For each key in path, extract the corresponding child property from obj,\n  // flattening arrays if encountered (uncommon for keyFields and keyArgs, but\n  // possible). The final result of path.reduce is normalized so unexpected leaf\n  // objects have their keys safely sorted. That final result is difficult to\n  // type as anything other than any. You're welcome to try to improve the\n  // return type, but keep in mind extractKeyPath is not a public function\n  // (exported only for testing), so the effort may not be worthwhile unless the\n  // limited set of actual callers (see above) pass arguments that TypeScript\n  // can statically type. If we know only that path is some array of strings\n  // (and not, say, a specific tuple of statically known strings), any (or\n  // possibly unknown) is the honest answer.\n  extract = extract || extractKey;\n  return normalize(\n    path.reduce(function reducer(obj, key): any {\n      return isArray(obj) ?\n          obj.map((child) => reducer(child, key))\n        : obj && extract!(obj, key);\n    }, object)\n  );\n}\n\nfunction normalize<T>(value: T): T {\n  // Usually the extracted value will be a scalar value, since most primary\n  // key fields are scalar, but just in case we get an object or an array, we\n  // need to do some normalization of the order of (nested) keys.\n  if (isNonNullObject(value)) {\n    if (isArray(value)) {\n      return value.map(normalize) as any;\n    }\n    return collectSpecifierPaths(Object.keys(value).sort(), (path) =>\n      extractKeyPath(value, path)\n    ) as T;\n  }\n  return value;\n}\n","import { Trie } from \"@wry/trie\";\nimport {\n  canUseWeakMap,\n  canUseWeakSet,\n  isNonNullObject as isObjectOrArray,\n} from \"../../utilities/index.js\";\nimport { isArray } from \"./helpers.js\";\n\nfunction shallowCopy<T>(value: T): T {\n  if (isObjectOrArray(value)) {\n    return isArray(value) ?\n        (value.slice(0) as any as T)\n      : { __proto__: Object.getPrototypeOf(value), ...value };\n  }\n  return value;\n}\n\n// When programmers talk about the \"canonical form\" of an object, they\n// usually have the following meaning in mind, which I've copied from\n// https://en.wiktionary.org/wiki/canonical_form:\n//\n// 1. A standard or normal presentation of a mathematical entity [or\n//    object]. A canonical form is an element of a set of representatives\n//    of equivalence classes of forms such that there is a function or\n//    procedure which projects every element of each equivalence class\n//    onto that one element, the canonical form of that equivalence\n//    class. The canonical form is expected to be simpler than the rest of\n//    the forms in some way.\n//\n// That's a long-winded way of saying any two objects that have the same\n// canonical form may be considered equivalent, even if they are !==,\n// which usually means the objects are structurally equivalent (deeply\n// equal), but don't necessarily use the same memory.\n//\n// Like a literary or musical canon, this ObjectCanon class represents a\n// collection of unique canonical items (JavaScript objects), with the\n// important property that canon.admit(a) === canon.admit(b) if a and b\n// are deeply equal to each other. In terms of the definition above, the\n// canon.admit method is the \"function or procedure which projects every\"\n// object \"onto that one element, the canonical form.\"\n//\n// In the worst case, the canonicalization process may involve looking at\n// every property in the provided object tree, so it takes the same order\n// of time as deep equality checking. Fortunately, already-canonicalized\n// objects are returned immediately from canon.admit, so the presence of\n// canonical subtrees tends to speed up canonicalization.\n//\n// Since consumers of canonical objects can check for deep equality in\n// constant time, canonicalizing cache results can massively improve the\n// performance of application code that skips re-rendering unchanged\n// results, such as \"pure\" UI components in a framework like React.\n//\n// Of course, since canonical objects may be shared widely between\n// unrelated consumers, it's important to think of them as immutable, even\n// though they are not actually frozen with Object.freeze in production,\n// due to the extra performance overhead that comes with frozen objects.\n//\n// Custom scalar objects whose internal class name is neither Array nor\n// Object can be included safely in the admitted tree, but they will not\n// be replaced with a canonical version (to put it another way, they are\n// assumed to be canonical already).\n//\n// If we ignore custom objects, no detection of cycles or repeated object\n// references is currently required by the StoreReader class, since\n// GraphQL result objects are JSON-serializable trees (and thus contain\n// neither cycles nor repeated subtrees), so we can avoid the complexity\n// of keeping track of objects we've already seen during the recursion of\n// the admit method.\n//\n// In the future, we may consider adding additional cases to the switch\n// statement to handle other common object types, such as \"[object Date]\"\n// objects, as needed.\nexport class ObjectCanon {\n  // Set of all canonical objects this ObjectCanon has admitted, allowing\n  // canon.admit to return previously-canonicalized objects immediately.\n  private known = new (canUseWeakSet ? WeakSet : Set)<object>();\n\n  // Efficient storage/lookup structure for canonical objects.\n  private pool = new Trie<{\n    array?: any[];\n    object?: Record<string, any>;\n    keys?: SortedKeysInfo;\n  }>(canUseWeakMap);\n\n  public isKnown(value: any): boolean {\n    return isObjectOrArray(value) && this.known.has(value);\n  }\n\n  // Make the ObjectCanon assume this value has already been\n  // canonicalized.\n  private passes = new WeakMap<object, object>();\n  public pass<T>(value: T): T;\n  public pass(value: any) {\n    if (isObjectOrArray(value)) {\n      const copy = shallowCopy(value);\n      this.passes.set(copy, value);\n      return copy;\n    }\n    return value;\n  }\n\n  // Returns the canonical version of value.\n  public admit<T>(value: T): T;\n  public admit(value: any) {\n    if (isObjectOrArray(value)) {\n      const original = this.passes.get(value);\n      if (original) return original;\n\n      const proto = Object.getPrototypeOf(value);\n      switch (proto) {\n        case Array.prototype: {\n          if (this.known.has(value)) return value;\n          const array: any[] = (value as any[]).map(this.admit, this);\n          // Arrays are looked up in the Trie using their recursively\n          // canonicalized elements, and the known version of the array is\n          // preserved as node.array.\n          const node = this.pool.lookupArray(array);\n          if (!node.array) {\n            this.known.add((node.array = array));\n            // Since canonical arrays may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(array);\n            }\n          }\n          return node.array;\n        }\n\n        case null:\n        case Object.prototype: {\n          if (this.known.has(value)) return value;\n          const proto = Object.getPrototypeOf(value);\n          const array = [proto];\n          const keys = this.sortedKeys(value);\n          array.push(keys.json);\n          const firstValueIndex = array.length;\n          keys.sorted.forEach((key) => {\n            array.push(this.admit((value as any)[key]));\n          });\n          // Objects are looked up in the Trie by their prototype (which\n          // is *not* recursively canonicalized), followed by a JSON\n          // representation of their (sorted) keys, followed by the\n          // sequence of recursively canonicalized values corresponding to\n          // those keys. To keep the final results unambiguous with other\n          // sequences (such as arrays that just happen to contain [proto,\n          // keys.json, value1, value2, ...]), the known version of the\n          // object is stored as node.object.\n          const node = this.pool.lookupArray(array);\n          if (!node.object) {\n            const obj = (node.object = Object.create(proto));\n            this.known.add(obj);\n            keys.sorted.forEach((key, i) => {\n              obj[key] = array[firstValueIndex + i];\n            });\n            // Since canonical objects may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(obj);\n            }\n          }\n          return node.object;\n        }\n      }\n    }\n    return value;\n  }\n\n  // It's worthwhile to cache the sorting of arrays of strings, since the\n  // same initial unsorted arrays tend to be encountered many times.\n  // Fortunately, we can reuse the Trie machinery to look up the sorted\n  // arrays in linear time (which is faster than sorting large arrays).\n  private sortedKeys(obj: object) {\n    const keys = Object.keys(obj);\n    const node = this.pool.lookupArray(keys);\n    if (!node.keys) {\n      keys.sort();\n      const json = JSON.stringify(keys);\n      if (!(node.keys = this.keysByJSON.get(json))) {\n        this.keysByJSON.set(json, (node.keys = { sorted: keys, json }));\n      }\n    }\n    return node.keys;\n  }\n  // Arrays that contain the same elements in a different order can share\n  // the same SortedKeysInfo object, to save memory.\n  private keysByJSON = new Map<string, SortedKeysInfo>();\n\n  // This has to come last because it depends on keysByJSON.\n  public readonly empty = this.admit({});\n}\n\ntype SortedKeysInfo = {\n  sorted: string[];\n  json: string;\n};\n\n// Since the keys of canonical objects are always created in lexicographically\n// sorted order, we can use the ObjectCanon to implement a fast and stable\n// version of JSON.stringify, which automatically sorts object keys.\nexport const canonicalStringify = Object.assign(\n  function (value: any): string {\n    if (isObjectOrArray(value)) {\n      if (stringifyCanon === void 0) {\n        resetCanonicalStringify();\n      }\n      const canonical = stringifyCanon.admit(value);\n      let json = stringifyCache.get(canonical);\n      if (json === void 0) {\n        stringifyCache.set(canonical, (json = JSON.stringify(canonical)));\n      }\n      return json;\n    }\n    return JSON.stringify(value);\n  },\n  {\n    reset: resetCanonicalStringify,\n  }\n);\n\n// Can be reset by calling canonicalStringify.reset().\nlet stringifyCanon: ObjectCanon;\nlet stringifyCache: WeakMap<object, string>;\n\nfunction resetCanonicalStringify() {\n  stringifyCanon = new ObjectCanon();\n  stringifyCache = new (canUseWeakMap ? WeakMap : Map)();\n}\n","import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\n\nimport type {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n  FieldNode,\n} from \"graphql\";\n\nimport type {\n  FragmentMap,\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  storeKeyNameFromField,\n  argumentsObjectFromField,\n  isReference,\n  getStoreKeyName,\n  isNonNullObject,\n  stringifyForDisplay,\n} from \"../../utilities/index.js\";\nimport type {\n  IdGetter,\n  MergeInfo,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport {\n  hasOwn,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  selectionSetMatchesResult,\n  TypeOrFieldNameRegExp,\n  defaultDataIdFromObject,\n  isArray,\n} from \"./helpers.js\";\nimport { cacheSlot } from \"./reactiveVars.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type {\n  SafeReadonly,\n  FieldSpecifier,\n  ToReferenceFunction,\n  ReadFieldFunction,\n  ReadFieldOptions,\n  CanReadFunction,\n} from \"../core/types/common.js\";\nimport type { WriteContext } from \"./writeToStore.js\";\n\n// Upgrade to a faster version of the default stable JSON.stringify function\n// used by getStoreKeyName. This function is used when computing storeFieldName\n// strings (when no keyArgs has been configured for a field).\nimport { canonicalStringify } from \"./object-canon.js\";\nimport {\n  keyArgsFnFromSpecifier,\n  keyFieldsFnFromSpecifier,\n} from \"./key-extractor.js\";\n\ngetStoreKeyName.setStringify(canonicalStringify);\n\nexport type TypePolicies = {\n  [__typename: string]: TypePolicy;\n};\n\n// TypeScript 3.7 will allow recursive type aliases, so this should work:\n// type KeySpecifier = (string | KeySpecifier)[]\nexport type KeySpecifier = ReadonlyArray<string | KeySpecifier>;\n\nexport type KeyFieldsContext = {\n  // The __typename of the incoming object, even if the __typename field was\n  // aliased to another name in the raw result object. May be undefined when\n  // dataIdFromObject is called for objects without __typename fields.\n  typename: string | undefined;\n\n  // The object to be identified, after processing to remove aliases and\n  // normalize identifiable child objects with references.\n  storeObject: StoreObject;\n\n  // Handy tool for reading additional fields from context.storeObject, either\n  // readField(\"fieldName\") to read storeObject[fieldName], or readField(\"name\",\n  // objectOrReference) to read from another object or Reference. If you read a\n  // field with a read function, that function will be invoked.\n  readField: ReadFieldFunction;\n\n  // If you are writing a custom keyFields function, and you plan to use the raw\n  // result object passed as the first argument, you may also need access to the\n  // selection set and available fragments for this object, just in case any\n  // fields have aliases. Since this logic is tricky to get right, and these\n  // context properties are not even always provided (for example, they are\n  // omitted when calling cache.identify(object), where object is assumed to be\n  // a StoreObject), we recommend you use context.storeObject (which has already\n  // been de-aliased) and context.readField (which can read from references as\n  // well as objects) instead of the raw result object in your keyFields\n  // functions, or just rely on the internal implementation of keyFields:[...]\n  // syntax to get these details right for you.\n  selectionSet?: SelectionSetNode;\n  fragmentMap?: FragmentMap;\n\n  // Internal. May be set by the KeyFieldsFunction to report fields that were\n  // involved in computing the ID. Never passed in by the caller.\n  keyObject?: Record<string, any>;\n};\n\nexport type KeyFieldsFunction = (\n  object: Readonly<StoreObject>,\n  context: KeyFieldsContext\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\ntype KeyFieldsResult = Exclude<ReturnType<KeyFieldsFunction>, KeySpecifier>;\n\n// TODO Should TypePolicy be a generic type, with a TObject or TEntity\n// type parameter?\nexport type TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names or a function that returns an arbitrary string.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n\n  // Allows defining a merge function (or merge:true/false shorthand) to\n  // be used for merging objects of this type wherever they appear, unless\n  // the parent field also defines a merge function/boolean (that is,\n  // parent field merge functions take precedence over type policy merge\n  // functions). In many cases, defining merge:true for a given type\n  // policy can save you from specifying merge:true for all the field\n  // policies where that type might be encountered.\n  merge?: FieldMergeFunction | boolean;\n\n  // In the rare event that your schema happens to use a different\n  // __typename for the root Query, Mutation, and/or Schema types, you can\n  // express your deviant preferences by enabling one of these options.\n  queryType?: true;\n  mutationType?: true;\n  subscriptionType?: true;\n\n  fields?: {\n    [fieldName: string]: FieldPolicy<any> | FieldReadFunction<any>;\n  };\n};\n\nexport type KeyArgsFunction = (\n  args: Record<string, any> | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record<string, any>;\n  }\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\nexport type FieldPolicy<\n  // The internal representation used to store the field's data in the\n  // cache. Must be JSON-serializable if you plan to serialize the result\n  // of cache.extract() using JSON.\n  TExisting = any,\n  // The type of the incoming parameter passed to the merge function,\n  // typically matching the GraphQL response format, but with Reference\n  // objects substituted for any identifiable child objects. Often the\n  // same as TExisting, but not necessarily.\n  TIncoming = TExisting,\n  // The type that the read function actually returns, using TExisting\n  // data and options.args as input. Usually the same as TIncoming.\n  TReadResult = TIncoming,\n  // Allows FieldFunctionOptions definition to be overwritten by the\n  // developer\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction<TExisting, TReadResult, TOptions>;\n  merge?: FieldMergeFunction<TExisting, TIncoming, TOptions> | boolean;\n};\n\nexport type StorageType = Record<string, any>;\n\nfunction argsFromFieldSpecifier(spec: FieldSpecifier) {\n  return (\n    spec.args !== void 0 ? spec.args\n    : spec.field ? argumentsObjectFromField(spec.field, spec.variables)\n    : null\n  );\n}\n\nexport interface FieldFunctionOptions<\n  TArgs = Record<string, any>,\n  TVars = Record<string, any>,\n> {\n  args: TArgs | null;\n\n  // The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n\n  // The full field key used internally, including serialized key arguments.\n  storeFieldName: string;\n\n  // The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n\n  variables?: TVars;\n\n  // Utilities for dealing with { __ref } objects.\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n\n  // A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: StorageType;\n\n  cache: InMemoryCache;\n\n  // Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField: ReadFieldFunction;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead: CanReadFunction;\n\n  // Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects: MergeObjectsFunction;\n}\n\ntype MergeObjectsFunction = <T extends StoreObject | Reference>(\n  existing: T,\n  incoming: T\n) => T;\n\nexport type FieldReadFunction<\n  TExisting = any,\n  TReadResult = TExisting,\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  // When reading a field, one often needs to know about any existing\n  // value stored for that field. If the field is read before any value\n  // has been written to the cache, this existing parameter will be\n  // undefined, which makes it easy to use a default parameter expression\n  // to supply the initial value. This parameter is positional (rather\n  // than one of the named options) because that makes it possible for the\n  // developer to annotate it with a type, without also having to provide\n  // a whole new type for the options object.\n  existing: SafeReadonly<TExisting> | undefined,\n  options: TOptions\n) => TReadResult | undefined;\n\nexport type FieldMergeFunction<\n  TExisting = any,\n  TIncoming = TExisting,\n  // Passing the whole FieldFunctionOptions makes the current definition\n  // independent from its implementation\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  existing: SafeReadonly<TExisting> | undefined,\n  // The incoming parameter needs to be positional as well, for the same\n  // reasons discussed in FieldReadFunction above.\n  incoming: SafeReadonly<TIncoming>,\n  options: TOptions\n) => SafeReadonly<TExisting>;\n\nconst nullKeyFieldsFn: KeyFieldsFunction = () => void 0;\nconst simpleKeyArgsFn: KeyArgsFunction = (_args, context) => context.fieldName;\n\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn: FieldMergeFunction<any> = (\n  existing,\n  incoming,\n  { mergeObjects }\n) => mergeObjects(existing, incoming);\nconst mergeFalseFn: FieldMergeFunction<any> = (_, incoming) => incoming;\n\nexport type PossibleTypesMap = {\n  [supertype: string]: string[];\n};\n\nexport class Policies {\n  private typePolicies: {\n    [__typename: string]: {\n      keyFn?: KeyFieldsFunction;\n      merge?: FieldMergeFunction<any>;\n      fields: {\n        [fieldName: string]: {\n          keyFn?: KeyArgsFunction;\n          read?: FieldReadFunction<any>;\n          merge?: FieldMergeFunction<any>;\n        };\n      };\n    };\n  } = Object.create(null);\n\n  private toBeAdded: {\n    [__typename: string]: TypePolicy[];\n  } = Object.create(null);\n\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  private supertypeMap = new Map<string, Set<string>>();\n\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  private fuzzySubtypes = new Map<string, RegExp>();\n\n  public readonly cache: InMemoryCache;\n\n  public readonly rootIdsByTypename: Record<string, string> =\n    Object.create(null);\n  public readonly rootTypenamesById: Record<string, string> =\n    Object.create(null);\n\n  public readonly usingPossibleTypes = false;\n\n  constructor(\n    private config: {\n      cache: InMemoryCache;\n      dataIdFromObject?: KeyFieldsFunction;\n      possibleTypes?: PossibleTypesMap;\n      typePolicies?: TypePolicies;\n    }\n  ) {\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config,\n    };\n\n    this.cache = this.config.cache;\n\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n\n  public identify(\n    object: StoreObject,\n    partialContext?: Partial<KeyFieldsContext>\n  ): [string?, StoreObject?] {\n    const policies = this;\n\n    const typename =\n      (partialContext &&\n        (partialContext.typename || partialContext.storeObject?.__typename)) ||\n      object.__typename;\n\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject =\n      (partialContext && partialContext.storeObject) || object;\n\n    const context: KeyFieldsContext = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField:\n        (partialContext && partialContext.readField) ||\n        function () {\n          const options = normalizeReadFieldOptions(arguments, storeObject);\n          return policies.readField(options, {\n            store: policies.cache[\"data\"],\n            variables: options.variables,\n          });\n        },\n    };\n\n    let id: KeyFieldsResult;\n\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = (policy && policy.keyFn) || this.config.dataIdFromObject;\n    while (keyFn) {\n      const specifierOrId = keyFn({ ...object, ...storeObject }, context);\n      if (isArray(specifierOrId)) {\n        keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n      } else {\n        id = specifierOrId;\n        break;\n      }\n    }\n\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n\n  public addTypePolicies(typePolicies: TypePolicies) {\n    Object.keys(typePolicies).forEach((typename) => {\n      const { queryType, mutationType, subscriptionType, ...incoming } =\n        typePolicies[typename];\n\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n\n  private updateTypePolicy(typename: string, incoming: TypePolicy) {\n    const existing = this.getTypePolicy(typename);\n    const { keyFields, fields } = incoming;\n\n    function setMerge(\n      existing: { merge?: FieldMergeFunction | boolean },\n      merge?: FieldMergeFunction | boolean\n    ) {\n      existing.merge =\n        typeof merge === \"function\" ? merge\n          // Pass merge:true as a shorthand for a merge implementation\n          // that returns options.mergeObjects(existing, incoming).\n        : merge === true ? mergeTrueFn\n          // Pass merge:false to make incoming always replace existing\n          // without any warnings about data clobbering.\n        : merge === false ? mergeFalseFn\n        : existing.merge;\n    }\n\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n\n    existing.keyFn =\n      // Pass false to disable normalization for this typename.\n      keyFields === false ? nullKeyFieldsFn\n        // Pass an array of strings to use those fields to compute a\n        // composite ID for objects of this typename.\n      : isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields)\n        // Pass a function to take full control over identification.\n      : typeof keyFields === \"function\" ? keyFields\n        // Leave existing.keyFn unchanged if above cases fail.\n      : existing.keyFn;\n\n    if (fields) {\n      Object.keys(fields).forEach((fieldName) => {\n        const existing = this.getFieldPolicy(typename, fieldName, true)!;\n        const incoming = fields[fieldName];\n\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const { keyArgs, read, merge } = incoming;\n\n          existing.keyFn =\n            // Pass false to disable argument-based differentiation of\n            // field identities.\n            keyArgs === false ? simpleKeyArgsFn\n              // Pass an array of strings to use named arguments to\n              // compute a composite identity for the field.\n            : isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs)\n              // Pass a function to take full control over field identity.\n            : typeof keyArgs === \"function\" ? keyArgs\n              // Leave existing.keyFn unchanged if above cases fail.\n            : existing.keyFn;\n\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n\n          setMerge(existing, merge);\n        }\n\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n\n  private setRootTypename(\n    which: \"Query\" | \"Mutation\" | \"Subscription\",\n    typename: string = which\n  ) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(\n        !old || old === which,\n        `Cannot change root %s __typename more than once`,\n        which\n      );\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n\n  public addPossibleTypes(possibleTypes: PossibleTypesMap) {\n    (this.usingPossibleTypes as boolean) = true;\n    Object.keys(possibleTypes).forEach((supertype) => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n\n      possibleTypes[supertype].forEach((subtype) => {\n        this.getSupertypeSet(subtype, true)!.add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n\n  private getTypePolicy(typename: string): Policies[\"typePolicies\"][string] {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy: Policies[\"typePolicies\"][string] = (this.typePolicies[\n        typename\n      ] = Object.create(null));\n      policy.fields = Object.create(null);\n\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its properties can\n      // still be updated directly using addTypePolicies, but future changes to\n      // inherited supertype policies will not be reflected in this subtype\n      // policy, because this code runs at most once per typename.\n      let supertypes = this.supertypeMap.get(typename);\n      if (!supertypes && this.fuzzySubtypes.size) {\n        // To make the inheritance logic work for unknown typename strings that\n        // may have fuzzy supertypes, we give this typename an empty supertype\n        // set and then populate it with any fuzzy supertypes that match.\n        supertypes = this.getSupertypeSet(typename, true)!;\n        // This only works for typenames that are directly matched by a fuzzy\n        // supertype. What if there is an intermediate chain of supertypes?\n        // While possible, that situation can only be solved effectively by\n        // specifying the intermediate relationships via possibleTypes, manually\n        // and in a non-fuzzy way.\n        this.fuzzySubtypes.forEach((regExp, fuzzy) => {\n          if (regExp.test(typename)) {\n            // The fuzzy parameter is just the original string version of regExp\n            // (not a valid __typename string), but we can look up the\n            // associated supertype(s) in this.supertypeMap.\n            const fuzzySupertypes = this.supertypeMap.get(fuzzy);\n            if (fuzzySupertypes) {\n              fuzzySupertypes.forEach((supertype) =>\n                supertypes!.add(supertype)\n              );\n            }\n          }\n        });\n      }\n      if (supertypes && supertypes.size) {\n        supertypes.forEach((supertype) => {\n          const { fields, ...rest } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach((policy) => {\n        this.updateTypePolicy(typename, policy);\n      });\n    }\n\n    return this.typePolicies[typename];\n  }\n\n  private getFieldPolicy(\n    typename: string | undefined,\n    fieldName: string,\n    createIfMissing: boolean\n  ):\n    | {\n        keyFn?: KeyArgsFunction;\n        read?: FieldReadFunction<any>;\n        merge?: FieldMergeFunction<any>;\n      }\n    | undefined {\n    if (typename) {\n      const fieldPolicies = this.getTypePolicy(typename).fields;\n      return (\n        fieldPolicies[fieldName] ||\n        (createIfMissing && (fieldPolicies[fieldName] = Object.create(null)))\n      );\n    }\n  }\n\n  private getSupertypeSet(\n    subtype: string,\n    createIfMissing: boolean\n  ): Set<string> | undefined {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, (supertypeSet = new Set<string>()));\n    }\n    return supertypeSet;\n  }\n\n  public fragmentMatches(\n    fragment: InlineFragmentNode | FragmentDefinitionNode,\n    typename: string | undefined,\n    result?: Record<string, any>,\n    variables?: Record<string, any>\n  ): boolean {\n    if (!fragment.typeCondition) return true;\n\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n\n    if (this.usingPossibleTypes && this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true)!;\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = (subtype: string) => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (\n          supertypeSet &&\n          supertypeSet.size &&\n          workQueue.indexOf(supertypeSet) < 0\n        ) {\n          workQueue.push(supertypeSet);\n        }\n      };\n\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              invariant.warn(\n                `Inferring subtype %s of supertype %s`,\n                typename,\n                supertype\n              );\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n\n        supertypeSet.forEach(maybeEnqueue);\n\n        if (\n          needToCheckFuzzySubtypes &&\n          // Start checking fuzzy subtypes only after exhausting all\n          // non-fuzzy subtypes (after the final iteration of the loop).\n          i === workQueue.length - 1 &&\n          // We could wait to compare fragment.selectionSet to result\n          // after we verify the supertype, but this check is often less\n          // expensive than that search, and we will have to do the\n          // comparison anyway whenever we find a potential match.\n          selectionSetMatchesResult(fragment.selectionSet, result!, variables)\n        ) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n\n    return false;\n  }\n\n  public hasKeyArgs(typename: string | undefined, fieldName: string) {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return !!(policy && policy.keyFn);\n  }\n\n  public getStoreFieldName(fieldSpec: FieldSpecifier): string {\n    const { typename, fieldName } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    let storeFieldName: Exclude<ReturnType<KeyArgsFunction>, KeySpecifier>;\n\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context: Parameters<KeyArgsFunction>[1] = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables,\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n\n    if (storeFieldName === void 0) {\n      storeFieldName =\n        fieldSpec.field ?\n          storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n        : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName) ? storeFieldName\n      : fieldName + \":\" + storeFieldName;\n  }\n\n  public readField<V = StoreValue>(\n    options: ReadFieldOptions,\n    context: ReadMergeModifyContext\n  ): SafeReadonly<V> | undefined {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue<string>(\n        objectOrReference,\n        \"__typename\"\n      );\n      if (typename) options.typename = typename;\n    }\n\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue<V>(\n      objectOrReference,\n      storeFieldName\n    );\n    const policy = this.getFieldPolicy(options.typename, fieldName, false);\n    const read = policy && policy.read;\n\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(\n        this,\n        objectOrReference,\n        options,\n        context,\n        context.store.getStorage(\n          isReference(objectOrReference) ?\n            objectOrReference.__ref\n          : objectOrReference,\n          storeFieldName\n        )\n      );\n\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(this.cache, read, [\n        existing,\n        readOptions,\n      ]) as SafeReadonly<V>;\n    }\n\n    return existing;\n  }\n\n  public getReadFunction(\n    typename: string | undefined,\n    fieldName: string\n  ): FieldReadFunction | undefined {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return policy && policy.read;\n  }\n\n  public getMergeFunction(\n    parentTypename: string | undefined,\n    fieldName: string,\n    childTypename: string | undefined\n  ): FieldMergeFunction | undefined {\n    let policy:\n      | Policies[\"typePolicies\"][string]\n      | Policies[\"typePolicies\"][string][\"fields\"][string]\n      | undefined = this.getFieldPolicy(parentTypename, fieldName, false);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n\n  public runMergeFunction(\n    existing: StoreValue,\n    incoming: StoreValue,\n    { field, typename, merge }: MergeInfo,\n    context: WriteContext,\n    storage?: StorageType\n  ) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(context.store)(\n        existing as StoreObject,\n        incoming as StoreObject\n      );\n    }\n\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n\n    return merge(\n      existing,\n      incoming,\n      makeFieldFunctionOptions(\n        this,\n        // Unlike options.readField for read functions, we do not fall\n        // back to the current object if no foreignObjOrRef is provided,\n        // because it's not clear what the current object should be for\n        // merge functions: the (possibly undefined) existing object, or\n        // the incoming object? If you think your merge function needs\n        // to read sibling fields in order to produce a new value for\n        // the current field, you might want to rethink your strategy,\n        // because that's a recipe for making merge behavior sensitive\n        // to the order in which fields are written into the cache.\n        // However, readField(name, ref) is useful for merge functions\n        // that need to deduplicate child objects and references.\n        void 0,\n        {\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        },\n        context,\n        storage || Object.create(null)\n      )\n    );\n  }\n}\n\nfunction makeFieldFunctionOptions(\n  policies: Policies,\n  objectOrReference: StoreObject | Reference | undefined,\n  fieldSpec: FieldSpecifier,\n  context: ReadMergeModifyContext,\n  storage: StorageType\n): FieldFunctionOptions {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const { toReference, canRead } = context.store;\n\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField<T>() {\n      return policies.readField<T>(\n        normalizeReadFieldOptions(arguments, objectOrReference, variables),\n        context\n      );\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store),\n  };\n}\n\nexport function normalizeReadFieldOptions(\n  readFieldArgs: IArguments,\n  objectOrReference: StoreObject | Reference | undefined,\n  variables?: ReadMergeModifyContext[\"variables\"]\n): ReadFieldOptions {\n  const { 0: fieldNameOrOptions, 1: from, length: argc } = readFieldArgs;\n\n  let options: ReadFieldOptions;\n\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference,\n    };\n  } else {\n    options = { ...fieldNameOrOptions };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n\n  if (__DEV__ && options.from === void 0) {\n    invariant.warn(\n      `Undefined 'from' passed to readField with arguments %s`,\n      stringifyForDisplay(Array.from(readFieldArgs))\n    );\n  }\n\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n\n  return options;\n}\n\nfunction makeMergeObjectsFunction(\n  store: NormalizedCache\n): MergeObjectsFunction {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw newInvariantError(\"Cannot automatically merge arrays\");\n    }\n\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) && isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n\n      if (typesDiffer) {\n        return incoming;\n      }\n\n      if (isReference(existing) && storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n\n      if (storeValueIsStoreObject(existing) && isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n\n      if (\n        storeValueIsStoreObject(existing) &&\n        storeValueIsStoreObject(incoming)\n      ) {\n        return { ...existing, ...incoming };\n      }\n    }\n\n    return incoming;\n  };\n}\n","import type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep, Slot } from \"optimism\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { ApolloCache } from \"../../core/index.js\";\n\nexport interface ReactiveVar<T> {\n  (newValue?: T): T;\n  onNextChange(listener: ReactiveListener<T>): () => void;\n  attachCache(cache: ApolloCache<any>): this;\n  forgetCache(cache: ApolloCache<any>): boolean;\n}\n\nexport type ReactiveListener<T> = (value: T) => any;\n\n// Contextual Slot that acquires its value when custom read functions are\n// called in Policies#readField.\nexport const cacheSlot = new Slot<ApolloCache<any>>();\n\nconst cacheInfoMap = new WeakMap<\n  ApolloCache<any>,\n  {\n    vars: Set<ReactiveVar<any>>;\n    dep: OptimisticDependencyFunction<ReactiveVar<any>>;\n  }\n>();\n\nfunction getCacheInfo(cache: ApolloCache<any>) {\n  let info = cacheInfoMap.get(cache)!;\n  if (!info) {\n    cacheInfoMap.set(\n      cache,\n      (info = {\n        vars: new Set(),\n        dep: dep(),\n      })\n    );\n  }\n  return info;\n}\n\nexport function forgetCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach((rv) => rv.forgetCache(cache));\n}\n\n// Calling forgetCache(cache) serves to silence broadcasts and allows the\n// cache to be garbage collected. However, the varsByCache WeakMap\n// preserves the set of reactive variables that were previously associated\n// with this cache, which makes it possible to \"recall\" the cache at a\n// later time, by reattaching it to those variables. If the cache has been\n// garbage collected in the meantime, because it is no longer reachable,\n// you won't be able to call recallCache(cache), and the cache will\n// automatically disappear from the varsByCache WeakMap.\nexport function recallCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach((rv) => rv.attachCache(cache));\n}\n\nexport function makeVar<T>(value: T): ReactiveVar<T> {\n  const caches = new Set<ApolloCache<any>>();\n  const listeners = new Set<ReactiveListener<T>>();\n\n  const rv: ReactiveVar<T> = function (newValue) {\n    if (arguments.length > 0) {\n      if (value !== newValue) {\n        value = newValue!;\n        caches.forEach((cache) => {\n          // Invalidate any fields with custom read functions that\n          // consumed this variable, so query results involving those\n          // fields will be recomputed the next time we read them.\n          getCacheInfo(cache).dep.dirty(rv);\n          // Broadcast changes to any caches that have previously read\n          // from this variable.\n          broadcast(cache);\n        });\n        // Finally, notify any listeners added via rv.onNextChange.\n        const oldListeners = Array.from(listeners);\n        listeners.clear();\n        oldListeners.forEach((listener) => listener(value));\n      }\n    } else {\n      // When reading from the variable, obtain the current cache from\n      // context via cacheSlot. This isn't entirely foolproof, but it's\n      // the same system that powers varDep.\n      const cache = cacheSlot.getValue();\n      if (cache) {\n        attach(cache);\n        getCacheInfo(cache).dep(rv);\n      }\n    }\n\n    return value;\n  };\n\n  rv.onNextChange = (listener) => {\n    listeners.add(listener);\n    return () => {\n      listeners.delete(listener);\n    };\n  };\n\n  const attach = (rv.attachCache = (cache) => {\n    caches.add(cache);\n    getCacheInfo(cache).vars.add(rv);\n    return rv;\n  });\n\n  rv.forgetCache = (cache) => caches.delete(cache);\n\n  return rv;\n}\n\ntype Broadcastable = ApolloCache<any> & {\n  // This method is protected in InMemoryCache, which we are ignoring, but\n  // we still want some semblance of type safety when we call it.\n  broadcastWatches?: InMemoryCache[\"broadcastWatches\"];\n};\n\nfunction broadcast(cache: Broadcastable) {\n  if (cache.broadcastWatches) {\n    cache.broadcastWatches();\n  }\n}\n","import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\n\nimport type { DocumentNode, FieldNode, SelectionSetNode } from \"graphql\";\nimport { Kind } from \"graphql\";\nimport type { OptimisticWrapperFunction } from \"optimism\";\nimport { wrap } from \"optimism\";\n\nimport type {\n  Reference,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction,\n} from \"../../utilities/index.js\";\nimport {\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  makeReference,\n  shouldInclude,\n  addTypenameToDocument,\n  getDefaultValues,\n  getMainDefinition,\n  getQueryDefinition,\n  getFragmentFromSelection,\n  maybeDeepFreeze,\n  mergeDeepArray,\n  DeepMerger,\n  isNonNullObject,\n  canUseWeakMap,\n  compact,\n} from \"../../utilities/index.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  DiffQueryAgainstStoreOptions,\n  InMemoryCacheConfig,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport {\n  maybeDependOnExistenceOfEntity,\n  supportsResultCaching,\n} from \"./entityStore.js\";\nimport {\n  isArray,\n  extractFragmentContext,\n  getTypenameFromStoreObject,\n  shouldCanonizeResults,\n} from \"./helpers.js\";\nimport type { Policies } from \"./policies.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { MissingTree } from \"../core/types/common.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { canonicalStringify, ObjectCanon } from \"./object-canon.js\";\n\nexport type VariableMap = { [name: string]: any };\n\ninterface ReadContext extends ReadMergeModifyContext {\n  query: DocumentNode;\n  policies: Policies;\n  canonizeResults: boolean;\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n}\n\nexport type ExecResult<R = any> = {\n  result: R;\n  missing?: MissingTree;\n};\n\ntype ExecSelectionSetOptions = {\n  selectionSet: SelectionSetNode;\n  objectOrReference: StoreObject | Reference;\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\ntype ExecSubSelectedArrayOptions = {\n  field: FieldNode;\n  array: readonly any[];\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\nexport interface StoreReaderConfig {\n  cache: InMemoryCache;\n  addTypename?: boolean;\n  resultCacheMaxSize?: number;\n  canonizeResults?: boolean;\n  canon?: ObjectCanon;\n  fragments?: InMemoryCacheConfig[\"fragments\"];\n}\n\n// Arguments type after keyArgs translation.\ntype ExecSelectionSetKeyArgs = [\n  SelectionSetNode,\n  StoreObject | Reference,\n  ReadMergeModifyContext,\n  boolean,\n];\n\nfunction execSelectionSetKeyArgs(\n  options: ExecSelectionSetOptions\n): ExecSelectionSetKeyArgs {\n  return [\n    options.selectionSet,\n    options.objectOrReference,\n    options.context,\n    // We split out this property so we can pass different values\n    // independently without modifying options.context itself.\n    options.context.canonizeResults,\n  ];\n}\n\nexport class StoreReader {\n  // cached version of executeSelectionSet\n  private executeSelectionSet: OptimisticWrapperFunction<\n    [ExecSelectionSetOptions], // Actual arguments tuple type.\n    ExecResult, // Actual return type.\n    ExecSelectionSetKeyArgs\n  >;\n\n  // cached version of executeSubSelectedArray\n  private executeSubSelectedArray: OptimisticWrapperFunction<\n    [ExecSubSelectedArrayOptions],\n    ExecResult<any>,\n    [ExecSubSelectedArrayOptions]\n  >;\n\n  private config: {\n    cache: InMemoryCache;\n    addTypename: boolean;\n    resultCacheMaxSize?: number;\n    canonizeResults: boolean;\n    fragments?: InMemoryCacheConfig[\"fragments\"];\n  };\n\n  private knownResults = new (canUseWeakMap ? WeakMap : Map)<\n    Record<string, any>,\n    SelectionSetNode\n  >();\n\n  public canon: ObjectCanon;\n  public resetCanon() {\n    this.canon = new ObjectCanon();\n  }\n\n  constructor(config: StoreReaderConfig) {\n    this.config = compact(config, {\n      addTypename: config.addTypename !== false,\n      canonizeResults: shouldCanonizeResults(config),\n    });\n\n    this.canon = config.canon || new ObjectCanon();\n\n    this.executeSelectionSet = wrap(\n      (options) => {\n        const { canonizeResults } = options.context;\n\n        const peekArgs = execSelectionSetKeyArgs(options);\n\n        // Negate this boolean option so we can find out if we've already read\n        // this result using the other boolean value.\n        peekArgs[3] = !canonizeResults;\n\n        const other = this.executeSelectionSet.peek(...peekArgs);\n\n        if (other) {\n          if (canonizeResults) {\n            return {\n              ...other,\n              // If we previously read this result without canonizing it, we can\n              // reuse that result simply by canonizing it now.\n              result: this.canon.admit(other.result),\n            };\n          }\n          // If we previously read this result with canonization enabled, we can\n          // return that canonized result as-is.\n          return other;\n        }\n\n        maybeDependOnExistenceOfEntity(\n          options.context.store,\n          options.enclosingRef.__ref\n        );\n\n        // Finally, if we didn't find any useful previous results, run the real\n        // execSelectionSetImpl method with the given options.\n        return this.execSelectionSetImpl(options);\n      },\n      {\n        max: this.config.resultCacheMaxSize,\n        keyArgs: execSelectionSetKeyArgs,\n        // Note that the parameters of makeCacheKey are determined by the\n        // array returned by keyArgs.\n        makeCacheKey(selectionSet, parent, context, canonizeResults) {\n          if (supportsResultCaching(context.store)) {\n            return context.store.makeCacheKey(\n              selectionSet,\n              isReference(parent) ? parent.__ref : parent,\n              context.varString,\n              canonizeResults\n            );\n          }\n        },\n      }\n    );\n\n    this.executeSubSelectedArray = wrap(\n      (options: ExecSubSelectedArrayOptions) => {\n        maybeDependOnExistenceOfEntity(\n          options.context.store,\n          options.enclosingRef.__ref\n        );\n        return this.execSubSelectedArrayImpl(options);\n      },\n      {\n        max: this.config.resultCacheMaxSize,\n        makeCacheKey({ field, array, context }) {\n          if (supportsResultCaching(context.store)) {\n            return context.store.makeCacheKey(field, array, context.varString);\n          }\n        },\n      }\n    );\n  }\n\n  /**\n   * Given a store and a query, return as much of the result as possible and\n   * identify if any data was missing from the store.\n   */\n  public diffQueryAgainstStore<T>({\n    store,\n    query,\n    rootId = \"ROOT_QUERY\",\n    variables,\n    returnPartialData = true,\n    canonizeResults = this.config.canonizeResults,\n  }: DiffQueryAgainstStoreOptions): Cache.DiffResult<T> {\n    const policies = this.config.cache.policies;\n\n    variables = {\n      ...getDefaultValues(getQueryDefinition(query)),\n      ...variables!,\n    };\n\n    const rootRef = makeReference(rootId);\n    const execResult = this.executeSelectionSet({\n      selectionSet: getMainDefinition(query).selectionSet,\n      objectOrReference: rootRef,\n      enclosingRef: rootRef,\n      context: {\n        store,\n        query,\n        policies,\n        variables,\n        varString: canonicalStringify(variables),\n        canonizeResults,\n        ...extractFragmentContext(query, this.config.fragments),\n      },\n    });\n\n    let missing: MissingFieldError[] | undefined;\n    if (execResult.missing) {\n      // For backwards compatibility we still report an array of\n      // MissingFieldError objects, even though there will only ever be at most\n      // one of them, now that all missing field error messages are grouped\n      // together in the execResult.missing tree.\n      missing = [\n        new MissingFieldError(\n          firstMissing(execResult.missing)!,\n          execResult.missing,\n          query,\n          variables\n        ),\n      ];\n      if (!returnPartialData) {\n        throw missing[0];\n      }\n    }\n\n    return {\n      result: execResult.result,\n      complete: !missing,\n      missing,\n    };\n  }\n\n  public isFresh(\n    result: Record<string, any>,\n    parent: StoreObject | Reference,\n    selectionSet: SelectionSetNode,\n    context: ReadMergeModifyContext\n  ): boolean {\n    if (\n      supportsResultCaching(context.store) &&\n      this.knownResults.get(result) === selectionSet\n    ) {\n      const latest = this.executeSelectionSet.peek(\n        selectionSet,\n        parent,\n        context,\n        // If result is canonical, then it could only have been previously\n        // cached by the canonizing version of executeSelectionSet, so we can\n        // avoid checking both possibilities here.\n        this.canon.isKnown(result)\n      );\n      if (latest && result === latest.result) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // Uncached version of executeSelectionSet.\n  private execSelectionSetImpl({\n    selectionSet,\n    objectOrReference,\n    enclosingRef,\n    context,\n  }: ExecSelectionSetOptions): ExecResult {\n    if (\n      isReference(objectOrReference) &&\n      !context.policies.rootTypenamesById[objectOrReference.__ref] &&\n      !context.store.has(objectOrReference.__ref)\n    ) {\n      return {\n        result: this.canon.empty,\n        missing: `Dangling reference to missing ${objectOrReference.__ref} object`,\n      };\n    }\n\n    const { variables, policies, store } = context;\n    const typename = store.getFieldValue<string>(\n      objectOrReference,\n      \"__typename\"\n    );\n\n    const objectsToMerge: Record<string, any>[] = [];\n    let missing: MissingTree | undefined;\n    const missingMerger = new DeepMerger();\n\n    if (\n      this.config.addTypename &&\n      typeof typename === \"string\" &&\n      !policies.rootIdsByTypename[typename]\n    ) {\n      // Ensure we always include a default value for the __typename\n      // field, if we have one, and this.config.addTypename is true. Note\n      // that this field can be overridden by other merged objects.\n      objectsToMerge.push({ __typename: typename });\n    }\n\n    function handleMissing<T>(result: ExecResult<T>, resultName: string): T {\n      if (result.missing) {\n        missing = missingMerger.merge(missing, {\n          [resultName]: result.missing,\n        });\n      }\n      return result.result;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach((selection) => {\n      // Omit fields with directives @skip(if: <truthy value>) or\n      // @include(if: <falsy value>).\n      if (!shouldInclude(selection, variables)) return;\n\n      if (isField(selection)) {\n        let fieldValue = policies.readField(\n          {\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n            from: objectOrReference,\n          },\n          context\n        );\n\n        const resultName = resultKeyNameFromField(selection);\n\n        if (fieldValue === void 0) {\n          if (!addTypenameToDocument.added(selection)) {\n            missing = missingMerger.merge(missing, {\n              [resultName]: `Can't find field '${selection.name.value}' on ${\n                isReference(objectOrReference) ?\n                  objectOrReference.__ref + \" object\"\n                : \"object \" + JSON.stringify(objectOrReference, null, 2)\n              }`,\n            });\n          }\n        } else if (isArray(fieldValue)) {\n          fieldValue = handleMissing(\n            this.executeSubSelectedArray({\n              field: selection,\n              array: fieldValue,\n              enclosingRef,\n              context,\n            }),\n            resultName\n          );\n        } else if (!selection.selectionSet) {\n          // If the field does not have a selection set, then we handle it\n          // as a scalar value. To keep this.canon from canonicalizing\n          // this value, we use this.canon.pass to wrap fieldValue in a\n          // Pass object that this.canon.admit will later unwrap as-is.\n          if (context.canonizeResults) {\n            fieldValue = this.canon.pass(fieldValue);\n          }\n        } else if (fieldValue != null) {\n          // In this case, because we know the field has a selection set,\n          // it must be trying to query a GraphQLObjectType, which is why\n          // fieldValue must be != null.\n          fieldValue = handleMissing(\n            this.executeSelectionSet({\n              selectionSet: selection.selectionSet,\n              objectOrReference: fieldValue as StoreObject | Reference,\n              enclosingRef: isReference(fieldValue) ? fieldValue : enclosingRef,\n              context,\n            }),\n            resultName\n          );\n        }\n\n        if (fieldValue !== void 0) {\n          objectsToMerge.push({ [resultName]: fieldValue });\n        }\n      } else {\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.lookupFragment\n        );\n\n        if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n          throw newInvariantError(`No fragment named %s`, selection.name.value);\n        }\n\n        if (fragment && policies.fragmentMatches(fragment, typename)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    const result = mergeDeepArray(objectsToMerge);\n    const finalResult: ExecResult = { result, missing };\n    const frozen =\n      context.canonizeResults ?\n        this.canon.admit(finalResult)\n        // Since this.canon is normally responsible for freezing results (only in\n        // development), freeze them manually if canonization is disabled.\n      : maybeDeepFreeze(finalResult);\n\n    // Store this result with its selection set so that we can quickly\n    // recognize it again in the StoreReader#isFresh method.\n    if (frozen.result) {\n      this.knownResults.set(frozen.result, selectionSet);\n    }\n\n    return frozen;\n  }\n\n  // Uncached version of executeSubSelectedArray.\n  private execSubSelectedArrayImpl({\n    field,\n    array,\n    enclosingRef,\n    context,\n  }: ExecSubSelectedArrayOptions): ExecResult {\n    let missing: MissingTree | undefined;\n    let missingMerger = new DeepMerger<MissingTree[]>();\n\n    function handleMissing<T>(childResult: ExecResult<T>, i: number): T {\n      if (childResult.missing) {\n        missing = missingMerger.merge(missing, { [i]: childResult.missing });\n      }\n      return childResult.result;\n    }\n\n    if (field.selectionSet) {\n      array = array.filter(context.store.canRead);\n    }\n\n    array = array.map((item, i) => {\n      // null value in array\n      if (item === null) {\n        return null;\n      }\n\n      // This is a nested array, recurse\n      if (isArray(item)) {\n        return handleMissing(\n          this.executeSubSelectedArray({\n            field,\n            array: item,\n            enclosingRef,\n            context,\n          }),\n          i\n        );\n      }\n\n      // This is an object, run the selection set on it\n      if (field.selectionSet) {\n        return handleMissing(\n          this.executeSelectionSet({\n            selectionSet: field.selectionSet,\n            objectOrReference: item,\n            enclosingRef: isReference(item) ? item : enclosingRef,\n            context,\n          }),\n          i\n        );\n      }\n\n      if (__DEV__) {\n        assertSelectionSetForIdValue(context.store, field, item);\n      }\n\n      return item;\n    });\n\n    return {\n      result: context.canonizeResults ? this.canon.admit(array) : array,\n      missing,\n    };\n  }\n}\n\nfunction firstMissing(tree: MissingTree): string | undefined {\n  try {\n    JSON.stringify(tree, (_, value) => {\n      if (typeof value === \"string\") throw value;\n      return value;\n    });\n  } catch (result) {\n    return result as string;\n  }\n}\n\nfunction assertSelectionSetForIdValue(\n  store: NormalizedCache,\n  field: FieldNode,\n  fieldValue: any\n) {\n  if (!field.selectionSet) {\n    const workSet = new Set([fieldValue]);\n    workSet.forEach((value) => {\n      if (isNonNullObject(value)) {\n        invariant(\n          !isReference(value),\n          `Missing selection set for object of type %s returned for query field %s`,\n          getTypenameFromStoreObject(store, value),\n          field.name.value\n        );\n        Object.values(value).forEach(workSet.add, workSet);\n      }\n    });\n  }\n}\n","import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport type { SelectionSetNode, FieldNode } from \"graphql\";\nimport { Kind } from \"graphql\";\n\nimport type {\n  FragmentMap,\n  FragmentMapFunction,\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  getFragmentFromSelection,\n  getDefaultValues,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n} from \"../../utilities/index.js\";\n\nimport type {\n  NormalizedCache,\n  ReadMergeModifyContext,\n  MergeTree,\n  InMemoryCacheConfig,\n} from \"./types.js\";\nimport {\n  isArray,\n  makeProcessedFieldsMerger,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  extractFragmentContext,\n} from \"./helpers.js\";\nimport type { StoreReader } from \"./readFromStore.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { EntityStore } from \"./entityStore.js\";\nimport type { Cache } from \"../../core/index.js\";\nimport { canonicalStringify } from \"./object-canon.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\";\nimport type { ReadFieldFunction } from \"../core/types/common.js\";\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<\n    string,\n    {\n      storeObject: StoreObject;\n      mergeTree?: MergeTree;\n      fieldNodeSet: Set<FieldNode>;\n    }\n  >;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n}\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  \"clientOnly\" | \"deferred\" | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"]\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(\n      key,\n      (flavored =\n        context.clientOnly === clientOnly && context.deferred === deferred ?\n          context\n        : {\n            ...context,\n            clientOnly,\n            deferred,\n          })\n    );\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string;\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n    private fragments?: InMemoryCacheConfig[\"fragments\"]\n  ) {}\n\n  public writeToStore(\n    store: NormalizedCache,\n    { query, result, dataId, variables, overwrite }: Cache.WriteOptions\n  ): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      ...extractFragmentContext(query, this.fragments),\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map(),\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map() },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(`Could not identify object %s`, result);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(\n      ({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n        const entityRef = makeReference(dataId);\n\n        if (mergeTree && mergeTree.map.size) {\n          const applied = this.applyMerges(\n            mergeTree,\n            entityRef,\n            storeObject,\n            context\n          );\n          if (isReference(applied)) {\n            // Assume References returned by applyMerges have already been merged\n            // into the store. See makeMergeObjectsFunction in policies.ts for an\n            // example of how this can happen.\n            return;\n          }\n          // Otherwise, applyMerges returned a StoreObject, whose fields we should\n          // merge into the store (see store.merge statement below).\n          storeObject = applied;\n        }\n\n        if (__DEV__ && !context.overwrite) {\n          const fieldsWithSelectionSets: Record<string, true> =\n            Object.create(null);\n          fieldNodeSet.forEach((field) => {\n            if (field.selectionSet) {\n              fieldsWithSelectionSets[field.name.value] = true;\n            }\n          });\n\n          const hasSelectionSet = (storeFieldName: string) =>\n            fieldsWithSelectionSets[fieldNameFromStoreName(storeFieldName)] ===\n            true;\n\n          const hasMergeFunction = (storeFieldName: string) => {\n            const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n            return Boolean(childTree && childTree.info && childTree.info.merge);\n          };\n\n          Object.keys(storeObject).forEach((storeFieldName) => {\n            // If a merge function was defined for this field, trust that it\n            // did the right thing about (not) clobbering data. If the field\n            // has no selection set, it's a scalar field, so it doesn't need\n            // a merge function (even if it's an object, like JSON data).\n            if (\n              hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)\n            ) {\n              warnAboutDataLoss(\n                entityRef,\n                storeObject,\n                storeFieldName,\n                context.store\n              );\n            }\n          });\n        }\n\n        store.merge(dataId, storeObject);\n      }\n    );\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && (context.store.get(dataId, \"__typename\") as string));\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField(\n            {\n              ...options,\n              from: info.storeObject,\n            },\n            context\n          );\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet ?\n            getContextFlavor(context, false, false)\n          : context,\n          childTree\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (\n          field.selectionSet &&\n          (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))\n        ) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(\n          `Missing field '%s' while writing result %o`,\n          resultKeyNameFromField(field),\n          result\n        );\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (\n        this.reader &&\n        this.reader.isFresh(result, dataRef, selectionSet, context)\n      ) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach((field) => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item,\n          field,\n          context,\n          getChildMergeTree(mergeTree, i)\n        );\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<\n    TContext extends Pick<\n      WriteContext,\n      | \"clientOnly\"\n      | \"deferred\"\n      | \"flavors\"\n      | \"fragmentMap\"\n      | \"lookupFragment\"\n      | \"variables\"\n    >,\n  >(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap)\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach((selection) => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach((dir) => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred)\n          );\n        } else {\n          const fragment = getFragmentFromSelection(\n            selection,\n            context.lookupFragment\n          );\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(\n              `No fragment named %s`,\n              selection.name.value\n            );\n          }\n\n          if (\n            fragment &&\n            policies.fragmentMatches(\n              fragment,\n              typename,\n              result,\n              context.variables\n            )\n          ) {\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred)\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined =\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        (\n          !isArray(incoming) &&\n          // Likewise, existing must be either a Reference or a StoreObject\n          // in order for its fields to be safe to merge with the fields of\n          // the incoming object.\n          (isReference(existing) || storeValueIsStoreObject(existing))\n        ) ?\n          existing\n        : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number\n      ): StoreValue => {\n        return (\n          isArray(from) ?\n            typeof name === \"number\" ?\n              from[name]\n            : void 0\n          : context.store.getFieldValue(from, String(name))\n        );\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map();\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs)\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map() });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info =\n    left.info && right.info ?\n      {\n        ...left.info,\n        ...right.info,\n      }\n    : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map =\n    needToMergeMaps ? new Map()\n    : left.map.size ? left.map\n    : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach((key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(right.map.get(key), left.map.get(key))\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree({ map }: MergeTree, name: string | number) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (\n    Object.keys(existing).every(\n      (key) => store.getFieldValue(incoming, key) !== void 0\n    )\n  ) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach((child) => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n    `Cache data may be lost when replacing the %s field of a %s object.\n\nThis could cause additional (usually avoidable) network requests to fetch data that were otherwise cached.\n\nTo address this problem (which is not a bug in Apollo Client), %sdefine a custom merge function for the %s field, so InMemoryCache can safely merge these objects:\n\n  existing: %o\n  incoming: %o\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`,\n    fieldName,\n    parentType,\n    childTypenames.length ?\n      \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") +\n        \" have an ID or a custom merge function, or \"\n    : \"\",\n    typeDotName,\n    existing,\n    incoming\n  );\n}\n","import { invariant, newInvariantError } from \"../utilities/globals/index.js\";\n\nimport type { ExecutionResult, DocumentNode } from \"graphql\";\n\nimport type { FetchResult, GraphQLRequest } from \"../link/core/index.js\";\nimport { ApolloLink, execute } from \"../link/core/index.js\";\nimport type { ApolloCache, DataProxy, Reference } from \"../cache/index.js\";\nimport type { DocumentTransform, Observable } from \"../utilities/index.js\";\nimport { version } from \"../version.js\";\nimport type { UriFunction } from \"../link/http/index.js\";\nimport { HttpLink } from \"../link/http/index.js\";\n\nimport { QueryManager } from \"./QueryManager.js\";\nimport type { ObservableQuery } from \"./ObservableQuery.js\";\n\nimport type {\n  ApolloQueryResult,\n  DefaultContext,\n  OperationVariables,\n  Resolvers,\n  RefetchQueriesOptions,\n  RefetchQueriesResult,\n  InternalRefetchQueriesResult,\n  RefetchQueriesInclude,\n} from \"./types.js\";\n\nimport type {\n  QueryOptions,\n  WatchQueryOptions,\n  MutationOptions,\n  SubscriptionOptions,\n  WatchQueryFetchPolicy,\n} from \"./watchQueryOptions.js\";\n\nimport type { FragmentMatcher } from \"./LocalState.js\";\nimport { LocalState } from \"./LocalState.js\";\n\nexport interface DefaultOptions {\n  watchQuery?: Partial<WatchQueryOptions<any, any>>;\n  query?: Partial<QueryOptions<any, any>>;\n  mutate?: Partial<MutationOptions<any, any, any>>;\n}\n\nlet hasSuggestedDevtools = false;\n\nexport interface ApolloClientOptions<TCacheShape> {\n  /**\n   * The URI of the GraphQL endpoint that Apollo Client will communicate with.\n   *\n   * One of `uri` or `link` is **required**. If you provide both, `link` takes precedence.\n   */\n  uri?: string | UriFunction;\n  credentials?: string;\n  headers?: Record<string, string>;\n  /**\n   * You can provide an {@link ApolloLink} instance to serve as Apollo Client's network layer. For more information, see [Advanced HTTP networking](https://www.apollographql.com/docs/react/networking/advanced-http-networking/).\n   *\n   * One of `uri` or `link` is **required**. If you provide both, `link` takes precedence.\n   */\n  link?: ApolloLink;\n  /**\n   * The cache that Apollo Client should use to store query results locally. The recommended cache is `InMemoryCache`, which is provided by the `@apollo/client` package.\n   *\n   * For more information, see [Configuring the cache](https://www.apollographql.com/docs/react/caching/cache-configuration/).\n   */\n  cache: ApolloCache<TCacheShape>;\n  /**\n   * The time interval (in milliseconds) before Apollo Client force-fetches queries after a server-side render.\n   *\n   * @defaultValue `0` (no delay)\n   */\n  ssrForceFetchDelay?: number;\n  /**\n   * When using Apollo Client for [server-side rendering](https://www.apollographql.com/docs/react//performance/server-side-rendering/), set this to `true` so that the [`getDataFromTree` function](../react/ssr/#getdatafromtree) can work effectively.\n   *\n   * @defaultValue `false`\n   */\n  ssrMode?: boolean;\n  /**\n   * If `true`, the [Apollo Client Devtools](https://www.apollographql.com/docs/react/development-testing/developer-tooling/#apollo-client-devtools) browser extension can connect to Apollo Client.\n   *\n   * The default value is `false` in production and `true` in development (if there is a `window` object).\n   */\n  connectToDevTools?: boolean;\n  /**\n   * If `false`, Apollo Client sends every created query to the server, even if a _completely_ identical query (identical in terms of query string, variable values, and operationName) is already in flight.\n   *\n   * @defaultValue `true`\n   */\n  queryDeduplication?: boolean;\n  /**\n   * Provide this object to set application-wide default values for options you can provide to the `watchQuery`, `query`, and `mutate` functions. See below for an example object.\n   *\n   * See this [example object](https://www.apollographql.com/docs/react/api/core/ApolloClient#example-defaultoptions-object).\n   */\n  defaultOptions?: DefaultOptions;\n  /**\n   * If `true`, Apollo Client will assume results read from the cache are never mutated by application code, which enables substantial performance optimizations.\n   *\n   * @defaultValue `false`\n   */\n  assumeImmutableResults?: boolean;\n  resolvers?: Resolvers | Resolvers[];\n  typeDefs?: string | string[] | DocumentNode | DocumentNode[];\n  fragmentMatcher?: FragmentMatcher;\n  /**\n   * A custom name (e.g., `iOS`) that identifies this particular client among your set of clients. Apollo Server and Apollo Studio use this property as part of the [client awareness](https://www.apollographql.com/docs/apollo-server/monitoring/metrics#identifying-distinct-clients) feature.\n   */\n  name?: string;\n  /**\n   * A custom version that identifies the current version of this particular client (e.g., `1.2`). Apollo Server and Apollo Studio use this property as part of the [client awareness](https://www.apollographql.com/docs/apollo-server/monitoring/metrics#identifying-distinct-clients) feature.\n   *\n   * This is **not** the version of Apollo Client that you are using, but rather any version string that helps you differentiate between versions of your client.\n   */\n  version?: string;\n  documentTransform?: DocumentTransform;\n}\n\n// Though mergeOptions now resides in @apollo/client/utilities, it was\n// previously declared and exported from this module, and then reexported from\n// @apollo/client/core. Since we need to preserve that API anyway, the easiest\n// solution is to reexport mergeOptions where it was previously declared (here).\nimport { mergeOptions } from \"../utilities/index.js\";\nexport { mergeOptions };\n\n/**\n * This is the primary Apollo Client class. It is used to send GraphQL documents (i.e. queries\n * and mutations) to a GraphQL spec-compliant server over an {@link ApolloLink} instance,\n * receive results from the server and cache the results in a store. It also delivers updates\n * to GraphQL queries through {@link Observable} instances.\n */\nexport class ApolloClient<TCacheShape> implements DataProxy {\n  public link: ApolloLink;\n  public cache: ApolloCache<TCacheShape>;\n  public disableNetworkFetches: boolean;\n  public version: string;\n  public queryDeduplication: boolean;\n  public defaultOptions: DefaultOptions;\n  public readonly typeDefs: ApolloClientOptions<TCacheShape>[\"typeDefs\"];\n\n  private queryManager: QueryManager<TCacheShape>;\n  private devToolsHookCb?: Function;\n  private resetStoreCallbacks: Array<() => Promise<any>> = [];\n  private clearStoreCallbacks: Array<() => Promise<any>> = [];\n  private localState: LocalState<TCacheShape>;\n\n  /**\n   * Constructs an instance of {@link ApolloClient}.\n   *\n   * @example\n   * ```js\n   * import { ApolloClient, InMemoryCache } from '@apollo/client';\n   *\n   * const cache = new InMemoryCache();\n   *\n   * const client = new ApolloClient({\n   *   // Provide required constructor fields\n   *   cache: cache,\n   *   uri: 'http://localhost:4000/',\n   *\n   *   // Provide some optional constructor fields\n   *   name: 'react-web-client',\n   *   version: '1.3',\n   *   queryDeduplication: false,\n   *   defaultOptions: {\n   *     watchQuery: {\n   *       fetchPolicy: 'cache-and-network',\n   *     },\n   *   },\n   * });\n   * ```\n   */\n  constructor(options: ApolloClientOptions<TCacheShape>) {\n    if (!options.cache) {\n      throw newInvariantError(\n        \"To initialize Apollo Client, you must specify a 'cache' property \" +\n          \"in the options object. \\n\" +\n          \"For more information, please visit: https://go.apollo.dev/c/docs\"\n      );\n    }\n\n    const {\n      uri,\n      credentials,\n      headers,\n      cache,\n      documentTransform,\n      ssrMode = false,\n      ssrForceFetchDelay = 0,\n      // Expose the client instance as window.__APOLLO_CLIENT__ and call\n      // onBroadcast in queryManager.broadcastQueries to enable browser\n      // devtools, but disable them by default in production.\n      connectToDevTools = typeof window === \"object\" &&\n        !(window as any).__APOLLO_CLIENT__ &&\n        __DEV__,\n      queryDeduplication = true,\n      defaultOptions,\n      assumeImmutableResults = cache.assumeImmutableResults,\n      resolvers,\n      typeDefs,\n      fragmentMatcher,\n      name: clientAwarenessName,\n      version: clientAwarenessVersion,\n    } = options;\n\n    let { link } = options;\n\n    if (!link) {\n      link =\n        uri ? new HttpLink({ uri, credentials, headers }) : ApolloLink.empty();\n    }\n\n    this.link = link;\n    this.cache = cache;\n    this.disableNetworkFetches = ssrMode || ssrForceFetchDelay > 0;\n    this.queryDeduplication = queryDeduplication;\n    this.defaultOptions = defaultOptions || Object.create(null);\n    this.typeDefs = typeDefs;\n\n    if (ssrForceFetchDelay) {\n      setTimeout(\n        () => (this.disableNetworkFetches = false),\n        ssrForceFetchDelay\n      );\n    }\n\n    this.watchQuery = this.watchQuery.bind(this);\n    this.query = this.query.bind(this);\n    this.mutate = this.mutate.bind(this);\n    this.resetStore = this.resetStore.bind(this);\n    this.reFetchObservableQueries = this.reFetchObservableQueries.bind(this);\n\n    this.version = version;\n\n    this.localState = new LocalState({\n      cache,\n      client: this,\n      resolvers,\n      fragmentMatcher,\n    });\n\n    this.queryManager = new QueryManager({\n      cache: this.cache,\n      link: this.link,\n      defaultOptions: this.defaultOptions,\n      documentTransform,\n      queryDeduplication,\n      ssrMode,\n      clientAwareness: {\n        name: clientAwarenessName!,\n        version: clientAwarenessVersion!,\n      },\n      localState: this.localState,\n      assumeImmutableResults,\n      onBroadcast:\n        connectToDevTools ?\n          () => {\n            if (this.devToolsHookCb) {\n              this.devToolsHookCb({\n                action: {},\n                state: {\n                  queries: this.queryManager.getQueryStore(),\n                  mutations: this.queryManager.mutationStore || {},\n                },\n                dataWithOptimisticResults: this.cache.extract(true),\n              });\n            }\n          }\n        : void 0,\n    });\n\n    if (connectToDevTools) this.connectToDevTools();\n  }\n\n  private connectToDevTools() {\n    if (typeof window === \"object\") {\n      type DevToolsConnector = {\n        push(client: ApolloClient<any>): void;\n      };\n      const windowWithDevTools = window as Window & {\n        [devtoolsSymbol]?: DevToolsConnector;\n        __APOLLO_CLIENT__?: ApolloClient<any>;\n      };\n      const devtoolsSymbol = Symbol.for(\"apollo.devtools\");\n      (windowWithDevTools[devtoolsSymbol] =\n        windowWithDevTools[devtoolsSymbol] || ([] as DevToolsConnector)).push(\n        this\n      );\n      windowWithDevTools.__APOLLO_CLIENT__ = this;\n    }\n\n    /**\n     * Suggest installing the devtools for developers who don't have them\n     */\n    if (!hasSuggestedDevtools && __DEV__) {\n      hasSuggestedDevtools = true;\n      setTimeout(() => {\n        if (\n          typeof window !== \"undefined\" &&\n          window.document &&\n          window.top === window.self &&\n          !(window as any).__APOLLO_DEVTOOLS_GLOBAL_HOOK__\n        ) {\n          const nav = window.navigator;\n          const ua = nav && nav.userAgent;\n          let url: string | undefined;\n          if (typeof ua === \"string\") {\n            if (ua.indexOf(\"Chrome/\") > -1) {\n              url =\n                \"https://chrome.google.com/webstore/detail/\" +\n                \"apollo-client-developer-t/jdkknkkbebbapilgoeccciglkfbmbnfm\";\n            } else if (ua.indexOf(\"Firefox/\") > -1) {\n              url =\n                \"https://addons.mozilla.org/en-US/firefox/addon/apollo-developer-tools/\";\n            }\n          }\n          if (url) {\n            invariant.log(\n              \"Download the Apollo DevTools for a better development \" +\n                \"experience: %s\",\n              url\n            );\n          }\n        }\n      }, 10000);\n    }\n  }\n\n  /**\n   * The `DocumentTransform` used to modify GraphQL documents before a request\n   * is made. If a custom `DocumentTransform` is not provided, this will be the\n   * default document transform.\n   */\n  get documentTransform() {\n    return this.queryManager.documentTransform;\n  }\n\n  /**\n   * Call this method to terminate any active client processes, making it safe\n   * to dispose of this `ApolloClient` instance.\n   */\n  public stop() {\n    this.queryManager.stop();\n  }\n\n  /**\n   * This watches the cache store of the query according to the options specified and\n   * returns an {@link ObservableQuery}. We can subscribe to this {@link ObservableQuery} and\n   * receive updated results through a GraphQL observer when the cache store changes.\n   *\n   * Note that this method is not an implementation of GraphQL subscriptions. Rather,\n   * it uses Apollo's store in order to reactively deliver updates to your query results.\n   *\n   * For example, suppose you call watchQuery on a GraphQL query that fetches a person's\n   * first and last name and this person has a particular object identifier, provided by\n   * dataIdFromObject. Later, a different query fetches that same person's\n   * first and last name and the first name has now changed. Then, any observers associated\n   * with the results of the first query will be updated with a new result object.\n   *\n   * Note that if the cache does not change, the subscriber will *not* be notified.\n   *\n   * See [here](https://medium.com/apollo-stack/the-concepts-of-graphql-bc68bd819be3#.3mb0cbcmc) for\n   * a description of store reactivity.\n   */\n  public watchQuery<\n    T = any,\n    TVariables extends OperationVariables = OperationVariables,\n  >(options: WatchQueryOptions<TVariables, T>): ObservableQuery<T, TVariables> {\n    if (this.defaultOptions.watchQuery) {\n      options = mergeOptions(this.defaultOptions.watchQuery, options);\n    }\n\n    // XXX Overwriting options is probably not the best way to do this long term...\n    if (\n      this.disableNetworkFetches &&\n      (options.fetchPolicy === \"network-only\" ||\n        options.fetchPolicy === \"cache-and-network\")\n    ) {\n      options = { ...options, fetchPolicy: \"cache-first\" };\n    }\n\n    return this.queryManager.watchQuery<T, TVariables>(options);\n  }\n\n  /**\n   * This resolves a single query according to the options specified and\n   * returns a `Promise` which is either resolved with the resulting data\n   * or rejected with an error.\n   *\n   * @param options - An object of type {@link QueryOptions} that allows us to\n   * describe how this query should be treated e.g. whether it should hit the\n   * server at all or just resolve from the cache, etc.\n   */\n  public query<\n    T = any,\n    TVariables extends OperationVariables = OperationVariables,\n  >(options: QueryOptions<TVariables, T>): Promise<ApolloQueryResult<T>> {\n    if (this.defaultOptions.query) {\n      options = mergeOptions(this.defaultOptions.query, options);\n    }\n\n    invariant(\n      (options.fetchPolicy as WatchQueryFetchPolicy) !== \"cache-and-network\",\n      \"The cache-and-network fetchPolicy does not work with client.query, because \" +\n        \"client.query can only return a single result. Please use client.watchQuery \" +\n        \"to receive multiple results from the cache and the network, or consider \" +\n        \"using a different fetchPolicy, such as cache-first or network-only.\"\n    );\n\n    if (this.disableNetworkFetches && options.fetchPolicy === \"network-only\") {\n      options = { ...options, fetchPolicy: \"cache-first\" };\n    }\n\n    return this.queryManager.query<T, TVariables>(options);\n  }\n\n  /**\n   * This resolves a single mutation according to the options specified and returns a\n   * Promise which is either resolved with the resulting data or rejected with an\n   * error.\n   *\n   * It takes options as an object with the following keys and values:\n   */\n  public mutate<\n    TData = any,\n    TVariables extends OperationVariables = OperationVariables,\n    TContext extends Record<string, any> = DefaultContext,\n    TCache extends ApolloCache<any> = ApolloCache<any>,\n  >(\n    options: MutationOptions<TData, TVariables, TContext>\n  ): Promise<FetchResult<TData>> {\n    if (this.defaultOptions.mutate) {\n      options = mergeOptions(this.defaultOptions.mutate, options);\n    }\n    return this.queryManager.mutate<TData, TVariables, TContext, TCache>(\n      options\n    );\n  }\n\n  /**\n   * This subscribes to a graphql subscription according to the options specified and returns an\n   * {@link Observable} which either emits received data or an error.\n   */\n  public subscribe<\n    T = any,\n    TVariables extends OperationVariables = OperationVariables,\n  >(options: SubscriptionOptions<TVariables, T>): Observable<FetchResult<T>> {\n    return this.queryManager.startGraphQLSubscription<T>(options);\n  }\n\n  /**\n   * Tries to read some data from the store in the shape of the provided\n   * GraphQL query without making a network request. This method will start at\n   * the root query. To start at a specific id returned by `dataIdFromObject`\n   * use `readFragment`.\n   *\n   * @param optimistic - Set to `true` to allow `readQuery` to return\n   * optimistic results. Is `false` by default.\n   */\n  public readQuery<T = any, TVariables = OperationVariables>(\n    options: DataProxy.Query<TVariables, T>,\n    optimistic: boolean = false\n  ): T | null {\n    return this.cache.readQuery<T, TVariables>(options, optimistic);\n  }\n\n  /**\n   * Tries to read some data from the store in the shape of the provided\n   * GraphQL fragment without making a network request. This method will read a\n   * GraphQL fragment from any arbitrary id that is currently cached, unlike\n   * `readQuery` which will only read from the root query.\n   *\n   * You must pass in a GraphQL document with a single fragment or a document\n   * with multiple fragments that represent what you are reading. If you pass\n   * in a document with multiple fragments then you must also specify a\n   * `fragmentName`.\n   *\n   * @param optimistic - Set to `true` to allow `readFragment` to return\n   * optimistic results. Is `false` by default.\n   */\n  public readFragment<T = any, TVariables = OperationVariables>(\n    options: DataProxy.Fragment<TVariables, T>,\n    optimistic: boolean = false\n  ): T | null {\n    return this.cache.readFragment<T, TVariables>(options, optimistic);\n  }\n\n  /**\n   * Writes some data in the shape of the provided GraphQL query directly to\n   * the store. This method will start at the root query. To start at a\n   * specific id returned by `dataIdFromObject` then use `writeFragment`.\n   */\n  public writeQuery<TData = any, TVariables = OperationVariables>(\n    options: DataProxy.WriteQueryOptions<TData, TVariables>\n  ): Reference | undefined {\n    const ref = this.cache.writeQuery<TData, TVariables>(options);\n\n    if (options.broadcast !== false) {\n      this.queryManager.broadcastQueries();\n    }\n\n    return ref;\n  }\n\n  /**\n   * Writes some data in the shape of the provided GraphQL fragment directly to\n   * the store. This method will write to a GraphQL fragment from any arbitrary\n   * id that is currently cached, unlike `writeQuery` which will only write\n   * from the root query.\n   *\n   * You must pass in a GraphQL document with a single fragment or a document\n   * with multiple fragments that represent what you are writing. If you pass\n   * in a document with multiple fragments then you must also specify a\n   * `fragmentName`.\n   */\n  public writeFragment<TData = any, TVariables = OperationVariables>(\n    options: DataProxy.WriteFragmentOptions<TData, TVariables>\n  ): Reference | undefined {\n    const ref = this.cache.writeFragment<TData, TVariables>(options);\n\n    if (options.broadcast !== false) {\n      this.queryManager.broadcastQueries();\n    }\n\n    return ref;\n  }\n\n  public __actionHookForDevTools(cb: () => any) {\n    this.devToolsHookCb = cb;\n  }\n\n  public __requestRaw(payload: GraphQLRequest): Observable<ExecutionResult> {\n    return execute(this.link, payload);\n  }\n\n  /**\n   * Resets your entire store by clearing out your cache and then re-executing\n   * all of your active queries. This makes it so that you may guarantee that\n   * there is no data left in your store from a time before you called this\n   * method.\n   *\n   * `resetStore()` is useful when your user just logged out. Youve removed the\n   * user session, and you now want to make sure that any references to data you\n   * might have fetched while the user session was active is gone.\n   *\n   * It is important to remember that `resetStore()` *will* refetch any active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   */\n  public resetStore(): Promise<ApolloQueryResult<any>[] | null> {\n    return Promise.resolve()\n      .then(() =>\n        this.queryManager.clearStore({\n          discardWatches: false,\n        })\n      )\n      .then(() => Promise.all(this.resetStoreCallbacks.map((fn) => fn())))\n      .then(() => this.reFetchObservableQueries());\n  }\n\n  /**\n   * Remove all data from the store. Unlike `resetStore`, `clearStore` will\n   * not refetch any active queries.\n   */\n  public clearStore(): Promise<any[]> {\n    return Promise.resolve()\n      .then(() =>\n        this.queryManager.clearStore({\n          discardWatches: true,\n        })\n      )\n      .then(() => Promise.all(this.clearStoreCallbacks.map((fn) => fn())));\n  }\n\n  /**\n   * Allows callbacks to be registered that are executed when the store is\n   * reset. `onResetStore` returns an unsubscribe function that can be used\n   * to remove registered callbacks.\n   */\n  public onResetStore(cb: () => Promise<any>): () => void {\n    this.resetStoreCallbacks.push(cb);\n    return () => {\n      this.resetStoreCallbacks = this.resetStoreCallbacks.filter(\n        (c) => c !== cb\n      );\n    };\n  }\n\n  /**\n   * Allows callbacks to be registered that are executed when the store is\n   * cleared. `onClearStore` returns an unsubscribe function that can be used\n   * to remove registered callbacks.\n   */\n  public onClearStore(cb: () => Promise<any>): () => void {\n    this.clearStoreCallbacks.push(cb);\n    return () => {\n      this.clearStoreCallbacks = this.clearStoreCallbacks.filter(\n        (c) => c !== cb\n      );\n    };\n  }\n\n  /**\n   * Refetches all of your active queries.\n   *\n   * `reFetchObservableQueries()` is useful if you want to bring the client back to proper state in case of a network outage\n   *\n   * It is important to remember that `reFetchObservableQueries()` *will* refetch any active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   * Takes optional parameter `includeStandby` which will include queries in standby-mode when refetching.\n   */\n  public reFetchObservableQueries(\n    includeStandby?: boolean\n  ): Promise<ApolloQueryResult<any>[]> {\n    return this.queryManager.reFetchObservableQueries(includeStandby);\n  }\n\n  /**\n   * Refetches specified active queries. Similar to \"reFetchObservableQueries()\" but with a specific list of queries.\n   *\n   * `refetchQueries()` is useful for use cases to imperatively refresh a selection of queries.\n   *\n   * It is important to remember that `refetchQueries()` *will* refetch specified active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   */\n  public refetchQueries<\n    TCache extends ApolloCache<any> = ApolloCache<TCacheShape>,\n    TResult = Promise<ApolloQueryResult<any>>,\n  >(\n    options: RefetchQueriesOptions<TCache, TResult>\n  ): RefetchQueriesResult<TResult> {\n    const map = this.queryManager.refetchQueries(\n      options as RefetchQueriesOptions<ApolloCache<TCacheShape>, TResult>\n    );\n    const queries: ObservableQuery<any>[] = [];\n    const results: InternalRefetchQueriesResult<TResult>[] = [];\n\n    map.forEach((result, obsQuery) => {\n      queries.push(obsQuery);\n      results.push(result);\n    });\n\n    const result = Promise.all<TResult>(\n      results as TResult[]\n    ) as RefetchQueriesResult<TResult>;\n\n    // In case you need the raw results immediately, without awaiting\n    // Promise.all(results):\n    result.queries = queries;\n    result.results = results;\n\n    // If you decide to ignore the result Promise because you're using\n    // result.queries and result.results instead, you shouldn't have to worry\n    // about preventing uncaught rejections for the Promise.all result.\n    result.catch((error) => {\n      invariant.debug(\n        `In client.refetchQueries, Promise.all promise rejected with error %o`,\n        error\n      );\n    });\n\n    return result;\n  }\n\n  /**\n   * Get all currently active `ObservableQuery` objects, in a `Map` keyed by\n   * query ID strings.\n   *\n   * An \"active\" query is one that has observers and a `fetchPolicy` other than\n   * \"standby\" or \"cache-only\".\n   *\n   * You can include all `ObservableQuery` objects (including the inactive ones)\n   * by passing \"all\" instead of \"active\", or you can include just a subset of\n   * active queries by passing an array of query names or DocumentNode objects.\n   */\n  public getObservableQueries(\n    include: RefetchQueriesInclude = \"active\"\n  ): Map<string, ObservableQuery<any>> {\n    return this.queryManager.getObservableQueries(include);\n  }\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public extract(optimistic?: boolean): TCacheShape {\n    return this.cache.extract(optimistic);\n  }\n\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public restore(serializedState: TCacheShape): ApolloCache<TCacheShape> {\n    return this.cache.restore(serializedState);\n  }\n\n  /**\n   * Add additional local resolvers.\n   */\n  public addResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.localState.addResolvers(resolvers);\n  }\n\n  /**\n   * Set (override existing) local resolvers.\n   */\n  public setResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.localState.setResolvers(resolvers);\n  }\n\n  /**\n   * Get all registered local resolvers.\n   */\n  public getResolvers() {\n    return this.localState.getResolvers();\n  }\n\n  /**\n   * Set a custom local state fragment matcher.\n   */\n  public setLocalStateFragmentMatcher(fragmentMatcher: FragmentMatcher) {\n    this.localState.setFragmentMatcher(fragmentMatcher);\n  }\n\n  /**\n   * Define a new ApolloLink (or link chain) that Apollo Client will use.\n   */\n  public setLink(newLink: ApolloLink) {\n    this.link = this.queryManager.link = newLink;\n  }\n}\n","import { invariant } from \"../utilities/globals/index.js\";\n\nimport type {\n  DocumentNode,\n  OperationDefinitionNode,\n  SelectionSetNode,\n  SelectionNode,\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  FieldNode,\n  ASTNode,\n  DirectiveNode,\n  FragmentSpreadNode,\n  ExecutableDefinitionNode,\n} from \"graphql\";\nimport { visit, BREAK, isSelectionNode } from \"graphql\";\n\nimport type { ApolloCache } from \"../cache/index.js\";\nimport type { FragmentMap, StoreObject } from \"../utilities/index.js\";\nimport {\n  argumentsObjectFromField,\n  buildQueryFromSelectionSet,\n  createFragmentMap,\n  getFragmentDefinitions,\n  getMainDefinition,\n  hasDirectives,\n  isField,\n  isInlineFragment,\n  mergeDeep,\n  mergeDeepArray,\n  removeClientSetsFromDocument,\n  resultKeyNameFromField,\n  shouldInclude,\n} from \"../utilities/index.js\";\nimport type { ApolloClient } from \"./ApolloClient.js\";\nimport type { Resolvers, OperationVariables } from \"./types.js\";\nimport type { FetchResult } from \"../link/core/index.js\";\nimport { cacheSlot } from \"../cache/index.js\";\n\nexport type Resolver = (\n  rootValue?: any,\n  args?: any,\n  context?: any,\n  info?: {\n    field: FieldNode;\n    fragmentMap: FragmentMap;\n  }\n) => any;\n\nexport type VariableMap = { [name: string]: any };\n\nexport type FragmentMatcher = (\n  rootValue: any,\n  typeCondition: string,\n  context: any\n) => boolean;\n\nexport type ExecContext = {\n  fragmentMap: FragmentMap;\n  context: any;\n  variables: VariableMap;\n  fragmentMatcher: FragmentMatcher;\n  defaultOperationType: string;\n  exportedVariables: Record<string, any>;\n  onlyRunForcedResolvers: boolean;\n  selectionsToResolve: Set<SelectionNode>;\n};\n\nexport type LocalStateOptions<TCacheShape> = {\n  cache: ApolloCache<TCacheShape>;\n  client?: ApolloClient<TCacheShape>;\n  resolvers?: Resolvers | Resolvers[];\n  fragmentMatcher?: FragmentMatcher;\n};\n\nexport class LocalState<TCacheShape> {\n  private cache: ApolloCache<TCacheShape>;\n  private client?: ApolloClient<TCacheShape>;\n  private resolvers?: Resolvers;\n  private fragmentMatcher?: FragmentMatcher;\n  private selectionsToResolveCache = new WeakMap<\n    ExecutableDefinitionNode,\n    Set<SelectionNode>\n  >();\n\n  constructor({\n    cache,\n    client,\n    resolvers,\n    fragmentMatcher,\n  }: LocalStateOptions<TCacheShape>) {\n    this.cache = cache;\n\n    if (client) {\n      this.client = client;\n    }\n\n    if (resolvers) {\n      this.addResolvers(resolvers);\n    }\n\n    if (fragmentMatcher) {\n      this.setFragmentMatcher(fragmentMatcher);\n    }\n  }\n\n  public addResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.resolvers = this.resolvers || {};\n    if (Array.isArray(resolvers)) {\n      resolvers.forEach((resolverGroup) => {\n        this.resolvers = mergeDeep(this.resolvers, resolverGroup);\n      });\n    } else {\n      this.resolvers = mergeDeep(this.resolvers, resolvers);\n    }\n  }\n\n  public setResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.resolvers = {};\n    this.addResolvers(resolvers);\n  }\n\n  public getResolvers() {\n    return this.resolvers || {};\n  }\n\n  // Run local client resolvers against the incoming query and remote data.\n  // Locally resolved field values are merged with the incoming remote data,\n  // and returned. Note that locally resolved fields will overwrite\n  // remote data using the same field name.\n  public async runResolvers<TData>({\n    document,\n    remoteResult,\n    context,\n    variables,\n    onlyRunForcedResolvers = false,\n  }: {\n    document: DocumentNode | null;\n    remoteResult: FetchResult<TData>;\n    context?: Record<string, any>;\n    variables?: Record<string, any>;\n    onlyRunForcedResolvers?: boolean;\n  }): Promise<FetchResult<TData>> {\n    if (document) {\n      return this.resolveDocument(\n        document,\n        remoteResult.data,\n        context,\n        variables,\n        this.fragmentMatcher,\n        onlyRunForcedResolvers\n      ).then((localResult) => ({\n        ...remoteResult,\n        data: localResult.result,\n      }));\n    }\n\n    return remoteResult;\n  }\n\n  public setFragmentMatcher(fragmentMatcher: FragmentMatcher) {\n    this.fragmentMatcher = fragmentMatcher;\n  }\n\n  public getFragmentMatcher(): FragmentMatcher | undefined {\n    return this.fragmentMatcher;\n  }\n\n  // Client queries contain everything in the incoming document (if a @client\n  // directive is found).\n  public clientQuery(document: DocumentNode) {\n    if (hasDirectives([\"client\"], document)) {\n      if (this.resolvers) {\n        return document;\n      }\n    }\n    return null;\n  }\n\n  // Server queries are stripped of all @client based selection sets.\n  public serverQuery(document: DocumentNode) {\n    return removeClientSetsFromDocument(document);\n  }\n\n  public prepareContext(context?: Record<string, any>) {\n    const { cache } = this;\n    return {\n      ...context,\n      cache,\n      // Getting an entry's cache key is useful for local state resolvers.\n      getCacheKey(obj: StoreObject) {\n        return cache.identify(obj);\n      },\n    };\n  }\n\n  // To support `@client @export(as: \"someVar\")` syntax, we'll first resolve\n  // @client @export fields locally, then pass the resolved values back to be\n  // used alongside the original operation variables.\n  public async addExportedVariables<TVars extends OperationVariables>(\n    document: DocumentNode,\n    variables: TVars = {} as TVars,\n    context = {}\n  ): /* returns at least the variables that were passed in */ Promise<TVars> {\n    if (document) {\n      return this.resolveDocument(\n        document,\n        this.buildRootValueFromCache(document, variables) || {},\n        this.prepareContext(context),\n        variables\n      ).then((data) => ({\n        ...variables,\n        ...data.exportedVariables,\n      }));\n    }\n\n    return {\n      ...variables,\n    };\n  }\n\n  public shouldForceResolvers(document: ASTNode) {\n    let forceResolvers = false;\n    visit(document, {\n      Directive: {\n        enter(node) {\n          if (node.name.value === \"client\" && node.arguments) {\n            forceResolvers = node.arguments.some(\n              (arg) =>\n                arg.name.value === \"always\" &&\n                arg.value.kind === \"BooleanValue\" &&\n                arg.value.value === true\n            );\n            if (forceResolvers) {\n              return BREAK;\n            }\n          }\n        },\n      },\n    });\n    return forceResolvers;\n  }\n\n  // Query the cache and return matching data.\n  private buildRootValueFromCache(\n    document: DocumentNode,\n    variables?: Record<string, any>\n  ) {\n    return this.cache.diff({\n      query: buildQueryFromSelectionSet(document),\n      variables,\n      returnPartialData: true,\n      optimistic: false,\n    }).result;\n  }\n\n  private async resolveDocument<TData>(\n    document: DocumentNode,\n    rootValue: TData,\n    context: any = {},\n    variables: VariableMap = {},\n    fragmentMatcher: FragmentMatcher = () => true,\n    onlyRunForcedResolvers: boolean = false\n  ) {\n    const mainDefinition = getMainDefinition(\n      document\n    ) as OperationDefinitionNode;\n    const fragments = getFragmentDefinitions(document);\n    const fragmentMap = createFragmentMap(fragments);\n    const selectionsToResolve = this.collectSelectionsToResolve(\n      mainDefinition,\n      fragmentMap\n    );\n\n    const definitionOperation = mainDefinition.operation;\n\n    const defaultOperationType =\n      definitionOperation ?\n        definitionOperation.charAt(0).toUpperCase() +\n        definitionOperation.slice(1)\n      : \"Query\";\n\n    const { cache, client } = this;\n    const execContext: ExecContext = {\n      fragmentMap,\n      context: {\n        ...context,\n        cache,\n        client,\n      },\n      variables,\n      fragmentMatcher,\n      defaultOperationType,\n      exportedVariables: {},\n      selectionsToResolve,\n      onlyRunForcedResolvers,\n    };\n    const isClientFieldDescendant = false;\n\n    return this.resolveSelectionSet(\n      mainDefinition.selectionSet,\n      isClientFieldDescendant,\n      rootValue,\n      execContext\n    ).then((result) => ({\n      result,\n      exportedVariables: execContext.exportedVariables,\n    }));\n  }\n\n  private async resolveSelectionSet<TData>(\n    selectionSet: SelectionSetNode,\n    isClientFieldDescendant: boolean,\n    rootValue: TData,\n    execContext: ExecContext\n  ) {\n    const { fragmentMap, context, variables } = execContext;\n    const resultsToMerge: TData[] = [rootValue];\n\n    const execute = async (selection: SelectionNode): Promise<void> => {\n      if (\n        !isClientFieldDescendant &&\n        !execContext.selectionsToResolve.has(selection)\n      ) {\n        // Skip selections without @client directives\n        // (still processing if one of the ancestors or one of the child fields has @client directive)\n        return;\n      }\n      if (!shouldInclude(selection, variables)) {\n        // Skip this entirely.\n        return;\n      }\n\n      if (isField(selection)) {\n        return this.resolveField(\n          selection,\n          isClientFieldDescendant,\n          rootValue,\n          execContext\n        ).then((fieldResult) => {\n          if (typeof fieldResult !== \"undefined\") {\n            resultsToMerge.push({\n              [resultKeyNameFromField(selection)]: fieldResult,\n            } as TData);\n          }\n        });\n      }\n\n      let fragment: InlineFragmentNode | FragmentDefinitionNode;\n\n      if (isInlineFragment(selection)) {\n        fragment = selection;\n      } else {\n        // This is a named fragment.\n        fragment = fragmentMap[selection.name.value];\n        invariant(fragment, `No fragment named %s`, selection.name.value);\n      }\n\n      if (fragment && fragment.typeCondition) {\n        const typeCondition = fragment.typeCondition.name.value;\n        if (execContext.fragmentMatcher(rootValue, typeCondition, context)) {\n          return this.resolveSelectionSet(\n            fragment.selectionSet,\n            isClientFieldDescendant,\n            rootValue,\n            execContext\n          ).then((fragmentResult) => {\n            resultsToMerge.push(fragmentResult);\n          });\n        }\n      }\n    };\n\n    return Promise.all(selectionSet.selections.map(execute)).then(function () {\n      return mergeDeepArray(resultsToMerge);\n    });\n  }\n\n  private async resolveField(\n    field: FieldNode,\n    isClientFieldDescendant: boolean,\n    rootValue: any,\n    execContext: ExecContext\n  ): Promise<any> {\n    if (!rootValue) {\n      return null;\n    }\n\n    const { variables } = execContext;\n    const fieldName = field.name.value;\n    const aliasedFieldName = resultKeyNameFromField(field);\n    const aliasUsed = fieldName !== aliasedFieldName;\n    const defaultResult = rootValue[aliasedFieldName] || rootValue[fieldName];\n    let resultPromise = Promise.resolve(defaultResult);\n\n    // Usually all local resolvers are run when passing through here, but\n    // if we've specifically identified that we only want to run forced\n    // resolvers (that is, resolvers for fields marked with\n    // `@client(always: true)`), then we'll skip running non-forced resolvers.\n    if (\n      !execContext.onlyRunForcedResolvers ||\n      this.shouldForceResolvers(field)\n    ) {\n      const resolverType =\n        rootValue.__typename || execContext.defaultOperationType;\n      const resolverMap = this.resolvers && this.resolvers[resolverType];\n      if (resolverMap) {\n        const resolve = resolverMap[aliasUsed ? fieldName : aliasedFieldName];\n        if (resolve) {\n          resultPromise = Promise.resolve(\n            // In case the resolve function accesses reactive variables,\n            // set cacheSlot to the current cache instance.\n            cacheSlot.withValue(this.cache, resolve, [\n              rootValue,\n              argumentsObjectFromField(field, variables),\n              execContext.context,\n              { field, fragmentMap: execContext.fragmentMap },\n            ])\n          );\n        }\n      }\n    }\n\n    return resultPromise.then((result = defaultResult) => {\n      // If an @export directive is associated with the current field, store\n      // the `as` export variable name and current result for later use.\n      if (field.directives) {\n        field.directives.forEach((directive) => {\n          if (directive.name.value === \"export\" && directive.arguments) {\n            directive.arguments.forEach((arg) => {\n              if (arg.name.value === \"as\" && arg.value.kind === \"StringValue\") {\n                execContext.exportedVariables[arg.value.value] = result;\n              }\n            });\n          }\n        });\n      }\n\n      // Handle all scalar types here.\n      if (!field.selectionSet) {\n        return result;\n      }\n\n      // From here down, the field has a selection set, which means it's trying\n      // to query a GraphQLObjectType.\n      if (result == null) {\n        // Basically any field in a GraphQL response can be null, or missing\n        return result;\n      }\n\n      const isClientField =\n        field.directives?.some((d) => d.name.value === \"client\") ?? false;\n\n      if (Array.isArray(result)) {\n        return this.resolveSubSelectedArray(\n          field,\n          isClientFieldDescendant || isClientField,\n          result,\n          execContext\n        );\n      }\n\n      // Returned value is an object, and the query has a sub-selection. Recurse.\n      if (field.selectionSet) {\n        return this.resolveSelectionSet(\n          field.selectionSet,\n          isClientFieldDescendant || isClientField,\n          result,\n          execContext\n        );\n      }\n    });\n  }\n\n  private resolveSubSelectedArray(\n    field: FieldNode,\n    isClientFieldDescendant: boolean,\n    result: any[],\n    execContext: ExecContext\n  ): any {\n    return Promise.all(\n      result.map((item) => {\n        if (item === null) {\n          return null;\n        }\n\n        // This is a nested array, recurse.\n        if (Array.isArray(item)) {\n          return this.resolveSubSelectedArray(\n            field,\n            isClientFieldDescendant,\n            item,\n            execContext\n          );\n        }\n\n        // This is an object, run the selection set on it.\n        if (field.selectionSet) {\n          return this.resolveSelectionSet(\n            field.selectionSet,\n            isClientFieldDescendant,\n            item,\n            execContext\n          );\n        }\n      })\n    );\n  }\n\n  // Collect selection nodes on paths from document root down to all @client directives.\n  // This function takes into account transitive fragment spreads.\n  // Complexity equals to a single `visit` over the full document.\n  private collectSelectionsToResolve(\n    mainDefinition: OperationDefinitionNode,\n    fragmentMap: FragmentMap\n  ): Set<SelectionNode> {\n    const isSingleASTNode = (\n      node: ASTNode | readonly ASTNode[]\n    ): node is ASTNode => !Array.isArray(node);\n    const selectionsToResolveCache = this.selectionsToResolveCache;\n\n    function collectByDefinition(\n      definitionNode: ExecutableDefinitionNode\n    ): Set<SelectionNode> {\n      if (!selectionsToResolveCache.has(definitionNode)) {\n        const matches = new Set<SelectionNode>();\n        selectionsToResolveCache.set(definitionNode, matches);\n\n        visit(definitionNode, {\n          Directive(node: DirectiveNode, _, __, ___, ancestors) {\n            if (node.name.value === \"client\") {\n              ancestors.forEach((node) => {\n                if (isSingleASTNode(node) && isSelectionNode(node)) {\n                  matches.add(node);\n                }\n              });\n            }\n          },\n          FragmentSpread(spread: FragmentSpreadNode, _, __, ___, ancestors) {\n            const fragment = fragmentMap[spread.name.value];\n            invariant(fragment, `No fragment named %s`, spread.name.value);\n\n            const fragmentSelections = collectByDefinition(fragment);\n            if (fragmentSelections.size > 0) {\n              // Fragment for this spread contains @client directive (either directly or transitively)\n              // Collect selection nodes on paths from the root down to fields with the @client directive\n              ancestors.forEach((node) => {\n                if (isSingleASTNode(node) && isSelectionNode(node)) {\n                  matches.add(node);\n                }\n              });\n              matches.add(spread);\n              fragmentSelections.forEach((selection) => {\n                matches.add(selection);\n              });\n            }\n          },\n        });\n      }\n      return selectionsToResolveCache.get(definitionNode)!;\n    }\n    return collectByDefinition(mainDefinition);\n  }\n}\n","import { invariant } from \"../utilities/globals/index.js\";\nimport type { DocumentNode } from \"graphql\";\nimport { equal } from \"@wry/equality\";\n\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nimport type {\n  Concast,\n  Observer,\n  ObservableSubscription,\n} from \"../utilities/index.js\";\nimport {\n  cloneDeep,\n  compact,\n  getOperationDefinition,\n  Observable,\n  iterateObserversSafely,\n  fixObservableSubclass,\n  getQueryDefinition,\n} from \"../utilities/index.js\";\nimport type { ApolloError } from \"../errors/index.js\";\nimport type { QueryManager } from \"./QueryManager.js\";\nimport type {\n  ApolloQueryResult,\n  OperationVariables,\n  TypedDocumentNode,\n} from \"./types.js\";\nimport type {\n  WatchQueryOptions,\n  FetchMoreQueryOptions,\n  SubscribeToMoreOptions,\n  NextFetchPolicyContext,\n  WatchQueryFetchPolicy,\n} from \"./watchQueryOptions.js\";\nimport type { QueryInfo } from \"./QueryInfo.js\";\nimport type { MissingFieldError } from \"../cache/index.js\";\nimport type { MissingTree } from \"../cache/core/types/common.js\";\nimport { equalByQuery } from \"./equalByQuery.js\";\nimport type { TODO } from \"../utilities/types/TODO.js\";\n\nconst { assign, hasOwnProperty } = Object;\n\nexport interface FetchMoreOptions<\n  TData = any,\n  TVariables = OperationVariables,\n> {\n  updateQuery?: (\n    previousQueryResult: TData,\n    options: {\n      fetchMoreResult?: TData;\n      variables?: TVariables;\n    }\n  ) => TData;\n}\n\nexport interface UpdateQueryOptions<TVariables> {\n  variables?: TVariables;\n}\n\ninterface Last<TData, TVariables> {\n  result: ApolloQueryResult<TData>;\n  variables?: TVariables;\n  error?: ApolloError;\n}\n\nexport class ObservableQuery<\n  TData = any,\n  TVariables extends OperationVariables = OperationVariables,\n> extends Observable<ApolloQueryResult<TData>> {\n  public readonly options: WatchQueryOptions<TVariables, TData>;\n  public readonly queryId: string;\n  public readonly queryName?: string;\n\n  // The `query` computed property will always reflect the document transformed\n  // by the last run query. `this.options.query` will always reflect the raw\n  // untransformed query to ensure document transforms with runtime conditionals\n  // are run on the original document.\n  public get query(): TypedDocumentNode<TData, TVariables> {\n    return this.lastQuery || this.options.query;\n  }\n\n  // Computed shorthand for this.options.variables, preserved for\n  // backwards compatibility.\n  public get variables(): TVariables | undefined {\n    return this.options.variables;\n  }\n\n  private isTornDown: boolean;\n  private queryManager: QueryManager<any>;\n  private observers = new Set<Observer<ApolloQueryResult<TData>>>();\n  private subscriptions = new Set<ObservableSubscription>();\n\n  private waitForOwnResult: boolean;\n  private last?: Last<TData, TVariables>;\n  private lastQuery?: DocumentNode;\n\n  private queryInfo: QueryInfo;\n\n  // When this.concast is defined, this.observer is the Observer currently\n  // subscribed to that Concast.\n  private concast?: Concast<ApolloQueryResult<TData>>;\n  private observer?: Observer<ApolloQueryResult<TData>>;\n\n  private pollingInfo?: {\n    interval: number;\n    timeout: ReturnType<typeof setTimeout>;\n  };\n\n  constructor({\n    queryManager,\n    queryInfo,\n    options,\n  }: {\n    queryManager: QueryManager<any>;\n    queryInfo: QueryInfo;\n    options: WatchQueryOptions<TVariables, TData>;\n  }) {\n    super((observer: Observer<ApolloQueryResult<TData>>) => {\n      // Zen Observable has its own error function, so in order to log correctly\n      // we need to provide a custom error callback.\n      try {\n        var subObserver = (observer as any)._subscription._observer;\n        if (subObserver && !subObserver.error) {\n          subObserver.error = defaultSubscriptionObserverErrorCallback;\n        }\n      } catch {}\n\n      const first = !this.observers.size;\n      this.observers.add(observer);\n\n      // Deliver most recent error or result.\n      const last = this.last;\n      if (last && last.error) {\n        observer.error && observer.error(last.error);\n      } else if (last && last.result) {\n        observer.next && observer.next(last.result);\n      }\n\n      // Initiate observation of this query if it hasn't been reported to\n      // the QueryManager yet.\n      if (first) {\n        // Blindly catching here prevents unhandled promise rejections,\n        // and is safe because the ObservableQuery handles this error with\n        // this.observer.error, so we're not just swallowing the error by\n        // ignoring it here.\n        this.reobserve().catch(() => {});\n      }\n\n      return () => {\n        if (this.observers.delete(observer) && !this.observers.size) {\n          this.tearDownQuery();\n        }\n      };\n    });\n\n    // related classes\n    this.queryInfo = queryInfo;\n    this.queryManager = queryManager;\n\n    // active state\n    this.waitForOwnResult = skipCacheDataFor(options.fetchPolicy);\n    this.isTornDown = false;\n\n    const {\n      watchQuery: { fetchPolicy: defaultFetchPolicy = \"cache-first\" } = {},\n    } = queryManager.defaultOptions;\n\n    const {\n      fetchPolicy = defaultFetchPolicy,\n      // Make sure we don't store \"standby\" as the initialFetchPolicy.\n      initialFetchPolicy = fetchPolicy === \"standby\" ? defaultFetchPolicy : (\n        fetchPolicy\n      ),\n    } = options;\n\n    this.options = {\n      ...options,\n\n      // Remember the initial options.fetchPolicy so we can revert back to this\n      // policy when variables change. This information can also be specified\n      // (or overridden) by providing options.initialFetchPolicy explicitly.\n      initialFetchPolicy,\n\n      // This ensures this.options.fetchPolicy always has a string value, in\n      // case options.fetchPolicy was not provided.\n      fetchPolicy,\n    };\n\n    this.queryId = queryInfo.queryId || queryManager.generateQueryId();\n\n    const opDef = getOperationDefinition(this.query);\n    this.queryName = opDef && opDef.name && opDef.name.value;\n  }\n\n  public result(): Promise<ApolloQueryResult<TData>> {\n    return new Promise((resolve, reject) => {\n      // TODO: this code doesnt actually make sense insofar as the observer\n      // will never exist in this.observers due how zen-observable wraps observables.\n      // https://github.com/zenparsing/zen-observable/blob/master/src/Observable.js#L169\n      const observer: Observer<ApolloQueryResult<TData>> = {\n        next: (result: ApolloQueryResult<TData>) => {\n          resolve(result);\n\n          // Stop the query within the QueryManager if we can before\n          // this function returns.\n          //\n          // We do this in order to prevent observers piling up within\n          // the QueryManager. Notice that we only fully unsubscribe\n          // from the subscription in a setTimeout(..., 0)  call. This call can\n          // actually be handled by the browser at a much later time. If queries\n          // are fired in the meantime, observers that should have been removed\n          // from the QueryManager will continue to fire, causing an unnecessary\n          // performance hit.\n          this.observers.delete(observer);\n          if (!this.observers.size) {\n            this.queryManager.removeQuery(this.queryId);\n          }\n\n          setTimeout(() => {\n            subscription.unsubscribe();\n          }, 0);\n        },\n        error: reject,\n      };\n      const subscription = this.subscribe(observer);\n    });\n  }\n\n  public getCurrentResult(saveAsLastResult = true): ApolloQueryResult<TData> {\n    // Use the last result as long as the variables match this.variables.\n    const lastResult = this.getLastResult(true);\n\n    const networkStatus =\n      this.queryInfo.networkStatus ||\n      (lastResult && lastResult.networkStatus) ||\n      NetworkStatus.ready;\n\n    const result = {\n      ...lastResult,\n      loading: isNetworkRequestInFlight(networkStatus),\n      networkStatus,\n    } as ApolloQueryResult<TData>;\n\n    const { fetchPolicy = \"cache-first\" } = this.options;\n    if (\n      // These fetch policies should never deliver data from the cache, unless\n      // redelivering a previously delivered result.\n      skipCacheDataFor(fetchPolicy) ||\n      // If this.options.query has @client(always: true) fields, we cannot\n      // trust diff.result, since it was read from the cache without running\n      // local resolvers (and it's too late to run resolvers now, since we must\n      // return a result synchronously).\n      this.queryManager.getDocumentInfo(this.query).hasForcedResolvers\n    ) {\n      // Fall through.\n    } else if (this.waitForOwnResult) {\n      // This would usually be a part of `QueryInfo.getDiff()`.\n      // which we skip in the waitForOwnResult case since we are not\n      // interested in the diff.\n      this.queryInfo[\"updateWatch\"]();\n    } else {\n      const diff = this.queryInfo.getDiff();\n\n      if (diff.complete || this.options.returnPartialData) {\n        result.data = diff.result;\n      }\n\n      if (equal(result.data, {})) {\n        result.data = void 0 as any;\n      }\n\n      if (diff.complete) {\n        // Similar to setting result.partial to false, but taking advantage of the\n        // falsiness of missing fields.\n        delete result.partial;\n\n        // If the diff is complete, and we're using a FetchPolicy that\n        // terminates after a complete cache read, we can assume the next result\n        // we receive will have NetworkStatus.ready and !loading.\n        if (\n          diff.complete &&\n          result.networkStatus === NetworkStatus.loading &&\n          (fetchPolicy === \"cache-first\" || fetchPolicy === \"cache-only\")\n        ) {\n          result.networkStatus = NetworkStatus.ready;\n          result.loading = false;\n        }\n      } else {\n        result.partial = true;\n      }\n\n      if (\n        __DEV__ &&\n        !diff.complete &&\n        !this.options.partialRefetch &&\n        !result.loading &&\n        !result.data &&\n        !result.error\n      ) {\n        logMissingFieldErrors(diff.missing);\n      }\n    }\n\n    if (saveAsLastResult) {\n      this.updateLastResult(result);\n    }\n\n    return result;\n  }\n\n  // Compares newResult to the snapshot we took of this.lastResult when it was\n  // first received.\n  public isDifferentFromLastResult(\n    newResult: ApolloQueryResult<TData>,\n    variables?: TVariables\n  ) {\n    if (!this.last) {\n      return true;\n    }\n\n    const resultIsDifferent =\n      this.queryManager.getDocumentInfo(this.query).hasNonreactiveDirective ?\n        !equalByQuery(this.query, this.last.result, newResult, this.variables)\n      : !equal(this.last.result, newResult);\n\n    return (\n      resultIsDifferent || (variables && !equal(this.last.variables, variables))\n    );\n  }\n\n  private getLast<K extends keyof Last<TData, TVariables>>(\n    key: K,\n    variablesMustMatch?: boolean\n  ) {\n    const last = this.last;\n    if (\n      last &&\n      last[key] &&\n      (!variablesMustMatch || equal(last.variables, this.variables))\n    ) {\n      return last[key];\n    }\n  }\n\n  public getLastResult(\n    variablesMustMatch?: boolean\n  ): ApolloQueryResult<TData> | undefined {\n    return this.getLast(\"result\", variablesMustMatch);\n  }\n\n  public getLastError(variablesMustMatch?: boolean): ApolloError | undefined {\n    return this.getLast(\"error\", variablesMustMatch);\n  }\n\n  public resetLastResults(): void {\n    delete this.last;\n    this.isTornDown = false;\n  }\n\n  public resetQueryStoreErrors() {\n    this.queryManager.resetErrors(this.queryId);\n  }\n\n  /**\n   * Update the variables of this observable query, and fetch the new results.\n   * This method should be preferred over `setVariables` in most use cases.\n   *\n   * @param variables - The new set of variables. If there are missing variables,\n   * the previous values of those variables will be used.\n   */\n  public refetch(\n    variables?: Partial<TVariables>\n  ): Promise<ApolloQueryResult<TData>> {\n    const reobserveOptions: Partial<WatchQueryOptions<TVariables, TData>> = {\n      // Always disable polling for refetches.\n      pollInterval: 0,\n    };\n\n    // Unless the provided fetchPolicy always consults the network\n    // (no-cache, network-only, or cache-and-network), override it with\n    // network-only to force the refetch for this fetchQuery call.\n    const { fetchPolicy } = this.options;\n    if (fetchPolicy === \"cache-and-network\") {\n      reobserveOptions.fetchPolicy = fetchPolicy;\n    } else if (fetchPolicy === \"no-cache\") {\n      reobserveOptions.fetchPolicy = \"no-cache\";\n    } else {\n      reobserveOptions.fetchPolicy = \"network-only\";\n    }\n\n    if (__DEV__ && variables && hasOwnProperty.call(variables, \"variables\")) {\n      const queryDef = getQueryDefinition(this.query);\n      const vars = queryDef.variableDefinitions;\n      if (!vars || !vars.some((v) => v.variable.name.value === \"variables\")) {\n        invariant.warn(\n          `Called refetch(%o) for query %o, which does not declare a $variables variable.\nDid you mean to call refetch(variables) instead of refetch({ variables })?`,\n          variables,\n          queryDef.name?.value || queryDef\n        );\n      }\n    }\n\n    if (variables && !equal(this.options.variables, variables)) {\n      // Update the existing options with new variables\n      reobserveOptions.variables = this.options.variables = {\n        ...this.options.variables,\n        ...variables,\n      } as TVariables;\n    }\n\n    this.queryInfo.resetLastWrite();\n    return this.reobserve(reobserveOptions, NetworkStatus.refetch);\n  }\n\n  public fetchMore<\n    TFetchData = TData,\n    TFetchVars extends OperationVariables = TVariables,\n  >(\n    fetchMoreOptions: FetchMoreQueryOptions<TFetchVars, TFetchData> & {\n      updateQuery?: (\n        previousQueryResult: TData,\n        options: {\n          fetchMoreResult: TFetchData;\n          variables: TFetchVars;\n        }\n      ) => TData;\n    }\n  ): Promise<ApolloQueryResult<TFetchData>> {\n    const combinedOptions = {\n      ...(fetchMoreOptions.query ? fetchMoreOptions : (\n        {\n          ...this.options,\n          query: this.options.query,\n          ...fetchMoreOptions,\n          variables: {\n            ...this.options.variables,\n            ...fetchMoreOptions.variables,\n          },\n        }\n      )),\n      // The fetchMore request goes immediately to the network and does\n      // not automatically write its result to the cache (hence no-cache\n      // instead of network-only), because we allow the caller of\n      // fetchMore to provide an updateQuery callback that determines how\n      // the data gets written to the cache.\n      fetchPolicy: \"no-cache\",\n    } as WatchQueryOptions<TFetchVars, TFetchData>;\n\n    combinedOptions.query = this.transformDocument(combinedOptions.query);\n\n    const qid = this.queryManager.generateQueryId();\n\n    // If a temporary query is passed to `fetchMore`, we don't want to store\n    // it as the last query result since it may be an optimized query for\n    // pagination. We will however run the transforms on the original document\n    // as well as the document passed in `fetchMoreOptions` to ensure the cache\n    // uses the most up-to-date document which may rely on runtime conditionals.\n    this.lastQuery =\n      fetchMoreOptions.query ?\n        this.transformDocument(this.options.query)\n      : combinedOptions.query;\n\n    // Simulate a loading result for the original query with\n    // result.networkStatus === NetworkStatus.fetchMore.\n    const { queryInfo } = this;\n    const originalNetworkStatus = queryInfo.networkStatus;\n    queryInfo.networkStatus = NetworkStatus.fetchMore;\n    if (combinedOptions.notifyOnNetworkStatusChange) {\n      this.observe();\n    }\n\n    const updatedQuerySet = new Set<DocumentNode>();\n\n    return this.queryManager\n      .fetchQuery(qid, combinedOptions, NetworkStatus.fetchMore)\n      .then((fetchMoreResult) => {\n        this.queryManager.removeQuery(qid);\n\n        if (queryInfo.networkStatus === NetworkStatus.fetchMore) {\n          queryInfo.networkStatus = originalNetworkStatus;\n        }\n\n        // Performing this cache update inside a cache.batch transaction ensures\n        // any affected cache.watch watchers are notified at most once about any\n        // updates. Most watchers will be using the QueryInfo class, which\n        // responds to notifications by calling reobserveCacheFirst to deliver\n        // fetchMore cache results back to this ObservableQuery.\n        this.queryManager.cache.batch({\n          update: (cache) => {\n            const { updateQuery } = fetchMoreOptions;\n            if (updateQuery) {\n              cache.updateQuery(\n                {\n                  query: this.query,\n                  variables: this.variables,\n                  returnPartialData: true,\n                  optimistic: false,\n                },\n                (previous) =>\n                  updateQuery(previous!, {\n                    fetchMoreResult: fetchMoreResult.data,\n                    variables: combinedOptions.variables as TFetchVars,\n                  })\n              );\n            } else {\n              // If we're using a field policy instead of updateQuery, the only\n              // thing we need to do is write the new data to the cache using\n              // combinedOptions.variables (instead of this.variables, which is\n              // what this.updateQuery uses, because it works by abusing the\n              // original field value, keyed by the original variables).\n              cache.writeQuery({\n                query: combinedOptions.query,\n                variables: combinedOptions.variables,\n                data: fetchMoreResult.data,\n              });\n            }\n          },\n\n          onWatchUpdated: (watch) => {\n            // Record the DocumentNode associated with any watched query whose\n            // data were updated by the cache writes above.\n            updatedQuerySet.add(watch.query);\n          },\n        });\n\n        return fetchMoreResult;\n      })\n      .finally(() => {\n        // In case the cache writes above did not generate a broadcast\n        // notification (which would have been intercepted by onWatchUpdated),\n        // likely because the written data were the same as what was already in\n        // the cache, we still want fetchMore to deliver its final loading:false\n        // result with the unchanged data.\n        if (!updatedQuerySet.has(this.query)) {\n          reobserveCacheFirst(this);\n        }\n      });\n  }\n\n  // XXX the subscription variables are separate from the query variables.\n  // if you want to update subscription variables, right now you have to do that separately,\n  // and you can only do it by stopping the subscription and then subscribing again with new variables.\n  public subscribeToMore<\n    TSubscriptionData = TData,\n    TSubscriptionVariables extends OperationVariables = TVariables,\n  >(\n    options: SubscribeToMoreOptions<\n      TData,\n      TSubscriptionVariables,\n      TSubscriptionData\n    >\n  ) {\n    const subscription = this.queryManager\n      .startGraphQLSubscription({\n        query: options.document,\n        variables: options.variables,\n        context: options.context,\n      })\n      .subscribe({\n        next: (subscriptionData: { data: TSubscriptionData }) => {\n          const { updateQuery } = options;\n          if (updateQuery) {\n            this.updateQuery<TSubscriptionVariables>(\n              (previous, { variables }) =>\n                updateQuery(previous, {\n                  subscriptionData,\n                  variables,\n                })\n            );\n          }\n        },\n        error: (err: any) => {\n          if (options.onError) {\n            options.onError(err);\n            return;\n          }\n          invariant.error(\"Unhandled GraphQL subscription error\", err);\n        },\n      });\n\n    this.subscriptions.add(subscription);\n\n    return () => {\n      if (this.subscriptions.delete(subscription)) {\n        subscription.unsubscribe();\n      }\n    };\n  }\n\n  public setOptions(\n    newOptions: Partial<WatchQueryOptions<TVariables, TData>>\n  ): Promise<ApolloQueryResult<TData>> {\n    return this.reobserve(newOptions);\n  }\n\n  public silentSetOptions(\n    newOptions: Partial<WatchQueryOptions<TVariables, TData>>\n  ) {\n    const mergedOptions = compact(this.options, newOptions || {});\n    assign(this.options, mergedOptions);\n  }\n\n  /**\n   * Update the variables of this observable query, and fetch the new results\n   * if they've changed. Most users should prefer `refetch` instead of\n   * `setVariables` in order to to be properly notified of results even when\n   * they come from the cache.\n   *\n   * Note: the `next` callback will *not* fire if the variables have not changed\n   * or if the result is coming from cache.\n   *\n   * Note: the promise will return the old results immediately if the variables\n   * have not changed.\n   *\n   * Note: the promise will return null immediately if the query is not active\n   * (there are no subscribers).\n   *\n   * @param variables - The new set of variables. If there are missing variables,\n   * the previous values of those variables will be used.\n   */\n  public setVariables(\n    variables: TVariables\n  ): Promise<ApolloQueryResult<TData> | void> {\n    if (equal(this.variables, variables)) {\n      // If we have no observers, then we don't actually want to make a network\n      // request. As soon as someone observes the query, the request will kick\n      // off. For now, we just store any changes. (See #1077)\n      return this.observers.size ? this.result() : Promise.resolve();\n    }\n\n    this.options.variables = variables;\n\n    // See comment above\n    if (!this.observers.size) {\n      return Promise.resolve();\n    }\n\n    return this.reobserve(\n      {\n        // Reset options.fetchPolicy to its original value.\n        fetchPolicy: this.options.initialFetchPolicy,\n        variables,\n      },\n      NetworkStatus.setVariables\n    );\n  }\n\n  public updateQuery<TVars extends OperationVariables = TVariables>(\n    mapFn: (\n      previousQueryResult: TData,\n      options: Pick<WatchQueryOptions<TVars, TData>, \"variables\">\n    ) => TData\n  ): void {\n    const { queryManager } = this;\n    const { result } = queryManager.cache.diff<TData>({\n      query: this.options.query,\n      variables: this.variables,\n      returnPartialData: true,\n      optimistic: false,\n    });\n\n    const newResult = mapFn(result!, {\n      variables: (this as any).variables,\n    });\n\n    if (newResult) {\n      queryManager.cache.writeQuery({\n        query: this.options.query,\n        data: newResult,\n        variables: this.variables,\n      });\n\n      queryManager.broadcastQueries();\n    }\n  }\n\n  public startPolling(pollInterval: number) {\n    this.options.pollInterval = pollInterval;\n    this.updatePolling();\n  }\n\n  public stopPolling() {\n    this.options.pollInterval = 0;\n    this.updatePolling();\n  }\n\n  // Update options.fetchPolicy according to options.nextFetchPolicy.\n  private applyNextFetchPolicy(\n    reason: NextFetchPolicyContext<TData, TVariables>[\"reason\"],\n    // It's possible to use this method to apply options.nextFetchPolicy to\n    // options.fetchPolicy even if options !== this.options, though that happens\n    // most often when the options are temporary, used for only one request and\n    // then thrown away, so nextFetchPolicy may not end up mattering.\n    options: WatchQueryOptions<TVariables, TData>\n  ) {\n    if (options.nextFetchPolicy) {\n      const { fetchPolicy = \"cache-first\", initialFetchPolicy = fetchPolicy } =\n        options;\n\n      if (fetchPolicy === \"standby\") {\n        // Do nothing, leaving options.fetchPolicy unchanged.\n      } else if (typeof options.nextFetchPolicy === \"function\") {\n        // When someone chooses \"cache-and-network\" or \"network-only\" as their\n        // initial FetchPolicy, they often do not want future cache updates to\n        // trigger unconditional network requests, which is what repeatedly\n        // applying the \"cache-and-network\" or \"network-only\" policies would\n        // seem to imply. Instead, when the cache reports an update after the\n        // initial network request, it may be desirable for subsequent network\n        // requests to be triggered only if the cache result is incomplete. To\n        // that end, the options.nextFetchPolicy option provides an easy way to\n        // update options.fetchPolicy after the initial network request, without\n        // having to call observableQuery.setOptions.\n        options.fetchPolicy = options.nextFetchPolicy(fetchPolicy, {\n          reason,\n          options,\n          observable: this,\n          initialFetchPolicy,\n        });\n      } else if (reason === \"variables-changed\") {\n        options.fetchPolicy = initialFetchPolicy;\n      } else {\n        options.fetchPolicy = options.nextFetchPolicy;\n      }\n    }\n\n    return options.fetchPolicy;\n  }\n\n  private fetch(\n    options: WatchQueryOptions<TVariables, TData>,\n    newNetworkStatus?: NetworkStatus,\n    query?: DocumentNode\n  ) {\n    // TODO Make sure we update the networkStatus (and infer fetchVariables)\n    // before actually committing to the fetch.\n    this.queryManager.setObservableQuery(this);\n    return this.queryManager[\"fetchConcastWithInfo\"](\n      this.queryId,\n      options,\n      newNetworkStatus,\n      query\n    );\n  }\n\n  // Turns polling on or off based on this.options.pollInterval.\n  private updatePolling() {\n    // Avoid polling in SSR mode\n    if (this.queryManager.ssrMode) {\n      return;\n    }\n\n    const {\n      pollingInfo,\n      options: { pollInterval },\n    } = this;\n\n    if (!pollInterval) {\n      if (pollingInfo) {\n        clearTimeout(pollingInfo.timeout);\n        delete this.pollingInfo;\n      }\n      return;\n    }\n\n    if (pollingInfo && pollingInfo.interval === pollInterval) {\n      return;\n    }\n\n    invariant(\n      pollInterval,\n      \"Attempted to start a polling query without a polling interval.\"\n    );\n\n    const info = pollingInfo || (this.pollingInfo = {} as any);\n    info.interval = pollInterval;\n\n    const maybeFetch = () => {\n      if (this.pollingInfo) {\n        if (!isNetworkRequestInFlight(this.queryInfo.networkStatus)) {\n          this.reobserve(\n            {\n              // Most fetchPolicy options don't make sense to use in a polling context, as\n              // users wouldn't want to be polling the cache directly. However, network-only and\n              // no-cache are both useful for when the user wants to control whether or not the\n              // polled results are written to the cache.\n              fetchPolicy:\n                this.options.initialFetchPolicy === \"no-cache\" ?\n                  \"no-cache\"\n                : \"network-only\",\n            },\n            NetworkStatus.poll\n          ).then(poll, poll);\n        } else {\n          poll();\n        }\n      }\n    };\n\n    const poll = () => {\n      const info = this.pollingInfo;\n      if (info) {\n        clearTimeout(info.timeout);\n        info.timeout = setTimeout(maybeFetch, info.interval);\n      }\n    };\n\n    poll();\n  }\n\n  private updateLastResult(\n    newResult: ApolloQueryResult<TData>,\n    variables = this.variables\n  ) {\n    let error: ApolloError | undefined = this.getLastError();\n    // Preserve this.last.error unless the variables have changed.\n    if (error && this.last && !equal(variables, this.last.variables)) {\n      error = void 0;\n    }\n    return (this.last = {\n      result:\n        this.queryManager.assumeImmutableResults ?\n          newResult\n        : cloneDeep(newResult),\n      variables,\n      ...(error ? { error } : null),\n    });\n  }\n\n  public reobserveAsConcast(\n    newOptions?: Partial<WatchQueryOptions<TVariables, TData>>,\n    newNetworkStatus?: NetworkStatus\n  ): Concast<ApolloQueryResult<TData>> {\n    this.isTornDown = false;\n\n    const useDisposableConcast =\n      // Refetching uses a disposable Concast to allow refetches using different\n      // options/variables, without permanently altering the options of the\n      // original ObservableQuery.\n      newNetworkStatus === NetworkStatus.refetch ||\n      // The fetchMore method does not actually call the reobserve method, but,\n      // if it did, it would definitely use a disposable Concast.\n      newNetworkStatus === NetworkStatus.fetchMore ||\n      // Polling uses a disposable Concast so the polling options (which force\n      // fetchPolicy to be \"network-only\" or \"no-cache\") won't override the original options.\n      newNetworkStatus === NetworkStatus.poll;\n\n    // Save the old variables, since Object.assign may modify them below.\n    const oldVariables = this.options.variables;\n    const oldFetchPolicy = this.options.fetchPolicy;\n\n    const mergedOptions = compact(this.options, newOptions || {});\n    const options =\n      useDisposableConcast ?\n        // Disposable Concast fetches receive a shallow copy of this.options\n        // (merged with newOptions), leaving this.options unmodified.\n        mergedOptions\n      : assign(this.options, mergedOptions);\n\n    // Don't update options.query with the transformed query to avoid\n    // overwriting this.options.query when we aren't using a disposable concast.\n    // We want to ensure we can re-run the custom document transforms the next\n    // time a request is made against the original query.\n    const query = this.transformDocument(options.query);\n\n    this.lastQuery = query;\n\n    if (!useDisposableConcast) {\n      // We can skip calling updatePolling if we're not changing this.options.\n      this.updatePolling();\n\n      // Reset options.fetchPolicy to its original value when variables change,\n      // unless a new fetchPolicy was provided by newOptions.\n      if (\n        newOptions &&\n        newOptions.variables &&\n        !equal(newOptions.variables, oldVariables) &&\n        // Don't mess with the fetchPolicy if it's currently \"standby\".\n        options.fetchPolicy !== \"standby\" &&\n        // If we're changing the fetchPolicy anyway, don't try to change it here\n        // using applyNextFetchPolicy. The explicit options.fetchPolicy wins.\n        options.fetchPolicy === oldFetchPolicy\n      ) {\n        this.applyNextFetchPolicy(\"variables-changed\", options);\n        if (newNetworkStatus === void 0) {\n          newNetworkStatus = NetworkStatus.setVariables;\n        }\n      }\n    }\n\n    this.waitForOwnResult &&= skipCacheDataFor(options.fetchPolicy);\n    const finishWaitingForOwnResult = () => {\n      if (this.concast === concast) {\n        this.waitForOwnResult = false;\n      }\n    };\n\n    const variables = options.variables && { ...options.variables };\n    const { concast, fromLink } = this.fetch(options, newNetworkStatus, query);\n    const observer: Observer<ApolloQueryResult<TData>> = {\n      next: (result) => {\n        finishWaitingForOwnResult();\n        this.reportResult(result, variables);\n      },\n      error: (error) => {\n        finishWaitingForOwnResult();\n        this.reportError(error, variables);\n      },\n    };\n\n    if (!useDisposableConcast && (fromLink || !this.concast)) {\n      // We use the {add,remove}Observer methods directly to avoid wrapping\n      // observer with an unnecessary SubscriptionObserver object.\n      if (this.concast && this.observer) {\n        this.concast.removeObserver(this.observer);\n      }\n\n      this.concast = concast;\n      this.observer = observer;\n    }\n\n    concast.addObserver(observer);\n\n    return concast;\n  }\n\n  public reobserve(\n    newOptions?: Partial<WatchQueryOptions<TVariables, TData>>,\n    newNetworkStatus?: NetworkStatus\n  ): Promise<ApolloQueryResult<TData>> {\n    return this.reobserveAsConcast(newOptions, newNetworkStatus)\n      .promise as TODO;\n  }\n\n  public resubscribeAfterError(\n    onNext: (value: ApolloQueryResult<TData>) => void,\n    onError?: (error: any) => void,\n    onComplete?: () => void\n  ): ObservableSubscription;\n\n  public resubscribeAfterError(\n    observer: Observer<ApolloQueryResult<TData>>\n  ): ObservableSubscription;\n\n  public resubscribeAfterError(...args: [any, any?, any?]) {\n    // If `lastError` is set in the current when the subscription is re-created,\n    // the subscription will immediately receive the error, which will\n    // cause it to terminate again. To avoid this, we first clear\n    // the last error/result from the `observableQuery` before re-starting\n    // the subscription, and restore the last value afterwards so that the\n    // subscription has a chance to stay open.\n    const last = this.last;\n    this.resetLastResults();\n\n    const subscription = this.subscribe(...args);\n    this.last = last;\n\n    return subscription;\n  }\n\n  // (Re)deliver the current result to this.observers without applying fetch\n  // policies or making network requests.\n  private observe() {\n    this.reportResult(\n      // Passing false is important so that this.getCurrentResult doesn't\n      // save the fetchMore result as this.lastResult, causing it to be\n      // ignored due to the this.isDifferentFromLastResult check in\n      // this.reportResult.\n      this.getCurrentResult(false),\n      this.variables\n    );\n  }\n\n  private reportResult(\n    result: ApolloQueryResult<TData>,\n    variables: TVariables | undefined\n  ) {\n    const lastError = this.getLastError();\n    const isDifferent = this.isDifferentFromLastResult(result, variables);\n    // Update the last result even when isDifferentFromLastResult returns false,\n    // because the query may be using the @nonreactive directive, and we want to\n    // save the the latest version of any nonreactive subtrees (in case\n    // getCurrentResult is called), even though we skip broadcasting changes.\n    if (lastError || !result.partial || this.options.returnPartialData) {\n      this.updateLastResult(result, variables);\n    }\n    if (lastError || isDifferent) {\n      iterateObserversSafely(this.observers, \"next\", result);\n    }\n  }\n\n  private reportError(error: ApolloError, variables: TVariables | undefined) {\n    // Since we don't get the current result on errors, only the error, we\n    // must mirror the updates that occur in QueryStore.markQueryError here\n    const errorResult = {\n      ...this.getLastResult(),\n      error,\n      errors: error.graphQLErrors,\n      networkStatus: NetworkStatus.error,\n      loading: false,\n    } as ApolloQueryResult<TData>;\n\n    this.updateLastResult(errorResult, variables);\n\n    iterateObserversSafely(this.observers, \"error\", (this.last!.error = error));\n  }\n\n  public hasObservers() {\n    return this.observers.size > 0;\n  }\n\n  private tearDownQuery() {\n    if (this.isTornDown) return;\n    if (this.concast && this.observer) {\n      this.concast.removeObserver(this.observer);\n      delete this.concast;\n      delete this.observer;\n    }\n\n    this.stopPolling();\n    // stop all active GraphQL subscriptions\n    this.subscriptions.forEach((sub) => sub.unsubscribe());\n    this.subscriptions.clear();\n    this.queryManager.stopQuery(this.queryId);\n    this.observers.clear();\n    this.isTornDown = true;\n  }\n\n  private transformDocument(document: DocumentNode) {\n    return this.queryManager.transform(document);\n  }\n}\n\n// Necessary because the ObservableQuery constructor has a different\n// signature than the Observable constructor.\nfixObservableSubclass(ObservableQuery);\n\n// Reobserve with fetchPolicy effectively set to \"cache-first\", triggering\n// delivery of any new data from the cache, possibly falling back to the network\n// if any cache data are missing. This allows _complete_ cache results to be\n// delivered without also kicking off unnecessary network requests when\n// this.options.fetchPolicy is \"cache-and-network\" or \"network-only\". When\n// this.options.fetchPolicy is any other policy (\"cache-first\", \"cache-only\",\n// \"standby\", or \"no-cache\"), we call this.reobserve() as usual.\nexport function reobserveCacheFirst<TData, TVars extends OperationVariables>(\n  obsQuery: ObservableQuery<TData, TVars>\n) {\n  const { fetchPolicy, nextFetchPolicy } = obsQuery.options;\n\n  if (fetchPolicy === \"cache-and-network\" || fetchPolicy === \"network-only\") {\n    return obsQuery.reobserve({\n      fetchPolicy: \"cache-first\",\n      // Use a temporary nextFetchPolicy function that replaces itself with the\n      // previous nextFetchPolicy value and returns the original fetchPolicy.\n      nextFetchPolicy(\n        this: WatchQueryOptions<TVars, TData>,\n        currentFetchPolicy: WatchQueryFetchPolicy,\n        context: NextFetchPolicyContext<TData, TVars>\n      ) {\n        // Replace this nextFetchPolicy function in the options object with the\n        // original this.options.nextFetchPolicy value.\n        this.nextFetchPolicy = nextFetchPolicy;\n        // If the original nextFetchPolicy value was a function, give it a\n        // chance to decide what happens here.\n        if (typeof this.nextFetchPolicy === \"function\") {\n          return this.nextFetchPolicy(currentFetchPolicy, context);\n        }\n        // Otherwise go back to the original this.options.fetchPolicy.\n        return fetchPolicy!;\n      },\n    });\n  }\n\n  return obsQuery.reobserve();\n}\n\nfunction defaultSubscriptionObserverErrorCallback(error: ApolloError) {\n  invariant.error(\"Unhandled error\", error.message, error.stack);\n}\n\nexport function logMissingFieldErrors(\n  missing: MissingFieldError[] | MissingTree | undefined\n) {\n  if (__DEV__ && missing) {\n    invariant.debug(`Missing cache result fields: %o`, missing);\n  }\n}\n\nfunction skipCacheDataFor(\n  fetchPolicy?: WatchQueryFetchPolicy /* `undefined` would mean `\"cache-first\"` */\n) {\n  return (\n    fetchPolicy === \"network-only\" ||\n    fetchPolicy === \"no-cache\" ||\n    fetchPolicy === \"standby\"\n  );\n}\n","import type { DocumentNode, GraphQLError } from \"graphql\";\nimport { equal } from \"@wry/equality\";\n\nimport type { Cache, ApolloCache } from \"../cache/index.js\";\nimport { DeepMerger } from \"../utilities/index.js\";\nimport { mergeIncrementalData } from \"../utilities/index.js\";\nimport type { WatchQueryOptions, ErrorPolicy } from \"./watchQueryOptions.js\";\nimport type { ObservableQuery } from \"./ObservableQuery.js\";\nimport { reobserveCacheFirst } from \"./ObservableQuery.js\";\nimport type { QueryListener, MethodKeys } from \"./types.js\";\nimport type { FetchResult } from \"../link/core/index.js\";\nimport {\n  isNonEmptyArray,\n  graphQLResultHasError,\n  canUseWeakMap,\n} from \"../utilities/index.js\";\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nimport type { ApolloError } from \"../errors/index.js\";\nimport type { QueryManager } from \"./QueryManager.js\";\n\nexport type QueryStoreValue = Pick<\n  QueryInfo,\n  \"variables\" | \"networkStatus\" | \"networkError\" | \"graphQLErrors\"\n>;\n\nexport const enum CacheWriteBehavior {\n  FORBID,\n  OVERWRITE,\n  MERGE,\n}\n\nconst destructiveMethodCounts = new (canUseWeakMap ? WeakMap : Map)<\n  ApolloCache<any>,\n  number\n>();\n\nfunction wrapDestructiveCacheMethod(\n  cache: ApolloCache<any>,\n  methodName: MethodKeys<ApolloCache<any>>\n) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(\n        cache,\n        // The %1e15 allows the count to wrap around to 0 safely every\n        // quadrillion evictions, so there's no risk of overflow. To be\n        // clear, this is more of a pedantic principle than something\n        // that matters in any conceivable practical scenario.\n        (destructiveMethodCounts.get(cache)! + 1) % 1e15\n      );\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\n\nfunction cancelNotifyTimeout(info: QueryInfo) {\n  if (info[\"notifyTimeout\"]) {\n    clearTimeout(info[\"notifyTimeout\"]);\n    info[\"notifyTimeout\"] = void 0;\n  }\n}\n\n// A QueryInfo object represents a single query managed by the\n// QueryManager, which tracks all QueryInfo objects by queryId in its\n// this.queries Map. QueryInfo objects store the latest results and errors\n// for the given query, and are responsible for reporting those results to\n// the corresponding ObservableQuery, via the QueryInfo.notify method.\n// Results are reported asynchronously whenever setDiff marks the\n// QueryInfo object as dirty, though a call to the QueryManager's\n// broadcastQueries method may trigger the notification before it happens\n// automatically. This class used to be a simple interface type without\n// any field privacy or meaningful methods, which is why it still has so\n// many public fields. The effort to lock down and simplify the QueryInfo\n// interface is ongoing, and further improvements are welcome.\nexport class QueryInfo {\n  listeners = new Set<QueryListener>();\n  document: DocumentNode | null = null;\n  lastRequestId = 1;\n  variables?: Record<string, any>;\n  networkStatus?: NetworkStatus;\n  networkError?: Error | null;\n  graphQLErrors?: ReadonlyArray<GraphQLError>;\n  stopped = false;\n\n  private cache: ApolloCache<any>;\n\n  constructor(\n    queryManager: QueryManager<any>,\n    public readonly queryId = queryManager.generateQueryId()\n  ) {\n    const cache = (this.cache = queryManager.cache);\n\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n\n  public init(query: {\n    document: DocumentNode;\n    variables: Record<string, any> | undefined;\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus?: NetworkStatus;\n    observableQuery?: ObservableQuery<any, any>;\n    lastRequestId?: number;\n  }): this {\n    let networkStatus = query.networkStatus || NetworkStatus.loading;\n    if (\n      this.variables &&\n      this.networkStatus !== NetworkStatus.loading &&\n      !equal(this.variables, query.variables)\n    ) {\n      networkStatus = NetworkStatus.setVariables;\n    }\n\n    if (!equal(query.variables, this.variables)) {\n      this.lastDiff = void 0;\n    }\n\n    Object.assign(this, {\n      document: query.document,\n      variables: query.variables,\n      networkError: null,\n      graphQLErrors: this.graphQLErrors || [],\n      networkStatus,\n    });\n\n    if (query.observableQuery) {\n      this.setObservableQuery(query.observableQuery);\n    }\n\n    if (query.lastRequestId) {\n      this.lastRequestId = query.lastRequestId;\n    }\n\n    return this;\n  }\n\n  private dirty: boolean = false;\n\n  private notifyTimeout?: ReturnType<typeof setTimeout>;\n\n  reset() {\n    cancelNotifyTimeout(this);\n    this.dirty = false;\n  }\n\n  getDiff(): Cache.DiffResult<any> {\n    const options = this.getDiffOptions();\n\n    if (this.lastDiff && equal(options, this.lastDiff.options)) {\n      return this.lastDiff.diff;\n    }\n\n    this.updateWatch(this.variables);\n\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return { complete: false };\n    }\n\n    const diff = this.cache.diff(options);\n    this.updateLastDiff(diff, options);\n    return diff;\n  }\n\n  private lastDiff?: {\n    diff: Cache.DiffResult<any>;\n    options: Cache.DiffOptions;\n  };\n\n  private updateLastDiff(\n    diff: Cache.DiffResult<any> | null,\n    options?: Cache.DiffOptions\n  ) {\n    this.lastDiff =\n      diff ?\n        {\n          diff,\n          options: options || this.getDiffOptions(),\n        }\n      : void 0;\n  }\n\n  private getDiffOptions(variables = this.variables): Cache.DiffOptions {\n    return {\n      query: this.document!,\n      variables,\n      returnPartialData: true,\n      optimistic: true,\n      canonizeResults: this.observableQuery?.options.canonizeResults,\n    };\n  }\n\n  setDiff(diff: Cache.DiffResult<any> | null) {\n    const oldDiff = this.lastDiff && this.lastDiff.diff;\n    this.updateLastDiff(diff);\n    if (!this.dirty && !equal(oldDiff && oldDiff.result, diff && diff.result)) {\n      this.dirty = true;\n      if (!this.notifyTimeout) {\n        this.notifyTimeout = setTimeout(() => this.notify(), 0);\n      }\n    }\n  }\n\n  public readonly observableQuery: ObservableQuery<any, any> | null = null;\n  private oqListener?: QueryListener;\n\n  setObservableQuery(oq: ObservableQuery<any, any> | null) {\n    if (oq === this.observableQuery) return;\n\n    if (this.oqListener) {\n      this.listeners.delete(this.oqListener);\n    }\n\n    (this as any).observableQuery = oq;\n\n    if (oq) {\n      oq[\"queryInfo\"] = this;\n      this.listeners.add(\n        (this.oqListener = () => {\n          const diff = this.getDiff();\n          if (diff.fromOptimisticTransaction) {\n            // If this diff came from an optimistic transaction, deliver the\n            // current cache data to the ObservableQuery, but don't perform a\n            // reobservation, since oq.reobserveCacheFirst might make a network\n            // request, and we never want to trigger network requests in the\n            // middle of optimistic updates.\n            oq[\"observe\"]();\n          } else {\n            // Otherwise, make the ObservableQuery \"reobserve\" the latest data\n            // using a temporary fetch policy of \"cache-first\", so complete cache\n            // results have a chance to be delivered without triggering additional\n            // network requests, even when options.fetchPolicy is \"network-only\"\n            // or \"cache-and-network\". All other fetch policies are preserved by\n            // this method, and are handled by calling oq.reobserve(). If this\n            // reobservation is spurious, isDifferentFromLastResult still has a\n            // chance to catch it before delivery to ObservableQuery subscribers.\n            reobserveCacheFirst(oq);\n          }\n        })\n      );\n    } else {\n      delete this.oqListener;\n    }\n  }\n\n  notify() {\n    cancelNotifyTimeout(this);\n\n    if (this.shouldNotify()) {\n      this.listeners.forEach((listener) => listener(this));\n    }\n\n    this.dirty = false;\n  }\n\n  private shouldNotify() {\n    if (!this.dirty || !this.listeners.size) {\n      return false;\n    }\n\n    if (isNetworkRequestInFlight(this.networkStatus) && this.observableQuery) {\n      const { fetchPolicy } = this.observableQuery.options;\n      if (fetchPolicy !== \"cache-only\" && fetchPolicy !== \"cache-and-network\") {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  public stop() {\n    if (!this.stopped) {\n      this.stopped = true;\n\n      // Cancel the pending notify timeout\n      this.reset();\n\n      this.cancel();\n      // Revert back to the no-op version of cancel inherited from\n      // QueryInfo.prototype.\n      this.cancel = QueryInfo.prototype.cancel;\n\n      const oq = this.observableQuery;\n      if (oq) oq.stopPolling();\n    }\n  }\n\n  // This method is a no-op by default, until/unless overridden by the\n  // updateWatch method.\n  private cancel() {}\n\n  private lastWatch?: Cache.WatchOptions;\n\n  private updateWatch(variables = this.variables) {\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return;\n    }\n\n    const watchOptions: Cache.WatchOptions = {\n      // Although this.getDiffOptions returns Cache.DiffOptions instead of\n      // Cache.WatchOptions, all the overlapping options should be the same, so\n      // we can reuse getDiffOptions here, for consistency.\n      ...this.getDiffOptions(variables),\n      watcher: this,\n      callback: (diff) => this.setDiff(diff),\n    };\n\n    if (!this.lastWatch || !equal(watchOptions, this.lastWatch)) {\n      this.cancel();\n      this.cancel = this.cache.watch((this.lastWatch = watchOptions));\n    }\n  }\n\n  private lastWrite?: {\n    result: FetchResult<any>;\n    variables: WatchQueryOptions[\"variables\"];\n    dmCount: number | undefined;\n  };\n\n  public resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n\n  private shouldWrite(\n    result: FetchResult<any>,\n    variables: WatchQueryOptions[\"variables\"]\n  ) {\n    const { lastWrite } = this;\n    return !(\n      lastWrite &&\n      // If cache.evict has been called since the last time we wrote this\n      // data into the cache, there's a chance writing this result into\n      // the cache will repair what was evicted.\n      lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n      equal(variables, lastWrite.variables) &&\n      equal(result.data, lastWrite.result.data)\n    );\n  }\n\n  public markResult<T>(\n    result: FetchResult<T>,\n    document: DocumentNode,\n    options: Pick<\n      WatchQueryOptions,\n      \"variables\" | \"fetchPolicy\" | \"errorPolicy\"\n    >,\n    cacheWriteBehavior: CacheWriteBehavior\n  ) {\n    const merger = new DeepMerger();\n    const graphQLErrors =\n      isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.reset();\n\n    if (\"incremental\" in result && isNonEmptyArray(result.incremental)) {\n      const mergedData = mergeIncrementalData(this.getDiff().result, result);\n      result.data = mergedData;\n\n      // Detect the first chunk of a deferred query and merge it with existing\n      // cache data. This ensures a `cache-first` fetch policy that returns\n      // partial cache data or a `cache-and-network` fetch policy that already\n      // has full data in the cache does not complain when trying to merge the\n      // initial deferred server data with existing cache data.\n    } else if (\"hasNext\" in result && result.hasNext) {\n      const diff = this.getDiff();\n      result.data = merger.merge(diff.result, result.data);\n    }\n\n    this.graphQLErrors = graphQLErrors;\n\n    if (options.fetchPolicy === \"no-cache\") {\n      this.updateLastDiff(\n        { result: result.data, complete: true },\n        this.getDiffOptions(options.variables)\n      );\n    } else if (cacheWriteBehavior !== CacheWriteBehavior.FORBID) {\n      if (shouldWriteResult(result, options.errorPolicy)) {\n        // Using a transaction here so we have a chance to read the result\n        // back from the cache before the watch callback fires as a result\n        // of writeQuery, so we can store the new diff quietly and ignore\n        // it when we receive it redundantly from the watch callback.\n        this.cache.performTransaction((cache) => {\n          if (this.shouldWrite(result, options.variables)) {\n            cache.writeQuery({\n              query: document,\n              data: result.data as T,\n              variables: options.variables,\n              overwrite: cacheWriteBehavior === CacheWriteBehavior.OVERWRITE,\n            });\n\n            this.lastWrite = {\n              result,\n              variables: options.variables,\n              dmCount: destructiveMethodCounts.get(this.cache),\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (this.lastDiff && this.lastDiff.diff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result.data = this.lastDiff.diff.result;\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n\n          const diffOptions = this.getDiffOptions(options.variables);\n          const diff = cache.diff<T>(diffOptions);\n\n          // In case the QueryManager stops this QueryInfo before its\n          // results are delivered, it's important to avoid restarting the\n          // cache watch when markResult is called. We also avoid updating\n          // the watch if we are writing a result that doesn't match the current\n          // variables to avoid race conditions from broadcasting the wrong\n          // result.\n          if (!this.stopped && equal(this.variables, options.variables)) {\n            // Any time we're about to update this.diff, we need to make\n            // sure we've started watching the cache.\n            this.updateWatch(options.variables);\n          }\n\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          this.updateLastDiff(diff, diffOptions);\n          if (diff.complete) {\n            result.data = diff.result;\n          }\n        });\n      } else {\n        this.lastWrite = void 0;\n      }\n    }\n  }\n\n  public markReady() {\n    this.networkError = null;\n    return (this.networkStatus = NetworkStatus.ready);\n  }\n\n  public markError(error: ApolloError) {\n    this.networkStatus = NetworkStatus.error;\n    this.lastWrite = void 0;\n\n    this.reset();\n\n    if (error.graphQLErrors) {\n      this.graphQLErrors = error.graphQLErrors;\n    }\n\n    if (error.networkError) {\n      this.networkError = error.networkError;\n    }\n\n    return error;\n  }\n}\n\nexport function shouldWriteResult<T>(\n  result: FetchResult<T>,\n  errorPolicy: ErrorPolicy = \"none\"\n) {\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}\n","import { invariant, newInvariantError } from \"../utilities/globals/index.js\";\n\nimport type { DocumentNode } from \"graphql\";\n// TODO(brian): A hack until this issue is resolved (https://github.com/graphql/graphql-js/issues/3356)\ntype OperationTypeNode = any;\nimport { equal } from \"@wry/equality\";\n\nimport type { ApolloLink, FetchResult } from \"../link/core/index.js\";\nimport { execute } from \"../link/core/index.js\";\nimport {\n  hasDirectives,\n  isExecutionPatchIncrementalResult,\n  isExecutionPatchResult,\n  removeDirectivesFromDocument,\n} from \"../utilities/index.js\";\nimport type { Cache, ApolloCache } from \"../cache/index.js\";\nimport { canonicalStringify } from \"../cache/index.js\";\n\nimport type {\n  ObservableSubscription,\n  ConcastSourcesArray,\n} from \"../utilities/index.js\";\nimport {\n  getDefaultValues,\n  getOperationDefinition,\n  getOperationName,\n  hasClientExports,\n  graphQLResultHasError,\n  getGraphQLErrorsFromResult,\n  canUseWeakMap,\n  Observable,\n  asyncMap,\n  isNonEmptyArray,\n  Concast,\n  makeUniqueId,\n  isDocumentNode,\n  isNonNullObject,\n  DocumentTransform,\n} from \"../utilities/index.js\";\nimport { mergeIncrementalData } from \"../utilities/common/incrementalResult.js\";\nimport {\n  ApolloError,\n  isApolloError,\n  graphQLResultHasProtocolErrors,\n} from \"../errors/index.js\";\nimport type {\n  QueryOptions,\n  WatchQueryOptions,\n  SubscriptionOptions,\n  MutationOptions,\n  ErrorPolicy,\n  MutationFetchPolicy,\n} from \"./watchQueryOptions.js\";\nimport { ObservableQuery, logMissingFieldErrors } from \"./ObservableQuery.js\";\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nimport type {\n  ApolloQueryResult,\n  OperationVariables,\n  MutationUpdaterFunction,\n  OnQueryUpdated,\n  InternalRefetchQueriesInclude,\n  InternalRefetchQueriesOptions,\n  InternalRefetchQueriesResult,\n  InternalRefetchQueriesMap,\n} from \"./types.js\";\nimport { LocalState } from \"./LocalState.js\";\n\nimport type { QueryStoreValue } from \"./QueryInfo.js\";\nimport {\n  QueryInfo,\n  shouldWriteResult,\n  CacheWriteBehavior,\n} from \"./QueryInfo.js\";\nimport type { ApolloErrorOptions } from \"../errors/index.js\";\nimport { PROTOCOL_ERRORS_SYMBOL } from \"../errors/index.js\";\nimport { print } from \"../utilities/index.js\";\nimport type { TODO } from \"../utilities/types/TODO.js\";\n\nconst { hasOwnProperty } = Object.prototype;\n\ninterface MutationStoreValue {\n  mutation: DocumentNode;\n  variables: Record<string, any>;\n  loading: boolean;\n  error: Error | null;\n}\n\ntype UpdateQueries<TData> = MutationOptions<TData, any, any>[\"updateQueries\"];\n\ninterface TransformCacheEntry {\n  hasClientExports: boolean;\n  hasForcedResolvers: boolean;\n  hasNonreactiveDirective: boolean;\n  clientQuery: DocumentNode | null;\n  serverQuery: DocumentNode | null;\n  defaultVars: OperationVariables;\n  asQuery: DocumentNode;\n}\n\nimport type { DefaultOptions } from \"./ApolloClient.js\";\n\nexport class QueryManager<TStore> {\n  public cache: ApolloCache<TStore>;\n  public link: ApolloLink;\n  public defaultOptions: DefaultOptions;\n\n  public readonly assumeImmutableResults: boolean;\n  public readonly documentTransform: DocumentTransform;\n  public readonly ssrMode: boolean;\n\n  private queryDeduplication: boolean;\n  private clientAwareness: Record<string, string> = {};\n  private localState: LocalState<TStore>;\n\n  private onBroadcast?: () => void;\n  public mutationStore?: {\n    [mutationId: string]: MutationStoreValue;\n  };\n\n  // All the queries that the QueryManager is currently managing (not\n  // including mutations and subscriptions).\n  private queries = new Map<string, QueryInfo>();\n\n  // Maps from queryId strings to Promise rejection functions for\n  // currently active queries and fetches.\n  // Use protected instead of private field so\n  // @apollo/experimental-nextjs-app-support can access type info.\n  protected fetchCancelFns = new Map<string, (error: any) => any>();\n\n  constructor({\n    cache,\n    link,\n    defaultOptions,\n    documentTransform,\n    queryDeduplication = false,\n    onBroadcast,\n    ssrMode = false,\n    clientAwareness = {},\n    localState,\n    assumeImmutableResults = !!cache.assumeImmutableResults,\n  }: {\n    cache: ApolloCache<TStore>;\n    link: ApolloLink;\n    defaultOptions?: DefaultOptions;\n    documentTransform?: DocumentTransform;\n    queryDeduplication?: boolean;\n    onBroadcast?: () => void;\n    ssrMode?: boolean;\n    clientAwareness?: Record<string, string>;\n    localState?: LocalState<TStore>;\n    assumeImmutableResults?: boolean;\n  }) {\n    const defaultDocumentTransform = new DocumentTransform(\n      (document) => this.cache.transformDocument(document),\n      // Allow the apollo cache to manage its own transform caches\n      { cache: false }\n    );\n\n    this.cache = cache;\n    this.link = link;\n    this.defaultOptions = defaultOptions || Object.create(null);\n    this.queryDeduplication = queryDeduplication;\n    this.clientAwareness = clientAwareness;\n    this.localState = localState || new LocalState({ cache });\n    this.ssrMode = ssrMode;\n    this.assumeImmutableResults = assumeImmutableResults;\n    this.documentTransform =\n      documentTransform ?\n        defaultDocumentTransform\n          .concat(documentTransform)\n          // The custom document transform may add new fragment spreads or new\n          // field selections, so we want to give the cache a chance to run\n          // again. For example, the InMemoryCache adds __typename to field\n          // selections and fragments from the fragment registry.\n          .concat(defaultDocumentTransform)\n      : defaultDocumentTransform;\n\n    if ((this.onBroadcast = onBroadcast)) {\n      this.mutationStore = Object.create(null);\n    }\n  }\n\n  /**\n   * Call this method to terminate any active query processes, making it safe\n   * to dispose of this QueryManager instance.\n   */\n  public stop() {\n    this.queries.forEach((_info, queryId) => {\n      this.stopQueryNoBroadcast(queryId);\n    });\n\n    this.cancelPendingFetches(\n      newInvariantError(\"QueryManager stopped while query was in flight\")\n    );\n  }\n\n  private cancelPendingFetches(error: Error) {\n    this.fetchCancelFns.forEach((cancel) => cancel(error));\n    this.fetchCancelFns.clear();\n  }\n\n  public async mutate<\n    TData,\n    TVariables extends OperationVariables,\n    TContext extends Record<string, any>,\n    TCache extends ApolloCache<any>,\n  >({\n    mutation,\n    variables,\n    optimisticResponse,\n    updateQueries,\n    refetchQueries = [],\n    awaitRefetchQueries = false,\n    update: updateWithProxyFn,\n    onQueryUpdated,\n    fetchPolicy = this.defaultOptions.mutate?.fetchPolicy || \"network-only\",\n    errorPolicy = this.defaultOptions.mutate?.errorPolicy || \"none\",\n    keepRootFields,\n    context,\n  }: MutationOptions<TData, TVariables, TContext>): Promise<\n    FetchResult<TData>\n  > {\n    invariant(\n      mutation,\n      \"mutation option is required. You must specify your GraphQL document in the mutation option.\"\n    );\n\n    invariant(\n      fetchPolicy === \"network-only\" || fetchPolicy === \"no-cache\",\n      \"Mutations support only 'network-only' or 'no-cache' fetchPolicy strings. The default `network-only` behavior automatically writes mutation results to the cache. Passing `no-cache` skips the cache write.\"\n    );\n\n    const mutationId = this.generateMutationId();\n\n    mutation = this.cache.transformForLink(this.transform(mutation));\n    const { hasClientExports } = this.getDocumentInfo(mutation);\n\n    variables = this.getVariables(mutation, variables) as TVariables;\n    if (hasClientExports) {\n      variables = (await this.localState.addExportedVariables(\n        mutation,\n        variables,\n        context\n      )) as TVariables;\n    }\n\n    const mutationStoreValue =\n      this.mutationStore &&\n      (this.mutationStore[mutationId] = {\n        mutation,\n        variables,\n        loading: true,\n        error: null,\n      } as MutationStoreValue);\n\n    if (optimisticResponse) {\n      this.markMutationOptimistic<TData, TVariables, TContext, TCache>(\n        optimisticResponse,\n        {\n          mutationId,\n          document: mutation,\n          variables,\n          fetchPolicy,\n          errorPolicy,\n          context,\n          updateQueries,\n          update: updateWithProxyFn,\n          keepRootFields,\n        }\n      );\n    }\n\n    this.broadcastQueries();\n\n    const self = this;\n\n    return new Promise((resolve, reject) => {\n      return asyncMap(\n        self.getObservableFromLink(\n          mutation,\n          {\n            ...context,\n            optimisticResponse,\n          },\n          variables,\n          false\n        ),\n\n        (result: FetchResult<TData>) => {\n          if (graphQLResultHasError(result) && errorPolicy === \"none\") {\n            throw new ApolloError({\n              graphQLErrors: getGraphQLErrorsFromResult(result),\n            });\n          }\n\n          if (mutationStoreValue) {\n            mutationStoreValue.loading = false;\n            mutationStoreValue.error = null;\n          }\n\n          const storeResult: typeof result = { ...result };\n\n          if (typeof refetchQueries === \"function\") {\n            refetchQueries = refetchQueries(storeResult);\n          }\n\n          if (errorPolicy === \"ignore\" && graphQLResultHasError(storeResult)) {\n            delete storeResult.errors;\n          }\n\n          return self.markMutationResult<TData, TVariables, TContext, TCache>({\n            mutationId,\n            result: storeResult,\n            document: mutation,\n            variables,\n            fetchPolicy,\n            errorPolicy,\n            context,\n            update: updateWithProxyFn,\n            updateQueries,\n            awaitRefetchQueries,\n            refetchQueries,\n            removeOptimistic: optimisticResponse ? mutationId : void 0,\n            onQueryUpdated,\n            keepRootFields,\n          });\n        }\n      ).subscribe({\n        next(storeResult) {\n          self.broadcastQueries();\n\n          // Since mutations might receive multiple payloads from the\n          // ApolloLink chain (e.g. when used with @defer),\n          // we resolve with a SingleExecutionResult or after the final\n          // ExecutionPatchResult has arrived and we have assembled the\n          // multipart response into a single result.\n          if (!(\"hasNext\" in storeResult) || storeResult.hasNext === false) {\n            resolve(storeResult);\n          }\n        },\n\n        error(err: Error) {\n          if (mutationStoreValue) {\n            mutationStoreValue.loading = false;\n            mutationStoreValue.error = err;\n          }\n\n          if (optimisticResponse) {\n            self.cache.removeOptimistic(mutationId);\n          }\n\n          self.broadcastQueries();\n\n          reject(\n            err instanceof ApolloError ? err : (\n              new ApolloError({\n                networkError: err,\n              })\n            )\n          );\n        },\n      });\n    });\n  }\n\n  public markMutationResult<\n    TData,\n    TVariables,\n    TContext,\n    TCache extends ApolloCache<any>,\n  >(\n    mutation: {\n      mutationId: string;\n      result: FetchResult<TData>;\n      document: DocumentNode;\n      variables?: TVariables;\n      fetchPolicy?: MutationFetchPolicy;\n      errorPolicy: ErrorPolicy;\n      context?: TContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TContext, TCache>;\n      awaitRefetchQueries?: boolean;\n      refetchQueries?: InternalRefetchQueriesInclude;\n      removeOptimistic?: string;\n      onQueryUpdated?: OnQueryUpdated<any>;\n      keepRootFields?: boolean;\n    },\n    cache = this.cache\n  ): Promise<FetchResult<TData>> {\n    let { result } = mutation;\n    const cacheWrites: Cache.WriteOptions[] = [];\n    const skipCache = mutation.fetchPolicy === \"no-cache\";\n\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      if (!isExecutionPatchIncrementalResult(result)) {\n        cacheWrites.push({\n          result: result.data,\n          dataId: \"ROOT_MUTATION\",\n          query: mutation.document,\n          variables: mutation.variables,\n        });\n      }\n      if (\n        isExecutionPatchIncrementalResult(result) &&\n        isNonEmptyArray(result.incremental)\n      ) {\n        const diff = cache.diff<TData>({\n          id: \"ROOT_MUTATION\",\n          // The cache complains if passed a mutation where it expects a\n          // query, so we transform mutations and subscriptions to queries\n          // (only once, thanks to this.transformCache).\n          query: this.getDocumentInfo(mutation.document).asQuery,\n          variables: mutation.variables,\n          optimistic: false,\n          returnPartialData: true,\n        });\n        let mergedData;\n        if (diff.result) {\n          mergedData = mergeIncrementalData(diff.result, result);\n        }\n        if (typeof mergedData !== \"undefined\") {\n          // cast the ExecutionPatchResult to FetchResult here since\n          // ExecutionPatchResult never has `data` when returned from the server\n          (result as FetchResult).data = mergedData;\n          cacheWrites.push({\n            result: mergedData,\n            dataId: \"ROOT_MUTATION\",\n            query: mutation.document,\n            variables: mutation.variables,\n          });\n        }\n      }\n\n      const { updateQueries } = mutation;\n      if (updateQueries) {\n        this.queries.forEach(({ observableQuery }, queryId) => {\n          const queryName = observableQuery && observableQuery.queryName;\n          if (!queryName || !hasOwnProperty.call(updateQueries, queryName)) {\n            return;\n          }\n          const updater = updateQueries[queryName];\n          const { document, variables } = this.queries.get(queryId)!;\n\n          // Read the current query result from the store.\n          const { result: currentQueryResult, complete } = cache.diff<TData>({\n            query: document!,\n            variables,\n            returnPartialData: true,\n            optimistic: false,\n          });\n\n          if (complete && currentQueryResult) {\n            // Run our reducer using the current query result and the mutation result.\n            const nextQueryResult = updater(currentQueryResult, {\n              mutationResult: result,\n              queryName: (document && getOperationName(document)) || void 0,\n              queryVariables: variables!,\n            });\n\n            // Write the modified result back into the store if we got a new result.\n            if (nextQueryResult) {\n              cacheWrites.push({\n                result: nextQueryResult,\n                dataId: \"ROOT_QUERY\",\n                query: document!,\n                variables,\n              });\n            }\n          }\n        });\n      }\n    }\n\n    if (\n      cacheWrites.length > 0 ||\n      mutation.refetchQueries ||\n      mutation.update ||\n      mutation.onQueryUpdated ||\n      mutation.removeOptimistic\n    ) {\n      const results: any[] = [];\n\n      this.refetchQueries({\n        updateCache: (cache) => {\n          if (!skipCache) {\n            cacheWrites.forEach((write) => cache.write(write));\n          }\n\n          // If the mutation has some writes associated with it then we need to\n          // apply those writes to the store by running this reducer again with\n          // a write action.\n          const { update } = mutation;\n          // Determine whether result is a SingleExecutionResult,\n          // or the final ExecutionPatchResult.\n          const isFinalResult =\n            !isExecutionPatchResult(result) ||\n            (isExecutionPatchIncrementalResult(result) && !result.hasNext);\n\n          if (update) {\n            if (!skipCache) {\n              // Re-read the ROOT_MUTATION data we just wrote into the cache\n              // (the first cache.write call in the cacheWrites.forEach loop\n              // above), so field read functions have a chance to run for\n              // fields within mutation result objects.\n              const diff = cache.diff<TData>({\n                id: \"ROOT_MUTATION\",\n                // The cache complains if passed a mutation where it expects a\n                // query, so we transform mutations and subscriptions to queries\n                // (only once, thanks to this.transformCache).\n                query: this.getDocumentInfo(mutation.document).asQuery,\n                variables: mutation.variables,\n                optimistic: false,\n                returnPartialData: true,\n              });\n\n              if (diff.complete) {\n                result = { ...(result as FetchResult), data: diff.result };\n                if (\"incremental\" in result) {\n                  delete result.incremental;\n                }\n                if (\"hasNext\" in result) {\n                  delete result.hasNext;\n                }\n              }\n            }\n\n            // If we've received the whole response,\n            // either a SingleExecutionResult or the final ExecutionPatchResult,\n            // call the update function.\n            if (isFinalResult) {\n              update(cache as TCache, result, {\n                context: mutation.context,\n                variables: mutation.variables,\n              });\n            }\n          }\n\n          // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n          // shallow to allow rolling back optimistic evictions.\n          if (!skipCache && !mutation.keepRootFields && isFinalResult) {\n            cache.modify({\n              id: \"ROOT_MUTATION\",\n              fields(value, { fieldName, DELETE }) {\n                return fieldName === \"__typename\" ? value : DELETE;\n              },\n            });\n          }\n        },\n\n        include: mutation.refetchQueries,\n\n        // Write the final mutation.result to the root layer of the cache.\n        optimistic: false,\n\n        // Remove the corresponding optimistic layer at the same time as we\n        // write the final non-optimistic result.\n        removeOptimistic: mutation.removeOptimistic,\n\n        // Let the caller of client.mutate optionally determine the refetching\n        // behavior for watched queries after the mutation.update function runs.\n        // If no onQueryUpdated function was provided for this mutation, pass\n        // null instead of undefined to disable the default refetching behavior.\n        onQueryUpdated: mutation.onQueryUpdated || null,\n      }).forEach((result) => results.push(result));\n\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n\n    return Promise.resolve(result);\n  }\n\n  public markMutationOptimistic<\n    TData,\n    TVariables,\n    TContext,\n    TCache extends ApolloCache<any>,\n  >(\n    optimisticResponse: any,\n    mutation: {\n      mutationId: string;\n      document: DocumentNode;\n      variables?: TVariables;\n      fetchPolicy?: MutationFetchPolicy;\n      errorPolicy: ErrorPolicy;\n      context?: TContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TContext, TCache>;\n      keepRootFields?: boolean;\n    }\n  ) {\n    const data =\n      typeof optimisticResponse === \"function\" ?\n        optimisticResponse(mutation.variables)\n      : optimisticResponse;\n\n    return this.cache.recordOptimisticTransaction((cache) => {\n      try {\n        this.markMutationResult<TData, TVariables, TContext, TCache>(\n          {\n            ...mutation,\n            result: { data },\n          },\n          cache\n        );\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, mutation.mutationId);\n  }\n\n  public fetchQuery<TData, TVars extends OperationVariables>(\n    queryId: string,\n    options: WatchQueryOptions<TVars, TData>,\n    networkStatus?: NetworkStatus\n  ): Promise<ApolloQueryResult<TData>> {\n    return this.fetchConcastWithInfo(queryId, options, networkStatus).concast\n      .promise as TODO;\n  }\n\n  public getQueryStore() {\n    const store: Record<string, QueryStoreValue> = Object.create(null);\n    this.queries.forEach((info, queryId) => {\n      store[queryId] = {\n        variables: info.variables,\n        networkStatus: info.networkStatus,\n        networkError: info.networkError,\n        graphQLErrors: info.graphQLErrors,\n      };\n    });\n    return store;\n  }\n\n  public resetErrors(queryId: string) {\n    const queryInfo = this.queries.get(queryId);\n    if (queryInfo) {\n      queryInfo.networkError = undefined;\n      queryInfo.graphQLErrors = [];\n    }\n  }\n\n  public transform(document: DocumentNode) {\n    return this.documentTransform.transformDocument(document);\n  }\n\n  private transformCache = new (canUseWeakMap ? WeakMap : Map)<\n    DocumentNode,\n    TransformCacheEntry\n  >();\n\n  public getDocumentInfo(document: DocumentNode) {\n    const { transformCache } = this;\n\n    if (!transformCache.has(document)) {\n      const cacheEntry: TransformCacheEntry = {\n        // TODO These three calls (hasClientExports, shouldForceResolvers, and\n        // usesNonreactiveDirective) are performing independent full traversals\n        // of the transformed document. We should consider merging these\n        // traversals into a single pass in the future, though the work is\n        // cached after the first time.\n        hasClientExports: hasClientExports(document),\n        hasForcedResolvers: this.localState.shouldForceResolvers(document),\n        hasNonreactiveDirective: hasDirectives([\"nonreactive\"], document),\n        clientQuery: this.localState.clientQuery(document),\n        serverQuery: removeDirectivesFromDocument(\n          [\n            { name: \"client\", remove: true },\n            { name: \"connection\" },\n            { name: \"nonreactive\" },\n          ],\n          document\n        ),\n        defaultVars: getDefaultValues(\n          getOperationDefinition(document)\n        ) as OperationVariables,\n        // Transform any mutation or subscription operations to query operations\n        // so we can read/write them from/to the cache.\n        asQuery: {\n          ...document,\n          definitions: document.definitions.map((def) => {\n            if (\n              def.kind === \"OperationDefinition\" &&\n              def.operation !== \"query\"\n            ) {\n              return { ...def, operation: \"query\" as OperationTypeNode };\n            }\n            return def;\n          }),\n        },\n      };\n\n      transformCache.set(document, cacheEntry);\n    }\n\n    return transformCache.get(document)!;\n  }\n\n  private getVariables<TVariables>(\n    document: DocumentNode,\n    variables?: TVariables\n  ): OperationVariables {\n    return {\n      ...this.getDocumentInfo(document).defaultVars,\n      ...variables,\n    };\n  }\n\n  public watchQuery<\n    T,\n    TVariables extends OperationVariables = OperationVariables,\n  >(options: WatchQueryOptions<TVariables, T>): ObservableQuery<T, TVariables> {\n    const query = this.transform(options.query);\n\n    // assign variable default values if supplied\n    // NOTE: We don't modify options.query here with the transformed query to\n    // ensure observable.options.query is set to the raw untransformed query.\n    options = {\n      ...options,\n      variables: this.getVariables(query, options.variables) as TVariables,\n    };\n\n    if (typeof options.notifyOnNetworkStatusChange === \"undefined\") {\n      options.notifyOnNetworkStatusChange = false;\n    }\n\n    const queryInfo = new QueryInfo(this);\n    const observable = new ObservableQuery<T, TVariables>({\n      queryManager: this,\n      queryInfo,\n      options,\n    });\n    observable[\"lastQuery\"] = query;\n\n    this.queries.set(observable.queryId, queryInfo);\n\n    // We give queryInfo the transformed query to ensure the first cache diff\n    // uses the transformed query instead of the raw query\n    queryInfo.init({\n      document: query,\n      observableQuery: observable,\n      variables: observable.variables,\n    });\n\n    return observable;\n  }\n\n  public query<TData, TVars extends OperationVariables = OperationVariables>(\n    options: QueryOptions<TVars, TData>,\n    queryId = this.generateQueryId()\n  ): Promise<ApolloQueryResult<TData>> {\n    invariant(\n      options.query,\n      \"query option is required. You must specify your GraphQL document \" +\n        \"in the query option.\"\n    );\n\n    invariant(\n      options.query.kind === \"Document\",\n      'You must wrap the query string in a \"gql\" tag.'\n    );\n\n    invariant(\n      !(options as any).returnPartialData,\n      \"returnPartialData option only supported on watchQuery.\"\n    );\n\n    invariant(\n      !(options as any).pollInterval,\n      \"pollInterval option only supported on watchQuery.\"\n    );\n\n    return this.fetchQuery<TData, TVars>(queryId, {\n      ...options,\n      query: this.transform(options.query),\n    }).finally(() => this.stopQuery(queryId));\n  }\n\n  private queryIdCounter = 1;\n  public generateQueryId() {\n    return String(this.queryIdCounter++);\n  }\n\n  private requestIdCounter = 1;\n  public generateRequestId() {\n    return this.requestIdCounter++;\n  }\n\n  private mutationIdCounter = 1;\n  public generateMutationId() {\n    return String(this.mutationIdCounter++);\n  }\n\n  public stopQueryInStore(queryId: string) {\n    this.stopQueryInStoreNoBroadcast(queryId);\n    this.broadcastQueries();\n  }\n\n  private stopQueryInStoreNoBroadcast(queryId: string) {\n    const queryInfo = this.queries.get(queryId);\n    if (queryInfo) queryInfo.stop();\n  }\n\n  public clearStore(\n    options: Cache.ResetOptions = {\n      discardWatches: true,\n    }\n  ): Promise<void> {\n    // Before we have sent the reset action to the store, we can no longer\n    // rely on the results returned by in-flight requests since these may\n    // depend on values that previously existed in the data portion of the\n    // store. So, we cancel the promises and observers that we have issued\n    // so far and not yet resolved (in the case of queries).\n    this.cancelPendingFetches(\n      newInvariantError(\n        \"Store reset while query was in flight (not completed in link chain)\"\n      )\n    );\n\n    this.queries.forEach((queryInfo) => {\n      if (queryInfo.observableQuery) {\n        // Set loading to true so listeners don't trigger unless they want\n        // results with partial data.\n        queryInfo.networkStatus = NetworkStatus.loading;\n      } else {\n        queryInfo.stop();\n      }\n    });\n\n    if (this.mutationStore) {\n      this.mutationStore = Object.create(null);\n    }\n\n    // begin removing data from the store\n    return this.cache.reset(options);\n  }\n\n  public getObservableQueries(\n    include: InternalRefetchQueriesInclude = \"active\"\n  ) {\n    const queries = new Map<string, ObservableQuery<any>>();\n    const queryNamesAndDocs = new Map<string | DocumentNode, boolean>();\n    const legacyQueryOptions = new Set<QueryOptions>();\n\n    if (Array.isArray(include)) {\n      include.forEach((desc) => {\n        if (typeof desc === \"string\") {\n          queryNamesAndDocs.set(desc, false);\n        } else if (isDocumentNode(desc)) {\n          queryNamesAndDocs.set(this.transform(desc), false);\n        } else if (isNonNullObject(desc) && desc.query) {\n          legacyQueryOptions.add(desc);\n        }\n      });\n    }\n\n    this.queries.forEach(({ observableQuery: oq, document }, queryId) => {\n      if (oq) {\n        if (include === \"all\") {\n          queries.set(queryId, oq);\n          return;\n        }\n\n        const {\n          queryName,\n          options: { fetchPolicy },\n        } = oq;\n\n        if (\n          fetchPolicy === \"standby\" ||\n          (include === \"active\" && !oq.hasObservers())\n        ) {\n          return;\n        }\n\n        if (\n          include === \"active\" ||\n          (queryName && queryNamesAndDocs.has(queryName)) ||\n          (document && queryNamesAndDocs.has(document))\n        ) {\n          queries.set(queryId, oq);\n          if (queryName) queryNamesAndDocs.set(queryName, true);\n          if (document) queryNamesAndDocs.set(document, true);\n        }\n      }\n    });\n\n    if (legacyQueryOptions.size) {\n      legacyQueryOptions.forEach((options: QueryOptions) => {\n        // We will be issuing a fresh network request for this query, so we\n        // pre-allocate a new query ID here, using a special prefix to enable\n        // cleaning up these temporary queries later, after fetching.\n        const queryId = makeUniqueId(\"legacyOneTimeQuery\");\n        const queryInfo = this.getQuery(queryId).init({\n          document: options.query,\n          variables: options.variables,\n        });\n        const oq = new ObservableQuery({\n          queryManager: this,\n          queryInfo,\n          options: {\n            ...options,\n            fetchPolicy: \"network-only\",\n          },\n        });\n        invariant(oq.queryId === queryId);\n        queryInfo.setObservableQuery(oq);\n        queries.set(queryId, oq);\n      });\n    }\n\n    if (__DEV__ && queryNamesAndDocs.size) {\n      queryNamesAndDocs.forEach((included, nameOrDoc) => {\n        if (!included) {\n          invariant.warn(\n            typeof nameOrDoc === \"string\" ?\n              `Unknown query named \"%s\" requested in refetchQueries options.include array`\n            : `Unknown query %s requested in refetchQueries options.include array`,\n            nameOrDoc\n          );\n        }\n      });\n    }\n\n    return queries;\n  }\n\n  public reFetchObservableQueries(\n    includeStandby: boolean = false\n  ): Promise<ApolloQueryResult<any>[]> {\n    const observableQueryPromises: Promise<ApolloQueryResult<any>>[] = [];\n\n    this.getObservableQueries(includeStandby ? \"all\" : \"active\").forEach(\n      (observableQuery, queryId) => {\n        const { fetchPolicy } = observableQuery.options;\n        observableQuery.resetLastResults();\n        if (\n          includeStandby ||\n          (fetchPolicy !== \"standby\" && fetchPolicy !== \"cache-only\")\n        ) {\n          observableQueryPromises.push(observableQuery.refetch());\n        }\n        this.getQuery(queryId).setDiff(null);\n      }\n    );\n\n    this.broadcastQueries();\n\n    return Promise.all(observableQueryPromises);\n  }\n\n  public setObservableQuery(observableQuery: ObservableQuery<any, any>) {\n    this.getQuery(observableQuery.queryId).setObservableQuery(observableQuery);\n  }\n\n  public startGraphQLSubscription<T = any>({\n    query,\n    fetchPolicy,\n    errorPolicy = \"none\",\n    variables,\n    context = {},\n  }: SubscriptionOptions): Observable<FetchResult<T>> {\n    query = this.transform(query);\n    variables = this.getVariables(query, variables);\n\n    const makeObservable = (variables: OperationVariables) =>\n      this.getObservableFromLink<T>(query, context, variables).map((result) => {\n        if (fetchPolicy !== \"no-cache\") {\n          // the subscription interface should handle not sending us results we no longer subscribe to.\n          // XXX I don't think we ever send in an object with errors, but we might in the future...\n          if (shouldWriteResult(result, errorPolicy)) {\n            this.cache.write({\n              query,\n              result: result.data,\n              dataId: \"ROOT_SUBSCRIPTION\",\n              variables: variables,\n            });\n          }\n\n          this.broadcastQueries();\n        }\n\n        const hasErrors = graphQLResultHasError(result);\n        const hasProtocolErrors = graphQLResultHasProtocolErrors(result);\n        if (hasErrors || hasProtocolErrors) {\n          const errors: ApolloErrorOptions = {};\n          if (hasErrors) {\n            errors.graphQLErrors = result.errors;\n          }\n          if (hasProtocolErrors) {\n            errors.protocolErrors = result.extensions[PROTOCOL_ERRORS_SYMBOL];\n          }\n\n          // `errorPolicy` is a mechanism for handling GraphQL errors, according\n          // to our documentation, so we throw protocol errors regardless of the\n          // set error policy.\n          if (errorPolicy === \"none\" || hasProtocolErrors) {\n            throw new ApolloError(errors);\n          }\n        }\n\n        if (errorPolicy === \"ignore\") {\n          delete result.errors;\n        }\n\n        return result;\n      });\n\n    if (this.getDocumentInfo(query).hasClientExports) {\n      const observablePromise = this.localState\n        .addExportedVariables(query, variables, context)\n        .then(makeObservable);\n\n      return new Observable<FetchResult<T>>((observer) => {\n        let sub: ObservableSubscription | null = null;\n        observablePromise.then(\n          (observable) => (sub = observable.subscribe(observer)),\n          observer.error\n        );\n        return () => sub && sub.unsubscribe();\n      });\n    }\n\n    return makeObservable(variables);\n  }\n\n  public stopQuery(queryId: string) {\n    this.stopQueryNoBroadcast(queryId);\n    this.broadcastQueries();\n  }\n\n  private stopQueryNoBroadcast(queryId: string) {\n    this.stopQueryInStoreNoBroadcast(queryId);\n    this.removeQuery(queryId);\n  }\n\n  public removeQuery(queryId: string) {\n    // teardown all links\n    // Both `QueryManager.fetchRequest` and `QueryManager.query` create separate promises\n    // that each add their reject functions to fetchCancelFns.\n    // A query created with `QueryManager.query()` could trigger a `QueryManager.fetchRequest`.\n    // The same queryId could have two rejection fns for two promises\n    this.fetchCancelFns.delete(queryId);\n    if (this.queries.has(queryId)) {\n      this.getQuery(queryId).stop();\n      this.queries.delete(queryId);\n    }\n  }\n\n  public broadcastQueries() {\n    if (this.onBroadcast) this.onBroadcast();\n    this.queries.forEach((info) => info.notify());\n  }\n\n  public getLocalState(): LocalState<TStore> {\n    return this.localState;\n  }\n\n  // Use protected instead of private field so\n  // @apollo/experimental-nextjs-app-support can access type info.\n  protected inFlightLinkObservables = new Map<\n    string,\n    Map<string, Observable<FetchResult>>\n  >();\n\n  private getObservableFromLink<T = any>(\n    query: DocumentNode,\n    context: any,\n    variables?: OperationVariables,\n    // Prefer context.queryDeduplication if specified.\n    deduplication: boolean = context?.queryDeduplication ??\n      this.queryDeduplication\n  ): Observable<FetchResult<T>> {\n    let observable: Observable<FetchResult<T>>;\n\n    const { serverQuery, clientQuery } = this.getDocumentInfo(query);\n    if (serverQuery) {\n      const { inFlightLinkObservables, link } = this;\n\n      const operation = {\n        query: serverQuery,\n        variables,\n        operationName: getOperationName(serverQuery) || void 0,\n        context: this.prepareContext({\n          ...context,\n          forceFetch: !deduplication,\n        }),\n      };\n\n      context = operation.context;\n\n      if (deduplication) {\n        const printedServerQuery = print(serverQuery);\n        const byVariables =\n          inFlightLinkObservables.get(printedServerQuery) || new Map();\n        inFlightLinkObservables.set(printedServerQuery, byVariables);\n\n        const varJson = canonicalStringify(variables);\n        observable = byVariables.get(varJson);\n\n        if (!observable) {\n          const concast = new Concast([\n            execute(link, operation) as Observable<FetchResult<T>>,\n          ]);\n\n          byVariables.set(varJson, (observable = concast));\n\n          concast.beforeNext(() => {\n            if (byVariables.delete(varJson) && byVariables.size < 1) {\n              inFlightLinkObservables.delete(printedServerQuery);\n            }\n          });\n        }\n      } else {\n        observable = new Concast([\n          execute(link, operation) as Observable<FetchResult<T>>,\n        ]);\n      }\n    } else {\n      observable = new Concast([Observable.of({ data: {} } as FetchResult<T>)]);\n      context = this.prepareContext(context);\n    }\n\n    if (clientQuery) {\n      observable = asyncMap(observable, (result) => {\n        return this.localState.runResolvers({\n          document: clientQuery,\n          remoteResult: result,\n          context,\n          variables,\n        });\n      });\n    }\n\n    return observable;\n  }\n\n  private getResultsFromLink<TData, TVars extends OperationVariables>(\n    queryInfo: QueryInfo,\n    cacheWriteBehavior: CacheWriteBehavior,\n    options: Pick<\n      WatchQueryOptions<TVars, TData>,\n      \"query\" | \"variables\" | \"context\" | \"fetchPolicy\" | \"errorPolicy\"\n    >\n  ): Observable<ApolloQueryResult<TData>> {\n    const requestId = (queryInfo.lastRequestId = this.generateRequestId());\n\n    // Performing transformForLink here gives this.cache a chance to fill in\n    // missing fragment definitions (for example) before sending this document\n    // through the link chain.\n    const linkDocument = this.cache.transformForLink(options.query);\n\n    return asyncMap(\n      this.getObservableFromLink(\n        linkDocument,\n        options.context,\n        options.variables\n      ),\n\n      (result) => {\n        const graphQLErrors = getGraphQLErrorsFromResult(result);\n        const hasErrors = graphQLErrors.length > 0;\n\n        // If we interrupted this request by calling getResultsFromLink again\n        // with the same QueryInfo object, we ignore the old results.\n        if (requestId >= queryInfo.lastRequestId) {\n          if (hasErrors && options.errorPolicy === \"none\") {\n            // Throwing here effectively calls observer.error.\n            throw queryInfo.markError(\n              new ApolloError({\n                graphQLErrors,\n              })\n            );\n          }\n          // Use linkDocument rather than queryInfo.document so the\n          // operation/fragments used to write the result are the same as the\n          // ones used to obtain it from the link.\n          queryInfo.markResult(\n            result,\n            linkDocument,\n            options,\n            cacheWriteBehavior\n          );\n          queryInfo.markReady();\n        }\n\n        const aqr: ApolloQueryResult<TData> = {\n          data: result.data,\n          loading: false,\n          networkStatus: NetworkStatus.ready,\n        };\n\n        if (hasErrors && options.errorPolicy !== \"ignore\") {\n          aqr.errors = graphQLErrors;\n          aqr.networkStatus = NetworkStatus.error;\n        }\n\n        return aqr;\n      },\n\n      (networkError) => {\n        const error =\n          isApolloError(networkError) ? networkError : (\n            new ApolloError({ networkError })\n          );\n\n        // Avoid storing errors from older interrupted queries.\n        if (requestId >= queryInfo.lastRequestId) {\n          queryInfo.markError(error);\n        }\n\n        throw error;\n      }\n    );\n  }\n\n  private fetchConcastWithInfo<TData, TVars extends OperationVariables>(\n    queryId: string,\n    options: WatchQueryOptions<TVars, TData>,\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus = NetworkStatus.loading,\n    query = options.query\n  ): ConcastAndInfo<TData> {\n    const variables = this.getVariables(query, options.variables) as TVars;\n    const queryInfo = this.getQuery(queryId);\n\n    const defaults = this.defaultOptions.watchQuery;\n    let {\n      fetchPolicy = (defaults && defaults.fetchPolicy) || \"cache-first\",\n      errorPolicy = (defaults && defaults.errorPolicy) || \"none\",\n      returnPartialData = false,\n      notifyOnNetworkStatusChange = false,\n      context = {},\n    } = options;\n\n    const normalized = Object.assign({}, options, {\n      query,\n      variables,\n      fetchPolicy,\n      errorPolicy,\n      returnPartialData,\n      notifyOnNetworkStatusChange,\n      context,\n    });\n\n    const fromVariables = (variables: TVars) => {\n      // Since normalized is always a fresh copy of options, it's safe to\n      // modify its properties here, rather than creating yet another new\n      // WatchQueryOptions object.\n      normalized.variables = variables;\n\n      const sourcesWithInfo = this.fetchQueryByPolicy<TData, TVars>(\n        queryInfo,\n        normalized,\n        networkStatus\n      );\n\n      if (\n        // If we're in standby, postpone advancing options.fetchPolicy using\n        // applyNextFetchPolicy.\n        normalized.fetchPolicy !== \"standby\" &&\n        // The \"standby\" policy currently returns [] from fetchQueryByPolicy, so\n        // this is another way to detect when nothing was done/fetched.\n        sourcesWithInfo.sources.length > 0 &&\n        queryInfo.observableQuery\n      ) {\n        queryInfo.observableQuery[\"applyNextFetchPolicy\"](\n          \"after-fetch\",\n          options\n        );\n      }\n\n      return sourcesWithInfo;\n    };\n\n    // This cancel function needs to be set before the concast is created,\n    // in case concast creation synchronously cancels the request.\n    const cleanupCancelFn = () => this.fetchCancelFns.delete(queryId);\n    this.fetchCancelFns.set(queryId, (reason) => {\n      cleanupCancelFn();\n      // This delay ensures the concast variable has been initialized.\n      setTimeout(() => concast.cancel(reason));\n    });\n\n    let concast: Concast<ApolloQueryResult<TData>>,\n      containsDataFromLink: boolean;\n    // If the query has @export(as: ...) directives, then we need to\n    // process those directives asynchronously. When there are no\n    // @export directives (the common case), we deliberately avoid\n    // wrapping the result of this.fetchQueryByPolicy in a Promise,\n    // since the timing of result delivery is (unfortunately) important\n    // for backwards compatibility. TODO This code could be simpler if\n    // we deprecated and removed LocalState.\n    if (this.getDocumentInfo(normalized.query).hasClientExports) {\n      concast = new Concast(\n        this.localState\n          .addExportedVariables(\n            normalized.query,\n            normalized.variables,\n            normalized.context\n          )\n          .then(fromVariables)\n          .then((sourcesWithInfo) => sourcesWithInfo.sources)\n      );\n      // there is just no way we can synchronously get the *right* value here,\n      // so we will assume `true`, which is the behaviour before the bug fix in\n      // #10597. This means that bug is not fixed in that case, and is probably\n      // un-fixable with reasonable effort for the edge case of @export as\n      // directives.\n      containsDataFromLink = true;\n    } else {\n      const sourcesWithInfo = fromVariables(normalized.variables);\n      containsDataFromLink = sourcesWithInfo.fromLink;\n      concast = new Concast(sourcesWithInfo.sources);\n    }\n\n    concast.promise.then(cleanupCancelFn, cleanupCancelFn);\n\n    return {\n      concast,\n      fromLink: containsDataFromLink,\n    };\n  }\n\n  public refetchQueries<TResult>({\n    updateCache,\n    include,\n    optimistic = false,\n    removeOptimistic = optimistic ? makeUniqueId(\"refetchQueries\") : void 0,\n    onQueryUpdated,\n  }: InternalRefetchQueriesOptions<\n    ApolloCache<TStore>,\n    TResult\n  >): InternalRefetchQueriesMap<TResult> {\n    const includedQueriesById = new Map<\n      string,\n      {\n        oq: ObservableQuery<any>;\n        lastDiff?: Cache.DiffResult<any>;\n        diff?: Cache.DiffResult<any>;\n      }\n    >();\n\n    if (include) {\n      this.getObservableQueries(include).forEach((oq, queryId) => {\n        includedQueriesById.set(queryId, {\n          oq,\n          lastDiff: this.getQuery(queryId).getDiff(),\n        });\n      });\n    }\n\n    const results: InternalRefetchQueriesMap<TResult> = new Map();\n\n    if (updateCache) {\n      this.cache.batch({\n        update: updateCache,\n\n        // Since you can perform any combination of cache reads and/or writes in\n        // the cache.batch update function, its optimistic option can be either\n        // a boolean or a string, representing three distinct modes of\n        // operation:\n        //\n        // * false: read/write only the root layer\n        // * true: read/write the topmost layer\n        // * string: read/write a fresh optimistic layer with that ID string\n        //\n        // When typeof optimistic === \"string\", a new optimistic layer will be\n        // temporarily created within cache.batch with that string as its ID. If\n        // we then pass that same string as the removeOptimistic option, we can\n        // make cache.batch immediately remove the optimistic layer after\n        // running the updateCache function, triggering only one broadcast.\n        //\n        // However, the refetchQueries method accepts only true or false for its\n        // optimistic option (not string). We interpret true to mean a temporary\n        // optimistic layer should be created, to allow efficiently rolling back\n        // the effect of the updateCache function, which involves passing a\n        // string instead of true as the optimistic option to cache.batch, when\n        // refetchQueries receives optimistic: true.\n        //\n        // In other words, we are deliberately not supporting the use case of\n        // writing to an *existing* optimistic layer (using the refetchQueries\n        // updateCache function), since that would potentially interfere with\n        // other optimistic updates in progress. Instead, you can read/write\n        // only the root layer by passing optimistic: false to refetchQueries,\n        // or you can read/write a brand new optimistic layer that will be\n        // automatically removed by passing optimistic: true.\n        optimistic: (optimistic && removeOptimistic) || false,\n\n        // The removeOptimistic option can also be provided by itself, even if\n        // optimistic === false, to remove some previously-added optimistic\n        // layer safely and efficiently, like we do in markMutationResult.\n        //\n        // If an explicit removeOptimistic string is provided with optimistic:\n        // true, the removeOptimistic string will determine the ID of the\n        // temporary optimistic layer, in case that ever matters.\n        removeOptimistic,\n\n        onWatchUpdated(watch, diff, lastDiff) {\n          const oq =\n            watch.watcher instanceof QueryInfo && watch.watcher.observableQuery;\n\n          if (oq) {\n            if (onQueryUpdated) {\n              // Since we're about to handle this query now, remove it from\n              // includedQueriesById, in case it was added earlier because of\n              // options.include.\n              includedQueriesById.delete(oq.queryId);\n\n              let result: TResult | boolean | Promise<ApolloQueryResult<any>> =\n                onQueryUpdated(oq, diff, lastDiff);\n\n              if (result === true) {\n                // The onQueryUpdated function requested the default refetching\n                // behavior by returning true.\n                result = oq.refetch();\n              }\n\n              // Record the result in the results Map, as long as onQueryUpdated\n              // did not return false to skip/ignore this result.\n              if (result !== false) {\n                results.set(\n                  oq,\n                  result as InternalRefetchQueriesResult<TResult>\n                );\n              }\n\n              // Allow the default cache broadcast to happen, except when\n              // onQueryUpdated returns false.\n              return result;\n            }\n\n            if (onQueryUpdated !== null) {\n              // If we don't have an onQueryUpdated function, and onQueryUpdated\n              // was not disabled by passing null, make sure this query is\n              // \"included\" like any other options.include-specified query.\n              includedQueriesById.set(oq.queryId, { oq, lastDiff, diff });\n            }\n          }\n        },\n      });\n    }\n\n    if (includedQueriesById.size) {\n      includedQueriesById.forEach(({ oq, lastDiff, diff }, queryId) => {\n        let result:\n          | TResult\n          | boolean\n          | Promise<ApolloQueryResult<any>>\n          | undefined;\n\n        // If onQueryUpdated is provided, we want to use it for all included\n        // queries, even the QueryOptions ones.\n        if (onQueryUpdated) {\n          if (!diff) {\n            const info = oq[\"queryInfo\"];\n            info.reset(); // Force info.getDiff() to read from cache.\n            diff = info.getDiff();\n          }\n          result = onQueryUpdated(oq, diff, lastDiff);\n        }\n\n        // Otherwise, we fall back to refetching.\n        if (!onQueryUpdated || result === true) {\n          result = oq.refetch();\n        }\n\n        if (result !== false) {\n          results.set(oq, result as InternalRefetchQueriesResult<TResult>);\n        }\n\n        if (queryId.indexOf(\"legacyOneTimeQuery\") >= 0) {\n          this.stopQueryNoBroadcast(queryId);\n        }\n      });\n    }\n\n    if (removeOptimistic) {\n      // In case no updateCache callback was provided (so cache.batch was not\n      // called above, and thus did not already remove the optimistic layer),\n      // remove it here. Since this is a no-op when the layer has already been\n      // removed, we do it even if we called cache.batch above, since it's\n      // possible this.cache is an instance of some ApolloCache subclass other\n      // than InMemoryCache, and does not fully support the removeOptimistic\n      // option for cache.batch.\n      this.cache.removeOptimistic(removeOptimistic);\n    }\n\n    return results;\n  }\n\n  private fetchQueryByPolicy<TData, TVars extends OperationVariables>(\n    queryInfo: QueryInfo,\n    {\n      query,\n      variables,\n      fetchPolicy,\n      refetchWritePolicy,\n      errorPolicy,\n      returnPartialData,\n      context,\n      notifyOnNetworkStatusChange,\n    }: WatchQueryOptions<TVars, TData>,\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus: NetworkStatus\n  ): SourcesAndInfo<TData> {\n    const oldNetworkStatus = queryInfo.networkStatus;\n\n    queryInfo.init({\n      document: query,\n      variables,\n      networkStatus,\n    });\n\n    const readCache = () => queryInfo.getDiff();\n\n    const resultsFromCache = (\n      diff: Cache.DiffResult<TData>,\n      networkStatus = queryInfo.networkStatus || NetworkStatus.loading\n    ) => {\n      const data = diff.result;\n\n      if (__DEV__ && !returnPartialData && !equal(data, {})) {\n        logMissingFieldErrors(diff.missing);\n      }\n\n      const fromData = (data: TData | undefined) =>\n        Observable.of({\n          data,\n          loading: isNetworkRequestInFlight(networkStatus),\n          networkStatus,\n          ...(diff.complete ? null : { partial: true }),\n        } as ApolloQueryResult<TData>);\n\n      if (data && this.getDocumentInfo(query).hasForcedResolvers) {\n        return this.localState\n          .runResolvers({\n            document: query,\n            remoteResult: { data },\n            context,\n            variables,\n            onlyRunForcedResolvers: true,\n          })\n          .then((resolved) => fromData(resolved.data || void 0));\n      }\n\n      // Resolves https://github.com/apollographql/apollo-client/issues/10317.\n      // If errorPolicy is 'none' and notifyOnNetworkStatusChange is true,\n      // data was incorrectly returned from the cache on refetch:\n      // if diff.missing exists, we should not return cache data.\n      if (\n        errorPolicy === \"none\" &&\n        networkStatus === NetworkStatus.refetch &&\n        Array.isArray(diff.missing)\n      ) {\n        return fromData(void 0);\n      }\n\n      return fromData(data);\n    };\n\n    const cacheWriteBehavior =\n      fetchPolicy === \"no-cache\" ? CacheWriteBehavior.FORBID\n        // Watched queries must opt into overwriting existing data on refetch,\n        // by passing refetchWritePolicy: \"overwrite\" in their WatchQueryOptions.\n      : (\n        networkStatus === NetworkStatus.refetch &&\n        refetchWritePolicy !== \"merge\"\n      ) ?\n        CacheWriteBehavior.OVERWRITE\n      : CacheWriteBehavior.MERGE;\n\n    const resultsFromLink = () =>\n      this.getResultsFromLink<TData, TVars>(queryInfo, cacheWriteBehavior, {\n        query,\n        variables,\n        context,\n        fetchPolicy,\n        errorPolicy,\n      });\n\n    const shouldNotify =\n      notifyOnNetworkStatusChange &&\n      typeof oldNetworkStatus === \"number\" &&\n      oldNetworkStatus !== networkStatus &&\n      isNetworkRequestInFlight(networkStatus);\n\n    switch (fetchPolicy) {\n      default:\n      case \"cache-first\": {\n        const diff = readCache();\n\n        if (diff.complete) {\n          return {\n            fromLink: false,\n            sources: [resultsFromCache(diff, queryInfo.markReady())],\n          };\n        }\n\n        if (returnPartialData || shouldNotify) {\n          return {\n            fromLink: true,\n            sources: [resultsFromCache(diff), resultsFromLink()],\n          };\n        }\n\n        return { fromLink: true, sources: [resultsFromLink()] };\n      }\n\n      case \"cache-and-network\": {\n        const diff = readCache();\n\n        if (diff.complete || returnPartialData || shouldNotify) {\n          return {\n            fromLink: true,\n            sources: [resultsFromCache(diff), resultsFromLink()],\n          };\n        }\n\n        return { fromLink: true, sources: [resultsFromLink()] };\n      }\n\n      case \"cache-only\":\n        return {\n          fromLink: false,\n          sources: [resultsFromCache(readCache(), queryInfo.markReady())],\n        };\n\n      case \"network-only\":\n        if (shouldNotify) {\n          return {\n            fromLink: true,\n            sources: [resultsFromCache(readCache()), resultsFromLink()],\n          };\n        }\n\n        return { fromLink: true, sources: [resultsFromLink()] };\n\n      case \"no-cache\":\n        if (shouldNotify) {\n          return {\n            fromLink: true,\n            // Note that queryInfo.getDiff() for no-cache queries does not call\n            // cache.diff, but instead returns a { complete: false } stub result\n            // when there is no queryInfo.diff already defined.\n            sources: [resultsFromCache(queryInfo.getDiff()), resultsFromLink()],\n          };\n        }\n\n        return { fromLink: true, sources: [resultsFromLink()] };\n\n      case \"standby\":\n        return { fromLink: false, sources: [] };\n    }\n  }\n\n  private getQuery(queryId: string): QueryInfo {\n    if (queryId && !this.queries.has(queryId)) {\n      this.queries.set(queryId, new QueryInfo(this, queryId));\n    }\n    return this.queries.get(queryId)!;\n  }\n\n  private prepareContext(context = {}) {\n    const newContext = this.localState.prepareContext(context);\n    return {\n      ...newContext,\n      clientAwareness: this.clientAwareness,\n    };\n  }\n}\n\n// Return types used by fetchQueryByPolicy and other private methods above.\ninterface FetchConcastInfo {\n  // Metadata properties that can be returned in addition to the Concast.\n  fromLink: boolean;\n}\ninterface SourcesAndInfo<TData> extends FetchConcastInfo {\n  sources: ConcastSourcesArray<ApolloQueryResult<TData>>;\n}\ninterface ConcastAndInfo<TData> extends FetchConcastInfo {\n  concast: Concast<ApolloQueryResult<TData>>;\n}\n","import equal from \"@wry/equality\";\n\nimport type {\n  DirectiveNode,\n  DocumentNode,\n  FieldNode,\n  FragmentDefinitionNode,\n  FragmentSpreadNode,\n  InlineFragmentNode,\n  SelectionNode,\n  SelectionSetNode,\n} from \"graphql\";\n\nimport type { ApolloQueryResult, OperationVariables } from \"./types.js\";\n\nimport type { FragmentMap } from \"../utilities/index.js\";\nimport {\n  createFragmentMap,\n  getFragmentDefinitions,\n  getFragmentFromSelection,\n  getMainDefinition,\n  isField,\n  resultKeyNameFromField,\n  shouldInclude,\n} from \"../utilities/index.js\";\n\n// Returns true if aResult and bResult are deeply equal according to the fields\n// selected by the given query, ignoring any fields marked as @nonreactive.\nexport function equalByQuery(\n  query: DocumentNode,\n  { data: aData, ...aRest }: Partial<ApolloQueryResult<unknown>>,\n  { data: bData, ...bRest }: Partial<ApolloQueryResult<unknown>>,\n  variables?: OperationVariables\n): boolean {\n  return (\n    equal(aRest, bRest) &&\n    equalBySelectionSet(getMainDefinition(query).selectionSet, aData, bData, {\n      fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      variables,\n    })\n  );\n}\n\n// Encapsulates the information used by equalBySelectionSet that does not change\n// during the recursion.\ninterface CompareContext<TVariables> {\n  fragmentMap: FragmentMap;\n  variables: TVariables | undefined;\n}\n\nfunction equalBySelectionSet(\n  selectionSet: SelectionSetNode,\n  aResult: any,\n  bResult: any,\n  context: CompareContext<OperationVariables>\n): boolean {\n  if (aResult === bResult) {\n    return true;\n  }\n\n  const seenSelections = new Set<SelectionNode>();\n\n  // Returning true from this Array.prototype.every callback function skips the\n  // current field/subtree. Returning false aborts the entire traversal\n  // immediately, causing equalBySelectionSet to return false.\n  return selectionSet.selections.every((selection) => {\n    // Avoid re-processing the same selection at the same level of recursion, in\n    // case the same field gets included via multiple indirect fragment spreads.\n    if (seenSelections.has(selection)) return true;\n    seenSelections.add(selection);\n\n    // Ignore @skip(if: true) and @include(if: false) fields.\n    if (!shouldInclude(selection, context.variables)) return true;\n\n    // If the field or (named) fragment spread has a @nonreactive directive on\n    // it, we don't care if it's different, so we pretend it's the same.\n    if (selectionHasNonreactiveDirective(selection)) return true;\n\n    if (isField(selection)) {\n      const resultKey = resultKeyNameFromField(selection);\n      const aResultChild = aResult && aResult[resultKey];\n      const bResultChild = bResult && bResult[resultKey];\n      const childSelectionSet = selection.selectionSet;\n\n      if (!childSelectionSet) {\n        // These are scalar values, so we can compare them with deep equal\n        // without redoing the main recursive work.\n        return equal(aResultChild, bResultChild);\n      }\n\n      const aChildIsArray = Array.isArray(aResultChild);\n      const bChildIsArray = Array.isArray(bResultChild);\n      if (aChildIsArray !== bChildIsArray) return false;\n      if (aChildIsArray && bChildIsArray) {\n        const length = aResultChild.length;\n        if (bResultChild.length !== length) {\n          return false;\n        }\n        for (let i = 0; i < length; ++i) {\n          if (\n            !equalBySelectionSet(\n              childSelectionSet,\n              aResultChild[i],\n              bResultChild[i],\n              context\n            )\n          ) {\n            return false;\n          }\n        }\n        return true;\n      }\n\n      return equalBySelectionSet(\n        childSelectionSet,\n        aResultChild,\n        bResultChild,\n        context\n      );\n    } else {\n      const fragment = getFragmentFromSelection(selection, context.fragmentMap);\n      if (fragment) {\n        // The fragment might === selection if it's an inline fragment, but\n        // could be !== if it's a named fragment ...spread.\n        if (selectionHasNonreactiveDirective(fragment)) return true;\n\n        return equalBySelectionSet(\n          fragment.selectionSet,\n          // Notice that we reuse the same aResult and bResult values here,\n          // since the fragment ...spread does not specify a field name, but\n          // consists of multiple fields (within the fragment's selection set)\n          // that should be applied to the current result value(s).\n          aResult,\n          bResult,\n          context\n        );\n      }\n    }\n  });\n}\n\nfunction selectionHasNonreactiveDirective(\n  selection:\n    | FieldNode\n    | InlineFragmentNode\n    | FragmentSpreadNode\n    | FragmentDefinitionNode\n): boolean {\n  return (\n    !!selection.directives && selection.directives.some(directiveIsNonreactive)\n  );\n}\n\nfunction directiveIsNonreactive(dir: DirectiveNode): boolean {\n  return dir.name.value === \"nonreactive\";\n}\n","/**\n * The current status of a querys execution in our system.\n */\nexport enum NetworkStatus {\n  /**\n   * The query has never been run before and the query is now currently running. A query will still\n   * have this network status even if a partial data result was returned from the cache, but a\n   * query was dispatched anyway.\n   */\n  loading = 1,\n\n  /**\n   * If `setVariables` was called and a query was fired because of that then the network status\n   * will be `setVariables` until the result of that query comes back.\n   */\n  setVariables = 2,\n\n  /**\n   * Indicates that `fetchMore` was called on this query and that the query created is currently in\n   * flight.\n   */\n  fetchMore = 3,\n\n  /**\n   * Similar to the `setVariables` network status. It means that `refetch` was called on a query\n   * and the refetch request is currently in flight.\n   */\n  refetch = 4,\n\n  /**\n   * Indicates that a polling query is currently in flight. So for example if you are polling a\n   * query every 10 seconds then the network status will switch to `poll` every 10 seconds whenever\n   * a poll request has been sent but not resolved.\n   */\n  poll = 6,\n\n  /**\n   * No request is in flight for this query, and no errors happened. Everything is OK.\n   */\n  ready = 7,\n\n  /**\n   * No request is in flight for this query, but one or more errors were detected.\n   */\n  error = 8,\n}\n\n/**\n * Returns true if there is currently a network request in flight according to a given network\n * status.\n */\nexport function isNetworkRequestInFlight(\n  networkStatus?: NetworkStatus\n): boolean {\n  return networkStatus ? networkStatus < 7 : false;\n}\n\n/**\n * Returns true if the network request is in ready or error state according to a given network\n * status.\n */\nexport function isNetworkRequestSettled(\n  networkStatus?: NetworkStatus\n): boolean {\n  return networkStatus === 7 || networkStatus === 8;\n}\n","import \"../utilities/globals/index.js\";\n\nimport type { GraphQLError, GraphQLErrorExtensions } from \"graphql\";\n\nimport { isNonNullObject } from \"../utilities/index.js\";\nimport type { ServerParseError } from \"../link/http/index.js\";\nimport type { ServerError } from \"../link/utils/index.js\";\nimport type { FetchResult } from \"../link/core/index.js\";\n\n// This Symbol allows us to pass transport-specific errors from the link chain\n// into QueryManager/client internals without risking a naming collision within\n// extensions (which implementers can use as they see fit).\nexport const PROTOCOL_ERRORS_SYMBOL: unique symbol = Symbol();\n\ntype FetchResultWithSymbolExtensions<T> = FetchResult<T> & {\n  extensions: Record<string | symbol, any>;\n};\n\nexport interface ApolloErrorOptions {\n  graphQLErrors?: ReadonlyArray<GraphQLError>;\n  protocolErrors?: ReadonlyArray<{\n    message: string;\n    extensions?: GraphQLErrorExtensions[];\n  }>;\n  clientErrors?: ReadonlyArray<Error>;\n  networkError?: Error | ServerParseError | ServerError | null;\n  errorMessage?: string;\n  extraInfo?: any;\n}\n\nexport function graphQLResultHasProtocolErrors<T>(\n  result: FetchResult<T>\n): result is FetchResultWithSymbolExtensions<T> {\n  if (result.extensions) {\n    return Array.isArray(\n      (result as FetchResultWithSymbolExtensions<T>).extensions[\n        PROTOCOL_ERRORS_SYMBOL\n      ]\n    );\n  }\n  return false;\n}\n\nexport function isApolloError(err: Error): err is ApolloError {\n  return err.hasOwnProperty(\"graphQLErrors\");\n}\n\n// Sets the error message on this error according to the\n// the GraphQL and network errors that are present.\n// If the error message has already been set through the\n// constructor or otherwise, this function is a nop.\nconst generateErrorMessage = (err: ApolloError) => {\n  const errors = [\n    ...err.graphQLErrors,\n    ...err.clientErrors,\n    ...err.protocolErrors,\n  ];\n  if (err.networkError) errors.push(err.networkError);\n  return (\n    errors\n      // The rest of the code sometimes unsafely types non-Error objects as GraphQLErrors\n      .map(\n        (err) =>\n          (isNonNullObject(err) && err.message) || \"Error message not found.\"\n      )\n      .join(\"\\n\")\n  );\n};\n\nexport type GraphQLErrors = ReadonlyArray<GraphQLError>;\n\nexport type NetworkError = Error | ServerParseError | ServerError | null;\n\nexport class ApolloError extends Error {\n  public name: string;\n  public message: string;\n  public graphQLErrors: GraphQLErrors;\n  public protocolErrors: ReadonlyArray<{\n    message: string;\n    extensions?: GraphQLErrorExtensions[];\n  }>;\n  public clientErrors: ReadonlyArray<Error>;\n  public networkError: Error | ServerParseError | ServerError | null;\n\n  // An object that can be used to provide some additional information\n  // about an error, e.g. specifying the type of error this is. Used\n  // internally within Apollo Client.\n  public extraInfo: any;\n\n  // Constructs an instance of ApolloError given a GraphQLError\n  // or a network error. Note that one of these has to be a valid\n  // value or the constructed error will be meaningless.\n  constructor({\n    graphQLErrors,\n    protocolErrors,\n    clientErrors,\n    networkError,\n    errorMessage,\n    extraInfo,\n  }: ApolloErrorOptions) {\n    super(errorMessage);\n    this.name = \"ApolloError\";\n    this.graphQLErrors = graphQLErrors || [];\n    this.protocolErrors = protocolErrors || [];\n    this.clientErrors = clientErrors || [];\n    this.networkError = networkError || null;\n    this.message = errorMessage || generateErrorMessage(this);\n    this.extraInfo = extraInfo;\n\n    // We're not using `Object.setPrototypeOf` here as it isn't fully\n    // supported on Android (see issue #3236).\n    (this as any).__proto__ = ApolloError.prototype;\n  }\n}\n","import { newInvariantError, invariant } from \"../../utilities/globals/index.js\";\n\nimport type { Observer } from \"../../utilities/index.js\";\nimport { Observable } from \"../../utilities/index.js\";\nimport type {\n  NextLink,\n  Operation,\n  RequestHandler,\n  FetchResult,\n  GraphQLRequest,\n} from \"./types.js\";\nimport {\n  validateOperation,\n  createOperation,\n  transformOperation,\n} from \"../utils/index.js\";\n\nfunction passthrough(op: Operation, forward: NextLink) {\n  return (forward ? forward(op) : Observable.of()) as Observable<FetchResult>;\n}\n\nfunction toLink(handler: RequestHandler | ApolloLink) {\n  return typeof handler === \"function\" ? new ApolloLink(handler) : handler;\n}\n\nfunction isTerminating(link: ApolloLink): boolean {\n  return link.request.length <= 1;\n}\n\nexport class ApolloLink {\n  public static empty(): ApolloLink {\n    return new ApolloLink(() => Observable.of());\n  }\n\n  public static from(links: (ApolloLink | RequestHandler)[]): ApolloLink {\n    if (links.length === 0) return ApolloLink.empty();\n    return links.map(toLink).reduce((x, y) => x.concat(y)) as ApolloLink;\n  }\n\n  public static split(\n    test: (op: Operation) => boolean,\n    left: ApolloLink | RequestHandler,\n    right?: ApolloLink | RequestHandler\n  ): ApolloLink {\n    const leftLink = toLink(left);\n    const rightLink = toLink(right || new ApolloLink(passthrough));\n\n    if (isTerminating(leftLink) && isTerminating(rightLink)) {\n      return new ApolloLink((operation) => {\n        return test(operation) ?\n            leftLink.request(operation) || Observable.of()\n          : rightLink.request(operation) || Observable.of();\n      });\n    } else {\n      return new ApolloLink((operation, forward) => {\n        return test(operation) ?\n            leftLink.request(operation, forward) || Observable.of()\n          : rightLink.request(operation, forward) || Observable.of();\n      });\n    }\n  }\n\n  public static execute(\n    link: ApolloLink,\n    operation: GraphQLRequest\n  ): Observable<FetchResult> {\n    return (\n      link.request(\n        createOperation(\n          operation.context,\n          transformOperation(validateOperation(operation))\n        )\n      ) || Observable.of()\n    );\n  }\n\n  public static concat(\n    first: ApolloLink | RequestHandler,\n    second: ApolloLink | RequestHandler\n  ) {\n    const firstLink = toLink(first);\n    if (isTerminating(firstLink)) {\n      invariant.warn(\n        `You are calling concat on a terminating link, which will have no effect %o`,\n        firstLink\n      );\n      return firstLink;\n    }\n    const nextLink = toLink(second);\n\n    if (isTerminating(nextLink)) {\n      return new ApolloLink(\n        (operation) =>\n          firstLink.request(\n            operation,\n            (op) => nextLink.request(op) || Observable.of()\n          ) || Observable.of()\n      );\n    } else {\n      return new ApolloLink((operation, forward) => {\n        return (\n          firstLink.request(operation, (op) => {\n            return nextLink.request(op, forward) || Observable.of();\n          }) || Observable.of()\n        );\n      });\n    }\n  }\n\n  constructor(request?: RequestHandler) {\n    if (request) this.request = request;\n  }\n\n  public split(\n    test: (op: Operation) => boolean,\n    left: ApolloLink | RequestHandler,\n    right?: ApolloLink | RequestHandler\n  ): ApolloLink {\n    return this.concat(\n      ApolloLink.split(test, left, right || new ApolloLink(passthrough))\n    );\n  }\n\n  public concat(next: ApolloLink | RequestHandler): ApolloLink {\n    return ApolloLink.concat(this, next);\n  }\n\n  public request(\n    operation: Operation,\n    forward?: NextLink\n  ): Observable<FetchResult> | null {\n    throw newInvariantError(\"request is not implemented\");\n  }\n\n  protected onError(\n    error: any,\n    observer?: Observer<FetchResult>\n  ): false | void {\n    if (observer && observer.error) {\n      observer.error(error);\n      // Returning false indicates that observer.error does not need to be\n      // called again, since it was already called (on the previous line).\n      // Calling observer.error again would not cause any real problems,\n      // since only the first call matters, but custom onError functions\n      // might have other reasons for wanting to prevent the default\n      // behavior by returning false.\n      return false;\n    }\n    // Throw errors will be passed to observer.error.\n    throw error;\n  }\n\n  public setOnError(fn: ApolloLink[\"onError\"]): this {\n    this.onError = fn;\n    return this;\n  }\n}\n","import { ApolloLink } from \"./ApolloLink.js\";\n\nexport const execute = ApolloLink.execute;\n","import { ApolloLink } from \"../core/index.js\";\nimport type { HttpOptions } from \"./selectHttpOptionsAndBody.js\";\nimport { createHttpLink } from \"./createHttpLink.js\";\n\nexport class HttpLink extends ApolloLink {\n  constructor(public options: HttpOptions = {}) {\n    super(createHttpLink(options).request);\n  }\n}\n","import { newInvariantError } from \"../../utilities/globals/index.js\";\n\nexport const checkFetcher = (fetcher: typeof fetch | undefined) => {\n  if (!fetcher && typeof fetch === \"undefined\") {\n    throw newInvariantError(`\n\"fetch\" has not been found globally and no fetcher has been \\\nconfigured. To fix this, install a fetch package (like \\\nhttps://www.npmjs.com/package/cross-fetch), instantiate the \\\nfetcher, and pass it into your HttpLink constructor. For example:\n\nimport fetch from 'cross-fetch';\nimport { ApolloClient, HttpLink } from '@apollo/client';\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: '/graphql', fetch })\n});\n    `);\n  }\n};\n","import { invariant } from \"../../utilities/globals/index.js\";\n\nimport type { DefinitionNode } from \"graphql\";\n\nimport { ApolloLink } from \"../core/index.js\";\nimport { Observable, hasDirectives } from \"../../utilities/index.js\";\nimport { serializeFetchParameter } from \"./serializeFetchParameter.js\";\nimport { selectURI } from \"./selectURI.js\";\nimport {\n  handleError,\n  readMultipartBody,\n  parseAndCheckHttpResponse,\n} from \"./parseAndCheckHttpResponse.js\";\nimport { checkFetcher } from \"./checkFetcher.js\";\nimport type { HttpOptions } from \"./selectHttpOptionsAndBody.js\";\nimport {\n  selectHttpOptionsAndBodyInternal,\n  defaultPrinter,\n  fallbackHttpConfig,\n} from \"./selectHttpOptionsAndBody.js\";\nimport { rewriteURIForGET } from \"./rewriteURIForGET.js\";\nimport { fromError, filterOperationVariables } from \"../utils/index.js\";\nimport {\n  maybe,\n  getMainDefinition,\n  removeClientSetsFromDocument,\n} from \"../../utilities/index.js\";\n\nconst backupFetch = maybe(() => fetch);\n\nexport const createHttpLink = (linkOptions: HttpOptions = {}) => {\n  let {\n    uri = \"/graphql\",\n    // use default global fetch if nothing passed in\n    fetch: preferredFetch,\n    print = defaultPrinter,\n    includeExtensions,\n    preserveHeaderCase,\n    useGETForQueries,\n    includeUnusedVariables = false,\n    ...requestOptions\n  } = linkOptions;\n\n  if (__DEV__) {\n    // Make sure at least one of preferredFetch, window.fetch, or backupFetch is\n    // defined, so requests won't fail at runtime.\n    checkFetcher(preferredFetch || backupFetch);\n  }\n\n  const linkConfig = {\n    http: { includeExtensions, preserveHeaderCase },\n    options: requestOptions.fetchOptions,\n    credentials: requestOptions.credentials,\n    headers: requestOptions.headers,\n  };\n\n  return new ApolloLink((operation) => {\n    let chosenURI = selectURI(operation, uri);\n\n    const context = operation.getContext();\n\n    // `apollographql-client-*` headers are automatically set if a\n    // `clientAwareness` object is found in the context. These headers are\n    // set first, followed by the rest of the headers pulled from\n    // `context.headers`. If desired, `apollographql-client-*` headers set by\n    // the `clientAwareness` object can be overridden by\n    // `apollographql-client-*` headers set in `context.headers`.\n    const clientAwarenessHeaders: {\n      \"apollographql-client-name\"?: string;\n      \"apollographql-client-version\"?: string;\n    } = {};\n\n    if (context.clientAwareness) {\n      const { name, version } = context.clientAwareness;\n      if (name) {\n        clientAwarenessHeaders[\"apollographql-client-name\"] = name;\n      }\n      if (version) {\n        clientAwarenessHeaders[\"apollographql-client-version\"] = version;\n      }\n    }\n\n    const contextHeaders = { ...clientAwarenessHeaders, ...context.headers };\n\n    const contextConfig = {\n      http: context.http,\n      options: context.fetchOptions,\n      credentials: context.credentials,\n      headers: contextHeaders,\n    };\n\n    if (hasDirectives([\"client\"], operation.query)) {\n      const transformedQuery = removeClientSetsFromDocument(operation.query);\n\n      if (!transformedQuery) {\n        return fromError(\n          new Error(\n            \"HttpLink: Trying to send a client-only query to the server. To send to the server, ensure a non-client field is added to the query or set the `transformOptions.removeClientFields` option to `true`.\"\n          )\n        );\n      }\n\n      operation.query = transformedQuery;\n    }\n\n    //uses fallback, link, and then context to build options\n    const { options, body } = selectHttpOptionsAndBodyInternal(\n      operation,\n      print,\n      fallbackHttpConfig,\n      linkConfig,\n      contextConfig\n    );\n\n    if (body.variables && !includeUnusedVariables) {\n      body.variables = filterOperationVariables(\n        body.variables,\n        operation.query\n      );\n    }\n\n    let controller: AbortController | undefined;\n    if (!options.signal && typeof AbortController !== \"undefined\") {\n      controller = new AbortController();\n      options.signal = controller.signal;\n    }\n\n    // If requested, set method to GET if there are no mutations.\n    const definitionIsMutation = (d: DefinitionNode) => {\n      return d.kind === \"OperationDefinition\" && d.operation === \"mutation\";\n    };\n    const definitionIsSubscription = (d: DefinitionNode) => {\n      return d.kind === \"OperationDefinition\" && d.operation === \"subscription\";\n    };\n    const isSubscription = definitionIsSubscription(\n      getMainDefinition(operation.query)\n    );\n    // does not match custom directives beginning with @defer\n    const hasDefer = hasDirectives([\"defer\"], operation.query);\n    if (\n      useGETForQueries &&\n      !operation.query.definitions.some(definitionIsMutation)\n    ) {\n      options.method = \"GET\";\n    }\n\n    if (hasDefer || isSubscription) {\n      options.headers = options.headers || {};\n      let acceptHeader = \"multipart/mixed;\";\n      // Omit defer-specific headers if the user attempts to defer a selection\n      // set on a subscription and log a warning.\n      if (isSubscription && hasDefer) {\n        invariant.warn(\"Multipart-subscriptions do not support @defer\");\n      }\n\n      if (isSubscription) {\n        acceptHeader +=\n          \"boundary=graphql;subscriptionSpec=1.0,application/json\";\n      } else if (hasDefer) {\n        acceptHeader += \"deferSpec=20220824,application/json\";\n      }\n      options.headers.accept = acceptHeader;\n    }\n\n    if (options.method === \"GET\") {\n      const { newURI, parseError } = rewriteURIForGET(chosenURI, body);\n      if (parseError) {\n        return fromError(parseError);\n      }\n      chosenURI = newURI;\n    } else {\n      try {\n        (options as any).body = serializeFetchParameter(body, \"Payload\");\n      } catch (parseError) {\n        return fromError(parseError);\n      }\n    }\n\n    return new Observable((observer) => {\n      // Prefer linkOptions.fetch (preferredFetch) if provided, and otherwise\n      // fall back to the *current* global window.fetch function (see issue\n      // #7832), or (if all else fails) the backupFetch function we saved when\n      // this module was first evaluated. This last option protects against the\n      // removal of window.fetch, which is unlikely but not impossible.\n      const currentFetch = preferredFetch || maybe(() => fetch) || backupFetch;\n\n      const observerNext = observer.next.bind(observer);\n      currentFetch!(chosenURI, options)\n        .then((response) => {\n          operation.setContext({ response });\n          const ctype = response.headers?.get(\"content-type\");\n\n          if (ctype !== null && /^multipart\\/mixed/i.test(ctype)) {\n            return readMultipartBody(response, observerNext);\n          } else {\n            return parseAndCheckHttpResponse(operation)(response).then(\n              observerNext\n            );\n          }\n        })\n        .then(() => {\n          controller = undefined;\n          observer.complete();\n        })\n        .catch((err) => {\n          controller = undefined;\n          handleError(err, observer);\n        });\n\n      return () => {\n        // XXX support canceling this request\n        // https://developers.google.com/web/updates/2017/09/abortable-fetch\n        if (controller) controller.abort();\n      };\n    });\n  });\n};\n","/**\n * Original source:\n * https://github.com/kmalakoff/response-iterator/blob/master/src/iterators/async.ts\n */\n\nexport default function asyncIterator<T>(\n  source: AsyncIterableIterator<T>\n): AsyncIterableIterator<T> {\n  const iterator = source[Symbol.asyncIterator]();\n  return {\n    next(): Promise<IteratorResult<T, boolean>> {\n      return iterator.next();\n    },\n    [Symbol.asyncIterator](): AsyncIterableIterator<T> {\n      return this;\n    },\n  };\n}\n","/**\n * Original source:\n * https://github.com/kmalakoff/response-iterator/blob/master/src/iterators/nodeStream.ts\n */\n\nimport type { Readable as NodeReadableStream } from \"stream\";\nimport { canUseAsyncIteratorSymbol } from \"../../../utilities/index.js\";\n\ninterface NodeStreamIterator<T> {\n  next(): Promise<IteratorResult<T, boolean | undefined>>;\n  [Symbol.asyncIterator]?(): AsyncIterator<T>;\n}\n\nexport default function nodeStreamIterator<T>(\n  stream: NodeReadableStream\n): AsyncIterableIterator<T> {\n  let cleanup: (() => void) | null = null;\n  let error: Error | null = null;\n  let done = false;\n  const data: unknown[] = [];\n\n  const waiting: [\n    (\n      value:\n        | IteratorResult<T, boolean | undefined>\n        | PromiseLike<IteratorResult<T, boolean | undefined>>\n    ) => void,\n    (reason?: any) => void,\n  ][] = [];\n\n  function onData(chunk: any) {\n    if (error) return;\n    if (waiting.length) {\n      const shiftedArr = waiting.shift();\n      if (Array.isArray(shiftedArr) && shiftedArr[0]) {\n        return shiftedArr[0]({ value: chunk, done: false });\n      }\n    }\n    data.push(chunk);\n  }\n  function onError(err: Error) {\n    error = err;\n    const all = waiting.slice();\n    all.forEach(function (pair) {\n      pair[1](err);\n    });\n    !cleanup || cleanup();\n  }\n  function onEnd() {\n    done = true;\n    const all = waiting.slice();\n    all.forEach(function (pair) {\n      pair[0]({ value: undefined, done: true });\n    });\n    !cleanup || cleanup();\n  }\n\n  cleanup = function () {\n    cleanup = null;\n    stream.removeListener(\"data\", onData);\n    stream.removeListener(\"error\", onError);\n    stream.removeListener(\"end\", onEnd);\n    stream.removeListener(\"finish\", onEnd);\n    stream.removeListener(\"close\", onEnd);\n  };\n  stream.on(\"data\", onData);\n  stream.on(\"error\", onError);\n  stream.on(\"end\", onEnd);\n  stream.on(\"finish\", onEnd);\n  stream.on(\"close\", onEnd);\n\n  function getNext(): Promise<IteratorResult<T, boolean | undefined>> {\n    return new Promise(function (resolve, reject) {\n      if (error) return reject(error);\n      if (data.length)\n        return resolve({ value: data.shift() as T, done: false });\n      if (done) return resolve({ value: undefined, done: true });\n      waiting.push([resolve, reject]);\n    });\n  }\n\n  const iterator: NodeStreamIterator<T> = {\n    next(): Promise<IteratorResult<T, boolean | undefined>> {\n      return getNext();\n    },\n  };\n\n  if (canUseAsyncIteratorSymbol) {\n    iterator[Symbol.asyncIterator] = function (): AsyncIterator<T> {\n      return this;\n    };\n  }\n\n  return iterator as AsyncIterableIterator<T>;\n}\n","/**\n * Original source:\n * https://github.com/kmalakoff/response-iterator/blob/master/src/iterators/promise.ts\n */\n\nimport { canUseAsyncIteratorSymbol } from \"../../../utilities/index.js\";\n\ninterface PromiseIterator<T> {\n  next(): Promise<IteratorResult<T, ArrayBuffer | undefined>>;\n  [Symbol.asyncIterator]?(): AsyncIterator<T>;\n}\n\nexport default function promiseIterator<T = ArrayBuffer>(\n  promise: Promise<ArrayBuffer>\n): AsyncIterableIterator<T> {\n  let resolved = false;\n\n  const iterator: PromiseIterator<T> = {\n    next(): Promise<IteratorResult<T, ArrayBuffer | undefined>> {\n      if (resolved)\n        return Promise.resolve({\n          value: undefined,\n          done: true,\n        });\n      resolved = true;\n      return new Promise(function (resolve, reject) {\n        promise\n          .then(function (value) {\n            resolve({ value: value as unknown as T, done: false });\n          })\n          .catch(reject);\n      });\n    },\n  };\n\n  if (canUseAsyncIteratorSymbol) {\n    iterator[Symbol.asyncIterator] = function (): AsyncIterator<T> {\n      return this;\n    };\n  }\n\n  return iterator as AsyncIterableIterator<T>;\n}\n","/**\n * Original source:\n * https://github.com/kmalakoff/response-iterator/blob/master/src/iterators/reader.ts\n */\n\nimport { canUseAsyncIteratorSymbol } from \"../../../utilities/index.js\";\n\ninterface ReaderIterator<T> {\n  next(): Promise<IteratorResult<T, T | undefined>>;\n  [Symbol.asyncIterator]?(): AsyncIterator<T>;\n}\n\nexport default function readerIterator<T>(\n  reader: ReadableStreamDefaultReader<T>\n): AsyncIterableIterator<T> {\n  const iterator: ReaderIterator<T> = {\n    next() {\n      return reader.read() as Promise<\n        | ReadableStreamReadValueResult<T>\n        // DoneResult has `value` optional, which doesn't comply with an\n        // `IteratorResult`, so we assert it to `T | undefined` instead\n        | Required<ReadableStreamReadDoneResult<T | undefined>>\n      >;\n    },\n  };\n\n  if (canUseAsyncIteratorSymbol) {\n    iterator[Symbol.asyncIterator] = function (): AsyncIterator<\n      T,\n      T | undefined\n    > {\n      return this;\n    };\n  }\n\n  return iterator as AsyncIterableIterator<T>;\n}\n","import { responseIterator } from \"./responseIterator.js\";\nimport type { Operation } from \"../core/index.js\";\nimport { throwServerError } from \"../utils/index.js\";\nimport { PROTOCOL_ERRORS_SYMBOL } from \"../../errors/index.js\";\nimport { isApolloPayloadResult } from \"../../utilities/common/incrementalResult.js\";\nimport type { SubscriptionObserver } from \"zen-observable-ts\";\n\nconst { hasOwnProperty } = Object.prototype;\n\nexport type ServerParseError = Error & {\n  response: Response;\n  statusCode: number;\n  bodyText: string;\n};\n\nexport async function readMultipartBody<\n  T extends object = Record<string, unknown>,\n>(response: Response, nextValue: (value: T) => void) {\n  if (TextDecoder === undefined) {\n    throw new Error(\n      \"TextDecoder must be defined in the environment: please import a polyfill.\"\n    );\n  }\n  const decoder = new TextDecoder(\"utf-8\");\n  const contentType = response.headers?.get(\"content-type\");\n  const delimiter = \"boundary=\";\n\n  // parse boundary value and ignore any subsequent name/value pairs after ;\n  // https://www.rfc-editor.org/rfc/rfc9110.html#name-parameters\n  // e.g. multipart/mixed;boundary=\"graphql\";deferSpec=20220824\n  // if no boundary is specified, default to -\n  const boundaryVal =\n    contentType?.includes(delimiter) ?\n      contentType\n        ?.substring(contentType?.indexOf(delimiter) + delimiter.length)\n        .replace(/['\"]/g, \"\")\n        .replace(/\\;(.*)/gm, \"\")\n        .trim()\n    : \"-\";\n\n  const boundary = `\\r\\n--${boundaryVal}`;\n  let buffer = \"\";\n  const iterator = responseIterator(response);\n  let running = true;\n\n  while (running) {\n    const { value, done } = await iterator.next();\n    const chunk = typeof value === \"string\" ? value : decoder.decode(value);\n    const searchFrom = buffer.length - boundary.length + 1;\n    running = !done;\n    buffer += chunk;\n    let bi = buffer.indexOf(boundary, searchFrom);\n\n    while (bi > -1) {\n      let message: string;\n      [message, buffer] = [\n        buffer.slice(0, bi),\n        buffer.slice(bi + boundary.length),\n      ];\n      const i = message.indexOf(\"\\r\\n\\r\\n\");\n      const headers = parseHeaders(message.slice(0, i));\n      const contentType = headers[\"content-type\"];\n      if (\n        contentType &&\n        contentType.toLowerCase().indexOf(\"application/json\") === -1\n      ) {\n        throw new Error(\n          \"Unsupported patch content type: application/json is required.\"\n        );\n      }\n      // nb: Technically you'd want to slice off the beginning \"\\r\\n\" but since\n      // this is going to be `JSON.parse`d there is no need.\n      const body = message.slice(i);\n\n      if (body) {\n        const result = parseJsonBody<T>(response, body);\n        if (\n          Object.keys(result).length > 1 ||\n          \"data\" in result ||\n          \"incremental\" in result ||\n          \"errors\" in result ||\n          \"payload\" in result\n        ) {\n          if (isApolloPayloadResult(result)) {\n            let next = {};\n            if (\"payload\" in result) {\n              next = { ...result.payload };\n            }\n            if (\"errors\" in result) {\n              next = {\n                ...next,\n                extensions: {\n                  ...(\"extensions\" in next ? next.extensions : (null as any)),\n                  [PROTOCOL_ERRORS_SYMBOL]: result.errors,\n                },\n              };\n            }\n            nextValue(next as T);\n          } else {\n            // for the last chunk with only `hasNext: false`\n            // we don't need to call observer.next as there is no data/errors\n            nextValue(result);\n          }\n        } else if (\n          // If the chunk contains only a \"hasNext: false\", we can call\n          // observer.complete() immediately.\n          Object.keys(result).length === 1 &&\n          \"hasNext\" in result &&\n          !result.hasNext\n        ) {\n          return;\n        }\n      }\n      bi = buffer.indexOf(boundary);\n    }\n  }\n}\n\nexport function parseHeaders(headerText: string): Record<string, string> {\n  const headersInit: Record<string, string> = {};\n  headerText.split(\"\\n\").forEach((line) => {\n    const i = line.indexOf(\":\");\n    if (i > -1) {\n      // normalize headers to lowercase\n      const name = line.slice(0, i).trim().toLowerCase();\n      const value = line.slice(i + 1).trim();\n      headersInit[name] = value;\n    }\n  });\n  return headersInit;\n}\n\nexport function parseJsonBody<T>(response: Response, bodyText: string): T {\n  if (response.status >= 300) {\n    // Network error\n    const getResult = (): Record<string, unknown> | string => {\n      try {\n        return JSON.parse(bodyText);\n      } catch (err) {\n        return bodyText;\n      }\n    };\n    throwServerError(\n      response,\n      getResult(),\n      `Response not successful: Received status code ${response.status}`\n    );\n  }\n\n  try {\n    return JSON.parse(bodyText) as T;\n  } catch (err) {\n    const parseError = err as ServerParseError;\n    parseError.name = \"ServerParseError\";\n    parseError.response = response;\n    parseError.statusCode = response.status;\n    parseError.bodyText = bodyText;\n    throw parseError;\n  }\n}\n\nexport function handleError(err: any, observer: SubscriptionObserver<any>) {\n  // if it is a network error, BUT there is graphql result info fire\n  // the next observer before calling error this gives apollo-client\n  // (and react-apollo) the `graphqlErrors` and `networkErrors` to\n  // pass to UI this should only happen if we *also* have data as\n  // part of the response key per the spec\n  if (err.result && err.result.errors && err.result.data) {\n    // if we don't call next, the UI can only show networkError\n    // because AC didn't get any graphqlErrors this is graphql\n    // execution result info (i.e errors and possibly data) this is\n    // because there is no formal spec how errors should translate to\n    // http status codes. So an auth error (401) could have both data\n    // from a public field, errors from a private field, and a status\n    // of 401\n    // {\n    //  user { // this will have errors\n    //    firstName\n    //  }\n    //  products { // this is public so will have data\n    //    cost\n    //  }\n    // }\n    //\n    // the result of above *could* look like this:\n    // {\n    //   data: { products: [{ cost: \"$10\" }] },\n    //   errors: [{\n    //      message: 'your session has timed out',\n    //      path: []\n    //   }]\n    // }\n    // status code of above would be a 401\n    // in the UI you want to show data where you can, errors as data where you can\n    // and use correct http status codes\n    observer.next(err.result);\n  }\n\n  observer.error(err);\n}\n\nexport function parseAndCheckHttpResponse(operations: Operation | Operation[]) {\n  return (response: Response) =>\n    response\n      .text()\n      .then((bodyText) => parseJsonBody(response, bodyText))\n      .then((result: any) => {\n        if (\n          !Array.isArray(result) &&\n          !hasOwnProperty.call(result, \"data\") &&\n          !hasOwnProperty.call(result, \"errors\")\n        ) {\n          // Data error\n          throwServerError(\n            response,\n            result,\n            `Server response was missing for query '${\n              Array.isArray(operations) ?\n                operations.map((op) => op.operationName)\n              : operations.operationName\n            }'.`\n          );\n        }\n        return result;\n      });\n}\n","/**\n * Original source:\n * https://github.com/kmalakoff/response-iterator/blob/master/src/index.ts\n */\n\nimport type { Response as NodeResponse } from \"node-fetch\";\nimport type { Readable as NodeReadableStream } from \"stream\";\nimport { canUseAsyncIteratorSymbol } from \"../../utilities/index.js\";\n\nimport asyncIterator from \"./iterators/async.js\";\nimport nodeStreamIterator from \"./iterators/nodeStream.js\";\nimport promiseIterator from \"./iterators/promise.js\";\nimport readerIterator from \"./iterators/reader.js\";\n\nfunction isNodeResponse(value: any): value is NodeResponse {\n  return !!(value as NodeResponse).body;\n}\n\nfunction isReadableStream(value: any): value is ReadableStream<any> {\n  return !!(value as ReadableStream<any>).getReader;\n}\n\nfunction isAsyncIterableIterator(\n  value: any\n): value is AsyncIterableIterator<any> {\n  return !!(\n    canUseAsyncIteratorSymbol &&\n    (value as AsyncIterableIterator<any>)[Symbol.asyncIterator]\n  );\n}\n\nfunction isStreamableBlob(value: any): value is Blob {\n  return !!(value as Blob).stream;\n}\n\nfunction isBlob(value: any): value is Blob {\n  return !!(value as Blob).arrayBuffer;\n}\n\nfunction isNodeReadableStream(value: any): value is NodeReadableStream {\n  return !!(value as NodeReadableStream).pipe;\n}\n\nexport function responseIterator<T>(\n  response: Response | NodeResponse\n): AsyncIterableIterator<T> {\n  let body: unknown = response;\n\n  if (isNodeResponse(response)) body = response.body;\n\n  if (isAsyncIterableIterator(body)) return asyncIterator<T>(body);\n\n  if (isReadableStream(body)) return readerIterator<T>(body.getReader());\n\n  // this errors without casting to ReadableStream<T>\n  // because Blob.stream() returns a NodeJS ReadableStream\n  if (isStreamableBlob(body)) {\n    return readerIterator<T>(\n      (body.stream() as unknown as ReadableStream<T>).getReader()\n    );\n  }\n\n  if (isBlob(body)) return promiseIterator<T>(body.arrayBuffer());\n\n  if (isNodeReadableStream(body)) return nodeStreamIterator<T>(body);\n\n  throw new Error(\n    \"Unknown body type for responseIterator. Please pass a streamable response.\"\n  );\n}\n","import { serializeFetchParameter } from \"./serializeFetchParameter.js\";\nimport type { Body } from \"./selectHttpOptionsAndBody.js\";\n\n// For GET operations, returns the given URI rewritten with parameters, or a\n// parse error.\nexport function rewriteURIForGET(chosenURI: string, body: Body) {\n  // Implement the standard HTTP GET serialization, plus 'extensions'. Note\n  // the extra level of JSON serialization!\n  const queryParams: string[] = [];\n  const addQueryParam = (key: string, value: string) => {\n    queryParams.push(`${key}=${encodeURIComponent(value)}`);\n  };\n\n  if (\"query\" in body) {\n    addQueryParam(\"query\", body.query!);\n  }\n  if (body.operationName) {\n    addQueryParam(\"operationName\", body.operationName);\n  }\n  if (body.variables) {\n    let serializedVariables;\n    try {\n      serializedVariables = serializeFetchParameter(\n        body.variables,\n        \"Variables map\"\n      );\n    } catch (parseError) {\n      return { parseError };\n    }\n    addQueryParam(\"variables\", serializedVariables);\n  }\n  if (body.extensions) {\n    let serializedExtensions;\n    try {\n      serializedExtensions = serializeFetchParameter(\n        body.extensions,\n        \"Extensions map\"\n      );\n    } catch (parseError) {\n      return { parseError };\n    }\n    addQueryParam(\"extensions\", serializedExtensions);\n  }\n\n  // Reconstruct the URI with added query params.\n  // XXX This assumes that the URI is well-formed and that it doesn't\n  //     already contain any of these query params. We could instead use the\n  //     URL API and take a polyfill (whatwg-url@6) for older browsers that\n  //     don't support URLSearchParams. Note that some browsers (and\n  //     versions of whatwg-url) support URL but not URLSearchParams!\n  let fragment = \"\",\n    preFragment = chosenURI;\n  const fragmentStart = chosenURI.indexOf(\"#\");\n  if (fragmentStart !== -1) {\n    fragment = chosenURI.substr(fragmentStart);\n    preFragment = chosenURI.substr(0, fragmentStart);\n  }\n  const queryParamsPrefix = preFragment.indexOf(\"?\") === -1 ? \"?\" : \"&\";\n  const newURI =\n    preFragment + queryParamsPrefix + queryParams.join(\"&\") + fragment;\n  return { newURI };\n}\n","import type { ASTNode } from \"graphql\";\nimport { print } from \"../../utilities/index.js\";\n\nimport type { Operation } from \"../core/index.js\";\n\nexport interface Printer {\n  (node: ASTNode, originalPrint: typeof print): string;\n}\n\nexport interface UriFunction {\n  (operation: Operation): string;\n}\n\nexport interface Body {\n  query?: string;\n  operationName?: string;\n  variables?: Record<string, any>;\n  extensions?: Record<string, any>;\n}\n\nexport interface HttpOptions {\n  /**\n   * The URI to use when fetching operations.\n   *\n   * Defaults to '/graphql'.\n   */\n  uri?: string | UriFunction;\n\n  /**\n   * Passes the extensions field to your graphql server.\n   *\n   * Defaults to false.\n   */\n  includeExtensions?: boolean;\n\n  /**\n   * A `fetch`-compatible API to use when making requests.\n   */\n  fetch?: typeof fetch;\n\n  /**\n   * An object representing values to be sent as headers on the request.\n   */\n  headers?: Record<string, string>;\n\n  /**\n   * If set to true, header names won't be automatically normalized to\n   * lowercase. This allows for non-http-spec-compliant servers that might\n   * expect capitalized header names.\n   */\n  preserveHeaderCase?: boolean;\n\n  /**\n   * The credentials policy you want to use for the fetch call.\n   */\n  credentials?: string;\n\n  /**\n   * Any overrides of the fetch options argument to pass to the fetch call.\n   */\n  fetchOptions?: any;\n\n  /**\n   * If set to true, use the HTTP GET method for query operations. Mutations\n   * will still use the method specified in fetchOptions.method (which defaults\n   * to POST).\n   */\n  useGETForQueries?: boolean;\n\n  /**\n   * If set to true, the default behavior of stripping unused variables\n   * from the request will be disabled.\n   *\n   * Unused variables are likely to trigger server-side validation errors,\n   * per https://spec.graphql.org/draft/#sec-All-Variables-Used, but this\n   * includeUnusedVariables option can be useful if your server deviates\n   * from the GraphQL specification by not strictly enforcing that rule.\n   */\n  includeUnusedVariables?: boolean;\n  /**\n   * A function to substitute for the default query print function. Can be\n   * used to apply changes to the results of the print function.\n   */\n  print?: Printer;\n}\n\nexport interface HttpQueryOptions {\n  includeQuery?: boolean;\n  includeExtensions?: boolean;\n  preserveHeaderCase?: boolean;\n}\n\nexport interface HttpConfig {\n  http?: HttpQueryOptions;\n  options?: any;\n  headers?: Record<string, string>;\n  credentials?: any;\n}\n\nconst defaultHttpOptions: HttpQueryOptions = {\n  includeQuery: true,\n  includeExtensions: false,\n  preserveHeaderCase: false,\n};\n\nconst defaultHeaders = {\n  // headers are case insensitive (https://stackoverflow.com/a/5259004)\n  accept: \"*/*\",\n  // The content-type header describes the type of the body of the request, and\n  // so it typically only is sent with requests that actually have bodies. One\n  // could imagine that Apollo Client would remove this header when constructing\n  // a GET request (which has no body), but we historically have not done that.\n  // This means that browsers will preflight all Apollo Client requests (even\n  // GET requests). Apollo Server's CSRF prevention feature (introduced in\n  // AS3.7) takes advantage of this fact and does not block requests with this\n  // header. If you want to drop this header from GET requests, then you should\n  // probably replace it with a `apollo-require-preflight` header, or servers\n  // with CSRF prevention enabled might block your GET request. See\n  // https://www.apollographql.com/docs/apollo-server/security/cors/#preventing-cross-site-request-forgery-csrf\n  // for more details.\n  \"content-type\": \"application/json\",\n};\n\nconst defaultOptions = {\n  method: \"POST\",\n};\n\nexport const fallbackHttpConfig = {\n  http: defaultHttpOptions,\n  headers: defaultHeaders,\n  options: defaultOptions,\n};\n\nexport const defaultPrinter: Printer = (ast, printer) => printer(ast);\n\nexport function selectHttpOptionsAndBody(\n  operation: Operation,\n  fallbackConfig: HttpConfig,\n  ...configs: Array<HttpConfig>\n) {\n  configs.unshift(fallbackConfig);\n  return selectHttpOptionsAndBodyInternal(\n    operation,\n    defaultPrinter,\n    ...configs\n  );\n}\n\nexport function selectHttpOptionsAndBodyInternal(\n  operation: Operation,\n  printer: Printer,\n  ...configs: HttpConfig[]\n) {\n  let options = {} as HttpConfig & Record<string, any>;\n  let http = {} as HttpQueryOptions;\n\n  configs.forEach((config) => {\n    options = {\n      ...options,\n      ...config.options,\n      headers: {\n        ...options.headers,\n        ...config.headers,\n      },\n    };\n\n    if (config.credentials) {\n      options.credentials = config.credentials;\n    }\n\n    http = {\n      ...http,\n      ...config.http,\n    };\n  });\n\n  if (options.headers) {\n    options.headers = removeDuplicateHeaders(\n      options.headers,\n      http.preserveHeaderCase\n    );\n  }\n\n  //The body depends on the http options\n  const { operationName, extensions, variables, query } = operation;\n  const body: Body = { operationName, variables };\n\n  if (http.includeExtensions) (body as any).extensions = extensions;\n\n  // not sending the query (i.e persisted queries)\n  if (http.includeQuery) (body as any).query = printer(query, print);\n\n  return {\n    options,\n    body,\n  };\n}\n\n// Remove potential duplicate header names, preserving last (by insertion order).\n// This is done to prevent unintentionally duplicating a header instead of\n// overwriting it (See #8447 and #8449).\nfunction removeDuplicateHeaders(\n  headers: Record<string, string>,\n  preserveHeaderCase: boolean | undefined\n): typeof headers {\n  // If we're not preserving the case, just remove duplicates w/ normalization.\n  if (!preserveHeaderCase) {\n    const normalizedHeaders = Object.create(null);\n    Object.keys(Object(headers)).forEach((name) => {\n      normalizedHeaders[name.toLowerCase()] = headers[name];\n    });\n    return normalizedHeaders;\n  }\n\n  // If we are preserving the case, remove duplicates w/ normalization,\n  // preserving the original name.\n  // This allows for non-http-spec-compliant servers that expect intentionally\n  // capitalized header names (See #6741).\n  const headerData = Object.create(null);\n  Object.keys(Object(headers)).forEach((name) => {\n    headerData[name.toLowerCase()] = {\n      originalName: name,\n      value: headers[name],\n    };\n  });\n\n  const normalizedHeaders = Object.create(null);\n  Object.keys(headerData).forEach((name) => {\n    normalizedHeaders[headerData[name].originalName] = headerData[name].value;\n  });\n  return normalizedHeaders;\n}\n","import type { Operation } from \"../core/index.js\";\n\nexport const selectURI = (\n  operation: Operation,\n  fallbackURI?: string | ((operation: Operation) => string)\n) => {\n  const context = operation.getContext();\n  const contextURI = context.uri;\n\n  if (contextURI) {\n    return contextURI;\n  } else if (typeof fallbackURI === \"function\") {\n    return fallbackURI(operation);\n  } else {\n    return (fallbackURI as string) || \"/graphql\";\n  }\n};\n","import { newInvariantError } from \"../../utilities/globals/index.js\";\nimport type { InvariantError } from \"../../utilities/globals/index.js\";\n\nexport type ClientParseError = InvariantError & {\n  parseError: Error;\n};\n\nexport const serializeFetchParameter = (p: any, label: string) => {\n  let serialized;\n  try {\n    serialized = JSON.stringify(p);\n  } catch (e: any) {\n    const parseError = newInvariantError(\n      `Network request failed. %s is not serializable: %s`,\n      label,\n      e.message\n    ) as ClientParseError;\n    parseError.parseError = e;\n    throw parseError;\n  }\n  return serialized;\n};\n","import type { GraphQLRequest, Operation } from \"../core/index.js\";\n\nexport function createOperation(\n  starting: any,\n  operation: GraphQLRequest\n): Operation {\n  let context = { ...starting };\n  const setContext = (next: any) => {\n    if (typeof next === \"function\") {\n      context = { ...context, ...next(context) };\n    } else {\n      context = { ...context, ...next };\n    }\n  };\n  const getContext = () => ({ ...context });\n\n  Object.defineProperty(operation, \"setContext\", {\n    enumerable: false,\n    value: setContext,\n  });\n\n  Object.defineProperty(operation, \"getContext\", {\n    enumerable: false,\n    value: getContext,\n  });\n\n  return operation as Operation;\n}\n","import type { VariableDefinitionNode, DocumentNode } from \"graphql\";\nimport { visit } from \"graphql\";\n\nexport function filterOperationVariables(\n  variables: Record<string, any>,\n  query: DocumentNode\n) {\n  const result = { ...variables };\n  const unusedNames = new Set(Object.keys(variables));\n  visit(query, {\n    Variable(node, _key, parent) {\n      // A variable type definition at the top level of a query is not\n      // enough to silence server-side errors about the variable being\n      // unused, so variable definitions do not count as usage.\n      // https://spec.graphql.org/draft/#sec-All-Variables-Used\n      if (\n        parent &&\n        (parent as VariableDefinitionNode).kind !== \"VariableDefinition\"\n      ) {\n        unusedNames.delete(node.name.value);\n      }\n    },\n  });\n  unusedNames.forEach((name) => {\n    delete result![name];\n  });\n  return result;\n}\n","import { Observable } from \"../../utilities/index.js\";\n\nexport function fromError<T>(errorValue: any): Observable<T> {\n  return new Observable<T>((observer) => {\n    observer.error(errorValue);\n  });\n}\n","export type ServerError = Error & {\n  response: Response;\n  result: Record<string, any> | string;\n  statusCode: number;\n};\n\nexport const throwServerError = (\n  response: Response,\n  result: any,\n  message: string\n) => {\n  const error = new Error(message) as ServerError;\n  error.name = \"ServerError\";\n  error.response = response;\n  error.statusCode = response.status;\n  error.result = result;\n  throw error;\n};\n","import type { GraphQLRequest, Operation } from \"../core/index.js\";\nimport { getOperationName } from \"../../utilities/index.js\";\n\nexport function transformOperation(operation: GraphQLRequest): GraphQLRequest {\n  const transformedOperation: GraphQLRequest = {\n    variables: operation.variables || {},\n    extensions: operation.extensions || {},\n    operationName: operation.operationName,\n    query: operation.query,\n  };\n\n  // Best guess at an operation name\n  if (!transformedOperation.operationName) {\n    transformedOperation.operationName =\n      typeof transformedOperation.query !== \"string\" ?\n        getOperationName(transformedOperation.query) || undefined\n      : \"\";\n  }\n\n  return transformedOperation as Operation;\n}\n","import { newInvariantError } from \"../../utilities/globals/index.js\";\nimport type { GraphQLRequest } from \"../core/index.js\";\n\nexport function validateOperation(operation: GraphQLRequest): GraphQLRequest {\n  const OPERATION_FIELDS = [\n    \"query\",\n    \"operationName\",\n    \"variables\",\n    \"extensions\",\n    \"context\",\n  ];\n  for (let key of Object.keys(operation)) {\n    if (OPERATION_FIELDS.indexOf(key) < 0) {\n      throw newInvariantError(`illegal argument: %s`, key);\n    }\n  }\n\n  return operation;\n}\n","// A version of Array.isArray that works better with readonly arrays.\nexport const isArray: (a: any) => a is any[] | readonly any[] = Array.isArray;\n\nexport function isNonEmptyArray<T>(value?: ArrayLike<T>): value is Array<T> {\n  return Array.isArray(value) && value.length > 0;\n}\n","import { maybe } from \"../globals/index.js\";\n\nexport const canUseWeakMap =\n  typeof WeakMap === \"function\" &&\n  maybe(() => navigator.product) !== \"ReactNative\";\n\nexport const canUseWeakSet = typeof WeakSet === \"function\";\n\nexport const canUseSymbol =\n  typeof Symbol === \"function\" && typeof Symbol.for === \"function\";\n\nexport const canUseAsyncIteratorSymbol = canUseSymbol && Symbol.asyncIterator;\n\nexport const canUseDOM =\n  typeof maybe(() => window.document.createElement) === \"function\";\n\nconst usingJSDOM: boolean =\n  // Following advice found in this comment from @domenic (maintainer of jsdom):\n  // https://github.com/jsdom/jsdom/issues/1537#issuecomment-229405327\n  //\n  // Since we control the version of Jest and jsdom used when running Apollo\n  // Client tests, and that version is recent enought to include \" jsdom/x.y.z\"\n  // at the end of the user agent string, I believe this case is all we need to\n  // check. Testing for \"Node.js\" was recommended for backwards compatibility\n  // with older version of jsdom, but we don't have that problem.\n  maybe(() => navigator.userAgent.indexOf(\"jsdom\") >= 0) || false;\n\n// Our tests should all continue to pass if we remove this !usingJSDOM\n// condition, thereby allowing useLayoutEffect when using jsdom. Unfortunately,\n// if we allow useLayoutEffect, then useSyncExternalStore generates many\n// warnings about useLayoutEffect doing nothing on the server. While these\n// warnings are harmless, this !usingJSDOM condition seems to be the best way to\n// prevent them (i.e. skipping useLayoutEffect when using jsdom).\nexport const canUseLayoutEffect = canUseDOM && !usingJSDOM;\n","const { toString } = Object.prototype;\n\n/**\n * Deeply clones a value to create a new instance.\n */\nexport function cloneDeep<T>(value: T): T {\n  return cloneDeepHelper(value);\n}\n\nfunction cloneDeepHelper<T>(val: T, seen?: Map<any, any>): T {\n  switch (toString.call(val)) {\n    case \"[object Array]\": {\n      seen = seen || new Map();\n      if (seen.has(val)) return seen.get(val);\n      const copy: T & any[] = (val as any).slice(0);\n      seen.set(val, copy);\n      copy.forEach(function (child, i) {\n        copy[i] = cloneDeepHelper(child, seen);\n      });\n      return copy;\n    }\n\n    case \"[object Object]\": {\n      seen = seen || new Map();\n      if (seen.has(val)) return seen.get(val);\n      // High fidelity polyfills of Object.create and Object.getPrototypeOf are\n      // possible in all JS environments, so we will assume they exist/work.\n      const copy = Object.create(Object.getPrototypeOf(val));\n      seen.set(val, copy);\n      Object.keys(val as T & Record<string, any>).forEach((key) => {\n        copy[key] = cloneDeepHelper((val as any)[key], seen);\n      });\n      return copy;\n    }\n\n    default:\n      return val;\n  }\n}\n","import type { TupleToIntersection } from \"./mergeDeep.js\";\n\n/**\n * Merges the provided objects shallowly and removes\n * all properties with an `undefined` value\n */\nexport function compact<TArgs extends any[]>(\n  ...objects: TArgs\n): TupleToIntersection<TArgs> {\n  const result = Object.create(null);\n\n  objects.forEach((obj) => {\n    if (!obj) return;\n    Object.keys(obj).forEach((key) => {\n      const value = (obj as any)[key];\n      if (value !== void 0) {\n        result[key] = value;\n      }\n    });\n  });\n\n  return result;\n}\n","import type { FetchResult } from \"../../link/core/index.js\";\nimport { isNonEmptyArray } from \"./arrays.js\";\nimport { isExecutionPatchIncrementalResult } from \"./incrementalResult.js\";\n\nexport function graphQLResultHasError<T>(result: FetchResult<T>): boolean {\n  const errors = getGraphQLErrorsFromResult(result);\n  return isNonEmptyArray(errors);\n}\n\nexport function getGraphQLErrorsFromResult<T>(result: FetchResult<T>) {\n  const graphQLErrors =\n    isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n\n  if (\n    isExecutionPatchIncrementalResult(result) &&\n    isNonEmptyArray(result.incremental)\n  ) {\n    result.incremental.forEach((incrementalResult) => {\n      if (incrementalResult.errors) {\n        graphQLErrors.push(...incrementalResult.errors);\n      }\n    });\n  }\n  return graphQLErrors;\n}\n","import type {\n  ExecutionPatchIncrementalResult,\n  ExecutionPatchInitialResult,\n  ExecutionPatchResult,\n  ApolloPayloadResult,\n  FetchResult,\n} from \"../../link/core/index.js\";\nimport { isNonNullObject } from \"./objects.js\";\nimport { isNonEmptyArray } from \"./arrays.js\";\nimport { DeepMerger } from \"./mergeDeep.js\";\n\nexport function isExecutionPatchIncrementalResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchIncrementalResult {\n  return \"incremental\" in value;\n}\n\nexport function isExecutionPatchInitialResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchInitialResult<T> {\n  return \"hasNext\" in value && \"data\" in value;\n}\n\nexport function isExecutionPatchResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchResult<T> {\n  return (\n    isExecutionPatchIncrementalResult(value) ||\n    isExecutionPatchInitialResult(value)\n  );\n}\n\n// This function detects an Apollo payload result before it is transformed\n// into a FetchResult via HttpLink; it cannot detect an ApolloPayloadResult\n// once it leaves the link chain.\nexport function isApolloPayloadResult(\n  value: unknown\n): value is ApolloPayloadResult {\n  return isNonNullObject(value) && \"payload\" in value;\n}\n\nexport function mergeIncrementalData<TData extends object>(\n  prevResult: TData,\n  result: ExecutionPatchResult<TData>\n) {\n  let mergedData = prevResult;\n  const merger = new DeepMerger();\n  if (\n    isExecutionPatchIncrementalResult(result) &&\n    isNonEmptyArray(result.incremental)\n  ) {\n    result.incremental.forEach(({ data, path }) => {\n      for (let i = path.length - 1; i >= 0; --i) {\n        const key = path[i];\n        const isNumericKey = !isNaN(+key);\n        const parent: Record<string | number, any> = isNumericKey ? [] : {};\n        parent[key] = data;\n        data = parent as typeof data;\n      }\n      mergedData = merger.merge(mergedData, data);\n    });\n  }\n  return mergedData as TData;\n}\n","const prefixCounts = new Map<string, number>();\n\n// These IDs won't be globally unique, but they will be unique within this\n// process, thanks to the counter, and unguessable thanks to the random suffix.\nexport function makeUniqueId(prefix: string) {\n  const count = prefixCounts.get(prefix) || 1;\n  prefixCounts.set(prefix, count + 1);\n  return `${prefix}:${count}:${Math.random().toString(36).slice(2)}`;\n}\n","import { isNonNullObject } from \"./objects.js\";\n\nfunction deepFreeze(value: any) {\n  const workSet = new Set([value]);\n  workSet.forEach((obj) => {\n    if (isNonNullObject(obj) && shallowFreeze(obj) === obj) {\n      Object.getOwnPropertyNames(obj).forEach((name) => {\n        if (isNonNullObject(obj[name])) workSet.add(obj[name]);\n      });\n    }\n  });\n  return value;\n}\n\nfunction shallowFreeze<T extends object>(obj: T): T | null {\n  if (__DEV__ && !Object.isFrozen(obj)) {\n    try {\n      Object.freeze(obj);\n    } catch (e) {\n      // Some types like Uint8Array and Node.js's Buffer cannot be frozen, but\n      // they all throw a TypeError when you try, so we re-throw any exceptions\n      // that are not TypeErrors, since that would be unexpected.\n      if (e instanceof TypeError) return null;\n      throw e;\n    }\n  }\n  return obj;\n}\n\nexport function maybeDeepFreeze<T>(obj: T): T {\n  if (__DEV__) {\n    deepFreeze(obj);\n  }\n  return obj;\n}\n","import { isNonNullObject } from \"./objects.js\";\n\nconst { hasOwnProperty } = Object.prototype;\n\n// These mergeDeep and mergeDeepArray utilities merge any number of objects\n// together, sharing as much memory as possible with the source objects, while\n// remaining careful to avoid modifying any source objects.\n\n// Logically, the return type of mergeDeep should be the intersection of\n// all the argument types. The binary call signature is by far the most\n// common, but we support 0- through 5-ary as well. After that, the\n// resulting type is just the inferred array element type. Note to nerds:\n// there is a more clever way of doing this that converts the tuple type\n// first to a union type (easy enough: T[number]) and then converts the\n// union to an intersection type using distributive conditional type\n// inference, but that approach has several fatal flaws (boolean becomes\n// true & false, and the inferred type ends up as unknown in many cases),\n// in addition to being nearly impossible to explain/understand.\nexport type TupleToIntersection<T extends any[]> =\n  T extends [infer A] ? A\n  : T extends [infer A, infer B] ? A & B\n  : T extends [infer A, infer B, infer C] ? A & B & C\n  : T extends [infer A, infer B, infer C, infer D] ? A & B & C & D\n  : T extends [infer A, infer B, infer C, infer D, infer E] ? A & B & C & D & E\n  : T extends (infer U)[] ? U\n  : any;\n\nexport function mergeDeep<T extends any[]>(\n  ...sources: T\n): TupleToIntersection<T> {\n  return mergeDeepArray(sources);\n}\n\n// In almost any situation where you could succeed in getting the\n// TypeScript compiler to infer a tuple type for the sources array, you\n// could just use mergeDeep instead of mergeDeepArray, so instead of\n// trying to convert T[] to an intersection type we just infer the array\n// element type, which works perfectly when the sources array has a\n// consistent element type.\nexport function mergeDeepArray<T>(sources: T[]): T {\n  let target = sources[0] || ({} as T);\n  const count = sources.length;\n  if (count > 1) {\n    const merger = new DeepMerger();\n    for (let i = 1; i < count; ++i) {\n      target = merger.merge(target, sources[i]);\n    }\n  }\n  return target;\n}\n\nexport type ReconcilerFunction<TContextArgs extends any[]> = (\n  this: DeepMerger<TContextArgs>,\n  target: Record<string | number, any>,\n  source: Record<string | number, any>,\n  property: string | number,\n  ...context: TContextArgs\n) => any;\n\nconst defaultReconciler: ReconcilerFunction<any[]> = function (\n  target,\n  source,\n  property\n) {\n  return this.merge(target[property], source[property]);\n};\n\nexport class DeepMerger<TContextArgs extends any[]> {\n  constructor(\n    private reconciler: ReconcilerFunction<TContextArgs> = defaultReconciler as any as ReconcilerFunction<TContextArgs>\n  ) {}\n\n  public merge(target: any, source: any, ...context: TContextArgs): any {\n    if (isNonNullObject(source) && isNonNullObject(target)) {\n      Object.keys(source).forEach((sourceKey) => {\n        if (hasOwnProperty.call(target, sourceKey)) {\n          const targetValue = target[sourceKey];\n          if (source[sourceKey] !== targetValue) {\n            const result = this.reconciler(\n              target,\n              source,\n              sourceKey,\n              ...context\n            );\n            // A well-implemented reconciler may return targetValue to indicate\n            // the merge changed nothing about the structure of the target.\n            if (result !== targetValue) {\n              target = this.shallowCopyForMerge(target);\n              target[sourceKey] = result;\n            }\n          }\n        } else {\n          // If there is no collision, the target can safely share memory with\n          // the source, and the recursion can terminate here.\n          target = this.shallowCopyForMerge(target);\n          target[sourceKey] = source[sourceKey];\n        }\n      });\n\n      return target;\n    }\n\n    // If source (or target) is not an object, let source replace target.\n    return source;\n  }\n\n  public isObject = isNonNullObject;\n\n  private pastCopies = new Set<any>();\n\n  public shallowCopyForMerge<T>(value: T): T {\n    if (isNonNullObject(value)) {\n      if (!this.pastCopies.has(value)) {\n        if (Array.isArray(value)) {\n          value = (value as any).slice(0);\n        } else {\n          value = {\n            __proto__: Object.getPrototypeOf(value),\n            ...value,\n          };\n        }\n        this.pastCopies.add(value);\n      }\n    }\n    return value;\n  }\n}\n","import type {\n  QueryOptions,\n  WatchQueryOptions,\n  MutationOptions,\n  OperationVariables,\n} from \"../../core/index.js\";\n\nimport { compact } from \"./compact.js\";\n\ntype OptionsUnion<TData, TVariables extends OperationVariables, TContext> =\n  | WatchQueryOptions<TVariables, TData>\n  | QueryOptions<TVariables, TData>\n  | MutationOptions<TData, TVariables, TContext, any>;\n\nexport function mergeOptions<\n  TDefaultOptions extends Partial<OptionsUnion<any, any, any>>,\n  TOptions extends TDefaultOptions,\n>(\n  defaults: TDefaultOptions | Partial<TDefaultOptions> | undefined,\n  options: TOptions | Partial<TOptions>\n): TOptions & TDefaultOptions {\n  return compact(\n    defaults,\n    options,\n    options.variables && {\n      variables: compact({\n        ...(defaults && defaults.variables),\n        ...options.variables,\n      }),\n    }\n  );\n}\n","export function isNonNullObject(obj: any): obj is Record<string | number, any> {\n  return obj !== null && typeof obj === \"object\";\n}\n\nexport function isPlainObject(obj: any): obj is Record<string | number, any> {\n  return (\n    obj !== null &&\n    typeof obj === \"object\" &&\n    (Object.getPrototypeOf(obj) === Object.prototype ||\n      Object.getPrototypeOf(obj) === null)\n  );\n}\n","import { makeUniqueId } from \"./makeUniqueId.js\";\n\nexport function stringifyForDisplay(value: any, space = 0): string {\n  const undefId = makeUniqueId(\"stringifyForDisplay\");\n  return JSON.stringify(\n    value,\n    (key, value) => {\n      return value === void 0 ? undefId : value;\n    },\n    space\n  )\n    .split(JSON.stringify(undefId))\n    .join(\"<undefined>\");\n}\n","import { maybe } from \"./maybe.js\";\n\ndeclare global {\n  const __DEV__: boolean; // will be removed in `dist` by the `postprocessDist` script\n  interface Window {\n    __DEV__?: boolean;\n  }\n}\n\nexport default (maybe(() => globalThis) ||\n  maybe(() => window) ||\n  maybe(() => self) ||\n  maybe(() => global) ||\n  // We don't expect the Function constructor ever to be invoked at runtime, as\n  // long as at least one of globalThis, window, self, or global is defined, so\n  // we are under no obligation to make it easy for static analysis tools to\n  // detect syntactic usage of the Function constructor. If you think you can\n  // improve your static analysis to detect this obfuscation, think again. This\n  // is an arms race you cannot win, at least not in JavaScript.\n  maybe(function () {\n    return maybe.constructor(\"return this\")();\n  })) as typeof globalThis & Window;\n","import {\n  invariant,\n  newInvariantError,\n  InvariantError,\n} from \"./invariantWrappers.js\";\n\nexport { maybe } from \"./maybe.js\";\nexport { default as global } from \"./global.js\";\nexport { invariant, newInvariantError, InvariantError };\n\n/**\n * @deprecated we do not use this internally anymore,\n * it is just exported for backwards compatibility\n */\n// this file is extempt from automatic `__DEV__` replacement\n// so we have to write it out here\n// @ts-ignore\nexport const DEV = globalThis.__DEV__ !== false;\nexport { DEV as __DEV__ };\n","import { invariant as originalInvariant, InvariantError } from \"ts-invariant\";\nimport { version } from \"../../version.js\";\nimport global from \"./global.js\";\nimport type { ErrorCodes } from \"../../invariantErrorCodes.js\";\nimport { stringifyForDisplay } from \"../common/stringifyForDisplay.js\";\n\nfunction wrap(fn: (msg?: string, ...args: any[]) => void) {\n  return function (message?: string | number, ...args: any[]) {\n    if (typeof message === \"number\") {\n      const arg0 = message;\n      message = getHandledErrorMsg(arg0);\n      if (!message) {\n        message = getFallbackErrorMsg(arg0, args);\n        args = [];\n      }\n    }\n    fn(...[message].concat(args));\n  };\n}\n\ntype LogFunction = {\n  /**\n   * Logs a `$level` message if the user used `ts-invariant`'s `setVerbosity` to set\n   * a verbosity level of `$level` or lower. (defaults to `\"log\"`).\n   *\n   * The user will either be presented with a link to the documentation for the message,\n   * or they can use the `loadDevMessages` to add the message strings to the bundle.\n   * The documentation will display the message without argument substitution.\n   * Instead, the arguments will be printed on the console after the link.\n   *\n   * `message` can only be a string, a concatenation of strings, or a ternary statement\n   * that results in a string. This will be enforced on build, where the message will\n   * be replaced with a message number.\n   *\n   * String substitutions like %s, %o, %d or %f are supported.\n   */\n  (message?: any, ...optionalParams: unknown[]): void;\n};\n\ntype WrappedInvariant = {\n  /**\n   * Throws and InvariantError with the given message if the condition is false.\n   *\n   * `message` can only be a string, a concatenation of strings, or a ternary statement\n   * that results in a string. This will be enforced on build, where the message will\n   * be replaced with a message number.\n   *\n   * The user will either be presented with a link to the documentation for the message,\n   * or they can use the `loadErrorMessages` to add the message strings to the bundle.\n   * The documentation will display the message with the arguments substituted.\n   *\n   * String substitutions with %s are supported and will also return\n   * pretty-stringified objects.\n   * Excess `optionalParams` will be swallowed.\n   */\n  (\n    condition: any,\n    message?: string | number,\n    ...optionalParams: unknown[]\n  ): asserts condition;\n\n  debug: LogFunction;\n  log: LogFunction;\n  warn: LogFunction;\n  error: LogFunction;\n};\nconst invariant: WrappedInvariant = Object.assign(\n  function invariant(\n    condition: any,\n    message?: string | number,\n    ...args: unknown[]\n  ): asserts condition {\n    if (!condition) {\n      originalInvariant(\n        condition,\n        getHandledErrorMsg(message, args) || getFallbackErrorMsg(message, args)\n      );\n    }\n  },\n  {\n    debug: wrap(originalInvariant.debug),\n    log: wrap(originalInvariant.log),\n    warn: wrap(originalInvariant.warn),\n    error: wrap(originalInvariant.error),\n  }\n);\n\n/**\n * Returns an InvariantError.\n *\n * `message` can only be a string, a concatenation of strings, or a ternary statement\n * that results in a string. This will be enforced on build, where the message will\n * be replaced with a message number.\n * String substitutions with %s are supported and will also return\n * pretty-stringified objects.\n * Excess `optionalParams` will be swallowed.\n */\nfunction newInvariantError(\n  message?: string | number,\n  ...optionalParams: unknown[]\n) {\n  return new InvariantError(\n    getHandledErrorMsg(message, optionalParams) ||\n      getFallbackErrorMsg(message, optionalParams)\n  );\n}\n\nconst ApolloErrorMessageHandler = Symbol.for(\n  \"ApolloErrorMessageHandler_\" + version\n);\ndeclare global {\n  interface Window {\n    [ApolloErrorMessageHandler]?: {\n      (message: string | number, args: unknown[]): string | undefined;\n    } & ErrorCodes;\n  }\n}\n\nfunction stringify(arg: any) {\n  return typeof arg == \"string\" ? arg : (\n      stringifyForDisplay(arg, 2).slice(0, 1000)\n    );\n}\n\nfunction getHandledErrorMsg(\n  message?: string | number,\n  messageArgs: unknown[] = []\n) {\n  if (!message) return;\n  return (\n    global[ApolloErrorMessageHandler] &&\n    global[ApolloErrorMessageHandler](message, messageArgs.map(stringify))\n  );\n}\n\nfunction getFallbackErrorMsg(\n  message?: string | number,\n  messageArgs: unknown[] = []\n) {\n  if (!message) return;\n  return `An error occurred! For more details, see the full error text at https://go.apollo.dev/c/err#${encodeURIComponent(\n    JSON.stringify({\n      version,\n      message,\n      args: messageArgs.map(stringify),\n    })\n  )}`;\n}\n\nexport {\n  invariant,\n  InvariantError,\n  newInvariantError,\n  ApolloErrorMessageHandler,\n};\n","export function maybe<T>(thunk: () => T): T | undefined {\n  try {\n    return thunk();\n  } catch {}\n}\n","import { Trie } from \"@wry/trie\";\nimport { canUseWeakMap, canUseWeakSet } from \"../common/canUse.js\";\nimport { checkDocument } from \"./getFromAST.js\";\nimport { invariant } from \"../globals/index.js\";\nimport type { DocumentNode } from \"graphql\";\n\nexport type DocumentTransformCacheKey = ReadonlyArray<unknown>;\n\ntype TransformFn = (document: DocumentNode) => DocumentNode;\n\ninterface DocumentTransformOptions {\n  cache?: boolean;\n  getCacheKey?: (\n    document: DocumentNode\n  ) => DocumentTransformCacheKey | undefined;\n}\n\nfunction identity(document: DocumentNode) {\n  return document;\n}\n\nexport class DocumentTransform {\n  private readonly transform: TransformFn;\n\n  private readonly resultCache =\n    canUseWeakSet ? new WeakSet<DocumentNode>() : new Set<DocumentNode>();\n\n  private stableCacheKeys:\n    | Trie<{ key: DocumentTransformCacheKey; value?: DocumentNode }>\n    | undefined;\n\n  // This default implementation of getCacheKey can be overridden by providing\n  // options.getCacheKey to the DocumentTransform constructor. In general, a\n  // getCacheKey function may either return an array of keys (often including\n  // the document) to be used as a cache key, or undefined to indicate the\n  // transform for this document should not be cached.\n  private getCacheKey(\n    document: DocumentNode\n  ): DocumentTransformCacheKey | undefined {\n    return [document];\n  }\n\n  static identity() {\n    // No need to cache this transform since it just returns the document\n    // unchanged. This should save a bit of memory that would otherwise be\n    // needed to populate the `documentCache` of this transform.\n    return new DocumentTransform(identity, { cache: false });\n  }\n\n  static split(\n    predicate: (document: DocumentNode) => boolean,\n    left: DocumentTransform,\n    right: DocumentTransform = DocumentTransform.identity()\n  ) {\n    return new DocumentTransform(\n      (document) => {\n        const documentTransform = predicate(document) ? left : right;\n\n        return documentTransform.transformDocument(document);\n      },\n      // Reasonably assume both `left` and `right` transforms handle their own caching\n      { cache: false }\n    );\n  }\n\n  constructor(\n    transform: TransformFn,\n    options: DocumentTransformOptions = Object.create(null)\n  ) {\n    this.transform = transform;\n\n    if (options.getCacheKey) {\n      // Override default `getCacheKey` function, which returns [document].\n      this.getCacheKey = options.getCacheKey;\n    }\n\n    if (options.cache !== false) {\n      this.stableCacheKeys = new Trie(canUseWeakMap, (key) => ({ key }));\n    }\n  }\n\n  transformDocument(document: DocumentNode) {\n    // If a user passes an already transformed result back to this function,\n    // immediately return it.\n    if (this.resultCache.has(document)) {\n      return document;\n    }\n\n    const cacheEntry = this.getStableCacheEntry(document);\n\n    if (cacheEntry && cacheEntry.value) {\n      return cacheEntry.value;\n    }\n\n    checkDocument(document);\n\n    const transformedDocument = this.transform(document);\n\n    this.resultCache.add(transformedDocument);\n\n    if (cacheEntry) {\n      cacheEntry.value = transformedDocument;\n    }\n\n    return transformedDocument;\n  }\n\n  concat(otherTransform: DocumentTransform) {\n    return new DocumentTransform(\n      (document) => {\n        return otherTransform.transformDocument(\n          this.transformDocument(document)\n        );\n      },\n      // Reasonably assume both transforms handle their own caching\n      { cache: false }\n    );\n  }\n\n  getStableCacheEntry(document: DocumentNode) {\n    if (!this.stableCacheKeys) return;\n    const cacheKeys = this.getCacheKey(document);\n    if (cacheKeys) {\n      invariant(\n        Array.isArray(cacheKeys),\n        \"`getCacheKey` must return an array or undefined\"\n      );\n      return this.stableCacheKeys.lookupArray(cacheKeys);\n    }\n  }\n}\n","import { invariant } from \"../globals/index.js\";\n\n// Provides the methods that allow QueryManager to handle the `skip` and\n// `include` directives within GraphQL.\nimport type {\n  SelectionNode,\n  VariableNode,\n  BooleanValueNode,\n  DirectiveNode,\n  DocumentNode,\n  ArgumentNode,\n  ValueNode,\n  ASTNode,\n} from \"graphql\";\nimport { visit, BREAK } from \"graphql\";\n\nexport type DirectiveInfo = {\n  [fieldName: string]: { [argName: string]: any };\n};\n\nexport function shouldInclude(\n  { directives }: SelectionNode,\n  variables?: Record<string, any>\n): boolean {\n  if (!directives || !directives.length) {\n    return true;\n  }\n  return getInclusionDirectives(directives).every(\n    ({ directive, ifArgument }) => {\n      let evaledValue: boolean = false;\n      if (ifArgument.value.kind === \"Variable\") {\n        evaledValue =\n          variables && variables[(ifArgument.value as VariableNode).name.value];\n        invariant(\n          evaledValue !== void 0,\n          `Invalid variable referenced in @%s directive.`,\n          directive.name.value\n        );\n      } else {\n        evaledValue = (ifArgument.value as BooleanValueNode).value;\n      }\n      return directive.name.value === \"skip\" ? !evaledValue : evaledValue;\n    }\n  );\n}\n\nexport function getDirectiveNames(root: ASTNode) {\n  const names: string[] = [];\n\n  visit(root, {\n    Directive(node: DirectiveNode) {\n      names.push(node.name.value);\n    },\n  });\n\n  return names;\n}\n\nexport const hasAnyDirectives = (names: string[], root: ASTNode) =>\n  hasDirectives(names, root, false);\n\nexport const hasAllDirectives = (names: string[], root: ASTNode) =>\n  hasDirectives(names, root, true);\n\nexport function hasDirectives(names: string[], root: ASTNode, all?: boolean) {\n  const nameSet = new Set(names);\n  const uniqueCount = nameSet.size;\n\n  visit(root, {\n    Directive(node) {\n      if (nameSet.delete(node.name.value) && (!all || !nameSet.size)) {\n        return BREAK;\n      }\n    },\n  });\n\n  // If we found all the names, nameSet will be empty. If we only care about\n  // finding some of them, the < condition is sufficient.\n  return all ? !nameSet.size : nameSet.size < uniqueCount;\n}\n\nexport function hasClientExports(document: DocumentNode) {\n  return document && hasDirectives([\"client\", \"export\"], document, true);\n}\n\nexport type InclusionDirectives = Array<{\n  directive: DirectiveNode;\n  ifArgument: ArgumentNode;\n}>;\n\nfunction isInclusionDirective({ name: { value } }: DirectiveNode): boolean {\n  return value === \"skip\" || value === \"include\";\n}\n\nexport function getInclusionDirectives(\n  directives: ReadonlyArray<DirectiveNode>\n): InclusionDirectives {\n  const result: InclusionDirectives = [];\n\n  if (directives && directives.length) {\n    directives.forEach((directive) => {\n      if (!isInclusionDirective(directive)) return;\n\n      const directiveArguments = directive.arguments;\n      const directiveName = directive.name.value;\n\n      invariant(\n        directiveArguments && directiveArguments.length === 1,\n        `Incorrect number of arguments for the @%s directive.`,\n        directiveName\n      );\n\n      const ifArgument = directiveArguments![0];\n      invariant(\n        ifArgument.name && ifArgument.name.value === \"if\",\n        `Invalid argument for the @%s directive.`,\n        directiveName\n      );\n\n      const ifValue: ValueNode = ifArgument.value;\n\n      // means it has to be a variable value if this is a valid @skip or @include directive\n      invariant(\n        ifValue &&\n          (ifValue.kind === \"Variable\" || ifValue.kind === \"BooleanValue\"),\n        `Argument for the @%s directive must be a variable or a boolean value.`,\n        directiveName\n      );\n\n      result.push({ directive, ifArgument });\n    });\n  }\n\n  return result;\n}\n","import { invariant, newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  FragmentDefinitionNode,\n  InlineFragmentNode,\n  SelectionNode,\n} from \"graphql\";\n\n// TODO(brian): A hack until this issue is resolved (https://github.com/graphql/graphql-js/issues/3356)\ntype Kind = any;\ntype OperationTypeNode = any;\n/**\n * Returns a query document which adds a single query operation that only\n * spreads the target fragment inside of it.\n *\n * So for example a document of:\n *\n * ```graphql\n * fragment foo on Foo { a b c }\n * ```\n *\n * Turns into:\n *\n * ```graphql\n * { ...foo }\n *\n * fragment foo on Foo { a b c }\n * ```\n *\n * The target fragment will either be the only fragment in the document, or a\n * fragment specified by the provided `fragmentName`. If there is more than one\n * fragment, but a `fragmentName` was not defined then an error will be thrown.\n */\nexport function getFragmentQueryDocument(\n  document: DocumentNode,\n  fragmentName?: string\n): DocumentNode {\n  let actualFragmentName = fragmentName;\n\n  // Build an array of all our fragment definitions that will be used for\n  // validations. We also do some validations on the other definitions in the\n  // document while building this list.\n  const fragments: Array<FragmentDefinitionNode> = [];\n  document.definitions.forEach((definition) => {\n    // Throw an error if we encounter an operation definition because we will\n    // define our own operation definition later on.\n    if (definition.kind === \"OperationDefinition\") {\n      throw newInvariantError(\n        `Found a %s operation%s. ` +\n          \"No operations are allowed when using a fragment as a query. Only fragments are allowed.\",\n        definition.operation,\n        definition.name ? ` named '${definition.name.value}'` : \"\"\n      );\n    }\n    // Add our definition to the fragments array if it is a fragment\n    // definition.\n    if (definition.kind === \"FragmentDefinition\") {\n      fragments.push(definition);\n    }\n  });\n\n  // If the user did not give us a fragment name then let us try to get a\n  // name from a single fragment in the definition.\n  if (typeof actualFragmentName === \"undefined\") {\n    invariant(\n      fragments.length === 1,\n      `Found %s fragments. \\`fragmentName\\` must be provided when there is not exactly 1 fragment.`,\n      fragments.length\n    );\n    actualFragmentName = fragments[0].name.value;\n  }\n\n  // Generate a query document with an operation that simply spreads the\n  // fragment inside of it.\n  const query: DocumentNode = {\n    ...document,\n    definitions: [\n      {\n        kind: \"OperationDefinition\" as Kind,\n        // OperationTypeNode is an enum\n        operation: \"query\" as OperationTypeNode,\n        selectionSet: {\n          kind: \"SelectionSet\" as Kind,\n          selections: [\n            {\n              kind: \"FragmentSpread\" as Kind,\n              name: {\n                kind: \"Name\" as Kind,\n                value: actualFragmentName,\n              },\n            },\n          ],\n        },\n      },\n      ...document.definitions,\n    ],\n  };\n\n  return query;\n}\n\n/**\n * This is an interface that describes a map from fragment names to fragment definitions.\n */\nexport interface FragmentMap {\n  [fragmentName: string]: FragmentDefinitionNode;\n}\n\nexport type FragmentMapFunction = (\n  fragmentName: string\n) => FragmentDefinitionNode | null;\n\n// Utility function that takes a list of fragment definitions and makes a hash out of them\n// that maps the name of the fragment to the fragment definition.\nexport function createFragmentMap(\n  fragments: FragmentDefinitionNode[] = []\n): FragmentMap {\n  const symTable: FragmentMap = {};\n  fragments.forEach((fragment) => {\n    symTable[fragment.name.value] = fragment;\n  });\n  return symTable;\n}\n\nexport function getFragmentFromSelection(\n  selection: SelectionNode,\n  fragmentMap?: FragmentMap | FragmentMapFunction\n): InlineFragmentNode | FragmentDefinitionNode | null {\n  switch (selection.kind) {\n    case \"InlineFragment\":\n      return selection;\n    case \"FragmentSpread\": {\n      const fragmentName = selection.name.value;\n      if (typeof fragmentMap === \"function\") {\n        return fragmentMap(fragmentName);\n      }\n      const fragment = fragmentMap && fragmentMap[fragmentName];\n      invariant(fragment, `No fragment named %s`, fragmentName);\n      return fragment || null;\n    }\n    default:\n      return null;\n  }\n}\n","import { invariant, newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  OperationDefinitionNode,\n  FragmentDefinitionNode,\n  ValueNode,\n} from \"graphql\";\n\nimport { valueToObjectRepresentation } from \"./storeUtils.js\";\n\ntype OperationDefinitionWithName = OperationDefinitionNode & {\n  name: NonNullable<OperationDefinitionNode[\"name\"]>;\n};\n\n// Checks the document for errors and throws an exception if there is an error.\nexport function checkDocument(doc: DocumentNode) {\n  invariant(\n    doc && doc.kind === \"Document\",\n    `Expecting a parsed GraphQL document. Perhaps you need to wrap the query \\\nstring in a \"gql\" tag? http://docs.apollostack.com/apollo-client/core.html#gql`\n  );\n\n  const operations = doc.definitions\n    .filter((d) => d.kind !== \"FragmentDefinition\")\n    .map((definition) => {\n      if (definition.kind !== \"OperationDefinition\") {\n        throw newInvariantError(\n          `Schema type definitions not allowed in queries. Found: \"%s\"`,\n          definition.kind\n        );\n      }\n      return definition;\n    });\n\n  invariant(\n    operations.length <= 1,\n    `Ambiguous GraphQL document: contains %s operations`,\n    operations.length\n  );\n\n  return doc;\n}\n\nexport function getOperationDefinition(\n  doc: DocumentNode\n): OperationDefinitionNode | undefined {\n  checkDocument(doc);\n  return doc.definitions.filter(\n    (definition): definition is OperationDefinitionNode =>\n      definition.kind === \"OperationDefinition\"\n  )[0];\n}\n\nexport function getOperationName(doc: DocumentNode): string | null {\n  return (\n    doc.definitions\n      .filter(\n        (definition): definition is OperationDefinitionWithName =>\n          definition.kind === \"OperationDefinition\" && !!definition.name\n      )\n      .map((x) => x.name.value)[0] || null\n  );\n}\n\n// Returns the FragmentDefinitions from a particular document as an array\nexport function getFragmentDefinitions(\n  doc: DocumentNode\n): FragmentDefinitionNode[] {\n  return doc.definitions.filter(\n    (definition): definition is FragmentDefinitionNode =>\n      definition.kind === \"FragmentDefinition\"\n  );\n}\n\nexport function getQueryDefinition(doc: DocumentNode): OperationDefinitionNode {\n  const queryDef = getOperationDefinition(doc)!;\n\n  invariant(\n    queryDef && queryDef.operation === \"query\",\n    \"Must contain a query definition.\"\n  );\n\n  return queryDef;\n}\n\nexport function getFragmentDefinition(\n  doc: DocumentNode\n): FragmentDefinitionNode {\n  invariant(\n    doc.kind === \"Document\",\n    `Expecting a parsed GraphQL document. Perhaps you need to wrap the query \\\nstring in a \"gql\" tag? http://docs.apollostack.com/apollo-client/core.html#gql`\n  );\n\n  invariant(\n    doc.definitions.length <= 1,\n    \"Fragment must have exactly one definition.\"\n  );\n\n  const fragmentDef = doc.definitions[0] as FragmentDefinitionNode;\n\n  invariant(\n    fragmentDef.kind === \"FragmentDefinition\",\n    \"Must be a fragment definition.\"\n  );\n\n  return fragmentDef as FragmentDefinitionNode;\n}\n\n/**\n * Returns the first operation definition found in this document.\n * If no operation definition is found, the first fragment definition will be returned.\n * If no definitions are found, an error will be thrown.\n */\nexport function getMainDefinition(\n  queryDoc: DocumentNode\n): OperationDefinitionNode | FragmentDefinitionNode {\n  checkDocument(queryDoc);\n\n  let fragmentDefinition;\n\n  for (let definition of queryDoc.definitions) {\n    if (definition.kind === \"OperationDefinition\") {\n      const operation = (definition as OperationDefinitionNode).operation;\n      if (\n        operation === \"query\" ||\n        operation === \"mutation\" ||\n        operation === \"subscription\"\n      ) {\n        return definition as OperationDefinitionNode;\n      }\n    }\n    if (definition.kind === \"FragmentDefinition\" && !fragmentDefinition) {\n      // we do this because we want to allow multiple fragment definitions\n      // to precede an operation definition.\n      fragmentDefinition = definition as FragmentDefinitionNode;\n    }\n  }\n\n  if (fragmentDefinition) {\n    return fragmentDefinition;\n  }\n\n  throw newInvariantError(\n    \"Expected a parsed GraphQL query with a query, mutation, subscription, or a fragment.\"\n  );\n}\n\nexport function getDefaultValues(\n  definition: OperationDefinitionNode | undefined\n): Record<string, any> {\n  const defaultValues = Object.create(null);\n  const defs = definition && definition.variableDefinitions;\n  if (defs && defs.length) {\n    defs.forEach((def) => {\n      if (def.defaultValue) {\n        valueToObjectRepresentation(\n          defaultValues,\n          def.variable.name,\n          def.defaultValue as ValueNode\n        );\n      }\n    });\n  }\n  return defaultValues;\n}\n","import { print as origPrint } from \"graphql\";\nimport { canUseWeakMap } from \"../common/canUse.js\";\n\nconst printCache = canUseWeakMap ? new WeakMap() : undefined;\nexport const print: typeof origPrint = (ast) => {\n  let result;\n  result = printCache?.get(ast);\n\n  if (!result) {\n    result = origPrint(ast);\n    printCache?.set(ast, result);\n  }\n  return result;\n};\n","import { newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DirectiveNode,\n  FieldNode,\n  IntValueNode,\n  FloatValueNode,\n  StringValueNode,\n  BooleanValueNode,\n  ObjectValueNode,\n  ListValueNode,\n  EnumValueNode,\n  NullValueNode,\n  VariableNode,\n  InlineFragmentNode,\n  ValueNode,\n  SelectionNode,\n  NameNode,\n  SelectionSetNode,\n  DocumentNode,\n  FragmentSpreadNode,\n} from \"graphql\";\n\nimport { isNonNullObject } from \"../common/objects.js\";\nimport type { FragmentMap } from \"./fragments.js\";\nimport { getFragmentFromSelection } from \"./fragments.js\";\n\nexport interface Reference {\n  readonly __ref: string;\n}\n\nexport function makeReference(id: string): Reference {\n  return { __ref: String(id) };\n}\n\nexport function isReference(obj: any): obj is Reference {\n  return Boolean(\n    obj && typeof obj === \"object\" && typeof obj.__ref === \"string\"\n  );\n}\n\nexport type StoreValue =\n  | number\n  | string\n  | string[]\n  | Reference\n  | Reference[]\n  | null\n  | undefined\n  | void\n  | Object;\n\nexport interface StoreObject {\n  __typename?: string;\n  [storeFieldName: string]: StoreValue;\n}\n\n/**\n * Workaround for a TypeScript quirk:\n * types per default have an implicit index signature that makes them\n * assignable to `StoreObject`.\n * interfaces do not have that implicit index signature, so they cannot\n * be assigned to `StoreObject`.\n * This type just maps over a type or interface that is passed in,\n * implicitly adding the index signature.\n * That way, the result can be assigned to `StoreObject`.\n *\n * This is important if some user-defined interface is used e.g.\n * in cache.modify, where the `toReference` method expects a\n * `StoreObject` as input.\n */\nexport type AsStoreObject<T extends { __typename?: string }> = {\n  [K in keyof T]: T[K];\n};\n\nexport function isDocumentNode(value: any): value is DocumentNode {\n  return (\n    isNonNullObject(value) &&\n    (value as DocumentNode).kind === \"Document\" &&\n    Array.isArray((value as DocumentNode).definitions)\n  );\n}\n\nfunction isStringValue(value: ValueNode): value is StringValueNode {\n  return value.kind === \"StringValue\";\n}\n\nfunction isBooleanValue(value: ValueNode): value is BooleanValueNode {\n  return value.kind === \"BooleanValue\";\n}\n\nfunction isIntValue(value: ValueNode): value is IntValueNode {\n  return value.kind === \"IntValue\";\n}\n\nfunction isFloatValue(value: ValueNode): value is FloatValueNode {\n  return value.kind === \"FloatValue\";\n}\n\nfunction isVariable(value: ValueNode): value is VariableNode {\n  return value.kind === \"Variable\";\n}\n\nfunction isObjectValue(value: ValueNode): value is ObjectValueNode {\n  return value.kind === \"ObjectValue\";\n}\n\nfunction isListValue(value: ValueNode): value is ListValueNode {\n  return value.kind === \"ListValue\";\n}\n\nfunction isEnumValue(value: ValueNode): value is EnumValueNode {\n  return value.kind === \"EnumValue\";\n}\n\nfunction isNullValue(value: ValueNode): value is NullValueNode {\n  return value.kind === \"NullValue\";\n}\n\nexport function valueToObjectRepresentation(\n  argObj: any,\n  name: NameNode,\n  value: ValueNode,\n  variables?: Object\n) {\n  if (isIntValue(value) || isFloatValue(value)) {\n    argObj[name.value] = Number(value.value);\n  } else if (isBooleanValue(value) || isStringValue(value)) {\n    argObj[name.value] = value.value;\n  } else if (isObjectValue(value)) {\n    const nestedArgObj = {};\n    value.fields.map((obj) =>\n      valueToObjectRepresentation(nestedArgObj, obj.name, obj.value, variables)\n    );\n    argObj[name.value] = nestedArgObj;\n  } else if (isVariable(value)) {\n    const variableValue = (variables || ({} as any))[value.name.value];\n    argObj[name.value] = variableValue;\n  } else if (isListValue(value)) {\n    argObj[name.value] = value.values.map((listValue) => {\n      const nestedArgArrayObj = {};\n      valueToObjectRepresentation(\n        nestedArgArrayObj,\n        name,\n        listValue,\n        variables\n      );\n      return (nestedArgArrayObj as any)[name.value];\n    });\n  } else if (isEnumValue(value)) {\n    argObj[name.value] = (value as EnumValueNode).value;\n  } else if (isNullValue(value)) {\n    argObj[name.value] = null;\n  } else {\n    throw newInvariantError(\n      `The inline argument \"%s\" of kind \"%s\"` +\n        \"is not supported. Use variables instead of inline arguments to \" +\n        \"overcome this limitation.\",\n      name.value,\n      (value as any).kind\n    );\n  }\n}\n\nexport function storeKeyNameFromField(\n  field: FieldNode,\n  variables?: Object\n): string {\n  let directivesObj: any = null;\n  if (field.directives) {\n    directivesObj = {};\n    field.directives.forEach((directive) => {\n      directivesObj[directive.name.value] = {};\n\n      if (directive.arguments) {\n        directive.arguments.forEach(({ name, value }) =>\n          valueToObjectRepresentation(\n            directivesObj[directive.name.value],\n            name,\n            value,\n            variables\n          )\n        );\n      }\n    });\n  }\n\n  let argObj: any = null;\n  if (field.arguments && field.arguments.length) {\n    argObj = {};\n    field.arguments.forEach(({ name, value }) =>\n      valueToObjectRepresentation(argObj, name, value, variables)\n    );\n  }\n\n  return getStoreKeyName(field.name.value, argObj, directivesObj);\n}\n\nexport type Directives = {\n  [directiveName: string]: {\n    [argName: string]: any;\n  };\n};\n\nconst KNOWN_DIRECTIVES: string[] = [\n  \"connection\",\n  \"include\",\n  \"skip\",\n  \"client\",\n  \"rest\",\n  \"export\",\n  \"nonreactive\",\n];\n\nexport const getStoreKeyName = Object.assign(\n  function (\n    fieldName: string,\n    args?: Record<string, any> | null,\n    directives?: Directives\n  ): string {\n    if (\n      args &&\n      directives &&\n      directives[\"connection\"] &&\n      directives[\"connection\"][\"key\"]\n    ) {\n      if (\n        directives[\"connection\"][\"filter\"] &&\n        (directives[\"connection\"][\"filter\"] as string[]).length > 0\n      ) {\n        const filterKeys =\n          directives[\"connection\"][\"filter\"] ?\n            (directives[\"connection\"][\"filter\"] as string[])\n          : [];\n        filterKeys.sort();\n\n        const filteredArgs = {} as { [key: string]: any };\n        filterKeys.forEach((key) => {\n          filteredArgs[key] = args[key];\n        });\n\n        return `${directives[\"connection\"][\"key\"]}(${stringify(filteredArgs)})`;\n      } else {\n        return directives[\"connection\"][\"key\"];\n      }\n    }\n\n    let completeFieldName: string = fieldName;\n\n    if (args) {\n      // We can't use `JSON.stringify` here since it's non-deterministic,\n      // and can lead to different store key names being created even though\n      // the `args` object used during creation has the same properties/values.\n      const stringifiedArgs: string = stringify(args);\n      completeFieldName += `(${stringifiedArgs})`;\n    }\n\n    if (directives) {\n      Object.keys(directives).forEach((key) => {\n        if (KNOWN_DIRECTIVES.indexOf(key) !== -1) return;\n        if (directives[key] && Object.keys(directives[key]).length) {\n          completeFieldName += `@${key}(${stringify(directives[key])})`;\n        } else {\n          completeFieldName += `@${key}`;\n        }\n      });\n    }\n\n    return completeFieldName;\n  },\n  {\n    setStringify(s: typeof stringify) {\n      const previous = stringify;\n      stringify = s;\n      return previous;\n    },\n  }\n);\n\n// Default stable JSON.stringify implementation. Can be updated/replaced with\n// something better by calling getStoreKeyName.setStringify.\nlet stringify = function defaultStringify(value: any): string {\n  return JSON.stringify(value, stringifyReplacer);\n};\n\nfunction stringifyReplacer(_key: string, value: any): any {\n  if (isNonNullObject(value) && !Array.isArray(value)) {\n    value = Object.keys(value)\n      .sort()\n      .reduce(\n        (copy, key) => {\n          copy[key] = value[key];\n          return copy;\n        },\n        {} as Record<string, any>\n      );\n  }\n  return value;\n}\n\nexport function argumentsObjectFromField(\n  field: FieldNode | DirectiveNode,\n  variables?: Record<string, any>\n): Object | null {\n  if (field.arguments && field.arguments.length) {\n    const argObj: Object = {};\n    field.arguments.forEach(({ name, value }) =>\n      valueToObjectRepresentation(argObj, name, value, variables)\n    );\n    return argObj;\n  }\n  return null;\n}\n\nexport function resultKeyNameFromField(field: FieldNode): string {\n  return field.alias ? field.alias.value : field.name.value;\n}\n\nexport function getTypenameFromResult(\n  result: Record<string, any>,\n  selectionSet: SelectionSetNode,\n  fragmentMap?: FragmentMap\n): string | undefined {\n  let fragments: undefined | Array<InlineFragmentNode | FragmentSpreadNode>;\n  for (const selection of selectionSet.selections) {\n    if (isField(selection)) {\n      if (selection.name.value === \"__typename\") {\n        return result[resultKeyNameFromField(selection)];\n      }\n    } else if (fragments) {\n      fragments.push(selection);\n    } else {\n      fragments = [selection];\n    }\n  }\n  if (typeof result.__typename === \"string\") {\n    return result.__typename;\n  }\n  if (fragments) {\n    for (const selection of fragments) {\n      const typename = getTypenameFromResult(\n        result,\n        getFragmentFromSelection(selection, fragmentMap)!.selectionSet,\n        fragmentMap\n      );\n      if (typeof typename === \"string\") {\n        return typename;\n      }\n    }\n  }\n}\n\nexport function isField(selection: SelectionNode): selection is FieldNode {\n  return selection.kind === \"Field\";\n}\n\nexport function isInlineFragment(\n  selection: SelectionNode\n): selection is InlineFragmentNode {\n  return selection.kind === \"InlineFragment\";\n}\n\nexport type VariableValue = (node: VariableNode) => any;\n","import { invariant } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  SelectionNode,\n  SelectionSetNode,\n  OperationDefinitionNode,\n  FieldNode,\n  DirectiveNode,\n  FragmentDefinitionNode,\n  ArgumentNode,\n  FragmentSpreadNode,\n  VariableDefinitionNode,\n  ASTNode,\n  ASTVisitFn,\n  InlineFragmentNode,\n} from \"graphql\";\nimport { visit, Kind } from \"graphql\";\n\nimport {\n  checkDocument,\n  getOperationDefinition,\n  getFragmentDefinition,\n  getFragmentDefinitions,\n  getMainDefinition,\n} from \"./getFromAST.js\";\nimport { isField } from \"./storeUtils.js\";\nimport type { FragmentMap } from \"./fragments.js\";\nimport { createFragmentMap } from \"./fragments.js\";\nimport { isArray, isNonEmptyArray } from \"../common/arrays.js\";\n\n// https://github.com/graphql/graphql-js/blob/8d7c8fccf5a9846a50785de04abda58a7eb13fc0/src/language/visitor.ts#L20-L23\ninterface EnterLeaveVisitor<TVisitedNode extends ASTNode> {\n  readonly enter?: ASTVisitFn<TVisitedNode>;\n  readonly leave?: ASTVisitFn<TVisitedNode>;\n}\n\nexport type RemoveNodeConfig<N> = {\n  name?: string;\n  test?: (node: N) => boolean;\n  remove?: boolean;\n};\n\nexport type GetNodeConfig<N> = {\n  name?: string;\n  test?: (node: N) => boolean;\n};\n\nexport type RemoveDirectiveConfig = RemoveNodeConfig<DirectiveNode>;\nexport type GetDirectiveConfig = GetNodeConfig<DirectiveNode>;\nexport type RemoveArgumentsConfig = RemoveNodeConfig<ArgumentNode>;\nexport type GetFragmentSpreadConfig = GetNodeConfig<FragmentSpreadNode>;\nexport type RemoveFragmentSpreadConfig = RemoveNodeConfig<FragmentSpreadNode>;\nexport type RemoveFragmentDefinitionConfig =\n  RemoveNodeConfig<FragmentDefinitionNode>;\nexport type RemoveVariableDefinitionConfig =\n  RemoveNodeConfig<VariableDefinitionNode>;\n\nconst TYPENAME_FIELD: FieldNode = {\n  kind: Kind.FIELD,\n  name: {\n    kind: Kind.NAME,\n    value: \"__typename\",\n  },\n};\n\nfunction isEmpty(\n  op: OperationDefinitionNode | FragmentDefinitionNode,\n  fragmentMap: FragmentMap\n): boolean {\n  return (\n    !op ||\n    op.selectionSet.selections.every(\n      (selection) =>\n        selection.kind === Kind.FRAGMENT_SPREAD &&\n        isEmpty(fragmentMap[selection.name.value], fragmentMap)\n    )\n  );\n}\n\nfunction nullIfDocIsEmpty(doc: DocumentNode) {\n  return (\n      isEmpty(\n        getOperationDefinition(doc) || getFragmentDefinition(doc),\n        createFragmentMap(getFragmentDefinitions(doc))\n      )\n    ) ?\n      null\n    : doc;\n}\n\nfunction getDirectiveMatcher(\n  configs: (RemoveDirectiveConfig | GetDirectiveConfig)[]\n) {\n  const names = new Map<string, RemoveDirectiveConfig | GetDirectiveConfig>();\n\n  const tests = new Map<\n    (directive: DirectiveNode) => boolean,\n    RemoveDirectiveConfig | GetDirectiveConfig\n  >();\n\n  configs.forEach((directive) => {\n    if (directive) {\n      if (directive.name) {\n        names.set(directive.name, directive);\n      } else if (directive.test) {\n        tests.set(directive.test, directive);\n      }\n    }\n  });\n\n  return (directive: DirectiveNode) => {\n    let config = names.get(directive.name.value);\n    if (!config && tests.size) {\n      tests.forEach((testConfig, test) => {\n        if (test(directive)) {\n          config = testConfig;\n        }\n      });\n    }\n    return config;\n  };\n}\n\n// Helper interface and function used by removeDirectivesFromDocument to keep\n// track of variable references and fragments spreads found within a given\n// operation or fragment definition.\ninterface InternalInUseInfo {\n  variables: Set<string>;\n  fragmentSpreads: Set<string>;\n  // Set to true when we deliberately remove a fragment definition, so we can\n  // make sure also to remove dangling ...spreads that refer to it.\n  removed?: boolean;\n  // Populated by the populateTransitiveVars helper function below.\n  transitiveVars?: Set<string>;\n}\nfunction makeInUseGetterFunction<TKey>(defaultKey: TKey) {\n  const map = new Map<TKey, InternalInUseInfo>();\n\n  return function inUseGetterFunction(\n    key: TKey = defaultKey\n  ): InternalInUseInfo {\n    let inUse = map.get(key);\n    if (!inUse) {\n      map.set(\n        key,\n        (inUse = {\n          // Variable and fragment spread names used directly within this\n          // operation or fragment definition, as identified by key. These sets\n          // will be populated during the first traversal of the document in\n          // removeDirectivesFromDocument below.\n          variables: new Set(),\n          fragmentSpreads: new Set(),\n        })\n      );\n    }\n    return inUse;\n  };\n}\n\nexport function removeDirectivesFromDocument(\n  directives: RemoveDirectiveConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  checkDocument(doc);\n\n  // Passing empty strings to makeInUseGetterFunction means we handle anonymous\n  // operations as if their names were \"\". Anonymous fragment definitions are\n  // not supposed to be possible, but the same default naming strategy seems\n  // appropriate for that case as well.\n  const getInUseByOperationName = makeInUseGetterFunction<string>(\"\");\n  const getInUseByFragmentName = makeInUseGetterFunction<string>(\"\");\n  const getInUse = (\n    ancestors: readonly (ASTNode | readonly ASTNode[])[]\n  ): InternalInUseInfo | null => {\n    for (\n      let p = 0, ancestor: ASTNode | readonly ASTNode[];\n      p < ancestors.length && (ancestor = ancestors[p]);\n      ++p\n    ) {\n      if (isArray(ancestor)) continue;\n      if (ancestor.kind === Kind.OPERATION_DEFINITION) {\n        // If an operation is anonymous, we use the empty string as its key.\n        return getInUseByOperationName(ancestor.name && ancestor.name.value);\n      }\n      if (ancestor.kind === Kind.FRAGMENT_DEFINITION) {\n        return getInUseByFragmentName(ancestor.name.value);\n      }\n    }\n    invariant.error(`Could not find operation or fragment`);\n    return null;\n  };\n\n  let operationCount = 0;\n  for (let i = doc.definitions.length - 1; i >= 0; --i) {\n    if (doc.definitions[i].kind === Kind.OPERATION_DEFINITION) {\n      ++operationCount;\n    }\n  }\n\n  const directiveMatcher = getDirectiveMatcher(directives);\n  const shouldRemoveField = (nodeDirectives: FieldNode[\"directives\"]) =>\n    isNonEmptyArray(nodeDirectives) &&\n    nodeDirectives\n      .map(directiveMatcher)\n      .some(\n        (config: RemoveDirectiveConfig | undefined) => config && config.remove\n      );\n\n  const originalFragmentDefsByPath = new Map<string, FragmentDefinitionNode>();\n\n  // Any time the first traversal of the document below makes a change like\n  // removing a fragment (by returning null), this variable should be set to\n  // true. Once it becomes true, it should never be set to false again. If this\n  // variable remains false throughout the traversal, then we can return the\n  // original doc immediately without any modifications.\n  let firstVisitMadeChanges = false;\n\n  const fieldOrInlineFragmentVisitor: EnterLeaveVisitor<\n    FieldNode | InlineFragmentNode\n  > = {\n    enter(node) {\n      if (shouldRemoveField(node.directives)) {\n        firstVisitMadeChanges = true;\n        return null;\n      }\n    },\n  };\n\n  const docWithoutDirectiveSubtrees = visit(doc, {\n    // These two AST node types share the same implementation, defined above.\n    Field: fieldOrInlineFragmentVisitor,\n    InlineFragment: fieldOrInlineFragmentVisitor,\n\n    VariableDefinition: {\n      enter() {\n        // VariableDefinition nodes do not count as variables in use, though\n        // they do contain Variable nodes that might be visited below. To avoid\n        // counting variable declarations as usages, we skip visiting the\n        // contents of this VariableDefinition node by returning false.\n        return false;\n      },\n    },\n\n    Variable: {\n      enter(node, _key, _parent, _path, ancestors) {\n        const inUse = getInUse(ancestors);\n        if (inUse) {\n          inUse.variables.add(node.name.value);\n        }\n      },\n    },\n\n    FragmentSpread: {\n      enter(node, _key, _parent, _path, ancestors) {\n        if (shouldRemoveField(node.directives)) {\n          firstVisitMadeChanges = true;\n          return null;\n        }\n        const inUse = getInUse(ancestors);\n        if (inUse) {\n          inUse.fragmentSpreads.add(node.name.value);\n        }\n        // We might like to remove this FragmentSpread by returning null here if\n        // the corresponding FragmentDefinition node is also going to be removed\n        // by the logic below, but we can't control the relative order of those\n        // events, so we have to postpone the removal of dangling FragmentSpread\n        // nodes until after the current visit of the document has finished.\n      },\n    },\n\n    FragmentDefinition: {\n      enter(node, _key, _parent, path) {\n        originalFragmentDefsByPath.set(JSON.stringify(path), node);\n      },\n      leave(node, _key, _parent, path) {\n        const originalNode = originalFragmentDefsByPath.get(\n          JSON.stringify(path)\n        );\n        if (node === originalNode) {\n          // If the FragmentNode received by this leave function is identical to\n          // the one received by the corresponding enter function (above), then\n          // the visitor must not have made any changes within this\n          // FragmentDefinition node. This fragment definition may still be\n          // removed if there are no ...spread references to it, but it won't be\n          // removed just because it has only a __typename field.\n          return node;\n        }\n\n        if (\n          // This logic applies only if the document contains one or more\n          // operations, since removing all fragments from a document containing\n          // only fragments makes the document useless.\n          operationCount > 0 &&\n          node.selectionSet.selections.every(\n            (selection) =>\n              selection.kind === Kind.FIELD &&\n              selection.name.value === \"__typename\"\n          )\n        ) {\n          // This is a somewhat opinionated choice: if a FragmentDefinition ends\n          // up having no fields other than __typename, we remove the whole\n          // fragment definition, and later prune ...spread references to it.\n          getInUseByFragmentName(node.name.value).removed = true;\n          firstVisitMadeChanges = true;\n          return null;\n        }\n      },\n    },\n\n    Directive: {\n      leave(node) {\n        // If a matching directive is found, remove the directive itself. Note\n        // that this does not remove the target (field, argument, etc) of the\n        // directive, but only the directive itself.\n        if (directiveMatcher(node)) {\n          firstVisitMadeChanges = true;\n          return null;\n        }\n      },\n    },\n  });\n\n  if (!firstVisitMadeChanges) {\n    // If our first pass did not change anything about the document, then there\n    // is no cleanup we need to do, and we can return the original doc.\n    return doc;\n  }\n\n  // Utility for making sure inUse.transitiveVars is recursively populated.\n  // Because this logic assumes inUse.fragmentSpreads has been completely\n  // populated and inUse.removed has been set if appropriate,\n  // populateTransitiveVars must be called after that information has been\n  // collected by the first traversal of the document.\n  const populateTransitiveVars = (inUse: InternalInUseInfo) => {\n    if (!inUse.transitiveVars) {\n      inUse.transitiveVars = new Set(inUse.variables);\n      if (!inUse.removed) {\n        inUse.fragmentSpreads.forEach((childFragmentName) => {\n          populateTransitiveVars(\n            getInUseByFragmentName(childFragmentName)\n          ).transitiveVars!.forEach((varName) => {\n            inUse.transitiveVars!.add(varName);\n          });\n        });\n      }\n    }\n    return inUse;\n  };\n\n  // Since we've been keeping track of fragment spreads used by particular\n  // operations and fragment definitions, we now need to compute the set of all\n  // spreads used (transitively) by any operations in the document.\n  const allFragmentNamesUsed = new Set<string>();\n  docWithoutDirectiveSubtrees.definitions.forEach((def) => {\n    if (def.kind === Kind.OPERATION_DEFINITION) {\n      populateTransitiveVars(\n        getInUseByOperationName(def.name && def.name.value)\n      ).fragmentSpreads.forEach((childFragmentName) => {\n        allFragmentNamesUsed.add(childFragmentName);\n      });\n    } else if (\n      def.kind === Kind.FRAGMENT_DEFINITION &&\n      // If there are no operations in the document, then all fragment\n      // definitions count as usages of their own fragment names. This heuristic\n      // prevents accidentally removing all fragment definitions from the\n      // document just because it contains no operations that use the fragments.\n      operationCount === 0 &&\n      !getInUseByFragmentName(def.name.value).removed\n    ) {\n      allFragmentNamesUsed.add(def.name.value);\n    }\n  });\n  // Now that we have added all fragment spreads used by operations to the\n  // allFragmentNamesUsed set, we can complete the set by transitively adding\n  // all fragment spreads used by those fragments, and so on.\n  allFragmentNamesUsed.forEach((fragmentName) => {\n    // Once all the childFragmentName strings added here have been seen already,\n    // the top-level allFragmentNamesUsed.forEach loop will terminate.\n    populateTransitiveVars(\n      getInUseByFragmentName(fragmentName)\n    ).fragmentSpreads.forEach((childFragmentName) => {\n      allFragmentNamesUsed.add(childFragmentName);\n    });\n  });\n\n  const fragmentWillBeRemoved = (fragmentName: string) =>\n    !!(\n      // A fragment definition will be removed if there are no spreads that refer\n      // to it, or the fragment was explicitly removed because it had no fields\n      // other than __typename.\n      (\n        !allFragmentNamesUsed.has(fragmentName) ||\n        getInUseByFragmentName(fragmentName).removed\n      )\n    );\n\n  const enterVisitor: EnterLeaveVisitor<\n    FragmentSpreadNode | FragmentDefinitionNode\n  > = {\n    enter(node) {\n      if (fragmentWillBeRemoved(node.name.value)) {\n        return null;\n      }\n    },\n  };\n\n  return nullIfDocIsEmpty(\n    visit(docWithoutDirectiveSubtrees, {\n      // If the fragment is going to be removed, then leaving any dangling\n      // FragmentSpread nodes with the same name would be a mistake.\n      FragmentSpread: enterVisitor,\n\n      // This is where the fragment definition is actually removed.\n      FragmentDefinition: enterVisitor,\n\n      OperationDefinition: {\n        leave(node) {\n          // Upon leaving each operation in the depth-first AST traversal, prune\n          // any variables that are declared by the operation but unused within.\n          if (node.variableDefinitions) {\n            const usedVariableNames = populateTransitiveVars(\n              // If an operation is anonymous, we use the empty string as its key.\n              getInUseByOperationName(node.name && node.name.value)\n            ).transitiveVars!;\n\n            // According to the GraphQL spec, all variables declared by an\n            // operation must either be used by that operation or used by some\n            // fragment included transitively into that operation:\n            // https://spec.graphql.org/draft/#sec-All-Variables-Used\n            //\n            // To stay on the right side of this validation rule, if/when we\n            // remove the last $var references from an operation or its fragments,\n            // we must also remove the corresponding $var declaration from the\n            // enclosing operation. This pruning applies only to operations and\n            // not fragment definitions, at the moment. Fragments may be able to\n            // declare variables eventually, but today they can only consume them.\n            if (usedVariableNames.size < node.variableDefinitions.length) {\n              return {\n                ...node,\n                variableDefinitions: node.variableDefinitions.filter((varDef) =>\n                  usedVariableNames.has(varDef.variable.name.value)\n                ),\n              };\n            }\n          }\n        },\n      },\n    })\n  );\n}\n\nexport const addTypenameToDocument = Object.assign(\n  function <TNode extends ASTNode>(doc: TNode): TNode {\n    return visit(doc, {\n      SelectionSet: {\n        enter(node, _key, parent) {\n          // Don't add __typename to OperationDefinitions.\n          if (\n            parent &&\n            (parent as OperationDefinitionNode).kind ===\n              Kind.OPERATION_DEFINITION\n          ) {\n            return;\n          }\n\n          // No changes if no selections.\n          const { selections } = node;\n          if (!selections) {\n            return;\n          }\n\n          // If selections already have a __typename, or are part of an\n          // introspection query, do nothing.\n          const skip = selections.some((selection) => {\n            return (\n              isField(selection) &&\n              (selection.name.value === \"__typename\" ||\n                selection.name.value.lastIndexOf(\"__\", 0) === 0)\n            );\n          });\n          if (skip) {\n            return;\n          }\n\n          // If this SelectionSet is @export-ed as an input variable, it should\n          // not have a __typename field (see issue #4691).\n          const field = parent as FieldNode;\n          if (\n            isField(field) &&\n            field.directives &&\n            field.directives.some((d) => d.name.value === \"export\")\n          ) {\n            return;\n          }\n\n          // Create and return a new SelectionSet with a __typename Field.\n          return {\n            ...node,\n            selections: [...selections, TYPENAME_FIELD],\n          };\n        },\n      },\n    });\n  },\n  {\n    added(field: FieldNode): boolean {\n      return field === TYPENAME_FIELD;\n    },\n  }\n);\n\nconst connectionRemoveConfig = {\n  test: (directive: DirectiveNode) => {\n    const willRemove = directive.name.value === \"connection\";\n    if (willRemove) {\n      if (\n        !directive.arguments ||\n        !directive.arguments.some((arg) => arg.name.value === \"key\")\n      ) {\n        invariant.warn(\n          \"Removing an @connection directive even though it does not have a key. \" +\n            \"You may want to use the key parameter to specify a store key.\"\n        );\n      }\n    }\n\n    return willRemove;\n  },\n};\n\nexport function removeConnectionDirectiveFromDocument(doc: DocumentNode) {\n  return removeDirectivesFromDocument(\n    [connectionRemoveConfig],\n    checkDocument(doc)\n  );\n}\n\nfunction hasDirectivesInSelectionSet(\n  directives: GetDirectiveConfig[],\n  selectionSet: SelectionSetNode | undefined,\n  nestedCheck = true\n): boolean {\n  return (\n    !!selectionSet &&\n    selectionSet.selections &&\n    selectionSet.selections.some((selection) =>\n      hasDirectivesInSelection(directives, selection, nestedCheck)\n    )\n  );\n}\n\nfunction hasDirectivesInSelection(\n  directives: GetDirectiveConfig[],\n  selection: SelectionNode,\n  nestedCheck = true\n): boolean {\n  if (!isField(selection)) {\n    return true;\n  }\n\n  if (!selection.directives) {\n    return false;\n  }\n\n  return (\n    selection.directives.some(getDirectiveMatcher(directives)) ||\n    (nestedCheck &&\n      hasDirectivesInSelectionSet(\n        directives,\n        selection.selectionSet,\n        nestedCheck\n      ))\n  );\n}\n\nfunction getArgumentMatcher(config: RemoveArgumentsConfig[]) {\n  return function argumentMatcher(argument: ArgumentNode) {\n    return config.some(\n      (aConfig: RemoveArgumentsConfig) =>\n        argument.value &&\n        argument.value.kind === Kind.VARIABLE &&\n        argument.value.name &&\n        (aConfig.name === argument.value.name.value ||\n          (aConfig.test && aConfig.test(argument)))\n    );\n  };\n}\n\nexport function removeArgumentsFromDocument(\n  config: RemoveArgumentsConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  const argMatcher = getArgumentMatcher(config);\n\n  return nullIfDocIsEmpty(\n    visit(doc, {\n      OperationDefinition: {\n        enter(node) {\n          return {\n            ...node,\n            // Remove matching top level variables definitions.\n            variableDefinitions:\n              node.variableDefinitions ?\n                node.variableDefinitions.filter(\n                  (varDef) =>\n                    !config.some(\n                      (arg) => arg.name === varDef.variable.name.value\n                    )\n                )\n              : [],\n          };\n        },\n      },\n\n      Field: {\n        enter(node) {\n          // If `remove` is set to true for an argument, and an argument match\n          // is found for a field, remove the field as well.\n          const shouldRemoveField = config.some(\n            (argConfig) => argConfig.remove\n          );\n\n          if (shouldRemoveField) {\n            let argMatchCount = 0;\n            if (node.arguments) {\n              node.arguments.forEach((arg) => {\n                if (argMatcher(arg)) {\n                  argMatchCount += 1;\n                }\n              });\n            }\n\n            if (argMatchCount === 1) {\n              return null;\n            }\n          }\n        },\n      },\n\n      Argument: {\n        enter(node) {\n          // Remove all matching arguments.\n          if (argMatcher(node)) {\n            return null;\n          }\n        },\n      },\n    })\n  );\n}\n\nexport function removeFragmentSpreadFromDocument(\n  config: RemoveFragmentSpreadConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  function enter(\n    node: FragmentSpreadNode | FragmentDefinitionNode\n  ): null | void {\n    if (config.some((def) => def.name === node.name.value)) {\n      return null;\n    }\n  }\n\n  return nullIfDocIsEmpty(\n    visit(doc, {\n      FragmentSpread: { enter },\n      FragmentDefinition: { enter },\n    })\n  );\n}\n\n// If the incoming document is a query, return it as is. Otherwise, build a\n// new document containing a query operation based on the selection set\n// of the previous main operation.\nexport function buildQueryFromSelectionSet(\n  document: DocumentNode\n): DocumentNode {\n  const definition = getMainDefinition(document);\n  const definitionOperation = (<OperationDefinitionNode>definition).operation;\n\n  if (definitionOperation === \"query\") {\n    // Already a query, so return the existing document.\n    return document;\n  }\n\n  // Build a new query using the selection set of the main operation.\n  const modifiedDoc = visit(document, {\n    OperationDefinition: {\n      enter(node) {\n        return {\n          ...node,\n          operation: \"query\",\n        };\n      },\n    },\n  });\n  return modifiedDoc;\n}\n\n// Remove fields / selection sets that include an @client directive.\nexport function removeClientSetsFromDocument(\n  document: DocumentNode\n): DocumentNode | null {\n  checkDocument(document);\n\n  let modifiedDoc = removeDirectivesFromDocument(\n    [\n      {\n        test: (directive: DirectiveNode) => directive.name.value === \"client\",\n        remove: true,\n      },\n    ],\n    document\n  );\n\n  return modifiedDoc;\n}\n","import type {\n  Observer,\n  ObservableSubscription,\n  Subscriber,\n} from \"./Observable.js\";\nimport { Observable } from \"./Observable.js\";\nimport { iterateObserversSafely } from \"./iteration.js\";\nimport { fixObservableSubclass } from \"./subclassing.js\";\n\ntype MaybeAsync<T> = T | PromiseLike<T>;\n\nfunction isPromiseLike<T>(value: MaybeAsync<T>): value is PromiseLike<T> {\n  return value && typeof (value as any).then === \"function\";\n}\n\n// Any individual Source<T> can be an Observable<T> or a promise for one.\ntype Source<T> = MaybeAsync<Observable<T>>;\n\nexport type ConcastSourcesIterable<T> = Iterable<Source<T>>;\nexport type ConcastSourcesArray<T> = Array<Source<T>>;\n\n// A Concast<T> observable concatenates the given sources into a single\n// non-overlapping sequence of Ts, automatically unwrapping any promises,\n// and broadcasts the T elements of that sequence to any number of\n// subscribers, all without creating a bunch of intermediary Observable\n// wrapper objects.\n//\n// Even though any number of observers can subscribe to the Concast, each\n// source observable is guaranteed to receive at most one subscribe call,\n// and the results are multicast to all observers.\n//\n// In addition to broadcasting every next/error message to this.observers,\n// the Concast stores the most recent message using this.latest, so any\n// new observers can immediately receive the latest message, even if it\n// was originally delivered in the past. This behavior means we can assume\n// every active observer in this.observers has received the same most\n// recent message.\n//\n// With the exception of this.latest replay, a Concast is a \"hot\"\n// observable in the sense that it does not replay past results from the\n// beginning of time for each new observer.\n//\n// Could we have used some existing RxJS class instead? Concast<T> is\n// similar to a BehaviorSubject<T>, because it is multicast and redelivers\n// the latest next/error message to new subscribers. Unlike Subject<T>,\n// Concast<T> does not expose an Observer<T> interface (this.handlers is\n// intentionally private), since Concast<T> gets its inputs from the\n// concatenated sources. If we ever switch to RxJS, there may be some\n// value in reusing their code, but for now we use zen-observable, which\n// does not contain any Subject implementations.\nexport class Concast<T> extends Observable<T> {\n  // Active observers receiving broadcast messages. Thanks to this.latest,\n  // we can assume all observers in this Set have received the same most\n  // recent message, though possibly at different times in the past.\n  private observers = new Set<Observer<T>>();\n\n  // This property starts off undefined to indicate the initial\n  // subscription has not yet begun, then points to each source\n  // subscription in turn, and finally becomes null after the sources have\n  // been exhausted. After that, it stays null.\n  private sub?: ObservableSubscription | null;\n\n  // Not only can the individual elements of the iterable be promises, but\n  // also the iterable itself can be wrapped in a promise.\n  constructor(sources: MaybeAsync<ConcastSourcesIterable<T>> | Subscriber<T>) {\n    super((observer) => {\n      this.addObserver(observer);\n      return () => this.removeObserver(observer);\n    });\n\n    // Suppress rejection warnings for this.promise, since it's perfectly\n    // acceptable to pay no attention to this.promise if you're consuming\n    // the results through the normal observable API.\n    this.promise.catch((_) => {});\n\n    // If someone accidentally tries to create a Concast using a subscriber\n    // function, recover by creating an Observable from that subscriber and\n    // using it as the source.\n    if (typeof sources === \"function\") {\n      sources = [new Observable(sources)];\n    }\n\n    if (isPromiseLike(sources)) {\n      sources.then((iterable) => this.start(iterable), this.handlers.error);\n    } else {\n      this.start(sources);\n    }\n  }\n\n  // A consumable array of source observables, incrementally consumed each time\n  // this.handlers.complete is called. This private field is not initialized\n  // until the concast.start method is called, which can happen asynchronously\n  // if a Promise is passed to the Concast constructor, so undefined is a\n  // possible value for this.sources before concast.start is called.\n  private sources: Source<T>[] | undefined;\n\n  private start(sources: ConcastSourcesIterable<T>) {\n    if (this.sub !== void 0) return;\n\n    // In practice, sources is most often simply an Array of observables.\n    // TODO Consider using sources[Symbol.iterator]() to take advantage\n    // of the laziness of non-Array iterables.\n    this.sources = Array.from(sources);\n\n    // Calling this.handlers.complete() kicks off consumption of the first\n    // source observable. It's tempting to do this step lazily in\n    // addObserver, but this.promise can be accessed without calling\n    // addObserver, so consumption needs to begin eagerly.\n    this.handlers.complete();\n  }\n\n  private deliverLastMessage(observer: Observer<T>) {\n    if (this.latest) {\n      const nextOrError = this.latest[0];\n      const method = observer[nextOrError];\n      if (method) {\n        method.call(observer, this.latest[1]);\n      }\n      // If the subscription is already closed, and the last message was\n      // a 'next' message, simulate delivery of the final 'complete'\n      // message again.\n      if (this.sub === null && nextOrError === \"next\" && observer.complete) {\n        observer.complete();\n      }\n    }\n  }\n\n  public addObserver(observer: Observer<T>) {\n    if (!this.observers.has(observer)) {\n      // Immediately deliver the most recent message, so we can always\n      // be sure all observers have the latest information.\n      this.deliverLastMessage(observer);\n      this.observers.add(observer);\n    }\n  }\n\n  public removeObserver(observer: Observer<T>) {\n    if (this.observers.delete(observer) && this.observers.size < 1) {\n      // In case there are still any listeners in this.nextResultListeners, and\n      // no error or completion has been broadcast yet, make sure those\n      // observers have a chance to run and then remove themselves from\n      // this.observers.\n      this.handlers.complete();\n    }\n  }\n\n  // Any Concast object can be trivially converted to a Promise, without\n  // having to create a new wrapper Observable. This promise provides an\n  // easy way to observe the final state of the Concast.\n  private resolve!: (result?: T | PromiseLike<T>) => void;\n  private reject!: (reason: any) => void;\n  public readonly promise = new Promise<T | undefined>((resolve, reject) => {\n    this.resolve = resolve;\n    this.reject = reject;\n  });\n\n  // Name and argument of the most recently invoked observer method, used\n  // to deliver latest results immediately to new observers.\n  private latest?: [\"next\", T] | [\"error\", any];\n\n  // Bound handler functions that can be reused for every internal\n  // subscription.\n  private handlers = {\n    next: (result: T) => {\n      if (this.sub !== null) {\n        this.latest = [\"next\", result];\n        this.notify(\"next\", result);\n        iterateObserversSafely(this.observers, \"next\", result);\n      }\n    },\n\n    error: (error: any) => {\n      const { sub } = this;\n      if (sub !== null) {\n        // Delay unsubscribing from the underlying subscription slightly,\n        // so that immediately subscribing another observer can keep the\n        // subscription active.\n        if (sub) setTimeout(() => sub.unsubscribe());\n        this.sub = null;\n        this.latest = [\"error\", error];\n        this.reject(error);\n        this.notify(\"error\", error);\n        iterateObserversSafely(this.observers, \"error\", error);\n      }\n    },\n\n    complete: () => {\n      const { sub, sources = [] } = this;\n      if (sub !== null) {\n        // If complete is called before concast.start, this.sources may be\n        // undefined, so we use a default value of [] for sources. That works\n        // here because it falls into the if (!value) {...} block, which\n        // appropriately terminates the Concast, even if this.sources might\n        // eventually have been initialized to a non-empty array.\n        const value = sources.shift();\n        if (!value) {\n          if (sub) setTimeout(() => sub.unsubscribe());\n          this.sub = null;\n          if (this.latest && this.latest[0] === \"next\") {\n            this.resolve(this.latest[1]);\n          } else {\n            this.resolve();\n          }\n          this.notify(\"complete\");\n          // We do not store this.latest = [\"complete\"], because doing so\n          // discards useful information about the previous next (or\n          // error) message. Instead, if new observers subscribe after\n          // this Concast has completed, they will receive the final\n          // 'next' message (unless there was an error) immediately\n          // followed by a 'complete' message (see addObserver).\n          iterateObserversSafely(this.observers, \"complete\");\n        } else if (isPromiseLike(value)) {\n          value.then((obs) => (this.sub = obs.subscribe(this.handlers)));\n        } else {\n          this.sub = value.subscribe(this.handlers);\n        }\n      }\n    },\n  };\n\n  private nextResultListeners = new Set<NextResultListener>();\n\n  private notify(\n    method: Parameters<NextResultListener>[0],\n    arg?: Parameters<NextResultListener>[1]\n  ) {\n    const { nextResultListeners } = this;\n    if (nextResultListeners.size) {\n      // Replacing this.nextResultListeners first ensures it does not grow while\n      // we are iterating over it, potentially leading to infinite loops.\n      this.nextResultListeners = new Set();\n      nextResultListeners.forEach((listener) => listener(method, arg));\n    }\n  }\n\n  // We need a way to run callbacks just *before* the next result (or error or\n  // completion) is delivered by this Concast, so we can be sure any code that\n  // runs as a result of delivering that result/error observes the effects of\n  // running the callback(s). It was tempting to reuse the Observer type instead\n  // of introducing NextResultListener, but that messes with the sizing and\n  // maintenance of this.observers, and ends up being more code overall.\n  beforeNext(callback: NextResultListener) {\n    let called = false;\n    this.nextResultListeners.add((method, arg) => {\n      if (!called) {\n        called = true;\n        callback(method, arg);\n      }\n    });\n  }\n\n  // A public way to abort observation and broadcast.\n  public cancel = (reason: any) => {\n    this.reject(reason);\n    this.sources = [];\n    this.handlers.complete();\n  };\n}\n\ntype NextResultListener = (\n  method: \"next\" | \"error\" | \"complete\",\n  arg?: any\n) => any;\n\n// Necessary because the Concast constructor has a different signature\n// than the Observable constructor.\nfixObservableSubclass(Concast);\n","import type { Observer } from \"./Observable.js\";\nimport { Observable } from \"./Observable.js\";\n\n// Like Observable.prototype.map, except that the mapping function can\n// optionally return a Promise (or be async).\nexport function asyncMap<V, R>(\n  observable: Observable<V>,\n  mapFn: (value: V) => R | PromiseLike<R>,\n  catchFn?: (error: any) => R | PromiseLike<R>\n): Observable<R> {\n  return new Observable<R>((observer) => {\n    let promiseQueue = {\n      // Normally we would initialize promiseQueue to Promise.resolve(), but\n      // in this case, for backwards compatibility, we need to be careful to\n      // invoke the first callback synchronously.\n      then(callback: () => any) {\n        return new Promise((resolve) => resolve(callback()));\n      },\n    } as Promise<void>;\n\n    function makeCallback(\n      examiner: typeof mapFn | typeof catchFn,\n      key: \"next\" | \"error\"\n    ): (arg: any) => void {\n      return (arg) => {\n        if (examiner) {\n          const both = () =>\n            // If the observer is closed, we don't want to continue calling the\n            // mapping function - it's result will be swallowed anyways.\n            observer.closed ?\n              /* will be swallowed */ (0 as any)\n            : examiner(arg);\n\n          promiseQueue = promiseQueue.then(both, both).then(\n            (result) => observer.next(result),\n            (error) => observer.error(error)\n          );\n        } else {\n          observer[key](arg);\n        }\n      };\n    }\n\n    const handler: Observer<V> = {\n      next: makeCallback(mapFn, \"next\"),\n      error: makeCallback(catchFn, \"error\"),\n      complete() {\n        // no need to reassign `promiseQueue`, after `observer.complete`,\n        // the observer will be closed and short-circuit everything anyways\n        /*promiseQueue = */ promiseQueue.then(() => observer.complete());\n      },\n    };\n\n    const sub = observable.subscribe(handler);\n    return () => sub.unsubscribe();\n  });\n}\n","import type { Observer } from \"./Observable.js\";\n\nexport function iterateObserversSafely<E, A>(\n  observers: Set<Observer<E>>,\n  method: keyof Observer<E>,\n  argument?: A\n) {\n  // In case observers is modified during iteration, we need to commit to the\n  // original elements, which also provides an opportunity to filter them down\n  // to just the observers with the given method.\n  const observersWithMethod: Observer<E>[] = [];\n  observers.forEach((obs) => obs[method] && observersWithMethod.push(obs));\n  observersWithMethod.forEach((obs) => (obs as any)[method](argument));\n}\n","import { Observable } from \"./Observable.js\";\nimport { canUseSymbol } from \"../common/canUse.js\";\n\n// Generic implementations of Observable.prototype methods like map and\n// filter need to know how to create a new Observable from an Observable\n// subclass (like Concast or ObservableQuery). Those methods assume\n// (perhaps unwisely?) that they can call the subtype's constructor with a\n// Subscriber function, even though the subclass constructor might expect\n// different parameters. Defining this static Symbol.species property on\n// the subclass is a hint to generic Observable code to use the default\n// constructor instead of trying to do `new Subclass(observer => ...)`.\nexport function fixObservableSubclass<\n  S extends new (...args: any[]) => Observable<any>,\n>(subclass: S): S {\n  function set(key: symbol | string) {\n    // Object.defineProperty is necessary because the Symbol.species\n    // property is a getter by default in modern JS environments, so we\n    // can't assign to it with a normal assignment expression.\n    Object.defineProperty(subclass, key, { value: Observable });\n  }\n  if (canUseSymbol && Symbol.species) {\n    set(Symbol.species);\n  }\n  // The \"@@species\" string is used as a fake Symbol.species value in some\n  // polyfill systems (including the SymbolSpecies variable used by\n  // zen-observable), so we should set it as well, to be safe.\n  set(\"@@species\");\n  return subclass;\n}\n","export const version = \"local\";\n",null,null,null,"export function devAssert(condition, message) {\n  const booleanCondition = Boolean(condition);\n\n  if (!booleanCondition) {\n    throw new Error(message);\n  }\n}\n","const MAX_ARRAY_LENGTH = 10;\nconst MAX_RECURSIVE_DEPTH = 2;\n/**\n * Used to print values in error messages.\n */\n\nexport function inspect(value) {\n  return formatValue(value, []);\n}\n\nfunction formatValue(value, seenValues) {\n  switch (typeof value) {\n    case 'string':\n      return JSON.stringify(value);\n\n    case 'function':\n      return value.name ? `[function ${value.name}]` : '[function]';\n\n    case 'object':\n      return formatObjectValue(value, seenValues);\n\n    default:\n      return String(value);\n  }\n}\n\nfunction formatObjectValue(value, previouslySeenValues) {\n  if (value === null) {\n    return 'null';\n  }\n\n  if (previouslySeenValues.includes(value)) {\n    return '[Circular]';\n  }\n\n  const seenValues = [...previouslySeenValues, value];\n\n  if (isJSONable(value)) {\n    const jsonValue = value.toJSON(); // check for infinite recursion\n\n    if (jsonValue !== value) {\n      return typeof jsonValue === 'string'\n        ? jsonValue\n        : formatValue(jsonValue, seenValues);\n    }\n  } else if (Array.isArray(value)) {\n    return formatArray(value, seenValues);\n  }\n\n  return formatObject(value, seenValues);\n}\n\nfunction isJSONable(value) {\n  return typeof value.toJSON === 'function';\n}\n\nfunction formatObject(object, seenValues) {\n  const entries = Object.entries(object);\n\n  if (entries.length === 0) {\n    return '{}';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[' + getObjectTag(object) + ']';\n  }\n\n  const properties = entries.map(\n    ([key, value]) => key + ': ' + formatValue(value, seenValues),\n  );\n  return '{ ' + properties.join(', ') + ' }';\n}\n\nfunction formatArray(array, seenValues) {\n  if (array.length === 0) {\n    return '[]';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[Array]';\n  }\n\n  const len = Math.min(MAX_ARRAY_LENGTH, array.length);\n  const remaining = array.length - len;\n  const items = [];\n\n  for (let i = 0; i < len; ++i) {\n    items.push(formatValue(array[i], seenValues));\n  }\n\n  if (remaining === 1) {\n    items.push('... 1 more item');\n  } else if (remaining > 1) {\n    items.push(`... ${remaining} more items`);\n  }\n\n  return '[' + items.join(', ') + ']';\n}\n\nfunction getObjectTag(object) {\n  const tag = Object.prototype.toString\n    .call(object)\n    .replace(/^\\[object /, '')\n    .replace(/]$/, '');\n\n  if (tag === 'Object' && typeof object.constructor === 'function') {\n    const name = object.constructor.name;\n\n    if (typeof name === 'string' && name !== '') {\n      return name;\n    }\n  }\n\n  return tag;\n}\n","/**\n * Contains a range of UTF-8 character offsets and token references that\n * identify the region of the source from which the AST derived.\n */\nexport class Location {\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The Token at which this Node begins.\n   */\n\n  /**\n   * The Token at which this Node ends.\n   */\n\n  /**\n   * The Source document the AST represents.\n   */\n  constructor(startToken, endToken, source) {\n    this.start = startToken.start;\n    this.end = endToken.end;\n    this.startToken = startToken;\n    this.endToken = endToken;\n    this.source = source;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Location';\n  }\n\n  toJSON() {\n    return {\n      start: this.start,\n      end: this.end,\n    };\n  }\n}\n/**\n * Represents a range of characters represented by a lexical token\n * within a Source.\n */\n\nexport class Token {\n  /**\n   * The kind of Token.\n   */\n\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The 1-indexed line number on which this Token appears.\n   */\n\n  /**\n   * The 1-indexed column number at which this Token begins.\n   */\n\n  /**\n   * For non-punctuation tokens, represents the interpreted value of the token.\n   *\n   * Note: is undefined for punctuation tokens, but typed as string for\n   * convenience in the parser.\n   */\n\n  /**\n   * Tokens exist as nodes in a double-linked-list amongst all tokens\n   * including ignored tokens. <SOF> is always the first node and <EOF>\n   * the last.\n   */\n  constructor(kind, start, end, line, column, value) {\n    this.kind = kind;\n    this.start = start;\n    this.end = end;\n    this.line = line;\n    this.column = column; // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n\n    this.value = value;\n    this.prev = null;\n    this.next = null;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'Token';\n  }\n\n  toJSON() {\n    return {\n      kind: this.kind,\n      value: this.value,\n      line: this.line,\n      column: this.column,\n    };\n  }\n}\n/**\n * The list of all possible AST node types.\n */\n\n/**\n * @internal\n */\nexport const QueryDocumentKeys = {\n  Name: [],\n  Document: ['definitions'],\n  OperationDefinition: [\n    'name',\n    'variableDefinitions',\n    'directives',\n    'selectionSet',\n  ],\n  VariableDefinition: ['variable', 'type', 'defaultValue', 'directives'],\n  Variable: ['name'],\n  SelectionSet: ['selections'],\n  Field: ['alias', 'name', 'arguments', 'directives', 'selectionSet'],\n  Argument: ['name', 'value'],\n  FragmentSpread: ['name', 'directives'],\n  InlineFragment: ['typeCondition', 'directives', 'selectionSet'],\n  FragmentDefinition: [\n    'name', // Note: fragment variable definitions are deprecated and will removed in v17.0.0\n    'variableDefinitions',\n    'typeCondition',\n    'directives',\n    'selectionSet',\n  ],\n  IntValue: [],\n  FloatValue: [],\n  StringValue: [],\n  BooleanValue: [],\n  NullValue: [],\n  EnumValue: [],\n  ListValue: ['values'],\n  ObjectValue: ['fields'],\n  ObjectField: ['name', 'value'],\n  Directive: ['name', 'arguments'],\n  NamedType: ['name'],\n  ListType: ['type'],\n  NonNullType: ['type'],\n  SchemaDefinition: ['description', 'directives', 'operationTypes'],\n  OperationTypeDefinition: ['type'],\n  ScalarTypeDefinition: ['description', 'name', 'directives'],\n  ObjectTypeDefinition: [\n    'description',\n    'name',\n    'interfaces',\n    'directives',\n    'fields',\n  ],\n  FieldDefinition: ['description', 'name', 'arguments', 'type', 'directives'],\n  InputValueDefinition: [\n    'description',\n    'name',\n    'type',\n    'defaultValue',\n    'directives',\n  ],\n  InterfaceTypeDefinition: [\n    'description',\n    'name',\n    'interfaces',\n    'directives',\n    'fields',\n  ],\n  UnionTypeDefinition: ['description', 'name', 'directives', 'types'],\n  EnumTypeDefinition: ['description', 'name', 'directives', 'values'],\n  EnumValueDefinition: ['description', 'name', 'directives'],\n  InputObjectTypeDefinition: ['description', 'name', 'directives', 'fields'],\n  DirectiveDefinition: ['description', 'name', 'arguments', 'locations'],\n  SchemaExtension: ['directives', 'operationTypes'],\n  ScalarTypeExtension: ['name', 'directives'],\n  ObjectTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  InterfaceTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  UnionTypeExtension: ['name', 'directives', 'types'],\n  EnumTypeExtension: ['name', 'directives', 'values'],\n  InputObjectTypeExtension: ['name', 'directives', 'fields'],\n};\nconst kindValues = new Set(Object.keys(QueryDocumentKeys));\n/**\n * @internal\n */\n\nexport function isNode(maybeNode) {\n  const maybeKind =\n    maybeNode === null || maybeNode === void 0 ? void 0 : maybeNode.kind;\n  return typeof maybeKind === 'string' && kindValues.has(maybeKind);\n}\n/** Name */\n\nvar OperationTypeNode;\n\n(function (OperationTypeNode) {\n  OperationTypeNode['QUERY'] = 'query';\n  OperationTypeNode['MUTATION'] = 'mutation';\n  OperationTypeNode['SUBSCRIPTION'] = 'subscription';\n})(OperationTypeNode || (OperationTypeNode = {}));\n\nexport { OperationTypeNode };\n","import { isWhiteSpace } from './characterClasses.mjs';\n/**\n * Produces the value of a block string from its parsed raw value, similar to\n * CoffeeScript's block string, Python's docstring trim or Ruby's strip_heredoc.\n *\n * This implements the GraphQL spec's BlockStringValue() static algorithm.\n *\n * @internal\n */\n\nexport function dedentBlockStringLines(lines) {\n  var _firstNonEmptyLine2;\n\n  let commonIndent = Number.MAX_SAFE_INTEGER;\n  let firstNonEmptyLine = null;\n  let lastNonEmptyLine = -1;\n\n  for (let i = 0; i < lines.length; ++i) {\n    var _firstNonEmptyLine;\n\n    const line = lines[i];\n    const indent = leadingWhitespace(line);\n\n    if (indent === line.length) {\n      continue; // skip empty lines\n    }\n\n    firstNonEmptyLine =\n      (_firstNonEmptyLine = firstNonEmptyLine) !== null &&\n      _firstNonEmptyLine !== void 0\n        ? _firstNonEmptyLine\n        : i;\n    lastNonEmptyLine = i;\n\n    if (i !== 0 && indent < commonIndent) {\n      commonIndent = indent;\n    }\n  }\n\n  return lines // Remove common indentation from all lines but first.\n    .map((line, i) => (i === 0 ? line : line.slice(commonIndent))) // Remove leading and trailing blank lines.\n    .slice(\n      (_firstNonEmptyLine2 = firstNonEmptyLine) !== null &&\n        _firstNonEmptyLine2 !== void 0\n        ? _firstNonEmptyLine2\n        : 0,\n      lastNonEmptyLine + 1,\n    );\n}\n\nfunction leadingWhitespace(str) {\n  let i = 0;\n\n  while (i < str.length && isWhiteSpace(str.charCodeAt(i))) {\n    ++i;\n  }\n\n  return i;\n}\n/**\n * @internal\n */\n\nexport function isPrintableAsBlockString(value) {\n  if (value === '') {\n    return true; // empty string is printable\n  }\n\n  let isEmptyLine = true;\n  let hasIndent = false;\n  let hasCommonIndent = true;\n  let seenNonEmptyLine = false;\n\n  for (let i = 0; i < value.length; ++i) {\n    switch (value.codePointAt(i)) {\n      case 0x0000:\n      case 0x0001:\n      case 0x0002:\n      case 0x0003:\n      case 0x0004:\n      case 0x0005:\n      case 0x0006:\n      case 0x0007:\n      case 0x0008:\n      case 0x000b:\n      case 0x000c:\n      case 0x000e:\n      case 0x000f:\n        return false;\n      // Has non-printable characters\n\n      case 0x000d:\n        //  \\r\n        return false;\n      // Has \\r or \\r\\n which will be replaced as \\n\n\n      case 10:\n        //  \\n\n        if (isEmptyLine && !seenNonEmptyLine) {\n          return false; // Has leading new line\n        }\n\n        seenNonEmptyLine = true;\n        isEmptyLine = true;\n        hasIndent = false;\n        break;\n\n      case 9: //   \\t\n\n      case 32:\n        //  <space>\n        hasIndent || (hasIndent = isEmptyLine);\n        break;\n\n      default:\n        hasCommonIndent && (hasCommonIndent = hasIndent);\n        isEmptyLine = false;\n    }\n  }\n\n  if (isEmptyLine) {\n    return false; // Has trailing empty lines\n  }\n\n  if (hasCommonIndent && seenNonEmptyLine) {\n    return false; // Has internal indent\n  }\n\n  return true;\n}\n/**\n * Print a block string in the indented block form by adding a leading and\n * trailing blank line. However, if a block string starts with whitespace and is\n * a single-line, adding a leading blank line would strip that whitespace.\n *\n * @internal\n */\n\nexport function printBlockString(value, options) {\n  const escapedValue = value.replace(/\"\"\"/g, '\\\\\"\"\"'); // Expand a block string's raw value into independent lines.\n\n  const lines = escapedValue.split(/\\r\\n|[\\n\\r]/g);\n  const isSingleLine = lines.length === 1; // If common indentation is found we can fix some of those cases by adding leading new line\n\n  const forceLeadingNewLine =\n    lines.length > 1 &&\n    lines\n      .slice(1)\n      .every((line) => line.length === 0 || isWhiteSpace(line.charCodeAt(0))); // Trailing triple quotes just looks confusing but doesn't force trailing new line\n\n  const hasTrailingTripleQuotes = escapedValue.endsWith('\\\\\"\"\"'); // Trailing quote (single or double) or slash forces trailing new line\n\n  const hasTrailingQuote = value.endsWith('\"') && !hasTrailingTripleQuotes;\n  const hasTrailingSlash = value.endsWith('\\\\');\n  const forceTrailingNewline = hasTrailingQuote || hasTrailingSlash;\n  const printAsMultipleLines =\n    !(options !== null && options !== void 0 && options.minimize) && // add leading and trailing new lines only if it improves readability\n    (!isSingleLine ||\n      value.length > 70 ||\n      forceTrailingNewline ||\n      forceLeadingNewLine ||\n      hasTrailingTripleQuotes);\n  let result = ''; // Format a multi-line block quote to account for leading space.\n\n  const skipLeadingNewLine = isSingleLine && isWhiteSpace(value.charCodeAt(0));\n\n  if ((printAsMultipleLines && !skipLeadingNewLine) || forceLeadingNewLine) {\n    result += '\\n';\n  }\n\n  result += escapedValue;\n\n  if (printAsMultipleLines || forceTrailingNewline) {\n    result += '\\n';\n  }\n\n  return '\"\"\"' + result + '\"\"\"';\n}\n","/**\n * ```\n * WhiteSpace ::\n *   - \"Horizontal Tab (U+0009)\"\n *   - \"Space (U+0020)\"\n * ```\n * @internal\n */\nexport function isWhiteSpace(code) {\n  return code === 0x0009 || code === 0x0020;\n}\n/**\n * ```\n * Digit :: one of\n *   - `0` `1` `2` `3` `4` `5` `6` `7` `8` `9`\n * ```\n * @internal\n */\n\nexport function isDigit(code) {\n  return code >= 0x0030 && code <= 0x0039;\n}\n/**\n * ```\n * Letter :: one of\n *   - `A` `B` `C` `D` `E` `F` `G` `H` `I` `J` `K` `L` `M`\n *   - `N` `O` `P` `Q` `R` `S` `T` `U` `V` `W` `X` `Y` `Z`\n *   - `a` `b` `c` `d` `e` `f` `g` `h` `i` `j` `k` `l` `m`\n *   - `n` `o` `p` `q` `r` `s` `t` `u` `v` `w` `x` `y` `z`\n * ```\n * @internal\n */\n\nexport function isLetter(code) {\n  return (\n    (code >= 0x0061 && code <= 0x007a) || // A-Z\n    (code >= 0x0041 && code <= 0x005a) // a-z\n  );\n}\n/**\n * ```\n * NameStart ::\n *   - Letter\n *   - `_`\n * ```\n * @internal\n */\n\nexport function isNameStart(code) {\n  return isLetter(code) || code === 0x005f;\n}\n/**\n * ```\n * NameContinue ::\n *   - Letter\n *   - Digit\n *   - `_`\n * ```\n * @internal\n */\n\nexport function isNameContinue(code) {\n  return isLetter(code) || isDigit(code) || code === 0x005f;\n}\n","/**\n * The set of allowed kind values for AST nodes.\n */\nvar Kind;\n\n(function (Kind) {\n  Kind['NAME'] = 'Name';\n  Kind['DOCUMENT'] = 'Document';\n  Kind['OPERATION_DEFINITION'] = 'OperationDefinition';\n  Kind['VARIABLE_DEFINITION'] = 'VariableDefinition';\n  Kind['SELECTION_SET'] = 'SelectionSet';\n  Kind['FIELD'] = 'Field';\n  Kind['ARGUMENT'] = 'Argument';\n  Kind['FRAGMENT_SPREAD'] = 'FragmentSpread';\n  Kind['INLINE_FRAGMENT'] = 'InlineFragment';\n  Kind['FRAGMENT_DEFINITION'] = 'FragmentDefinition';\n  Kind['VARIABLE'] = 'Variable';\n  Kind['INT'] = 'IntValue';\n  Kind['FLOAT'] = 'FloatValue';\n  Kind['STRING'] = 'StringValue';\n  Kind['BOOLEAN'] = 'BooleanValue';\n  Kind['NULL'] = 'NullValue';\n  Kind['ENUM'] = 'EnumValue';\n  Kind['LIST'] = 'ListValue';\n  Kind['OBJECT'] = 'ObjectValue';\n  Kind['OBJECT_FIELD'] = 'ObjectField';\n  Kind['DIRECTIVE'] = 'Directive';\n  Kind['NAMED_TYPE'] = 'NamedType';\n  Kind['LIST_TYPE'] = 'ListType';\n  Kind['NON_NULL_TYPE'] = 'NonNullType';\n  Kind['SCHEMA_DEFINITION'] = 'SchemaDefinition';\n  Kind['OPERATION_TYPE_DEFINITION'] = 'OperationTypeDefinition';\n  Kind['SCALAR_TYPE_DEFINITION'] = 'ScalarTypeDefinition';\n  Kind['OBJECT_TYPE_DEFINITION'] = 'ObjectTypeDefinition';\n  Kind['FIELD_DEFINITION'] = 'FieldDefinition';\n  Kind['INPUT_VALUE_DEFINITION'] = 'InputValueDefinition';\n  Kind['INTERFACE_TYPE_DEFINITION'] = 'InterfaceTypeDefinition';\n  Kind['UNION_TYPE_DEFINITION'] = 'UnionTypeDefinition';\n  Kind['ENUM_TYPE_DEFINITION'] = 'EnumTypeDefinition';\n  Kind['ENUM_VALUE_DEFINITION'] = 'EnumValueDefinition';\n  Kind['INPUT_OBJECT_TYPE_DEFINITION'] = 'InputObjectTypeDefinition';\n  Kind['DIRECTIVE_DEFINITION'] = 'DirectiveDefinition';\n  Kind['SCHEMA_EXTENSION'] = 'SchemaExtension';\n  Kind['SCALAR_TYPE_EXTENSION'] = 'ScalarTypeExtension';\n  Kind['OBJECT_TYPE_EXTENSION'] = 'ObjectTypeExtension';\n  Kind['INTERFACE_TYPE_EXTENSION'] = 'InterfaceTypeExtension';\n  Kind['UNION_TYPE_EXTENSION'] = 'UnionTypeExtension';\n  Kind['ENUM_TYPE_EXTENSION'] = 'EnumTypeExtension';\n  Kind['INPUT_OBJECT_TYPE_EXTENSION'] = 'InputObjectTypeExtension';\n})(Kind || (Kind = {}));\n\nexport { Kind };\n/**\n * The enum type representing the possible kind values of AST nodes.\n *\n * @deprecated Please use `Kind`. Will be remove in v17.\n */\n","import { Kind } from './kinds.mjs';\nexport function isDefinitionNode(node) {\n  return (\n    isExecutableDefinitionNode(node) ||\n    isTypeSystemDefinitionNode(node) ||\n    isTypeSystemExtensionNode(node)\n  );\n}\nexport function isExecutableDefinitionNode(node) {\n  return (\n    node.kind === Kind.OPERATION_DEFINITION ||\n    node.kind === Kind.FRAGMENT_DEFINITION\n  );\n}\nexport function isSelectionNode(node) {\n  return (\n    node.kind === Kind.FIELD ||\n    node.kind === Kind.FRAGMENT_SPREAD ||\n    node.kind === Kind.INLINE_FRAGMENT\n  );\n}\nexport function isValueNode(node) {\n  return (\n    node.kind === Kind.VARIABLE ||\n    node.kind === Kind.INT ||\n    node.kind === Kind.FLOAT ||\n    node.kind === Kind.STRING ||\n    node.kind === Kind.BOOLEAN ||\n    node.kind === Kind.NULL ||\n    node.kind === Kind.ENUM ||\n    node.kind === Kind.LIST ||\n    node.kind === Kind.OBJECT\n  );\n}\nexport function isConstValueNode(node) {\n  return (\n    isValueNode(node) &&\n    (node.kind === Kind.LIST\n      ? node.values.some(isConstValueNode)\n      : node.kind === Kind.OBJECT\n      ? node.fields.some((field) => isConstValueNode(field.value))\n      : node.kind !== Kind.VARIABLE)\n  );\n}\nexport function isTypeNode(node) {\n  return (\n    node.kind === Kind.NAMED_TYPE ||\n    node.kind === Kind.LIST_TYPE ||\n    node.kind === Kind.NON_NULL_TYPE\n  );\n}\nexport function isTypeSystemDefinitionNode(node) {\n  return (\n    node.kind === Kind.SCHEMA_DEFINITION ||\n    isTypeDefinitionNode(node) ||\n    node.kind === Kind.DIRECTIVE_DEFINITION\n  );\n}\nexport function isTypeDefinitionNode(node) {\n  return (\n    node.kind === Kind.SCALAR_TYPE_DEFINITION ||\n    node.kind === Kind.OBJECT_TYPE_DEFINITION ||\n    node.kind === Kind.INTERFACE_TYPE_DEFINITION ||\n    node.kind === Kind.UNION_TYPE_DEFINITION ||\n    node.kind === Kind.ENUM_TYPE_DEFINITION ||\n    node.kind === Kind.INPUT_OBJECT_TYPE_DEFINITION\n  );\n}\nexport function isTypeSystemExtensionNode(node) {\n  return node.kind === Kind.SCHEMA_EXTENSION || isTypeExtensionNode(node);\n}\nexport function isTypeExtensionNode(node) {\n  return (\n    node.kind === Kind.SCALAR_TYPE_EXTENSION ||\n    node.kind === Kind.OBJECT_TYPE_EXTENSION ||\n    node.kind === Kind.INTERFACE_TYPE_EXTENSION ||\n    node.kind === Kind.UNION_TYPE_EXTENSION ||\n    node.kind === Kind.ENUM_TYPE_EXTENSION ||\n    node.kind === Kind.INPUT_OBJECT_TYPE_EXTENSION\n  );\n}\n","/**\n * Prints a string as a GraphQL StringValue literal. Replaces control characters\n * and excluded characters (\" U+0022 and \\\\ U+005C) with escape sequences.\n */\nexport function printString(str) {\n  return `\"${str.replace(escapedRegExp, escapedReplacer)}\"`;\n} // eslint-disable-next-line no-control-regex\n\nconst escapedRegExp = /[\\x00-\\x1f\\x22\\x5c\\x7f-\\x9f]/g;\n\nfunction escapedReplacer(str) {\n  return escapeSequences[str.charCodeAt(0)];\n} // prettier-ignore\n\nconst escapeSequences = [\n  '\\\\u0000',\n  '\\\\u0001',\n  '\\\\u0002',\n  '\\\\u0003',\n  '\\\\u0004',\n  '\\\\u0005',\n  '\\\\u0006',\n  '\\\\u0007',\n  '\\\\b',\n  '\\\\t',\n  '\\\\n',\n  '\\\\u000B',\n  '\\\\f',\n  '\\\\r',\n  '\\\\u000E',\n  '\\\\u000F',\n  '\\\\u0010',\n  '\\\\u0011',\n  '\\\\u0012',\n  '\\\\u0013',\n  '\\\\u0014',\n  '\\\\u0015',\n  '\\\\u0016',\n  '\\\\u0017',\n  '\\\\u0018',\n  '\\\\u0019',\n  '\\\\u001A',\n  '\\\\u001B',\n  '\\\\u001C',\n  '\\\\u001D',\n  '\\\\u001E',\n  '\\\\u001F',\n  '',\n  '',\n  '\\\\\"',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 2F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 3F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 4F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '\\\\\\\\',\n  '',\n  '',\n  '', // 5F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '', // 6F\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '\\\\u007F',\n  '\\\\u0080',\n  '\\\\u0081',\n  '\\\\u0082',\n  '\\\\u0083',\n  '\\\\u0084',\n  '\\\\u0085',\n  '\\\\u0086',\n  '\\\\u0087',\n  '\\\\u0088',\n  '\\\\u0089',\n  '\\\\u008A',\n  '\\\\u008B',\n  '\\\\u008C',\n  '\\\\u008D',\n  '\\\\u008E',\n  '\\\\u008F',\n  '\\\\u0090',\n  '\\\\u0091',\n  '\\\\u0092',\n  '\\\\u0093',\n  '\\\\u0094',\n  '\\\\u0095',\n  '\\\\u0096',\n  '\\\\u0097',\n  '\\\\u0098',\n  '\\\\u0099',\n  '\\\\u009A',\n  '\\\\u009B',\n  '\\\\u009C',\n  '\\\\u009D',\n  '\\\\u009E',\n  '\\\\u009F',\n];\n","import { printBlockString } from './blockString.mjs';\nimport { printString } from './printString.mjs';\nimport { visit } from './visitor.mjs';\n/**\n * Converts an AST into a string, using one set of reasonable\n * formatting rules.\n */\n\nexport function print(ast) {\n  return visit(ast, printDocASTReducer);\n}\nconst MAX_LINE_LENGTH = 80;\nconst printDocASTReducer = {\n  Name: {\n    leave: (node) => node.value,\n  },\n  Variable: {\n    leave: (node) => '$' + node.name,\n  },\n  // Document\n  Document: {\n    leave: (node) => join(node.definitions, '\\n\\n'),\n  },\n  OperationDefinition: {\n    leave(node) {\n      const varDefs = wrap('(', join(node.variableDefinitions, ', '), ')');\n      const prefix = join(\n        [\n          node.operation,\n          join([node.name, varDefs]),\n          join(node.directives, ' '),\n        ],\n        ' ',\n      ); // Anonymous queries with no directives or variable definitions can use\n      // the query short form.\n\n      return (prefix === 'query' ? '' : prefix + ' ') + node.selectionSet;\n    },\n  },\n  VariableDefinition: {\n    leave: ({ variable, type, defaultValue, directives }) =>\n      variable +\n      ': ' +\n      type +\n      wrap(' = ', defaultValue) +\n      wrap(' ', join(directives, ' ')),\n  },\n  SelectionSet: {\n    leave: ({ selections }) => block(selections),\n  },\n  Field: {\n    leave({ alias, name, arguments: args, directives, selectionSet }) {\n      const prefix = wrap('', alias, ': ') + name;\n      let argsLine = prefix + wrap('(', join(args, ', '), ')');\n\n      if (argsLine.length > MAX_LINE_LENGTH) {\n        argsLine = prefix + wrap('(\\n', indent(join(args, '\\n')), '\\n)');\n      }\n\n      return join([argsLine, join(directives, ' '), selectionSet], ' ');\n    },\n  },\n  Argument: {\n    leave: ({ name, value }) => name + ': ' + value,\n  },\n  // Fragments\n  FragmentSpread: {\n    leave: ({ name, directives }) =>\n      '...' + name + wrap(' ', join(directives, ' ')),\n  },\n  InlineFragment: {\n    leave: ({ typeCondition, directives, selectionSet }) =>\n      join(\n        [\n          '...',\n          wrap('on ', typeCondition),\n          join(directives, ' '),\n          selectionSet,\n        ],\n        ' ',\n      ),\n  },\n  FragmentDefinition: {\n    leave: (\n      { name, typeCondition, variableDefinitions, directives, selectionSet }, // Note: fragment variable definitions are experimental and may be changed\n    ) =>\n      // or removed in the future.\n      `fragment ${name}${wrap('(', join(variableDefinitions, ', '), ')')} ` +\n      `on ${typeCondition} ${wrap('', join(directives, ' '), ' ')}` +\n      selectionSet,\n  },\n  // Value\n  IntValue: {\n    leave: ({ value }) => value,\n  },\n  FloatValue: {\n    leave: ({ value }) => value,\n  },\n  StringValue: {\n    leave: ({ value, block: isBlockString }) =>\n      isBlockString ? printBlockString(value) : printString(value),\n  },\n  BooleanValue: {\n    leave: ({ value }) => (value ? 'true' : 'false'),\n  },\n  NullValue: {\n    leave: () => 'null',\n  },\n  EnumValue: {\n    leave: ({ value }) => value,\n  },\n  ListValue: {\n    leave: ({ values }) => '[' + join(values, ', ') + ']',\n  },\n  ObjectValue: {\n    leave: ({ fields }) => '{' + join(fields, ', ') + '}',\n  },\n  ObjectField: {\n    leave: ({ name, value }) => name + ': ' + value,\n  },\n  // Directive\n  Directive: {\n    leave: ({ name, arguments: args }) =>\n      '@' + name + wrap('(', join(args, ', '), ')'),\n  },\n  // Type\n  NamedType: {\n    leave: ({ name }) => name,\n  },\n  ListType: {\n    leave: ({ type }) => '[' + type + ']',\n  },\n  NonNullType: {\n    leave: ({ type }) => type + '!',\n  },\n  // Type System Definitions\n  SchemaDefinition: {\n    leave: ({ description, directives, operationTypes }) =>\n      wrap('', description, '\\n') +\n      join(['schema', join(directives, ' '), block(operationTypes)], ' '),\n  },\n  OperationTypeDefinition: {\n    leave: ({ operation, type }) => operation + ': ' + type,\n  },\n  ScalarTypeDefinition: {\n    leave: ({ description, name, directives }) =>\n      wrap('', description, '\\n') +\n      join(['scalar', name, join(directives, ' ')], ' '),\n  },\n  ObjectTypeDefinition: {\n    leave: ({ description, name, interfaces, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(\n        [\n          'type',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  FieldDefinition: {\n    leave: ({ description, name, arguments: args, type, directives }) =>\n      wrap('', description, '\\n') +\n      name +\n      (hasMultilineItems(args)\n        ? wrap('(\\n', indent(join(args, '\\n')), '\\n)')\n        : wrap('(', join(args, ', '), ')')) +\n      ': ' +\n      type +\n      wrap(' ', join(directives, ' ')),\n  },\n  InputValueDefinition: {\n    leave: ({ description, name, type, defaultValue, directives }) =>\n      wrap('', description, '\\n') +\n      join(\n        [name + ': ' + type, wrap('= ', defaultValue), join(directives, ' ')],\n        ' ',\n      ),\n  },\n  InterfaceTypeDefinition: {\n    leave: ({ description, name, interfaces, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(\n        [\n          'interface',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  UnionTypeDefinition: {\n    leave: ({ description, name, directives, types }) =>\n      wrap('', description, '\\n') +\n      join(\n        ['union', name, join(directives, ' '), wrap('= ', join(types, ' | '))],\n        ' ',\n      ),\n  },\n  EnumTypeDefinition: {\n    leave: ({ description, name, directives, values }) =>\n      wrap('', description, '\\n') +\n      join(['enum', name, join(directives, ' '), block(values)], ' '),\n  },\n  EnumValueDefinition: {\n    leave: ({ description, name, directives }) =>\n      wrap('', description, '\\n') + join([name, join(directives, ' ')], ' '),\n  },\n  InputObjectTypeDefinition: {\n    leave: ({ description, name, directives, fields }) =>\n      wrap('', description, '\\n') +\n      join(['input', name, join(directives, ' '), block(fields)], ' '),\n  },\n  DirectiveDefinition: {\n    leave: ({ description, name, arguments: args, repeatable, locations }) =>\n      wrap('', description, '\\n') +\n      'directive @' +\n      name +\n      (hasMultilineItems(args)\n        ? wrap('(\\n', indent(join(args, '\\n')), '\\n)')\n        : wrap('(', join(args, ', '), ')')) +\n      (repeatable ? ' repeatable' : '') +\n      ' on ' +\n      join(locations, ' | '),\n  },\n  SchemaExtension: {\n    leave: ({ directives, operationTypes }) =>\n      join(\n        ['extend schema', join(directives, ' '), block(operationTypes)],\n        ' ',\n      ),\n  },\n  ScalarTypeExtension: {\n    leave: ({ name, directives }) =>\n      join(['extend scalar', name, join(directives, ' ')], ' '),\n  },\n  ObjectTypeExtension: {\n    leave: ({ name, interfaces, directives, fields }) =>\n      join(\n        [\n          'extend type',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  InterfaceTypeExtension: {\n    leave: ({ name, interfaces, directives, fields }) =>\n      join(\n        [\n          'extend interface',\n          name,\n          wrap('implements ', join(interfaces, ' & ')),\n          join(directives, ' '),\n          block(fields),\n        ],\n        ' ',\n      ),\n  },\n  UnionTypeExtension: {\n    leave: ({ name, directives, types }) =>\n      join(\n        [\n          'extend union',\n          name,\n          join(directives, ' '),\n          wrap('= ', join(types, ' | ')),\n        ],\n        ' ',\n      ),\n  },\n  EnumTypeExtension: {\n    leave: ({ name, directives, values }) =>\n      join(['extend enum', name, join(directives, ' '), block(values)], ' '),\n  },\n  InputObjectTypeExtension: {\n    leave: ({ name, directives, fields }) =>\n      join(['extend input', name, join(directives, ' '), block(fields)], ' '),\n  },\n};\n/**\n * Given maybeArray, print an empty string if it is null or empty, otherwise\n * print all items together separated by separator if provided\n */\n\nfunction join(maybeArray, separator = '') {\n  var _maybeArray$filter$jo;\n\n  return (_maybeArray$filter$jo =\n    maybeArray === null || maybeArray === void 0\n      ? void 0\n      : maybeArray.filter((x) => x).join(separator)) !== null &&\n    _maybeArray$filter$jo !== void 0\n    ? _maybeArray$filter$jo\n    : '';\n}\n/**\n * Given array, print each item on its own line, wrapped in an indented `{ }` block.\n */\n\nfunction block(array) {\n  return wrap('{\\n', indent(join(array, '\\n')), '\\n}');\n}\n/**\n * If maybeString is not null or empty, then wrap with start and end, otherwise print an empty string.\n */\n\nfunction wrap(start, maybeString, end = '') {\n  return maybeString != null && maybeString !== ''\n    ? start + maybeString + end\n    : '';\n}\n\nfunction indent(str) {\n  return wrap('  ', str.replace(/\\n/g, '\\n  '));\n}\n\nfunction hasMultilineItems(maybeArray) {\n  var _maybeArray$some;\n\n  // FIXME: https://github.com/graphql/graphql-js/issues/2203\n\n  /* c8 ignore next */\n  return (_maybeArray$some =\n    maybeArray === null || maybeArray === void 0\n      ? void 0\n      : maybeArray.some((str) => str.includes('\\n'))) !== null &&\n    _maybeArray$some !== void 0\n    ? _maybeArray$some\n    : false;\n}\n","import { devAssert } from '../jsutils/devAssert.mjs';\nimport { inspect } from '../jsutils/inspect.mjs';\nimport { isNode, QueryDocumentKeys } from './ast.mjs';\nimport { Kind } from './kinds.mjs';\n/**\n * A visitor is provided to visit, it contains the collection of\n * relevant functions to be called during the visitor's traversal.\n */\n\nexport const BREAK = Object.freeze({});\n/**\n * visit() will walk through an AST using a depth-first traversal, calling\n * the visitor's enter function at each node in the traversal, and calling the\n * leave function after visiting that node and all of its child nodes.\n *\n * By returning different values from the enter and leave functions, the\n * behavior of the visitor can be altered, including skipping over a sub-tree of\n * the AST (by returning false), editing the AST by returning a value or null\n * to remove the value, or to stop the whole traversal by returning BREAK.\n *\n * When using visit() to edit an AST, the original AST will not be modified, and\n * a new version of the AST with the changes applied will be returned from the\n * visit function.\n *\n * ```ts\n * const editedAST = visit(ast, {\n *   enter(node, key, parent, path, ancestors) {\n *     // @return\n *     //   undefined: no action\n *     //   false: skip visiting this node\n *     //   visitor.BREAK: stop visiting altogether\n *     //   null: delete this node\n *     //   any value: replace this node with the returned value\n *   },\n *   leave(node, key, parent, path, ancestors) {\n *     // @return\n *     //   undefined: no action\n *     //   false: no action\n *     //   visitor.BREAK: stop visiting altogether\n *     //   null: delete this node\n *     //   any value: replace this node with the returned value\n *   }\n * });\n * ```\n *\n * Alternatively to providing enter() and leave() functions, a visitor can\n * instead provide functions named the same as the kinds of AST nodes, or\n * enter/leave visitors at a named key, leading to three permutations of the\n * visitor API:\n *\n * 1) Named visitors triggered when entering a node of a specific kind.\n *\n * ```ts\n * visit(ast, {\n *   Kind(node) {\n *     // enter the \"Kind\" node\n *   }\n * })\n * ```\n *\n * 2) Named visitors that trigger upon entering and leaving a node of a specific kind.\n *\n * ```ts\n * visit(ast, {\n *   Kind: {\n *     enter(node) {\n *       // enter the \"Kind\" node\n *     }\n *     leave(node) {\n *       // leave the \"Kind\" node\n *     }\n *   }\n * })\n * ```\n *\n * 3) Generic visitors that trigger upon entering and leaving any node.\n *\n * ```ts\n * visit(ast, {\n *   enter(node) {\n *     // enter any node\n *   },\n *   leave(node) {\n *     // leave any node\n *   }\n * })\n * ```\n */\n\nexport function visit(root, visitor, visitorKeys = QueryDocumentKeys) {\n  const enterLeaveMap = new Map();\n\n  for (const kind of Object.values(Kind)) {\n    enterLeaveMap.set(kind, getEnterLeaveForKind(visitor, kind));\n  }\n  /* eslint-disable no-undef-init */\n\n  let stack = undefined;\n  let inArray = Array.isArray(root);\n  let keys = [root];\n  let index = -1;\n  let edits = [];\n  let node = root;\n  let key = undefined;\n  let parent = undefined;\n  const path = [];\n  const ancestors = [];\n  /* eslint-enable no-undef-init */\n\n  do {\n    index++;\n    const isLeaving = index === keys.length;\n    const isEdited = isLeaving && edits.length !== 0;\n\n    if (isLeaving) {\n      key = ancestors.length === 0 ? undefined : path[path.length - 1];\n      node = parent;\n      parent = ancestors.pop();\n\n      if (isEdited) {\n        if (inArray) {\n          node = node.slice();\n          let editOffset = 0;\n\n          for (const [editKey, editValue] of edits) {\n            const arrayKey = editKey - editOffset;\n\n            if (editValue === null) {\n              node.splice(arrayKey, 1);\n              editOffset++;\n            } else {\n              node[arrayKey] = editValue;\n            }\n          }\n        } else {\n          node = Object.defineProperties(\n            {},\n            Object.getOwnPropertyDescriptors(node),\n          );\n\n          for (const [editKey, editValue] of edits) {\n            node[editKey] = editValue;\n          }\n        }\n      }\n\n      index = stack.index;\n      keys = stack.keys;\n      edits = stack.edits;\n      inArray = stack.inArray;\n      stack = stack.prev;\n    } else if (parent) {\n      key = inArray ? index : keys[index];\n      node = parent[key];\n\n      if (node === null || node === undefined) {\n        continue;\n      }\n\n      path.push(key);\n    }\n\n    let result;\n\n    if (!Array.isArray(node)) {\n      var _enterLeaveMap$get, _enterLeaveMap$get2;\n\n      isNode(node) || devAssert(false, `Invalid AST Node: ${inspect(node)}.`);\n      const visitFn = isLeaving\n        ? (_enterLeaveMap$get = enterLeaveMap.get(node.kind)) === null ||\n          _enterLeaveMap$get === void 0\n          ? void 0\n          : _enterLeaveMap$get.leave\n        : (_enterLeaveMap$get2 = enterLeaveMap.get(node.kind)) === null ||\n          _enterLeaveMap$get2 === void 0\n        ? void 0\n        : _enterLeaveMap$get2.enter;\n      result =\n        visitFn === null || visitFn === void 0\n          ? void 0\n          : visitFn.call(visitor, node, key, parent, path, ancestors);\n\n      if (result === BREAK) {\n        break;\n      }\n\n      if (result === false) {\n        if (!isLeaving) {\n          path.pop();\n          continue;\n        }\n      } else if (result !== undefined) {\n        edits.push([key, result]);\n\n        if (!isLeaving) {\n          if (isNode(result)) {\n            node = result;\n          } else {\n            path.pop();\n            continue;\n          }\n        }\n      }\n    }\n\n    if (result === undefined && isEdited) {\n      edits.push([key, node]);\n    }\n\n    if (isLeaving) {\n      path.pop();\n    } else {\n      var _node$kind;\n\n      stack = {\n        inArray,\n        index,\n        keys,\n        edits,\n        prev: stack,\n      };\n      inArray = Array.isArray(node);\n      keys = inArray\n        ? node\n        : (_node$kind = visitorKeys[node.kind]) !== null &&\n          _node$kind !== void 0\n        ? _node$kind\n        : [];\n      index = -1;\n      edits = [];\n\n      if (parent) {\n        ancestors.push(parent);\n      }\n\n      parent = node;\n    }\n  } while (stack !== undefined);\n\n  if (edits.length !== 0) {\n    // New root\n    return edits[edits.length - 1][1];\n  }\n\n  return root;\n}\n/**\n * Creates a new visitor instance which delegates to many visitors to run in\n * parallel. Each visitor will be visited for each node before moving on.\n *\n * If a prior visitor edits a node, no following visitors will see that node.\n */\n\nexport function visitInParallel(visitors) {\n  const skipping = new Array(visitors.length).fill(null);\n  const mergedVisitor = Object.create(null);\n\n  for (const kind of Object.values(Kind)) {\n    let hasVisitor = false;\n    const enterList = new Array(visitors.length).fill(undefined);\n    const leaveList = new Array(visitors.length).fill(undefined);\n\n    for (let i = 0; i < visitors.length; ++i) {\n      const { enter, leave } = getEnterLeaveForKind(visitors[i], kind);\n      hasVisitor || (hasVisitor = enter != null || leave != null);\n      enterList[i] = enter;\n      leaveList[i] = leave;\n    }\n\n    if (!hasVisitor) {\n      continue;\n    }\n\n    const mergedEnterLeave = {\n      enter(...args) {\n        const node = args[0];\n\n        for (let i = 0; i < visitors.length; i++) {\n          if (skipping[i] === null) {\n            var _enterList$i;\n\n            const result =\n              (_enterList$i = enterList[i]) === null || _enterList$i === void 0\n                ? void 0\n                : _enterList$i.apply(visitors[i], args);\n\n            if (result === false) {\n              skipping[i] = node;\n            } else if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined) {\n              return result;\n            }\n          }\n        }\n      },\n\n      leave(...args) {\n        const node = args[0];\n\n        for (let i = 0; i < visitors.length; i++) {\n          if (skipping[i] === null) {\n            var _leaveList$i;\n\n            const result =\n              (_leaveList$i = leaveList[i]) === null || _leaveList$i === void 0\n                ? void 0\n                : _leaveList$i.apply(visitors[i], args);\n\n            if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined && result !== false) {\n              return result;\n            }\n          } else if (skipping[i] === node) {\n            skipping[i] = null;\n          }\n        }\n      },\n    };\n    mergedVisitor[kind] = mergedEnterLeave;\n  }\n\n  return mergedVisitor;\n}\n/**\n * Given a visitor instance and a node kind, return EnterLeaveVisitor for that kind.\n */\n\nexport function getEnterLeaveForKind(visitor, kind) {\n  const kindVisitor = visitor[kind];\n\n  if (typeof kindVisitor === 'object') {\n    // { Kind: { enter() {}, leave() {} } }\n    return kindVisitor;\n  } else if (typeof kindVisitor === 'function') {\n    // { Kind() {} }\n    return {\n      enter: kindVisitor,\n      leave: undefined,\n    };\n  } // { enter() {}, leave() {} }\n\n  return {\n    enter: visitor.enter,\n    leave: visitor.leave,\n  };\n}\n/**\n * Given a visitor instance, if it is leaving or not, and a node kind, return\n * the function the visitor runtime should call.\n *\n * @deprecated Please use `getEnterLeaveForKind` instead. Will be removed in v17\n */\n\n/* c8 ignore next 8 */\n\nexport function getVisitFn(visitor, kind, isLeaving) {\n  const { enter, leave } = getEnterLeaveForKind(visitor, kind);\n  return isLeaving ? leave : enter;\n}\n",null,null,null,null,"const genericMessage = \"Invariant Violation\";\nconst {\n  setPrototypeOf = function (obj: any, proto: any) {\n    obj.__proto__ = proto;\n    return obj;\n  },\n} = Object as any;\n\nexport class InvariantError extends Error {\n  framesToPop = 1;\n  name = genericMessage;\n  constructor(message: string | number = genericMessage) {\n    super(\n      typeof message === \"number\"\n        ? `${genericMessage}: ${message} (see https://github.com/apollographql/invariant-packages)`\n        : message\n    );\n    setPrototypeOf(this, InvariantError.prototype);\n  }\n}\n\nexport function invariant(\n  condition: any,\n  message?: string | number,\n): asserts condition {\n  if (!condition) {\n    throw new InvariantError(message);\n  }\n}\n\nconst verbosityLevels = [\"debug\", \"log\", \"warn\", \"error\", \"silent\"] as const;\nexport type VerbosityLevel = (typeof verbosityLevels)[number];\nexport type ConsoleMethodName = Exclude<VerbosityLevel, \"silent\">;\nlet verbosityLevel = verbosityLevels.indexOf(\"log\");\n\nfunction wrapConsoleMethod<M extends ConsoleMethodName>(name: M) {\n  return function () {\n    if (verbosityLevels.indexOf(name) >= verbosityLevel) {\n      // Default to console.log if this host environment happens not to provide\n      // all the console.* methods we need.\n      const method = console[name] || console.log;\n      return method.apply(console, arguments as any);\n    }\n  } as (typeof console)[M];\n}\n\nexport namespace invariant {\n  export const debug = wrapConsoleMethod(\"debug\");\n  export const log = wrapConsoleMethod(\"log\");\n  export const warn = wrapConsoleMethod(\"warn\");\n  export const error = wrapConsoleMethod(\"error\");\n}\n\nexport function setVerbosity(level: VerbosityLevel): VerbosityLevel {\n  const old = verbosityLevels[verbosityLevel];\n  verbosityLevel = Math.max(0, verbosityLevels.indexOf(level));\n  return old;\n}\n\nexport default invariant;\n","/******************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise, SuppressedError, Symbol */\n\nvar extendStatics = function(d, b) {\n  extendStatics = Object.setPrototypeOf ||\n      ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n      function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n  return extendStatics(d, b);\n};\n\nexport function __extends(d, b) {\n  if (typeof b !== \"function\" && b !== null)\n      throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n  extendStatics(d, b);\n  function __() { this.constructor = d; }\n  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\n\nexport var __assign = function() {\n  __assign = Object.assign || function __assign(t) {\n      for (var s, i = 1, n = arguments.length; i < n; i++) {\n          s = arguments[i];\n          for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n      }\n      return t;\n  }\n  return __assign.apply(this, arguments);\n}\n\nexport function __rest(s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n      t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n      for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n          if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n              t[p[i]] = s[p[i]];\n      }\n  return t;\n}\n\nexport function __decorate(decorators, target, key, desc) {\n  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n}\n\nexport function __param(paramIndex, decorator) {\n  return function (target, key) { decorator(target, key, paramIndex); }\n}\n\nexport function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\n  function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\n  var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\n  var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\n  var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\n  var _, done = false;\n  for (var i = decorators.length - 1; i >= 0; i--) {\n      var context = {};\n      for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\n      for (var p in contextIn.access) context.access[p] = contextIn.access[p];\n      context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\n      var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\n      if (kind === \"accessor\") {\n          if (result === void 0) continue;\n          if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\n          if (_ = accept(result.get)) descriptor.get = _;\n          if (_ = accept(result.set)) descriptor.set = _;\n          if (_ = accept(result.init)) initializers.unshift(_);\n      }\n      else if (_ = accept(result)) {\n          if (kind === \"field\") initializers.unshift(_);\n          else descriptor[key] = _;\n      }\n  }\n  if (target) Object.defineProperty(target, contextIn.name, descriptor);\n  done = true;\n};\n\nexport function __runInitializers(thisArg, initializers, value) {\n  var useValue = arguments.length > 2;\n  for (var i = 0; i < initializers.length; i++) {\n      value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\n  }\n  return useValue ? value : void 0;\n};\n\nexport function __propKey(x) {\n  return typeof x === \"symbol\" ? x : \"\".concat(x);\n};\n\nexport function __setFunctionName(f, name, prefix) {\n  if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\n  return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\n};\n\nexport function __metadata(metadataKey, metadataValue) {\n  if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n}\n\nexport function __awaiter(thisArg, _arguments, P, generator) {\n  function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n  return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n      function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n      function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n}\n\nexport function __generator(thisArg, body) {\n  var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n  return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n  function verb(n) { return function (v) { return step([n, v]); }; }\n  function step(op) {\n      if (f) throw new TypeError(\"Generator is already executing.\");\n      while (g && (g = 0, op[0] && (_ = 0)), _) try {\n          if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n          if (y = 0, t) op = [op[0] & 2, t.value];\n          switch (op[0]) {\n              case 0: case 1: t = op; break;\n              case 4: _.label++; return { value: op[1], done: false };\n              case 5: _.label++; y = op[1]; op = [0]; continue;\n              case 7: op = _.ops.pop(); _.trys.pop(); continue;\n              default:\n                  if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                  if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                  if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                  if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                  if (t[2]) _.ops.pop();\n                  _.trys.pop(); continue;\n          }\n          op = body.call(thisArg, _);\n      } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n      if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n  }\n}\n\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n  }\n  Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nexport function __exportStar(m, o) {\n  for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\n}\n\nexport function __values(o) {\n  var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n  if (m) return m.call(o);\n  if (o && typeof o.length === \"number\") return {\n      next: function () {\n          if (o && i >= o.length) o = void 0;\n          return { value: o && o[i++], done: !o };\n      }\n  };\n  throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\n\nexport function __read(o, n) {\n  var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n  if (!m) return o;\n  var i = m.call(o), r, ar = [], e;\n  try {\n      while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n  }\n  catch (error) { e = { error: error }; }\n  finally {\n      try {\n          if (r && !r.done && (m = i[\"return\"])) m.call(i);\n      }\n      finally { if (e) throw e.error; }\n  }\n  return ar;\n}\n\n/** @deprecated */\nexport function __spread() {\n  for (var ar = [], i = 0; i < arguments.length; i++)\n      ar = ar.concat(__read(arguments[i]));\n  return ar;\n}\n\n/** @deprecated */\nexport function __spreadArrays() {\n  for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n  for (var r = Array(s), k = 0, i = 0; i < il; i++)\n      for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n          r[k] = a[j];\n  return r;\n}\n\nexport function __spreadArray(to, from, pack) {\n  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n      if (ar || !(i in from)) {\n          if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n          ar[i] = from[i];\n      }\n  }\n  return to.concat(ar || Array.prototype.slice.call(from));\n}\n\nexport function __await(v) {\n  return this instanceof __await ? (this.v = v, this) : new __await(v);\n}\n\nexport function __asyncGenerator(thisArg, _arguments, generator) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var g = generator.apply(thisArg, _arguments || []), i, q = [];\n  return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n  function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n  function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n  function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n  function fulfill(value) { resume(\"next\", value); }\n  function reject(value) { resume(\"throw\", value); }\n  function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n}\n\nexport function __asyncDelegator(o) {\n  var i, p;\n  return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n  function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\n}\n\nexport function __asyncValues(o) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var m = o[Symbol.asyncIterator], i;\n  return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n  function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n  function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n}\n\nexport function __makeTemplateObject(cooked, raw) {\n  if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\n  return cooked;\n};\n\nvar __setModuleDefault = Object.create ? (function(o, v) {\n  Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n  o[\"default\"] = v;\n};\n\nexport function __importStar(mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n}\n\nexport function __importDefault(mod) {\n  return (mod && mod.__esModule) ? mod : { default: mod };\n}\n\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\n\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n}\n\nexport function __classPrivateFieldIn(state, receiver) {\n  if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\n  return typeof state === \"function\" ? receiver === state : state.has(receiver);\n}\n\nexport function __addDisposableResource(env, value, async) {\n  if (value !== null && value !== void 0) {\n    if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\n    var dispose;\n    if (async) {\n        if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\n        dispose = value[Symbol.asyncDispose];\n    }\n    if (dispose === void 0) {\n        if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\n        dispose = value[Symbol.dispose];\n    }\n    if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\n    env.stack.push({ value: value, dispose: dispose, async: async });\n  }\n  else if (async) {\n    env.stack.push({ async: true });\n  }\n  return value;\n}\n\nvar _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\n  var e = new Error(message);\n  return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\n};\n\nexport function __disposeResources(env) {\n  function fail(e) {\n    env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\n    env.hasError = true;\n  }\n  function next() {\n    while (env.stack.length) {\n      var rec = env.stack.pop();\n      try {\n        var result = rec.dispose && rec.dispose.call(rec.value);\n        if (rec.async) return Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\n      }\n      catch (e) {\n          fail(e);\n      }\n    }\n    if (env.hasError) throw env.error;\n  }\n  return next();\n}\n\nexport default {\n  __extends,\n  __assign,\n  __rest,\n  __decorate,\n  __param,\n  __metadata,\n  __awaiter,\n  __generator,\n  __createBinding,\n  __exportStar,\n  __values,\n  __read,\n  __spread,\n  __spreadArrays,\n  __spreadArray,\n  __await,\n  __asyncGenerator,\n  __asyncDelegator,\n  __asyncValues,\n  __makeTemplateObject,\n  __importStar,\n  __importDefault,\n  __classPrivateFieldGet,\n  __classPrivateFieldSet,\n  __classPrivateFieldIn,\n  __addDisposableResource,\n  __disposeResources,\n};\n","function _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n// === Symbol Support ===\nvar hasSymbols = function () {\n  return typeof Symbol === 'function';\n};\n\nvar hasSymbol = function (name) {\n  return hasSymbols() && Boolean(Symbol[name]);\n};\n\nvar getSymbol = function (name) {\n  return hasSymbol(name) ? Symbol[name] : '@@' + name;\n};\n\nif (hasSymbols() && !hasSymbol('observable')) {\n  Symbol.observable = Symbol('observable');\n}\n\nvar SymbolIterator = getSymbol('iterator');\nvar SymbolObservable = getSymbol('observable');\nvar SymbolSpecies = getSymbol('species'); // === Abstract Operations ===\n\nfunction getMethod(obj, key) {\n  var value = obj[key];\n  if (value == null) return undefined;\n  if (typeof value !== 'function') throw new TypeError(value + ' is not a function');\n  return value;\n}\n\nfunction getSpecies(obj) {\n  var ctor = obj.constructor;\n\n  if (ctor !== undefined) {\n    ctor = ctor[SymbolSpecies];\n\n    if (ctor === null) {\n      ctor = undefined;\n    }\n  }\n\n  return ctor !== undefined ? ctor : Observable;\n}\n\nfunction isObservable(x) {\n  return x instanceof Observable; // SPEC: Brand check\n}\n\nfunction hostReportError(e) {\n  if (hostReportError.log) {\n    hostReportError.log(e);\n  } else {\n    setTimeout(function () {\n      throw e;\n    });\n  }\n}\n\nfunction enqueue(fn) {\n  Promise.resolve().then(function () {\n    try {\n      fn();\n    } catch (e) {\n      hostReportError(e);\n    }\n  });\n}\n\nfunction cleanupSubscription(subscription) {\n  var cleanup = subscription._cleanup;\n  if (cleanup === undefined) return;\n  subscription._cleanup = undefined;\n\n  if (!cleanup) {\n    return;\n  }\n\n  try {\n    if (typeof cleanup === 'function') {\n      cleanup();\n    } else {\n      var unsubscribe = getMethod(cleanup, 'unsubscribe');\n\n      if (unsubscribe) {\n        unsubscribe.call(cleanup);\n      }\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n}\n\nfunction closeSubscription(subscription) {\n  subscription._observer = undefined;\n  subscription._queue = undefined;\n  subscription._state = 'closed';\n}\n\nfunction flushSubscription(subscription) {\n  var queue = subscription._queue;\n\n  if (!queue) {\n    return;\n  }\n\n  subscription._queue = undefined;\n  subscription._state = 'ready';\n\n  for (var i = 0; i < queue.length; ++i) {\n    notifySubscription(subscription, queue[i].type, queue[i].value);\n    if (subscription._state === 'closed') break;\n  }\n}\n\nfunction notifySubscription(subscription, type, value) {\n  subscription._state = 'running';\n  var observer = subscription._observer;\n\n  try {\n    var m = getMethod(observer, type);\n\n    switch (type) {\n      case 'next':\n        if (m) m.call(observer, value);\n        break;\n\n      case 'error':\n        closeSubscription(subscription);\n        if (m) m.call(observer, value);else throw value;\n        break;\n\n      case 'complete':\n        closeSubscription(subscription);\n        if (m) m.call(observer);\n        break;\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n\n  if (subscription._state === 'closed') cleanupSubscription(subscription);else if (subscription._state === 'running') subscription._state = 'ready';\n}\n\nfunction onNotify(subscription, type, value) {\n  if (subscription._state === 'closed') return;\n\n  if (subscription._state === 'buffering') {\n    subscription._queue.push({\n      type: type,\n      value: value\n    });\n\n    return;\n  }\n\n  if (subscription._state !== 'ready') {\n    subscription._state = 'buffering';\n    subscription._queue = [{\n      type: type,\n      value: value\n    }];\n    enqueue(function () {\n      return flushSubscription(subscription);\n    });\n    return;\n  }\n\n  notifySubscription(subscription, type, value);\n}\n\nvar Subscription = /*#__PURE__*/function () {\n  function Subscription(observer, subscriber) {\n    // ASSERT: observer is an object\n    // ASSERT: subscriber is callable\n    this._cleanup = undefined;\n    this._observer = observer;\n    this._queue = undefined;\n    this._state = 'initializing';\n    var subscriptionObserver = new SubscriptionObserver(this);\n\n    try {\n      this._cleanup = subscriber.call(undefined, subscriptionObserver);\n    } catch (e) {\n      subscriptionObserver.error(e);\n    }\n\n    if (this._state === 'initializing') this._state = 'ready';\n  }\n\n  var _proto = Subscription.prototype;\n\n  _proto.unsubscribe = function unsubscribe() {\n    if (this._state !== 'closed') {\n      closeSubscription(this);\n      cleanupSubscription(this);\n    }\n  };\n\n  _createClass(Subscription, [{\n    key: \"closed\",\n    get: function () {\n      return this._state === 'closed';\n    }\n  }]);\n\n  return Subscription;\n}();\n\nvar SubscriptionObserver = /*#__PURE__*/function () {\n  function SubscriptionObserver(subscription) {\n    this._subscription = subscription;\n  }\n\n  var _proto2 = SubscriptionObserver.prototype;\n\n  _proto2.next = function next(value) {\n    onNotify(this._subscription, 'next', value);\n  };\n\n  _proto2.error = function error(value) {\n    onNotify(this._subscription, 'error', value);\n  };\n\n  _proto2.complete = function complete() {\n    onNotify(this._subscription, 'complete');\n  };\n\n  _createClass(SubscriptionObserver, [{\n    key: \"closed\",\n    get: function () {\n      return this._subscription._state === 'closed';\n    }\n  }]);\n\n  return SubscriptionObserver;\n}();\n\nvar Observable = /*#__PURE__*/function () {\n  function Observable(subscriber) {\n    if (!(this instanceof Observable)) throw new TypeError('Observable cannot be called as a function');\n    if (typeof subscriber !== 'function') throw new TypeError('Observable initializer must be a function');\n    this._subscriber = subscriber;\n  }\n\n  var _proto3 = Observable.prototype;\n\n  _proto3.subscribe = function subscribe(observer) {\n    if (typeof observer !== 'object' || observer === null) {\n      observer = {\n        next: observer,\n        error: arguments[1],\n        complete: arguments[2]\n      };\n    }\n\n    return new Subscription(observer, this._subscriber);\n  };\n\n  _proto3.forEach = function forEach(fn) {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      if (typeof fn !== 'function') {\n        reject(new TypeError(fn + ' is not a function'));\n        return;\n      }\n\n      function done() {\n        subscription.unsubscribe();\n        resolve();\n      }\n\n      var subscription = _this.subscribe({\n        next: function (value) {\n          try {\n            fn(value, done);\n          } catch (e) {\n            reject(e);\n            subscription.unsubscribe();\n          }\n        },\n        error: reject,\n        complete: resolve\n      });\n    });\n  };\n\n  _proto3.map = function map(fn) {\n    var _this2 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this2.subscribe({\n        next: function (value) {\n          try {\n            value = fn(value);\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.filter = function filter(fn) {\n    var _this3 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this3.subscribe({\n        next: function (value) {\n          try {\n            if (!fn(value)) return;\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.reduce = function reduce(fn) {\n    var _this4 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    var hasSeed = arguments.length > 1;\n    var hasValue = false;\n    var seed = arguments[1];\n    var acc = seed;\n    return new C(function (observer) {\n      return _this4.subscribe({\n        next: function (value) {\n          var first = !hasValue;\n          hasValue = true;\n\n          if (!first || hasSeed) {\n            try {\n              acc = fn(acc, value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          } else {\n            acc = value;\n          }\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          if (!hasValue && !hasSeed) return observer.error(new TypeError('Cannot reduce an empty sequence'));\n          observer.next(acc);\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.concat = function concat() {\n    var _this5 = this;\n\n    for (var _len = arguments.length, sources = new Array(_len), _key = 0; _key < _len; _key++) {\n      sources[_key] = arguments[_key];\n    }\n\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscription;\n      var index = 0;\n\n      function startNext(next) {\n        subscription = next.subscribe({\n          next: function (v) {\n            observer.next(v);\n          },\n          error: function (e) {\n            observer.error(e);\n          },\n          complete: function () {\n            if (index === sources.length) {\n              subscription = undefined;\n              observer.complete();\n            } else {\n              startNext(C.from(sources[index++]));\n            }\n          }\n        });\n      }\n\n      startNext(_this5);\n      return function () {\n        if (subscription) {\n          subscription.unsubscribe();\n          subscription = undefined;\n        }\n      };\n    });\n  };\n\n  _proto3.flatMap = function flatMap(fn) {\n    var _this6 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscriptions = [];\n\n      var outer = _this6.subscribe({\n        next: function (value) {\n          if (fn) {\n            try {\n              value = fn(value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          }\n\n          var inner = C.from(value).subscribe({\n            next: function (value) {\n              observer.next(value);\n            },\n            error: function (e) {\n              observer.error(e);\n            },\n            complete: function () {\n              var i = subscriptions.indexOf(inner);\n              if (i >= 0) subscriptions.splice(i, 1);\n              completeIfDone();\n            }\n          });\n          subscriptions.push(inner);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          completeIfDone();\n        }\n      });\n\n      function completeIfDone() {\n        if (outer.closed && subscriptions.length === 0) observer.complete();\n      }\n\n      return function () {\n        subscriptions.forEach(function (s) {\n          return s.unsubscribe();\n        });\n        outer.unsubscribe();\n      };\n    });\n  };\n\n  _proto3[SymbolObservable] = function () {\n    return this;\n  };\n\n  Observable.from = function from(x) {\n    var C = typeof this === 'function' ? this : Observable;\n    if (x == null) throw new TypeError(x + ' is not an object');\n    var method = getMethod(x, SymbolObservable);\n\n    if (method) {\n      var observable = method.call(x);\n      if (Object(observable) !== observable) throw new TypeError(observable + ' is not an object');\n      if (isObservable(observable) && observable.constructor === C) return observable;\n      return new C(function (observer) {\n        return observable.subscribe(observer);\n      });\n    }\n\n    if (hasSymbol('iterator')) {\n      method = getMethod(x, SymbolIterator);\n\n      if (method) {\n        return new C(function (observer) {\n          enqueue(function () {\n            if (observer.closed) return;\n\n            for (var _iterator = _createForOfIteratorHelperLoose(method.call(x)), _step; !(_step = _iterator()).done;) {\n              var item = _step.value;\n              observer.next(item);\n              if (observer.closed) return;\n            }\n\n            observer.complete();\n          });\n        });\n      }\n    }\n\n    if (Array.isArray(x)) {\n      return new C(function (observer) {\n        enqueue(function () {\n          if (observer.closed) return;\n\n          for (var i = 0; i < x.length; ++i) {\n            observer.next(x[i]);\n            if (observer.closed) return;\n          }\n\n          observer.complete();\n        });\n      });\n    }\n\n    throw new TypeError(x + ' is not observable');\n  };\n\n  Observable.of = function of() {\n    for (var _len2 = arguments.length, items = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      items[_key2] = arguments[_key2];\n    }\n\n    var C = typeof this === 'function' ? this : Observable;\n    return new C(function (observer) {\n      enqueue(function () {\n        if (observer.closed) return;\n\n        for (var i = 0; i < items.length; ++i) {\n          observer.next(items[i]);\n          if (observer.closed) return;\n        }\n\n        observer.complete();\n      });\n    });\n  };\n\n  _createClass(Observable, null, [{\n    key: SymbolSpecies,\n    get: function () {\n      return this;\n    }\n  }]);\n\n  return Observable;\n}();\n\nif (hasSymbols()) {\n  Object.defineProperty(Observable, Symbol('extensions'), {\n    value: {\n      symbol: SymbolObservable,\n      hostReportError: hostReportError\n    },\n    configurable: true\n  });\n}\n\nexport { Observable };\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.nmd = function(module) {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","__webpack_require__.p = \"/decidim-packs/\";","import \"src/decidim/elections/admin/vote_statistics\";\nimport \"src/decidim/elections/admin/trustees_process\";\nimport \"src/decidim/elections/admin/pending_action\";\n\n// Images\nrequire.context(\"../images\", true)\n"],"names":[],"sourceRoot":""}